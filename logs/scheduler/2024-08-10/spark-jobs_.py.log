[2024-08-10T00:00:01.642+0000] {processor.py:157} INFO - Started process (PID=13731) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:00:01.643+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:00:01.647+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:00:01.647+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:00:01.664+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:00:01.684+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:00:01.684+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:00:01.694+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:00:01.694+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:00:01.702+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-10T00:00:32.021+0000] {processor.py:157} INFO - Started process (PID=13741) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:00:32.022+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:00:32.024+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:00:32.024+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:00:32.035+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:00:32.055+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:00:32.055+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:00:32.068+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:00:32.068+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:00:32.078+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-10T00:01:02.341+0000] {processor.py:157} INFO - Started process (PID=13751) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:01:02.342+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:01:02.344+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:01:02.344+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:01:02.354+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:01:02.371+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:01:02.371+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:01:02.382+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:01:02.382+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:01:02.391+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-10T00:01:32.656+0000] {processor.py:157} INFO - Started process (PID=13761) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:01:32.658+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:01:32.660+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:01:32.660+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:01:32.671+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:01:32.689+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:01:32.689+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:01:32.702+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:01:32.702+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:01:32.712+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-10T00:02:03.028+0000] {processor.py:157} INFO - Started process (PID=13771) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:02:03.029+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:02:03.031+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:02:03.031+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:02:03.046+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:02:03.064+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:02:03.064+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:02:03.075+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:02:03.075+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:02:03.084+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-10T00:02:33.412+0000] {processor.py:157} INFO - Started process (PID=13781) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:02:33.413+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:02:33.415+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:02:33.415+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:02:33.425+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:02:33.444+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:02:33.444+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:02:33.456+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:02:33.456+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:02:33.466+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-10T00:03:03.762+0000] {processor.py:157} INFO - Started process (PID=13791) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:03:03.763+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:03:03.765+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:03:03.764+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:03:03.781+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:03:03.795+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:03:03.795+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:03:03.805+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:03:03.805+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:03:03.814+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-10T00:03:34.063+0000] {processor.py:157} INFO - Started process (PID=13801) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:03:34.064+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:03:34.065+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:03:34.065+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:03:34.077+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:03:34.094+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:03:34.094+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:03:34.105+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:03:34.105+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:03:34.113+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-10T00:04:04.432+0000] {processor.py:157} INFO - Started process (PID=13811) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:04:04.433+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:04:04.435+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:04:04.435+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:04:04.447+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:04:04.464+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:04:04.464+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:04:04.475+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:04:04.475+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:04:04.486+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-10T00:04:34.817+0000] {processor.py:157} INFO - Started process (PID=13821) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:04:34.819+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:04:34.820+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:04:34.820+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:04:34.836+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:04:34.852+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:04:34.852+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:04:34.865+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:04:34.864+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:04:34.873+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-10T00:05:05.217+0000] {processor.py:157} INFO - Started process (PID=13831) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:05:05.221+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:05:05.224+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:05:05.224+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:05:05.237+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:05:05.255+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:05:05.255+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:05:05.266+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:05:05.266+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:05:05.274+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-10T00:05:35.521+0000] {processor.py:157} INFO - Started process (PID=13841) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:05:35.522+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:05:35.525+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:05:35.524+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:05:35.546+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:05:35.566+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:05:35.566+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:05:35.576+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:05:35.576+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:05:35.584+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-10T00:06:05.857+0000] {processor.py:157} INFO - Started process (PID=13851) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:06:05.859+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:06:05.862+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:06:05.861+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:06:05.874+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:06:05.892+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:06:05.891+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:06:05.904+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:06:05.904+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:06:05.913+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-10T00:06:36.150+0000] {processor.py:157} INFO - Started process (PID=13861) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:06:36.152+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:06:36.154+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:06:36.154+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:06:36.168+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:06:36.184+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:06:36.183+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:06:36.195+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:06:36.195+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:06:36.204+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-10T00:07:06.521+0000] {processor.py:157} INFO - Started process (PID=13871) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:07:06.524+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:07:06.535+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:07:06.533+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:07:06.572+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:07:06.596+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:07:06.596+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:07:06.613+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:07:06.613+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:07:06.629+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-08-10T00:07:36.835+0000] {processor.py:157} INFO - Started process (PID=13881) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:07:36.840+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:07:36.848+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:07:36.848+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:07:36.869+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:07:36.898+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:07:36.898+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:07:36.914+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:07:36.914+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:07:36.924+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-08-10T00:08:07.128+0000] {processor.py:157} INFO - Started process (PID=13891) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:08:07.129+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:08:07.131+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:08:07.131+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:08:07.145+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:08:07.160+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:08:07.160+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:08:07.172+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:08:07.172+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:08:07.180+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-10T00:08:37.520+0000] {processor.py:157} INFO - Started process (PID=13901) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:08:37.522+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:08:37.530+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:08:37.529+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:08:37.556+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:08:37.591+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:08:37.591+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:08:37.608+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:08:37.608+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:08:37.620+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-08-10T00:09:07.853+0000] {processor.py:157} INFO - Started process (PID=13911) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:09:07.854+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:09:07.857+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:09:07.857+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:09:07.866+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:09:07.881+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:09:07.881+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:09:07.892+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:09:07.892+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:09:07.901+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-10T00:09:38.237+0000] {processor.py:157} INFO - Started process (PID=13921) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:09:38.239+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:09:38.242+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:09:38.242+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:09:38.259+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:09:38.278+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:09:38.278+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:09:38.290+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:09:38.290+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:09:38.299+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-10T00:10:08.605+0000] {processor.py:157} INFO - Started process (PID=13931) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:10:08.607+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:10:08.609+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:10:08.608+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:10:08.620+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:10:08.636+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:10:08.636+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:10:08.648+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:10:08.648+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:10:08.658+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-10T00:10:38.913+0000] {processor.py:157} INFO - Started process (PID=13941) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:10:38.914+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:10:38.916+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:10:38.916+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:10:38.926+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:10:38.944+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:10:38.944+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:10:38.956+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:10:38.956+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:10:38.965+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-10T00:11:09.272+0000] {processor.py:157} INFO - Started process (PID=13951) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:11:09.272+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:11:09.274+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:11:09.274+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:11:09.287+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:11:09.302+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:11:09.302+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:11:09.313+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:11:09.313+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:11:09.322+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-10T00:11:39.650+0000] {processor.py:157} INFO - Started process (PID=13961) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:11:39.652+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:11:39.654+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:11:39.653+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:11:39.669+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:11:39.685+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:11:39.685+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:11:39.696+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:11:39.696+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:11:39.706+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-10T00:12:10.002+0000] {processor.py:157} INFO - Started process (PID=13971) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:12:10.003+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:12:10.006+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:12:10.006+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:12:10.022+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:12:10.043+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:12:10.043+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:12:10.056+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:12:10.056+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:12:10.067+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-10T00:12:40.351+0000] {processor.py:157} INFO - Started process (PID=13981) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:12:40.352+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:12:40.353+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:12:40.353+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:12:40.367+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:12:40.382+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:12:40.382+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:12:40.393+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:12:40.393+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:12:40.403+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-10T00:13:10.701+0000] {processor.py:157} INFO - Started process (PID=13991) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:13:10.702+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:13:10.703+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:13:10.703+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:13:10.714+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:13:10.731+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:13:10.731+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:13:10.743+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:13:10.743+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:13:10.754+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-10T00:13:41.096+0000] {processor.py:157} INFO - Started process (PID=14001) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:13:41.097+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:13:41.099+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:13:41.098+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:13:41.109+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:13:41.128+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:13:41.128+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:13:41.139+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:13:41.139+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:13:41.146+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-10T00:14:11.457+0000] {processor.py:157} INFO - Started process (PID=14011) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:14:11.459+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:14:11.460+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:14:11.460+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:14:11.471+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:14:11.489+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:14:11.488+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:14:11.501+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:14:11.501+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:14:11.510+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-10T00:14:41.842+0000] {processor.py:157} INFO - Started process (PID=14021) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:14:41.845+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:14:41.850+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:14:41.849+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:14:41.866+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:14:41.889+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:14:41.889+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:14:41.902+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:14:41.902+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:14:41.911+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-10T00:15:12.181+0000] {processor.py:157} INFO - Started process (PID=14031) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:15:12.183+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:15:12.185+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:15:12.185+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:15:12.194+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:15:12.212+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:15:12.212+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:15:12.222+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:15:12.222+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:15:12.231+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-10T00:15:42.480+0000] {processor.py:157} INFO - Started process (PID=14041) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:15:42.482+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:15:42.485+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:15:42.485+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:15:42.499+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:15:42.514+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:15:42.514+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:15:42.526+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:15:42.526+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:15:42.535+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-10T00:16:12.853+0000] {processor.py:157} INFO - Started process (PID=14049) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:16:12.857+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:16:12.861+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:16:12.861+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:16:12.893+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:16:12.920+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:16:12.920+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:16:12.934+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:16:12.933+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:16:12.944+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-08-10T00:16:43.229+0000] {processor.py:157} INFO - Started process (PID=14061) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:16:43.230+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:16:43.233+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:16:43.232+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:16:43.243+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:16:43.260+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:16:43.260+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:16:43.272+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:16:43.272+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:16:43.281+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-10T00:17:13.577+0000] {processor.py:157} INFO - Started process (PID=14071) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:17:13.578+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:17:13.580+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:17:13.580+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:17:13.592+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:17:13.607+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:17:13.607+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:17:13.620+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:17:13.620+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:17:13.630+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-10T00:17:43.915+0000] {processor.py:157} INFO - Started process (PID=14081) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:17:43.918+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:17:43.921+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:17:43.921+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:17:43.933+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:17:43.949+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:17:43.949+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:17:43.959+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:17:43.959+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:17:43.966+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-10T00:18:14.190+0000] {processor.py:157} INFO - Started process (PID=14091) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:18:14.191+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:18:14.193+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:18:14.192+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:18:14.210+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:18:14.226+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:18:14.226+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:18:14.241+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:18:14.241+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:18:14.250+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-10T00:18:44.503+0000] {processor.py:157} INFO - Started process (PID=14101) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:18:44.504+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:18:44.505+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:18:44.505+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:18:44.515+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:18:44.532+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:18:44.532+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:18:44.543+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:18:44.543+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:18:44.551+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-10T00:19:14.875+0000] {processor.py:157} INFO - Started process (PID=14111) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:19:14.876+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:19:14.877+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:19:14.877+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:19:14.888+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:19:14.906+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:19:14.906+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:19:14.918+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:19:14.918+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:19:14.927+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-10T00:19:45.287+0000] {processor.py:157} INFO - Started process (PID=14121) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:19:45.288+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:19:45.290+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:19:45.289+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:19:45.301+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:19:45.317+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:19:45.317+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:19:45.327+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:19:45.327+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:19:45.337+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-10T00:20:15.677+0000] {processor.py:157} INFO - Started process (PID=14130) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:20:15.678+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:20:15.681+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:20:15.681+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:20:15.700+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:20:15.725+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:20:15.725+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:20:15.748+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:20:15.747+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:20:15.758+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-08-10T00:20:46.113+0000] {processor.py:157} INFO - Started process (PID=14141) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:20:46.114+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:20:46.116+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:20:46.116+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:20:46.128+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:20:46.143+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:20:46.143+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:20:46.152+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:20:46.152+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:20:46.161+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-10T00:21:16.421+0000] {processor.py:157} INFO - Started process (PID=14151) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:21:16.422+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:21:16.424+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:21:16.424+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:21:16.435+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:21:16.452+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:21:16.452+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:21:16.462+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:21:16.461+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:21:16.470+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-10T00:21:46.786+0000] {processor.py:157} INFO - Started process (PID=14161) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:21:46.788+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:21:46.791+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:21:46.790+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:21:46.806+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:21:46.827+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:21:46.827+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:21:46.842+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:21:46.842+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:21:46.853+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-10T00:22:17.196+0000] {processor.py:157} INFO - Started process (PID=14171) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:22:17.198+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:22:17.200+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:22:17.200+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:22:17.212+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:22:17.229+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:22:17.229+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:22:17.242+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:22:17.242+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:22:17.252+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-10T00:22:47.553+0000] {processor.py:157} INFO - Started process (PID=14181) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:22:47.553+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:22:47.556+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:22:47.556+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:22:47.566+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:22:47.582+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:22:47.582+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:22:47.594+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:22:47.594+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:22:47.605+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-10T00:23:17.864+0000] {processor.py:157} INFO - Started process (PID=14191) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:23:17.867+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:23:17.869+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:23:17.869+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:23:17.880+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:23:17.898+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:23:17.898+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:23:17.910+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:23:17.910+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:23:17.919+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-10T00:23:48.214+0000] {processor.py:157} INFO - Started process (PID=14201) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:23:48.217+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:23:48.220+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:23:48.219+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:23:48.234+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:23:48.255+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:23:48.255+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:23:48.267+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:23:48.267+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:23:48.276+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-10T00:24:18.600+0000] {processor.py:157} INFO - Started process (PID=14211) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:24:18.601+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:24:18.603+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:24:18.603+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:24:18.614+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:24:18.631+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:24:18.631+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:24:18.642+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:24:18.642+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:24:18.651+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-10T00:24:48.908+0000] {processor.py:157} INFO - Started process (PID=14221) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:24:48.909+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:24:48.911+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:24:48.911+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:24:48.920+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:24:48.940+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:24:48.939+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:24:48.952+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:24:48.952+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:24:48.960+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-10T00:25:19.307+0000] {processor.py:157} INFO - Started process (PID=14231) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:25:19.308+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:25:19.309+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:25:19.309+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:25:19.321+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:25:19.337+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:25:19.337+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:25:19.350+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:25:19.350+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:25:19.359+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-10T00:25:49.668+0000] {processor.py:157} INFO - Started process (PID=14241) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:25:49.669+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:25:49.671+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:25:49.671+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:25:49.683+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:25:49.701+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:25:49.701+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:25:49.714+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:25:49.714+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:25:49.722+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-10T00:26:20.021+0000] {processor.py:157} INFO - Started process (PID=14251) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:26:20.022+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:26:20.024+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:26:20.023+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:26:20.039+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:26:20.053+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:26:20.053+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:26:20.065+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:26:20.065+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:26:20.074+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-10T00:26:50.409+0000] {processor.py:157} INFO - Started process (PID=14260) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:26:50.411+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:26:50.415+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:26:50.415+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:26:50.451+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:26:50.476+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:26:50.476+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:26:50.490+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:26:50.490+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:26:50.500+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-08-10T00:27:20.731+0000] {processor.py:157} INFO - Started process (PID=14271) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:27:20.732+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:27:20.733+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:27:20.733+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:27:20.748+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:27:20.762+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:27:20.762+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:27:20.774+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:27:20.774+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:27:20.784+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-10T00:27:51.059+0000] {processor.py:157} INFO - Started process (PID=14281) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:27:51.060+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:27:51.062+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:27:51.062+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:27:51.072+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:27:51.089+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:27:51.089+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:27:51.099+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:27:51.099+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:27:51.108+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-10T00:28:21.452+0000] {processor.py:157} INFO - Started process (PID=14291) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:28:21.455+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:28:21.458+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:28:21.457+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:28:21.471+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:28:21.489+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:28:21.489+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:28:21.500+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:28:21.500+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:28:21.510+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-10T00:28:51.822+0000] {processor.py:157} INFO - Started process (PID=14301) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:28:51.823+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:28:51.825+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:28:51.825+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:28:51.837+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:28:51.853+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:28:51.853+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:28:51.863+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:28:51.863+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:28:51.874+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-10T00:29:22.131+0000] {processor.py:157} INFO - Started process (PID=14311) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:29:22.133+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:29:22.135+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:29:22.135+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:29:22.151+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:29:22.171+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:29:22.171+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:29:22.183+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:29:22.182+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:29:22.192+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-10T00:29:52.503+0000] {processor.py:157} INFO - Started process (PID=14321) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:29:52.504+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:29:52.506+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:29:52.506+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:29:52.515+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:29:52.532+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:29:52.532+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:29:52.542+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:29:52.542+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:29:52.550+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-10T00:30:22.795+0000] {processor.py:157} INFO - Started process (PID=14933) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:30:22.801+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:30:22.810+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:30:22.810+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:30:22.826+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:30:22.847+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:30:22.847+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:30:22.878+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:30:22.878+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:30:22.888+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-08-10T00:30:53.188+0000] {processor.py:157} INFO - Started process (PID=14943) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:30:53.189+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:30:53.192+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:30:53.192+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:30:53.202+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:30:53.222+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:30:53.222+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:30:53.236+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:30:53.236+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:30:53.260+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-08-10T00:31:23.600+0000] {processor.py:157} INFO - Started process (PID=14953) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:31:23.601+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:31:23.605+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:31:23.604+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:31:23.619+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:31:23.640+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:31:23.640+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:31:23.665+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:31:23.665+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:31:23.683+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-08-10T00:31:54.014+0000] {processor.py:157} INFO - Started process (PID=14963) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:31:54.016+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:31:54.019+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:31:54.019+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:31:54.035+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:31:54.069+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:31:54.069+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:31:54.085+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:31:54.085+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:31:54.096+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-08-10T00:32:24.354+0000] {processor.py:157} INFO - Started process (PID=15140) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:32:24.356+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:32:24.359+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:32:24.359+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:32:24.372+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:32:24.403+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:32:24.403+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:32:24.420+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:32:24.419+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:32:24.430+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-08-10T00:32:54.772+0000] {processor.py:157} INFO - Started process (PID=15150) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:32:54.774+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:32:54.778+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:32:54.778+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:32:54.791+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:32:54.813+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:32:54.813+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:32:54.829+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:32:54.829+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:32:54.841+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-10T00:33:25.099+0000] {processor.py:157} INFO - Started process (PID=15160) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:33:25.100+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:33:25.101+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:33:25.101+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:33:25.114+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:33:25.130+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:33:25.130+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:33:25.147+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:33:25.147+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:33:25.163+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-10T00:33:55.476+0000] {processor.py:157} INFO - Started process (PID=15170) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:33:55.479+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:33:55.481+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:33:55.481+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:33:55.494+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:33:55.513+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:33:55.513+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:33:55.525+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:33:55.525+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:33:55.533+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-10T00:34:25.920+0000] {processor.py:157} INFO - Started process (PID=15180) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:34:25.922+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:34:25.926+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:34:25.926+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:34:25.947+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:34:25.987+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:34:25.987+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:34:26.017+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:34:26.016+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:34:26.030+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-08-10T00:34:56.219+0000] {processor.py:157} INFO - Started process (PID=15190) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:34:56.220+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:34:56.223+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:34:56.223+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:34:56.236+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:34:56.254+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:34:56.254+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:34:56.274+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:34:56.273+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:34:56.284+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-10T00:35:26.560+0000] {processor.py:157} INFO - Started process (PID=15200) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:35:26.562+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:35:26.564+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:35:26.563+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:35:26.574+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:35:26.589+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:35:26.589+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:35:26.601+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:35:26.601+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:35:26.611+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-10T00:35:56.897+0000] {processor.py:157} INFO - Started process (PID=15210) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:35:56.899+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:35:56.901+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:35:56.901+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:35:56.915+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:35:56.939+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:35:56.939+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:35:56.954+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:35:56.954+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:35:56.962+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-10T00:36:27.272+0000] {processor.py:157} INFO - Started process (PID=15220) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:36:27.276+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:36:27.279+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:36:27.279+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:36:27.289+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:36:27.305+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:36:27.305+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:36:27.321+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:36:27.321+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:36:27.331+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-10T00:36:57.613+0000] {processor.py:157} INFO - Started process (PID=15230) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:36:57.614+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:36:57.617+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:36:57.616+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:36:57.633+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:36:57.649+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:36:57.649+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:36:57.662+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:36:57.662+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:36:57.672+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-10T00:37:27.981+0000] {processor.py:157} INFO - Started process (PID=15240) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:37:27.982+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:37:27.985+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:37:27.985+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:37:28.000+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:37:28.024+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:37:28.023+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:37:28.049+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:37:28.049+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:37:28.061+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-08-10T00:37:58.394+0000] {processor.py:157} INFO - Started process (PID=15250) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:37:58.394+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:37:58.397+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:37:58.397+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:37:58.411+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:37:58.430+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:37:58.430+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:37:58.450+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:37:58.450+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:37:58.461+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-10T00:38:28.784+0000] {processor.py:157} INFO - Started process (PID=15260) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:38:28.785+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:38:28.787+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:38:28.786+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:38:28.796+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:38:28.814+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:38:28.814+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:38:28.824+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:38:28.824+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:38:28.832+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-10T00:38:59.137+0000] {processor.py:157} INFO - Started process (PID=15270) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:38:59.139+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:38:59.141+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:38:59.141+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:38:59.149+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:38:59.165+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:38:59.165+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:38:59.175+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:38:59.175+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:38:59.184+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-10T00:39:29.516+0000] {processor.py:157} INFO - Started process (PID=15280) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:39:29.517+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:39:29.519+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:39:29.519+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:39:29.530+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:39:29.547+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:39:29.547+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:39:29.559+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:39:29.559+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:39:29.569+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-10T00:39:59.877+0000] {processor.py:157} INFO - Started process (PID=15290) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:39:59.877+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:39:59.879+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:39:59.879+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:39:59.888+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:39:59.906+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:39:59.906+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:39:59.917+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:39:59.917+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:39:59.926+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-10T00:40:30.264+0000] {processor.py:157} INFO - Started process (PID=15300) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:40:30.267+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:40:30.270+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:40:30.270+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:40:30.285+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:40:30.308+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:40:30.307+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:40:30.322+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:40:30.322+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:40:30.331+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-10T00:41:00.536+0000] {processor.py:157} INFO - Started process (PID=15310) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:41:00.537+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:41:00.539+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:41:00.539+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:41:00.555+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:41:00.570+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:41:00.570+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:41:00.584+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:41:00.584+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:41:00.593+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-10T00:41:30.865+0000] {processor.py:157} INFO - Started process (PID=15320) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:41:30.866+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:41:30.868+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:41:30.868+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:41:30.877+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:41:30.896+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:41:30.896+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:41:30.909+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:41:30.909+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:41:30.919+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-10T00:42:01.243+0000] {processor.py:157} INFO - Started process (PID=15330) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:42:01.243+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:42:01.245+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:42:01.244+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:42:01.256+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:42:01.272+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:42:01.272+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:42:01.285+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:42:01.285+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:42:01.294+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-10T00:42:31.598+0000] {processor.py:157} INFO - Started process (PID=15340) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:42:31.599+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:42:31.600+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:42:31.600+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:42:31.614+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:42:31.630+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:42:31.630+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:42:31.640+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:42:31.639+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:42:31.650+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-10T00:43:01.857+0000] {processor.py:157} INFO - Started process (PID=15350) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:43:01.859+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:43:01.861+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:43:01.860+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:43:01.871+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:43:01.889+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:43:01.888+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:43:01.902+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:43:01.902+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:43:01.912+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-10T00:43:32.241+0000] {processor.py:157} INFO - Started process (PID=15360) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:43:32.242+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:43:32.243+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:43:32.243+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:43:32.258+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:43:32.272+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:43:32.272+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:43:32.284+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:43:32.283+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:43:32.294+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-10T00:44:02.622+0000] {processor.py:157} INFO - Started process (PID=15370) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:44:02.625+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:44:02.626+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:44:02.626+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:44:02.639+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:44:02.658+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:44:02.658+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:44:02.672+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:44:02.672+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:44:02.680+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-10T00:44:32.967+0000] {processor.py:157} INFO - Started process (PID=15380) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:44:32.969+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:44:32.971+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:44:32.970+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:44:32.981+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:44:32.997+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:44:32.997+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:44:33.008+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:44:33.008+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:44:33.018+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-10T00:45:03.342+0000] {processor.py:157} INFO - Started process (PID=15390) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:45:03.343+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:45:03.345+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:45:03.345+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:45:03.355+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:45:03.373+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:45:03.373+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:45:03.386+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:45:03.386+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:45:03.395+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-10T00:45:33.715+0000] {processor.py:157} INFO - Started process (PID=15400) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:45:33.716+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:45:33.718+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:45:33.718+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:45:33.728+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:45:33.745+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:45:33.745+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:45:33.756+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:45:33.756+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:45:33.766+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-10T00:46:03.992+0000] {processor.py:157} INFO - Started process (PID=15410) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:46:03.992+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:46:03.994+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:46:03.994+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:46:04.008+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:46:04.022+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:46:04.022+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:46:04.035+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:46:04.035+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:46:04.044+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-10T00:46:34.382+0000] {processor.py:157} INFO - Started process (PID=15420) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:46:34.383+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:46:34.384+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:46:34.384+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:46:34.396+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:46:34.411+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:46:34.411+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:46:34.420+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:46:34.420+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:46:34.430+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-10T00:47:04.703+0000] {processor.py:157} INFO - Started process (PID=15430) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:47:04.705+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:47:04.708+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:47:04.708+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:47:04.721+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:47:04.742+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:47:04.742+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:47:04.755+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:47:04.755+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:47:04.765+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-10T00:47:35.033+0000] {processor.py:157} INFO - Started process (PID=15440) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:47:35.033+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:47:35.035+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:47:35.035+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:47:35.043+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:47:35.063+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:47:35.063+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:47:35.075+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:47:35.075+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:47:35.083+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-10T00:48:05.371+0000] {processor.py:157} INFO - Started process (PID=15450) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:48:05.372+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:48:05.374+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:48:05.374+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:48:05.385+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:48:05.402+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:48:05.402+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:48:05.415+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:48:05.415+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:48:05.425+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-10T00:48:35.734+0000] {processor.py:157} INFO - Started process (PID=15460) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:48:35.735+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:48:35.737+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:48:35.737+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:48:35.752+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:48:35.770+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:48:35.770+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:48:35.781+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:48:35.781+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:48:35.790+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-10T00:49:06.092+0000] {processor.py:157} INFO - Started process (PID=15470) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:49:06.096+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:49:06.099+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:49:06.099+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:49:06.110+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:49:06.128+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:49:06.128+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:49:06.139+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:49:06.139+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:49:06.147+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-10T00:49:36.485+0000] {processor.py:157} INFO - Started process (PID=15480) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:49:36.487+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:49:36.488+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:49:36.488+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:49:36.499+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:49:36.518+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:49:36.517+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:49:36.529+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:49:36.529+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:49:36.538+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-10T00:50:06.863+0000] {processor.py:157} INFO - Started process (PID=15490) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:50:06.864+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:50:06.866+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:50:06.866+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:50:06.877+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:50:06.893+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:50:06.893+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:50:06.905+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:50:06.905+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:50:06.915+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-10T00:50:37.164+0000] {processor.py:157} INFO - Started process (PID=15500) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:50:37.166+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:50:37.167+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:50:37.167+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:50:37.176+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:50:37.192+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:50:37.192+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:50:37.203+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:50:37.203+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:50:37.212+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-10T00:51:07.538+0000] {processor.py:157} INFO - Started process (PID=15510) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:51:07.539+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:51:07.541+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:51:07.540+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:51:07.552+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:51:07.570+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:51:07.570+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:51:07.583+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:51:07.583+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:51:07.593+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-10T00:51:37.902+0000] {processor.py:157} INFO - Started process (PID=15520) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:51:37.903+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:51:37.905+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:51:37.904+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:51:37.919+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:51:37.936+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:51:37.936+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:51:37.947+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:51:37.947+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:51:37.953+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-10T00:52:08.190+0000] {processor.py:157} INFO - Started process (PID=15530) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:52:08.191+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:52:08.192+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:52:08.192+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:52:08.206+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:52:08.220+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:52:08.220+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:52:08.231+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:52:08.231+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:52:08.237+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-10T00:52:38.542+0000] {processor.py:157} INFO - Started process (PID=15540) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:52:38.544+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:52:38.545+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:52:38.545+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:52:38.558+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:52:38.577+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:52:38.577+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:52:38.586+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:52:38.586+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:52:38.595+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-10T00:53:08.880+0000] {processor.py:157} INFO - Started process (PID=15550) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:53:08.882+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:53:08.883+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:53:08.883+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:53:08.895+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:53:08.916+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:53:08.916+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:53:08.933+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:53:08.933+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:53:08.943+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-10T00:53:39.211+0000] {processor.py:157} INFO - Started process (PID=15560) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:53:39.211+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:53:39.213+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:53:39.213+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:53:39.224+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:53:39.241+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:53:39.241+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:53:39.251+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:53:39.250+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:53:39.260+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-10T00:54:09.457+0000] {processor.py:157} INFO - Started process (PID=15570) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:54:09.458+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:54:09.460+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:54:09.460+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:54:09.476+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:54:09.494+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:54:09.494+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:54:09.507+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:54:09.507+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:54:09.518+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-10T00:54:39.822+0000] {processor.py:157} INFO - Started process (PID=15580) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:54:39.824+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:54:39.826+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:54:39.826+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:54:39.838+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:54:39.857+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:54:39.857+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:54:39.868+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:54:39.868+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:54:39.877+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-10T00:55:10.194+0000] {processor.py:157} INFO - Started process (PID=15590) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:55:10.195+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:55:10.197+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:55:10.196+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:55:10.206+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:55:10.223+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:55:10.223+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:55:10.234+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:55:10.234+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:55:10.247+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-10T00:55:40.509+0000] {processor.py:157} INFO - Started process (PID=15600) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:55:40.510+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:55:40.512+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:55:40.512+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:55:40.520+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:55:40.539+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:55:40.539+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:55:40.549+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:55:40.549+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:55:40.558+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-10T00:56:10.882+0000] {processor.py:157} INFO - Started process (PID=15610) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:56:10.883+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:56:10.885+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:56:10.884+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:56:10.896+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:56:10.912+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:56:10.912+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:56:10.924+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:56:10.924+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:56:10.933+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-10T00:56:41.250+0000] {processor.py:157} INFO - Started process (PID=15620) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:56:41.252+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:56:41.254+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:56:41.254+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:56:41.264+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:56:41.281+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:56:41.281+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:56:41.294+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:56:41.294+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:56:41.301+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-10T00:57:11.599+0000] {processor.py:157} INFO - Started process (PID=15630) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:57:11.601+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:57:11.603+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:57:11.603+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:57:11.613+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:57:11.634+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:57:11.634+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:57:11.643+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:57:11.643+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:57:11.652+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-10T00:57:41.918+0000] {processor.py:157} INFO - Started process (PID=15640) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:57:41.919+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:57:41.923+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:57:41.923+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:57:41.936+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:57:41.958+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:57:41.958+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:57:41.971+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:57:41.971+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:57:41.981+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-10T00:58:12.256+0000] {processor.py:157} INFO - Started process (PID=15650) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:58:12.257+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:58:12.260+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:58:12.260+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:58:12.270+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:58:12.289+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:58:12.288+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:58:12.302+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:58:12.302+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:58:12.314+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-10T00:58:42.611+0000] {processor.py:157} INFO - Started process (PID=15660) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:58:42.612+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:58:42.615+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:58:42.615+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:58:42.626+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:58:42.645+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:58:42.645+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:58:42.655+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:58:42.655+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:58:42.662+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-10T00:59:12.974+0000] {processor.py:157} INFO - Started process (PID=15670) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:59:12.976+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:59:12.977+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:59:12.977+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:59:12.987+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:59:13.004+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:59:13.004+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:59:13.015+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:59:13.014+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:59:13.024+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-10T00:59:43.333+0000] {processor.py:157} INFO - Started process (PID=15680) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:59:43.334+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T00:59:43.335+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:59:43.335+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:59:43.348+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T00:59:43.368+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:59:43.368+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T00:59:43.378+0000] {logging_mixin.py:151} INFO - [2024-08-10T00:59:43.378+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T00:59:43.387+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-10T01:00:13.664+0000] {processor.py:157} INFO - Started process (PID=15690) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:00:13.665+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:00:13.667+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:00:13.667+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:00:13.682+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:00:13.699+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:00:13.699+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:00:13.712+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:00:13.712+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:00:13.723+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-10T01:00:44.013+0000] {processor.py:157} INFO - Started process (PID=15700) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:00:44.014+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:00:44.016+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:00:44.016+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:00:44.026+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:00:44.043+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:00:44.043+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:00:44.056+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:00:44.055+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:00:44.065+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-10T01:01:14.353+0000] {processor.py:157} INFO - Started process (PID=15710) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:01:14.354+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:01:14.356+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:01:14.356+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:01:14.367+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:01:14.384+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:01:14.384+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:01:14.394+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:01:14.394+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:01:14.404+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-10T01:01:44.687+0000] {processor.py:157} INFO - Started process (PID=15720) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:01:44.688+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:01:44.689+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:01:44.689+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:01:44.697+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:01:44.714+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:01:44.714+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:01:44.723+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:01:44.723+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:01:44.730+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-08-10T01:02:15.052+0000] {processor.py:157} INFO - Started process (PID=15730) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:02:15.053+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:02:15.055+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:02:15.055+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:02:15.071+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:02:15.094+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:02:15.094+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:02:15.108+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:02:15.108+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:02:15.122+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-10T01:02:45.389+0000] {processor.py:157} INFO - Started process (PID=15740) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:02:45.392+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:02:45.394+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:02:45.394+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:02:45.411+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:02:45.429+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:02:45.429+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:02:45.441+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:02:45.441+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:02:45.450+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-10T01:03:15.762+0000] {processor.py:157} INFO - Started process (PID=15750) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:03:15.763+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:03:15.765+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:03:15.764+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:03:15.781+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:03:15.797+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:03:15.797+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:03:15.806+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:03:15.806+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:03:15.817+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-10T01:03:46.115+0000] {processor.py:157} INFO - Started process (PID=15760) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:03:46.116+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:03:46.118+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:03:46.118+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:03:46.129+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:03:46.146+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:03:46.146+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:03:46.158+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:03:46.158+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:03:46.166+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-10T01:04:16.488+0000] {processor.py:157} INFO - Started process (PID=15770) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:04:16.489+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:04:16.493+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:04:16.493+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:04:16.505+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:04:16.528+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:04:16.528+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:04:16.545+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:04:16.545+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:04:16.556+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-10T01:04:46.879+0000] {processor.py:157} INFO - Started process (PID=15780) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:04:46.880+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:04:46.882+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:04:46.882+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:04:46.894+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:04:46.912+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:04:46.912+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:04:46.925+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:04:46.925+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:04:46.935+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-10T01:05:17.236+0000] {processor.py:157} INFO - Started process (PID=15790) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:05:17.237+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:05:17.240+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:05:17.239+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:05:17.249+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:05:17.267+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:05:17.267+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:05:17.279+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:05:17.279+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:05:17.287+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-10T01:05:47.540+0000] {processor.py:157} INFO - Started process (PID=15800) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:05:47.542+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:05:47.544+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:05:47.544+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:05:47.554+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:05:47.571+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:05:47.571+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:05:47.581+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:05:47.581+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:05:47.590+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-10T01:06:17.867+0000] {processor.py:157} INFO - Started process (PID=15810) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:06:17.868+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:06:17.870+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:06:17.870+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:06:17.882+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:06:17.898+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:06:17.898+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:06:17.908+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:06:17.908+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:06:17.916+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-10T01:06:48.254+0000] {processor.py:157} INFO - Started process (PID=15820) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:06:48.256+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:06:48.258+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:06:48.258+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:06:48.271+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:06:48.295+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:06:48.295+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:06:48.310+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:06:48.310+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:06:48.321+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-10T01:07:18.579+0000] {processor.py:157} INFO - Started process (PID=15830) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:07:18.580+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:07:18.582+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:07:18.582+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:07:18.596+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:07:18.617+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:07:18.617+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:07:18.628+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:07:18.628+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:07:18.638+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-10T01:07:48.948+0000] {processor.py:157} INFO - Started process (PID=15840) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:07:48.950+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:07:48.952+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:07:48.952+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:07:48.967+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:07:48.992+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:07:48.992+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:07:49.006+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:07:49.006+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:07:49.015+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-10T01:08:19.337+0000] {processor.py:157} INFO - Started process (PID=15850) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:08:19.337+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:08:19.339+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:08:19.339+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:08:19.347+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:08:19.366+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:08:19.366+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:08:19.376+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:08:19.376+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:08:19.383+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-08-10T01:08:49.698+0000] {processor.py:157} INFO - Started process (PID=15860) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:08:49.699+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:08:49.700+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:08:49.700+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:08:49.710+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:08:49.727+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:08:49.727+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:08:49.737+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:08:49.737+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:08:49.746+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-10T01:09:19.992+0000] {processor.py:157} INFO - Started process (PID=15870) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:09:19.993+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:09:19.995+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:09:19.995+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:09:20.008+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:09:20.027+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:09:20.027+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:09:20.040+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:09:20.040+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:09:20.050+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-10T01:09:50.391+0000] {processor.py:157} INFO - Started process (PID=15880) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:09:50.396+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:09:50.400+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:09:50.399+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:09:50.412+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:09:50.431+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:09:50.431+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:09:50.442+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:09:50.442+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:09:50.453+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-10T01:10:20.711+0000] {processor.py:157} INFO - Started process (PID=15890) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:10:20.712+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:10:20.717+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:10:20.717+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:10:20.740+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:10:20.773+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:10:20.773+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:10:20.791+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:10:20.790+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:10:20.806+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-08-10T01:10:51.019+0000] {processor.py:157} INFO - Started process (PID=15900) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:10:51.020+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:10:51.022+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:10:51.022+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:10:51.032+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:10:51.052+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:10:51.052+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:10:51.065+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:10:51.065+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:10:51.074+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-10T01:11:21.373+0000] {processor.py:157} INFO - Started process (PID=15910) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:11:21.374+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:11:21.375+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:11:21.375+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:11:21.391+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:11:21.408+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:11:21.407+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:11:21.420+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:11:21.420+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:11:21.428+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-10T01:11:51.727+0000] {processor.py:157} INFO - Started process (PID=15920) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:11:51.728+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:11:51.730+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:11:51.730+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:11:51.739+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:11:51.757+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:11:51.757+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:11:51.766+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:11:51.766+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:11:51.775+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-10T01:12:22.109+0000] {processor.py:157} INFO - Started process (PID=15930) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:12:22.111+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:12:22.113+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:12:22.112+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:12:22.124+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:12:22.139+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:12:22.139+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:12:22.149+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:12:22.149+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:12:22.160+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-10T01:12:52.499+0000] {processor.py:157} INFO - Started process (PID=15940) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:12:52.500+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:12:52.502+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:12:52.502+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:12:52.513+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:12:52.532+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:12:52.532+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:12:52.543+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:12:52.543+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:12:52.552+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-10T01:13:22.854+0000] {processor.py:157} INFO - Started process (PID=15950) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:13:22.856+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:13:22.860+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:13:22.859+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:13:22.874+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:13:22.897+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:13:22.897+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:13:22.911+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:13:22.910+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:13:22.921+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-10T01:13:53.149+0000] {processor.py:157} INFO - Started process (PID=15960) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:13:53.150+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:13:53.152+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:13:53.151+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:13:53.164+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:13:53.182+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:13:53.182+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:13:53.196+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:13:53.196+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:13:53.204+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-10T01:14:23.483+0000] {processor.py:157} INFO - Started process (PID=15970) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:14:23.485+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:14:23.487+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:14:23.487+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:14:23.499+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:14:23.517+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:14:23.517+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:14:23.530+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:14:23.529+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:14:23.538+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-10T01:14:53.868+0000] {processor.py:157} INFO - Started process (PID=15980) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:14:53.869+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:14:53.871+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:14:53.871+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:14:53.882+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:14:53.899+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:14:53.899+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:14:53.909+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:14:53.909+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:14:53.919+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-10T01:15:24.212+0000] {processor.py:157} INFO - Started process (PID=15990) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:15:24.213+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:15:24.215+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:15:24.215+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:15:24.230+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:15:24.248+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:15:24.247+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:15:24.262+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:15:24.262+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:15:24.271+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-10T01:15:54.494+0000] {processor.py:157} INFO - Started process (PID=16000) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:15:54.495+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:15:54.499+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:15:54.499+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:15:54.515+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:15:54.535+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:15:54.535+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:15:54.547+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:15:54.547+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:15:54.555+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-10T01:16:24.816+0000] {processor.py:157} INFO - Started process (PID=16010) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:16:24.817+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:16:24.819+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:16:24.819+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:16:24.833+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:16:24.850+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:16:24.850+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:16:24.865+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:16:24.865+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:16:24.873+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-10T01:16:55.225+0000] {processor.py:157} INFO - Started process (PID=16020) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:16:55.226+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:16:55.228+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:16:55.227+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:16:55.248+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:16:55.288+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:16:55.288+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:16:55.309+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:16:55.309+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:16:55.320+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-08-10T01:17:25.533+0000] {processor.py:157} INFO - Started process (PID=16030) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:17:25.535+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:17:25.538+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:17:25.538+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:17:25.556+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:17:25.580+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:17:25.580+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:17:25.593+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:17:25.593+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:17:25.602+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-10T01:17:55.837+0000] {processor.py:157} INFO - Started process (PID=16040) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:17:55.838+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:17:55.840+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:17:55.839+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:17:55.850+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:17:55.869+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:17:55.869+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:17:55.881+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:17:55.881+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:17:55.891+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-10T01:18:26.219+0000] {processor.py:157} INFO - Started process (PID=16050) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:18:26.222+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:18:26.225+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:18:26.225+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:18:26.238+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:18:26.259+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:18:26.259+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:18:26.274+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:18:26.274+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:18:26.284+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-10T01:18:56.595+0000] {processor.py:157} INFO - Started process (PID=16060) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:18:56.596+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:18:56.597+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:18:56.597+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:18:56.609+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:18:56.627+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:18:56.627+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:18:56.638+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:18:56.638+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:18:56.647+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-10T01:19:26.994+0000] {processor.py:157} INFO - Started process (PID=16070) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:19:26.996+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:19:26.999+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:19:26.999+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:19:27.015+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:19:27.040+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:19:27.040+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:19:27.062+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:19:27.062+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:19:27.079+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-10T01:19:57.326+0000] {processor.py:157} INFO - Started process (PID=16080) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:19:57.328+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:19:57.330+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:19:57.330+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:19:57.342+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:19:57.361+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:19:57.361+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:19:57.373+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:19:57.373+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:19:57.382+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-10T01:20:27.682+0000] {processor.py:157} INFO - Started process (PID=16090) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:20:27.686+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:20:27.689+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:20:27.689+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:20:27.707+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:20:27.733+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:20:27.733+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:20:27.748+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:20:27.748+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:20:27.759+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-08-10T01:20:57.981+0000] {processor.py:157} INFO - Started process (PID=16100) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:20:57.982+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:20:57.985+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:20:57.985+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:20:57.997+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:20:58.019+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:20:58.019+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:20:58.035+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:20:58.035+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:20:58.044+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-10T01:21:28.409+0000] {processor.py:157} INFO - Started process (PID=16110) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:21:28.412+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:21:28.416+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:21:28.415+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:21:28.433+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:21:28.457+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:21:28.457+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:21:28.487+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:21:28.487+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:21:28.499+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-08-10T01:21:58.802+0000] {processor.py:157} INFO - Started process (PID=16120) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:21:58.804+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:21:58.809+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:21:58.808+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:21:58.822+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:21:58.849+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:21:58.848+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:21:58.866+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:21:58.866+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:21:58.876+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-08-10T01:22:29.136+0000] {processor.py:157} INFO - Started process (PID=16130) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:22:29.140+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:22:29.143+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:22:29.143+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:22:29.159+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:22:29.179+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:22:29.178+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:22:29.193+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:22:29.192+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:22:29.200+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-10T01:22:59.519+0000] {processor.py:157} INFO - Started process (PID=16140) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:22:59.523+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:22:59.525+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:22:59.525+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:22:59.538+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:22:59.555+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:22:59.555+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:22:59.567+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:22:59.567+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:22:59.577+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-10T01:23:29.890+0000] {processor.py:157} INFO - Started process (PID=16150) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:23:29.891+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:23:29.893+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:23:29.892+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:23:29.907+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:23:29.925+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:23:29.925+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:23:29.940+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:23:29.939+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:23:29.950+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-10T01:24:00.272+0000] {processor.py:157} INFO - Started process (PID=16160) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:24:00.274+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:24:00.275+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:24:00.275+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:24:00.290+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:24:00.310+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:24:00.310+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:24:00.322+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:24:00.322+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:24:00.332+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-10T01:24:30.658+0000] {processor.py:157} INFO - Started process (PID=16170) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:24:30.659+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:24:30.660+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:24:30.660+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:24:30.677+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:24:30.693+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:24:30.693+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:24:30.707+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:24:30.707+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:24:30.719+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-10T01:25:01.029+0000] {processor.py:157} INFO - Started process (PID=16180) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:25:01.030+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:25:01.031+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:25:01.031+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:25:01.041+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:25:01.060+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:25:01.060+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:25:01.069+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:25:01.069+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:25:01.078+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-10T01:25:31.434+0000] {processor.py:157} INFO - Started process (PID=16190) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:25:31.436+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:25:31.438+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:25:31.438+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:25:31.454+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:25:31.476+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:25:31.476+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:25:31.488+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:25:31.488+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:25:31.497+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-10T01:26:01.795+0000] {processor.py:157} INFO - Started process (PID=16200) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:26:01.796+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:26:01.799+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:26:01.798+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:26:01.817+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:26:01.832+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:26:01.832+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:26:01.842+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:26:01.842+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:26:01.853+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-10T01:26:32.142+0000] {processor.py:157} INFO - Started process (PID=16210) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:26:32.143+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:26:32.145+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:26:32.145+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:26:32.156+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:26:32.178+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:26:32.177+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:26:32.188+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:26:32.188+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:26:32.197+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-10T01:27:02.527+0000] {processor.py:157} INFO - Started process (PID=16220) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:27:02.528+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:27:02.530+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:27:02.530+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:27:02.541+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:27:02.559+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:27:02.559+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:27:02.574+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:27:02.574+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:27:02.583+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-10T01:27:32.900+0000] {processor.py:157} INFO - Started process (PID=16230) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:27:32.902+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:27:32.905+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:27:32.904+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:27:32.919+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:27:32.941+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:27:32.941+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:27:32.953+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:27:32.953+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:27:32.963+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-10T01:28:03.222+0000] {processor.py:157} INFO - Started process (PID=16240) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:28:03.223+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:28:03.224+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:28:03.224+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:28:03.237+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:28:03.256+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:28:03.256+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:28:03.266+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:28:03.266+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:28:03.275+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-10T01:28:33.609+0000] {processor.py:157} INFO - Started process (PID=16250) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:28:33.610+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:28:33.612+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:28:33.611+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:28:33.624+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:28:33.652+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:28:33.652+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:28:33.663+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:28:33.663+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:28:33.673+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-10T01:29:03.983+0000] {processor.py:157} INFO - Started process (PID=16260) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:29:03.984+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:29:03.986+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:29:03.986+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:29:03.996+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:29:04.017+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:29:04.017+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:29:04.030+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:29:04.030+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:29:04.041+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-10T01:29:34.321+0000] {processor.py:157} INFO - Started process (PID=16270) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:29:34.322+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:29:34.325+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:29:34.324+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:29:34.341+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:29:34.356+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:29:34.356+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:29:34.367+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:29:34.367+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:29:34.379+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-10T01:30:04.724+0000] {processor.py:157} INFO - Started process (PID=16280) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:30:04.726+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:30:04.730+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:30:04.729+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:30:04.748+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:30:04.767+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:30:04.767+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:30:04.781+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:30:04.780+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:30:04.789+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-10T01:30:35.087+0000] {processor.py:157} INFO - Started process (PID=16290) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:30:35.088+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:30:35.091+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:30:35.091+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:30:35.101+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:30:35.128+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:30:35.128+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:30:35.148+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:30:35.148+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:30:35.159+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-08-10T01:31:05.400+0000] {processor.py:157} INFO - Started process (PID=16300) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:31:05.401+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:31:05.403+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:31:05.403+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:31:05.416+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:31:05.434+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:31:05.434+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:31:05.446+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:31:05.446+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:31:05.457+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-10T01:31:35.784+0000] {processor.py:157} INFO - Started process (PID=16310) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:31:35.785+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:31:35.788+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:31:35.788+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:31:35.804+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:31:35.819+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:31:35.819+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:31:35.829+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:31:35.829+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:31:35.838+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-10T01:32:06.169+0000] {processor.py:157} INFO - Started process (PID=16320) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:32:06.170+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:32:06.172+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:32:06.172+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:32:06.184+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:32:06.203+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:32:06.203+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:32:06.214+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:32:06.213+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:32:06.222+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-10T01:32:36.540+0000] {processor.py:157} INFO - Started process (PID=16330) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:32:36.542+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:32:36.543+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:32:36.543+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:32:36.554+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:32:36.572+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:32:36.572+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:32:36.585+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:32:36.585+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:32:36.597+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-10T01:33:06.921+0000] {processor.py:157} INFO - Started process (PID=16340) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:33:06.923+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:33:06.925+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:33:06.925+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:33:06.935+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:33:06.952+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:33:06.952+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:33:06.962+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:33:06.962+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:33:06.972+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-10T01:33:37.262+0000] {processor.py:157} INFO - Started process (PID=16350) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:33:37.263+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:33:37.264+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:33:37.264+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:33:37.275+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:33:37.290+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:33:37.290+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:33:37.300+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:33:37.300+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:33:37.307+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-08-10T01:34:07.703+0000] {processor.py:157} INFO - Started process (PID=16360) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:34:07.705+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:34:07.708+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:34:07.708+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:34:07.730+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:34:07.778+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:34:07.778+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:34:07.800+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:34:07.800+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:34:07.813+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-08-10T01:34:38.058+0000] {processor.py:157} INFO - Started process (PID=16370) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:34:38.060+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:34:38.062+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:34:38.061+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:34:38.078+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:34:38.106+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:34:38.106+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:34:38.122+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:34:38.121+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:34:38.134+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-08-10T01:35:08.152+0000] {processor.py:157} INFO - Started process (PID=16380) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:35:08.153+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:35:08.154+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:35:08.154+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:35:08.164+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:35:08.182+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:35:08.182+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:35:08.196+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:35:08.196+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:35:08.205+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-10T01:35:38.718+0000] {processor.py:157} INFO - Started process (PID=16390) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:35:38.721+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:35:38.729+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:35:38.729+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:35:38.766+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:35:38.816+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:35:38.816+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:35:38.842+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:35:38.842+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:35:38.859+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.147 seconds
[2024-08-10T01:37:17.440+0000] {processor.py:157} INFO - Started process (PID=16400) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:37:17.447+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:37:17.449+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:37:17.449+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:37:17.458+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:37:17.473+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:37:17.473+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:37:17.484+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:37:17.484+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:37:17.493+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-10T01:37:47.781+0000] {processor.py:157} INFO - Started process (PID=16412) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:37:47.784+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:37:47.786+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:37:47.786+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:37:47.803+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:37:47.827+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:37:47.827+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:37:47.842+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:37:47.842+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:37:47.854+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-08-10T01:38:23.534+0000] {processor.py:157} INFO - Started process (PID=16422) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:38:23.535+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:38:23.537+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:38:23.537+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:38:23.553+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:38:23.574+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:38:23.574+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:38:23.584+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:38:23.584+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:38:23.593+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-10T01:38:53.903+0000] {processor.py:157} INFO - Started process (PID=16432) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:38:53.908+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:38:53.912+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:38:53.911+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:38:53.929+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:38:53.953+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:38:53.953+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:38:53.967+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:38:53.967+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:38:53.979+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-08-10T01:41:59.380+0000] {processor.py:157} INFO - Started process (PID=16442) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:41:59.388+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:41:59.395+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:41:59.395+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:41:59.420+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:41:59.467+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:41:59.467+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:41:59.489+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:41:59.488+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:41:59.505+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-08-10T01:42:29.746+0000] {processor.py:157} INFO - Started process (PID=16454) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:42:29.752+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:42:29.765+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:42:29.764+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:42:29.808+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:42:29.894+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:42:29.894+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:42:29.933+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:42:29.932+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:42:29.957+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.219 seconds
[2024-08-10T01:43:00.087+0000] {processor.py:157} INFO - Started process (PID=16464) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:43:00.090+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:43:00.094+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:43:00.094+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:43:00.116+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:43:00.162+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:43:00.162+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:43:00.189+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:43:00.189+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:43:00.209+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-08-10T01:43:30.540+0000] {processor.py:157} INFO - Started process (PID=16473) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:43:30.547+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:43:30.551+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:43:30.551+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:43:30.570+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:43:30.614+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:43:30.614+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:43:30.633+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:43:30.633+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:43:30.645+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-08-10T01:44:00.881+0000] {processor.py:157} INFO - Started process (PID=16484) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:44:00.887+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:44:00.890+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:44:00.890+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:44:00.906+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:44:00.945+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:44:00.944+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:44:00.963+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:44:00.963+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:44:00.975+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-08-10T01:44:31.200+0000] {processor.py:157} INFO - Started process (PID=16494) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:44:31.203+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:44:31.206+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:44:31.206+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:44:31.223+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:44:31.262+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:44:31.262+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:44:31.279+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:44:31.279+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:44:31.292+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-08-10T01:45:01.522+0000] {processor.py:157} INFO - Started process (PID=16504) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:45:01.525+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:45:01.529+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:45:01.529+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:45:01.560+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:45:01.604+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:45:01.604+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:45:01.621+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:45:01.621+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:45:01.638+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-08-10T01:45:31.822+0000] {processor.py:157} INFO - Started process (PID=16514) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:45:31.825+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:45:31.828+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:45:31.828+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:45:31.844+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:45:31.873+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:45:31.873+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:45:31.890+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:45:31.890+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:45:31.901+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-08-10T01:46:02.110+0000] {processor.py:157} INFO - Started process (PID=16524) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:46:02.112+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:46:02.116+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:46:02.116+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:46:02.134+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:46:02.161+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:46:02.161+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:46:02.177+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:46:02.177+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:46:02.189+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-08-10T01:46:32.368+0000] {processor.py:157} INFO - Started process (PID=16534) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:46:32.369+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:46:32.371+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:46:32.371+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:46:32.387+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:46:32.403+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:46:32.403+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:46:32.415+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:46:32.415+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:46:32.423+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-10T01:47:02.772+0000] {processor.py:157} INFO - Started process (PID=16544) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:47:02.773+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:47:02.776+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:47:02.776+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:47:02.794+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:47:02.824+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:47:02.824+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:47:02.845+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:47:02.845+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:47:02.859+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-08-10T01:47:33.049+0000] {processor.py:157} INFO - Started process (PID=16554) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:47:33.050+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:47:33.052+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:47:33.051+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:47:33.064+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:47:33.084+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:47:33.084+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:47:33.094+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:47:33.094+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:47:33.104+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-10T01:48:03.426+0000] {processor.py:157} INFO - Started process (PID=16563) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:48:03.428+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:48:03.430+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:48:03.430+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:48:03.448+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:48:03.476+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:48:03.476+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:48:03.496+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:48:03.496+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:48:03.508+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-08-10T01:48:33.805+0000] {processor.py:157} INFO - Started process (PID=16574) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:48:33.807+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:48:33.809+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:48:33.809+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:48:33.823+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:48:33.840+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:48:33.840+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:48:33.851+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:48:33.851+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:48:33.862+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-10T01:49:04.158+0000] {processor.py:157} INFO - Started process (PID=16584) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:49:04.159+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:49:04.163+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:49:04.162+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:49:04.194+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:49:04.225+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:49:04.225+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:49:04.244+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:49:04.244+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:49:04.258+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-08-10T01:49:34.583+0000] {processor.py:157} INFO - Started process (PID=16594) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:49:34.584+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:49:34.586+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:49:34.586+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:49:34.597+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:49:34.616+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:49:34.616+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:49:34.629+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:49:34.629+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:49:34.639+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-10T01:50:04.972+0000] {processor.py:157} INFO - Started process (PID=16603) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:50:04.974+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:50:04.977+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:50:04.977+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:50:04.993+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:50:05.029+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:50:05.029+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:50:05.049+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:50:05.049+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:50:05.060+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-08-10T01:50:35.252+0000] {processor.py:157} INFO - Started process (PID=16614) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:50:35.252+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:50:35.256+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:50:35.256+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:50:35.276+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:50:35.302+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:50:35.302+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:50:35.314+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:50:35.313+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:50:35.322+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-10T01:51:05.690+0000] {processor.py:157} INFO - Started process (PID=16624) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:51:05.691+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:51:05.697+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:51:05.697+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:51:05.715+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:51:05.754+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:51:05.754+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:51:05.781+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:51:05.781+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:51:05.793+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-08-10T01:51:36.115+0000] {processor.py:157} INFO - Started process (PID=16634) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:51:36.118+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:51:36.120+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:51:36.120+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:51:36.139+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:51:36.186+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:51:36.185+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:51:36.202+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:51:36.201+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:51:36.216+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-08-10T01:52:06.558+0000] {processor.py:157} INFO - Started process (PID=16644) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:52:06.565+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:52:06.585+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:52:06.584+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:52:06.604+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:52:06.651+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:52:06.650+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:52:06.669+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:52:06.669+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:52:06.679+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-08-10T01:52:37.029+0000] {processor.py:157} INFO - Started process (PID=16654) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:52:37.031+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:52:37.038+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:52:37.038+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:52:37.068+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:52:37.109+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:52:37.109+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:52:37.136+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:52:37.135+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:52:37.164+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.141 seconds
[2024-08-10T01:53:07.271+0000] {processor.py:157} INFO - Started process (PID=16664) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:53:07.275+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:53:07.276+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:53:07.276+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:53:07.283+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:53:07.300+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:53:07.300+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:53:07.309+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:53:07.309+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:53:07.319+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-10T01:53:37.606+0000] {processor.py:157} INFO - Started process (PID=16674) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:53:37.608+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:53:37.610+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:53:37.609+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:53:37.620+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:53:37.639+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:53:37.639+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:53:37.649+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:53:37.649+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:53:37.657+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-10T01:54:07.986+0000] {processor.py:157} INFO - Started process (PID=16684) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:54:07.990+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:54:07.996+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:54:07.995+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:54:08.018+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:54:08.053+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:54:08.053+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:54:08.077+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:54:08.077+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:54:08.088+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-08-10T01:54:38.295+0000] {processor.py:157} INFO - Started process (PID=16694) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:54:38.302+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:54:38.320+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:54:38.314+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:54:38.342+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:54:38.383+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:54:38.383+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:54:38.404+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:54:38.404+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:54:38.416+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-08-10T01:55:08.690+0000] {processor.py:157} INFO - Started process (PID=16704) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:55:08.692+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:55:08.694+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:55:08.694+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:55:08.706+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:55:08.722+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:55:08.722+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:55:08.735+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:55:08.735+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:55:08.744+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-10T01:55:38.992+0000] {processor.py:157} INFO - Started process (PID=16714) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:55:38.994+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:55:38.997+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:55:38.996+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:55:39.007+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:55:39.026+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:55:39.026+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:55:39.039+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:55:39.039+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:55:39.046+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-10T01:56:09.293+0000] {processor.py:157} INFO - Started process (PID=16724) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:56:09.297+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:56:09.300+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:56:09.299+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:56:09.313+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:56:09.337+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:56:09.337+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:56:09.352+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:56:09.352+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:56:09.364+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-10T01:56:39.515+0000] {processor.py:157} INFO - Started process (PID=16734) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:56:39.515+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:56:39.517+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:56:39.517+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:56:39.526+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:56:39.543+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:56:39.543+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:56:39.556+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:56:39.556+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:56:39.564+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-10T01:57:09.797+0000] {processor.py:157} INFO - Started process (PID=16744) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:57:09.798+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:57:09.799+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:57:09.799+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:57:09.813+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:57:09.828+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:57:09.828+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:57:09.841+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:57:09.841+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:57:09.850+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-10T01:57:40.133+0000] {processor.py:157} INFO - Started process (PID=16754) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:57:40.134+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:57:40.135+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:57:40.135+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:57:40.148+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:57:40.164+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:57:40.164+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:57:40.174+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:57:40.174+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:57:40.183+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-10T01:58:10.466+0000] {processor.py:157} INFO - Started process (PID=16764) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:58:10.467+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:58:10.469+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:58:10.469+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:58:10.485+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:58:10.508+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:58:10.508+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:58:10.523+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:58:10.523+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:58:10.535+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-10T01:58:40.751+0000] {processor.py:157} INFO - Started process (PID=16774) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:58:40.752+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:58:40.754+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:58:40.754+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:58:40.765+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:58:40.783+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:58:40.783+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:58:40.798+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:58:40.798+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:58:40.807+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-10T01:59:11.112+0000] {processor.py:157} INFO - Started process (PID=16784) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:59:11.114+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:59:11.116+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:59:11.116+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:59:11.131+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:59:11.159+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:59:11.159+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:59:11.178+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:59:11.178+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:59:11.190+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-08-10T01:59:41.357+0000] {processor.py:157} INFO - Started process (PID=16794) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:59:41.359+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T01:59:41.360+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:59:41.360+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:59:41.374+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T01:59:41.398+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:59:41.398+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T01:59:41.410+0000] {logging_mixin.py:151} INFO - [2024-08-10T01:59:41.410+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T01:59:41.420+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-10T02:00:11.651+0000] {processor.py:157} INFO - Started process (PID=16804) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:00:11.656+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:00:11.660+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:00:11.660+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:00:11.681+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:00:11.731+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:00:11.731+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:00:11.761+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:00:11.761+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:00:11.772+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-08-10T02:00:41.955+0000] {processor.py:157} INFO - Started process (PID=16814) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:00:41.958+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:00:41.961+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:00:41.960+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:00:41.982+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:00:42.031+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:00:42.031+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:00:42.054+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:00:42.054+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:00:42.065+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-08-10T02:01:12.417+0000] {processor.py:157} INFO - Started process (PID=16824) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:01:12.419+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:01:12.421+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:01:12.421+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:01:12.441+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:01:12.480+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:01:12.480+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:01:12.502+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:01:12.502+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:01:12.517+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-08-10T02:01:43.008+0000] {processor.py:157} INFO - Started process (PID=16833) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:01:43.010+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:01:43.017+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:01:43.016+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:01:43.044+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:01:43.081+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:01:43.081+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:01:43.101+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:01:43.101+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:01:43.114+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-08-10T02:02:13.392+0000] {processor.py:157} INFO - Started process (PID=16844) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:02:13.394+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:02:13.399+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:02:13.399+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:02:13.419+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:02:13.475+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:02:13.475+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:02:13.493+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:02:13.493+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:02:13.506+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-08-10T02:02:43.666+0000] {processor.py:157} INFO - Started process (PID=16854) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:02:43.670+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:02:43.676+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:02:43.676+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:02:43.701+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:02:43.733+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:02:43.733+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:02:43.753+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:02:43.753+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:02:43.765+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-08-10T02:03:14.088+0000] {processor.py:157} INFO - Started process (PID=16863) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:03:14.090+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:03:14.095+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:03:14.095+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:03:14.118+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:03:14.154+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:03:14.154+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:03:14.173+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:03:14.173+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:03:14.187+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-08-10T02:03:44.430+0000] {processor.py:157} INFO - Started process (PID=16874) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:03:44.432+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:03:44.437+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:03:44.436+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:03:44.462+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:03:44.513+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:03:44.513+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:03:44.535+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:03:44.535+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:03:44.546+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-08-10T02:04:14.714+0000] {processor.py:157} INFO - Started process (PID=16884) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:04:14.719+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:04:14.730+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:04:14.728+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:04:14.761+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:04:14.810+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:04:14.810+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:04:14.829+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:04:14.828+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:04:14.845+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-08-10T02:04:45.054+0000] {processor.py:157} INFO - Started process (PID=16894) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:04:45.061+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:04:45.065+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:04:45.065+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:04:45.088+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:04:45.148+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:04:45.148+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:04:45.167+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:04:45.167+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:04:45.193+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.146 seconds
[2024-08-10T02:05:15.392+0000] {processor.py:157} INFO - Started process (PID=16904) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:05:15.394+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:05:15.398+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:05:15.397+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:05:15.414+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:05:15.438+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:05:15.438+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:05:15.453+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:05:15.453+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:05:15.464+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-08-10T02:05:45.762+0000] {processor.py:157} INFO - Started process (PID=16914) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:05:45.763+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:05:45.766+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:05:45.765+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:05:45.777+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:05:45.799+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:05:45.799+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:05:45.813+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:05:45.813+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:05:45.827+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-10T02:06:16.055+0000] {processor.py:157} INFO - Started process (PID=16924) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:06:16.057+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:06:16.061+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:06:16.061+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:06:16.076+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:06:16.099+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:06:16.098+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:06:16.111+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:06:16.110+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:06:16.120+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-10T02:06:46.423+0000] {processor.py:157} INFO - Started process (PID=16934) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:06:46.425+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:06:46.427+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:06:46.427+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:06:46.442+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:06:46.470+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:06:46.470+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:06:46.486+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:06:46.486+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:06:46.495+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-10T02:07:16.750+0000] {processor.py:157} INFO - Started process (PID=16944) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:07:16.754+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:07:16.757+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:07:16.756+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:07:16.773+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:07:16.793+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:07:16.793+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:07:16.804+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:07:16.804+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:07:16.815+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-10T02:07:47.016+0000] {processor.py:157} INFO - Started process (PID=16954) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:07:47.017+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:07:47.019+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:07:47.019+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:07:47.031+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:07:47.048+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:07:47.048+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:07:47.057+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:07:47.057+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:07:47.066+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-10T02:08:17.409+0000] {processor.py:157} INFO - Started process (PID=16964) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:08:17.411+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:08:17.414+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:08:17.414+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:08:17.435+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:08:17.473+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:08:17.472+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:08:17.490+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:08:17.490+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:08:17.501+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-08-10T02:08:47.780+0000] {processor.py:157} INFO - Started process (PID=16974) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:08:47.783+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:08:47.806+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:08:47.800+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:08:47.842+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:08:47.901+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:08:47.901+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:08:47.929+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:08:47.929+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:08:47.946+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.174 seconds
[2024-08-10T02:09:18.044+0000] {processor.py:157} INFO - Started process (PID=16984) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:09:18.047+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:09:18.049+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:09:18.049+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:09:18.072+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:09:18.112+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:09:18.112+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:09:18.130+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:09:18.130+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:09:18.146+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-08-10T02:09:48.418+0000] {processor.py:157} INFO - Started process (PID=16993) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:09:48.423+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:09:48.426+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:09:48.426+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:09:48.445+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:09:48.475+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:09:48.475+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:09:48.492+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:09:48.492+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:09:48.503+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-08-10T02:10:18.701+0000] {processor.py:157} INFO - Started process (PID=17004) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:10:18.703+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:10:18.706+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:10:18.705+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:10:18.716+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:10:18.732+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:10:18.732+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:10:18.745+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:10:18.745+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:10:18.752+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-10T02:10:49.035+0000] {processor.py:157} INFO - Started process (PID=17014) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:10:49.036+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:10:49.039+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:10:49.039+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:10:49.058+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:10:49.087+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:10:49.086+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:10:49.101+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:10:49.101+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:10:49.110+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-08-10T02:11:19.261+0000] {processor.py:157} INFO - Started process (PID=17024) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:11:19.262+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:11:19.264+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:11:19.263+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:11:19.275+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:11:19.291+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:11:19.291+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:11:19.301+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:11:19.301+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:11:19.310+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-10T02:11:49.626+0000] {processor.py:157} INFO - Started process (PID=17033) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:11:49.627+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:11:49.646+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:11:49.644+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:11:49.668+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:11:49.699+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:11:49.699+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:11:49.731+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:11:49.731+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:11:49.740+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-08-10T02:12:19.951+0000] {processor.py:157} INFO - Started process (PID=17044) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:12:19.956+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:12:19.959+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:12:19.959+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:12:19.967+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:12:19.985+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:12:19.985+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:12:19.997+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:12:19.997+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:12:20.004+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-10T02:12:50.330+0000] {processor.py:157} INFO - Started process (PID=17054) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:12:50.332+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:12:50.335+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:12:50.335+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:12:50.359+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:12:50.398+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:12:50.398+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:12:50.414+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:12:50.414+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:12:50.423+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-08-10T02:13:20.650+0000] {processor.py:157} INFO - Started process (PID=17064) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:13:20.651+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:13:20.653+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:13:20.653+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:13:20.664+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:13:20.682+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:13:20.682+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:13:20.692+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:13:20.692+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:13:20.701+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-10T02:13:51.035+0000] {processor.py:157} INFO - Started process (PID=17074) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:13:51.039+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:13:51.042+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:13:51.042+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:13:51.057+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:13:51.084+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:13:51.084+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:13:51.099+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:13:51.099+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:13:51.108+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-08-10T02:14:21.330+0000] {processor.py:157} INFO - Started process (PID=17084) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:14:21.331+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:14:21.334+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:14:21.333+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:14:21.347+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:14:21.363+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:14:21.363+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:14:21.374+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:14:21.373+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:14:21.382+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-10T02:14:51.677+0000] {processor.py:157} INFO - Started process (PID=17094) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:14:51.678+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:14:51.682+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:14:51.681+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:14:51.699+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:14:51.723+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:14:51.723+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:14:51.737+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:14:51.737+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:14:51.747+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-10T02:15:22.088+0000] {processor.py:157} INFO - Started process (PID=17104) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:15:22.090+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:15:22.093+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:15:22.093+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:15:22.107+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:15:22.125+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:15:22.125+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:15:22.136+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:15:22.136+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:15:22.146+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-10T02:15:52.485+0000] {processor.py:157} INFO - Started process (PID=17113) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:15:52.486+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:15:52.491+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:15:52.490+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:15:52.517+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:15:52.572+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:15:52.572+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:15:52.598+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:15:52.597+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:15:52.613+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-08-10T02:16:22.975+0000] {processor.py:157} INFO - Started process (PID=17124) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:16:22.977+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:16:22.980+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:16:22.980+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:16:22.994+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:16:23.029+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:16:23.029+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:16:23.047+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:16:23.047+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:16:23.058+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-08-10T02:16:53.363+0000] {processor.py:157} INFO - Started process (PID=17134) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:16:53.368+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:16:53.373+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:16:53.373+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:16:53.394+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:16:53.441+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:16:53.441+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:16:53.456+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:16:53.456+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:16:53.467+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-08-10T02:17:23.686+0000] {processor.py:157} INFO - Started process (PID=17144) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:17:23.687+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:17:23.690+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:17:23.689+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:17:23.700+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:17:23.717+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:17:23.717+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:17:23.728+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:17:23.728+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:17:23.738+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-10T02:17:54.023+0000] {processor.py:157} INFO - Started process (PID=17154) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:17:54.026+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:17:54.035+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:17:54.034+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:17:54.057+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:17:54.098+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:17:54.098+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:17:54.114+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:17:54.114+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:17:54.126+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-08-10T02:18:24.311+0000] {processor.py:157} INFO - Started process (PID=17164) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:18:24.313+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:18:24.314+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:18:24.314+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:18:24.325+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:18:24.340+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:18:24.340+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:18:24.350+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:18:24.350+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:18:24.361+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-10T02:18:54.622+0000] {processor.py:157} INFO - Started process (PID=17174) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:18:54.623+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:18:54.627+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:18:54.627+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:18:54.650+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:18:54.700+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:18:54.700+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:18:54.719+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:18:54.719+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:18:54.729+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-08-10T02:19:24.961+0000] {processor.py:157} INFO - Started process (PID=17184) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:19:24.965+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:19:24.967+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:19:24.966+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:19:24.981+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:19:24.999+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:19:24.999+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:19:25.009+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:19:25.009+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:19:25.018+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-10T02:19:55.324+0000] {processor.py:157} INFO - Started process (PID=17194) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:19:55.325+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:19:55.326+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:19:55.326+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:19:55.342+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:19:55.398+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:19:55.398+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:19:55.414+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:19:55.414+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:19:55.425+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-08-10T02:20:25.622+0000] {processor.py:157} INFO - Started process (PID=17204) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:20:25.623+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:20:25.625+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:20:25.625+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:20:25.635+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:20:25.651+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:20:25.651+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:20:25.661+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:20:25.661+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:20:25.670+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-10T02:20:56.045+0000] {processor.py:157} INFO - Started process (PID=17214) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:20:56.048+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:20:56.050+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:20:56.050+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:20:56.081+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:20:56.110+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:20:56.110+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:20:56.138+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:20:56.138+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:20:56.149+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-08-10T02:21:26.448+0000] {processor.py:157} INFO - Started process (PID=17224) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:21:26.448+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:21:26.450+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:21:26.449+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:21:26.460+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:21:26.477+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:21:26.477+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:21:26.489+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:21:26.489+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:21:26.499+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-10T02:21:56.802+0000] {processor.py:157} INFO - Started process (PID=17234) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:21:56.804+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:21:56.807+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:21:56.807+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:21:56.858+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:21:56.889+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:21:56.889+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:21:56.921+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:21:56.921+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:21:56.931+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-08-10T02:22:27.110+0000] {processor.py:157} INFO - Started process (PID=17244) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:22:27.112+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:22:27.128+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:22:27.126+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:22:27.159+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:22:27.190+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:22:27.190+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:22:27.206+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:22:27.205+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:22:27.227+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-08-10T02:22:57.433+0000] {processor.py:157} INFO - Started process (PID=17254) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:22:57.434+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:22:57.437+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:22:57.436+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:22:57.448+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:22:57.465+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:22:57.465+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:22:57.476+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:22:57.476+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:22:57.487+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-10T02:23:27.791+0000] {processor.py:157} INFO - Started process (PID=17264) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:23:27.795+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:23:27.799+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:23:27.799+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:23:27.815+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:23:27.839+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:23:27.839+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:23:27.853+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:23:27.853+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:23:27.863+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-08-10T02:23:58.167+0000] {processor.py:157} INFO - Started process (PID=17274) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:23:58.168+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:23:58.171+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:23:58.171+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:23:58.183+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:23:58.199+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:23:58.199+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:23:58.211+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:23:58.211+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:23:58.226+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-10T02:24:28.544+0000] {processor.py:157} INFO - Started process (PID=17284) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:24:28.545+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:24:28.548+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:24:28.548+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:24:28.562+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:24:28.583+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:24:28.583+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:24:28.595+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:24:28.595+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:24:28.605+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-10T02:24:58.902+0000] {processor.py:157} INFO - Started process (PID=17294) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:24:58.906+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:24:58.910+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:24:58.910+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:24:58.964+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:24:59.014+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:24:59.014+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:24:59.032+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:24:59.032+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:24:59.041+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.145 seconds
[2024-08-10T02:25:29.255+0000] {processor.py:157} INFO - Started process (PID=17304) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:25:29.260+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:25:29.264+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:25:29.264+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:25:29.281+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:25:29.334+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:25:29.334+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:25:29.352+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:25:29.352+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:25:29.362+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-08-10T02:25:59.642+0000] {processor.py:157} INFO - Started process (PID=17314) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:25:59.645+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:25:59.653+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:25:59.652+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:25:59.673+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:25:59.725+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:25:59.725+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:25:59.745+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:25:59.744+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:25:59.755+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-08-10T02:26:29.935+0000] {processor.py:157} INFO - Started process (PID=17324) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:26:29.939+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:26:29.943+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:26:29.943+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:26:29.974+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:26:30.014+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:26:30.014+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:26:30.029+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:26:30.029+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:26:30.039+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-08-10T02:27:00.270+0000] {processor.py:157} INFO - Started process (PID=17334) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:27:00.271+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:27:00.273+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:27:00.273+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:27:00.285+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:27:00.302+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:27:00.302+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:27:00.316+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:27:00.316+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:27:00.324+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-10T02:27:30.637+0000] {processor.py:157} INFO - Started process (PID=17344) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:27:30.638+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:27:30.640+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:27:30.640+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:27:30.653+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:27:30.668+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:27:30.668+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:27:30.680+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:27:30.680+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:27:30.688+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-10T02:28:00.961+0000] {processor.py:157} INFO - Started process (PID=17354) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:28:00.962+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:28:00.964+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:28:00.964+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:28:00.979+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:28:00.997+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:28:00.997+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:28:01.008+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:28:01.008+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:28:01.016+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-10T02:28:31.297+0000] {processor.py:157} INFO - Started process (PID=17364) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:28:31.299+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:28:31.301+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:28:31.300+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:28:31.315+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:28:31.340+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:28:31.340+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:28:31.354+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:28:31.354+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:28:31.363+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-10T02:29:01.664+0000] {processor.py:157} INFO - Started process (PID=17374) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:29:01.665+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:29:01.666+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:29:01.666+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:29:01.679+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:29:01.695+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:29:01.695+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:29:01.707+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:29:01.706+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:29:01.717+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-10T02:29:32.070+0000] {processor.py:157} INFO - Started process (PID=17384) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:29:32.074+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:29:32.098+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:29:32.092+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:29:32.136+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:29:32.203+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:29:32.203+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:29:32.227+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:29:32.227+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:29:32.238+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.175 seconds
[2024-08-10T02:30:02.454+0000] {processor.py:157} INFO - Started process (PID=17394) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:30:02.455+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:30:02.459+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:30:02.458+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:30:02.490+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:30:02.524+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:30:02.524+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:30:02.546+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:30:02.546+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:30:02.562+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-08-10T02:30:32.813+0000] {processor.py:157} INFO - Started process (PID=17404) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:30:32.816+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:30:32.820+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:30:32.820+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:30:32.847+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:30:32.894+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:30:32.894+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:30:32.910+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:30:32.910+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:30:32.923+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-08-10T02:31:03.208+0000] {processor.py:157} INFO - Started process (PID=17414) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:31:03.212+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:31:03.217+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:31:03.216+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:31:03.250+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:31:03.315+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:31:03.315+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:31:03.336+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:31:03.336+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:31:03.351+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.157 seconds
[2024-08-10T02:31:33.613+0000] {processor.py:157} INFO - Started process (PID=17424) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:31:33.617+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:31:33.619+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:31:33.618+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:31:33.648+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:31:33.682+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:31:33.682+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:31:33.705+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:31:33.705+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:31:33.714+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-08-10T02:32:03.913+0000] {processor.py:157} INFO - Started process (PID=17434) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:32:03.915+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:32:03.921+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:32:03.920+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:32:03.940+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:32:03.967+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:32:03.967+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:32:03.982+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:32:03.982+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:32:03.995+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-08-10T02:32:34.189+0000] {processor.py:157} INFO - Started process (PID=17444) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:32:34.192+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:32:34.195+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:32:34.195+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:32:34.212+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:32:34.236+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:32:34.235+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:32:34.247+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:32:34.247+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:32:34.258+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-08-10T02:33:04.484+0000] {processor.py:157} INFO - Started process (PID=17454) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:33:04.489+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:33:04.493+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:33:04.492+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:33:04.528+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:33:04.558+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:33:04.558+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:33:04.573+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:33:04.573+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:33:04.591+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-08-10T02:33:34.770+0000] {processor.py:157} INFO - Started process (PID=17463) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:33:34.783+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:33:34.791+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:33:34.791+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:33:34.811+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:33:34.838+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:33:34.838+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:33:34.852+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:33:34.852+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:33:34.864+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-08-10T02:34:05.165+0000] {processor.py:157} INFO - Started process (PID=17473) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:34:05.173+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:34:05.181+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:34:05.180+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:34:05.197+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:34:05.224+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:34:05.224+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:34:05.240+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:34:05.240+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:34:05.251+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-08-10T02:34:35.684+0000] {processor.py:157} INFO - Started process (PID=17484) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:34:35.690+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:34:35.698+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:34:35.697+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:34:35.734+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:34:35.785+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:34:35.785+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:34:35.805+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:34:35.805+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:34:35.818+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-08-10T02:35:06.048+0000] {processor.py:157} INFO - Started process (PID=17494) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:35:06.050+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:35:06.055+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:35:06.055+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:35:06.078+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:35:06.107+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:35:06.107+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:35:06.121+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:35:06.121+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:35:06.136+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-08-10T02:35:36.482+0000] {processor.py:157} INFO - Started process (PID=17504) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:35:36.483+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:35:36.493+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:35:36.490+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:35:36.520+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:35:36.549+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:35:36.549+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:35:36.563+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:35:36.563+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:35:36.573+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-08-10T02:36:06.845+0000] {processor.py:157} INFO - Started process (PID=17514) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:36:06.848+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:36:06.855+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:36:06.854+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:36:06.886+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:36:06.927+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:36:06.927+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:36:06.950+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:36:06.949+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:36:06.965+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-08-10T02:36:37.264+0000] {processor.py:157} INFO - Started process (PID=17524) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:36:37.267+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:36:37.277+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:36:37.275+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:36:37.302+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:36:37.343+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:36:37.343+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:36:37.362+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:36:37.362+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:36:37.372+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-08-10T02:37:07.693+0000] {processor.py:157} INFO - Started process (PID=17533) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:37:07.695+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:37:07.699+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:37:07.699+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:37:07.720+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:37:07.766+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:37:07.766+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:37:07.783+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:37:07.783+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:37:07.791+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-08-10T02:37:38.124+0000] {processor.py:157} INFO - Started process (PID=17544) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:37:38.126+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:37:38.134+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:37:38.131+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:37:38.170+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:37:38.229+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:37:38.229+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:37:38.250+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:37:38.250+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:37:38.262+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.144 seconds
[2024-08-10T02:38:08.409+0000] {processor.py:157} INFO - Started process (PID=17554) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:38:08.411+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:38:08.413+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:38:08.412+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:38:08.422+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:38:08.440+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:38:08.440+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:38:08.453+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:38:08.453+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:38:08.462+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-10T02:38:38.732+0000] {processor.py:157} INFO - Started process (PID=17564) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:38:38.733+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:38:38.735+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:38:38.735+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:38:38.754+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:38:38.771+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:38:38.771+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:38:38.785+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:38:38.785+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:38:38.798+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-10T02:39:09.071+0000] {processor.py:157} INFO - Started process (PID=17574) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:39:09.073+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:39:09.076+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:39:09.076+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:39:09.093+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:39:09.117+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:39:09.117+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:39:09.130+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:39:09.130+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:39:09.141+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-10T02:39:39.355+0000] {processor.py:157} INFO - Started process (PID=17584) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:39:39.358+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:39:39.361+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:39:39.361+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:39:39.374+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:39:39.393+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:39:39.393+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:39:39.404+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:39:39.404+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:39:39.415+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-10T02:40:09.709+0000] {processor.py:157} INFO - Started process (PID=17594) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:40:09.710+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:40:09.713+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:40:09.713+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:40:09.729+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:40:09.761+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:40:09.761+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:40:09.777+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:40:09.777+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:40:09.788+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-08-10T02:40:39.997+0000] {processor.py:157} INFO - Started process (PID=17604) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:40:39.998+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:40:40.000+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:40:40.000+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:40:40.017+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:40:40.032+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:40:40.032+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:40:40.042+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:40:40.042+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:40:40.052+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-10T02:41:10.326+0000] {processor.py:157} INFO - Started process (PID=17614) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:41:10.327+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:41:10.330+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:41:10.330+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:41:10.349+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:41:10.400+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:41:10.399+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:41:10.415+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:41:10.415+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:41:10.426+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-08-10T02:41:40.742+0000] {processor.py:157} INFO - Started process (PID=17624) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:41:40.745+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:41:40.748+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:41:40.747+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:41:40.761+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:41:40.777+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:41:40.777+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:41:40.788+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:41:40.788+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:41:40.797+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-10T02:42:11.093+0000] {processor.py:157} INFO - Started process (PID=17634) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:42:11.096+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:42:11.101+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:42:11.100+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:42:11.118+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:42:11.143+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:42:11.143+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:42:11.155+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:42:11.155+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:42:11.164+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-08-10T02:42:41.428+0000] {processor.py:157} INFO - Started process (PID=17644) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:42:41.430+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:42:41.433+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:42:41.433+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:42:41.443+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:42:41.462+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:42:41.462+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:42:41.474+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:42:41.474+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:42:41.484+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-10T02:43:11.720+0000] {processor.py:157} INFO - Started process (PID=17654) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:43:11.722+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:43:11.725+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:43:11.725+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:43:11.745+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:43:11.767+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:43:11.767+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:43:11.780+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:43:11.780+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:43:11.792+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-08-10T02:43:41.984+0000] {processor.py:157} INFO - Started process (PID=17664) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:43:41.986+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:43:41.989+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:43:41.989+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:43:42.000+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:43:42.020+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:43:42.020+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:43:42.034+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:43:42.034+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:43:42.043+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-10T02:44:12.326+0000] {processor.py:157} INFO - Started process (PID=17674) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:44:12.328+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:44:12.334+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:44:12.333+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:44:12.361+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:44:12.386+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:44:12.386+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:44:12.400+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:44:12.400+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:44:12.410+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-08-10T02:44:42.630+0000] {processor.py:157} INFO - Started process (PID=17684) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:44:42.633+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:44:42.635+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:44:42.635+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:44:42.644+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:44:42.663+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:44:42.663+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:44:42.672+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:44:42.672+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:44:42.682+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-10T02:45:12.988+0000] {processor.py:157} INFO - Started process (PID=17694) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:45:12.989+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:45:13.008+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:45:13.007+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:45:13.028+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:45:13.061+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:45:13.061+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:45:13.075+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:45:13.075+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:45:13.087+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-08-10T02:45:43.299+0000] {processor.py:157} INFO - Started process (PID=17704) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:45:43.302+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:45:43.304+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:45:43.304+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:45:43.315+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:45:43.331+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:45:43.331+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:45:43.341+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:45:43.341+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:45:43.349+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-10T02:46:13.651+0000] {processor.py:157} INFO - Started process (PID=17714) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:46:13.654+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:46:13.657+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:46:13.656+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:46:13.673+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:46:13.698+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:46:13.698+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:46:13.711+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:46:13.711+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:46:13.721+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-10T02:46:44.050+0000] {processor.py:157} INFO - Started process (PID=17723) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:46:44.051+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:46:44.053+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:46:44.053+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:46:44.063+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:46:44.078+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:46:44.078+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:46:44.088+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:46:44.088+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:46:44.096+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-10T02:47:14.361+0000] {processor.py:157} INFO - Started process (PID=17734) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:47:14.365+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:47:14.367+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:47:14.367+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:47:14.410+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:47:14.446+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:47:14.445+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:47:14.463+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:47:14.463+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:47:14.482+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-08-10T02:47:45.019+0000] {processor.py:157} INFO - Started process (PID=17744) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:47:45.022+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:47:45.026+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:47:45.026+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:47:45.053+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:47:45.088+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:47:45.088+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:47:45.109+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:47:45.109+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:47:45.121+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-08-10T02:48:15.268+0000] {processor.py:157} INFO - Started process (PID=17754) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:48:15.269+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:48:15.271+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:48:15.271+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:48:15.287+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:48:15.301+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:48:15.301+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:48:15.312+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:48:15.312+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:48:15.321+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-10T02:48:45.641+0000] {processor.py:157} INFO - Started process (PID=17764) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:48:45.642+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:48:45.646+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:48:45.645+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:48:45.669+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:48:45.699+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:48:45.699+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:48:45.716+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:48:45.716+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:48:45.727+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-08-10T02:49:15.911+0000] {processor.py:157} INFO - Started process (PID=17774) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:49:15.913+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:49:15.915+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:49:15.914+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:49:15.929+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:49:15.943+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:49:15.943+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:49:15.953+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:49:15.953+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:49:15.963+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-10T02:49:46.308+0000] {processor.py:157} INFO - Started process (PID=17784) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:49:46.309+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:49:46.312+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:49:46.312+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:49:46.357+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:49:46.395+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:49:46.395+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:49:46.412+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:49:46.412+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:49:46.422+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-08-10T02:50:16.559+0000] {processor.py:157} INFO - Started process (PID=17794) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:50:16.559+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:50:16.561+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:50:16.561+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:50:16.572+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:50:16.588+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:50:16.588+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:50:16.601+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:50:16.601+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:50:16.614+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-10T02:50:46.943+0000] {processor.py:157} INFO - Started process (PID=17803) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:50:46.948+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:50:46.965+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:50:46.964+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:50:46.984+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:50:47.013+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:50:47.013+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:50:47.032+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:50:47.032+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:50:47.054+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-08-10T02:51:17.234+0000] {processor.py:157} INFO - Started process (PID=17814) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:51:17.236+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:51:17.242+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:51:17.242+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:51:17.297+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:51:17.345+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:51:17.345+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:51:17.377+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:51:17.377+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:51:17.387+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.161 seconds
[2024-08-10T02:51:47.672+0000] {processor.py:157} INFO - Started process (PID=17824) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:51:47.673+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:51:47.674+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:51:47.674+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:51:47.684+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:51:47.701+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:51:47.701+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:51:47.714+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:51:47.714+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:51:47.723+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-10T02:52:18.006+0000] {processor.py:157} INFO - Started process (PID=17834) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:52:18.007+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:52:18.010+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:52:18.009+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:52:18.020+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:52:18.036+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:52:18.036+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:52:18.046+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:52:18.046+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:52:18.055+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-10T02:52:48.354+0000] {processor.py:157} INFO - Started process (PID=17844) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:52:48.356+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:52:48.359+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:52:48.359+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:52:48.367+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:52:48.384+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:52:48.384+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:52:48.394+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:52:48.394+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:52:48.403+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-10T02:53:18.665+0000] {processor.py:157} INFO - Started process (PID=17854) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:53:18.667+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:53:18.671+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:53:18.670+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:53:18.690+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:53:18.713+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:53:18.713+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:53:18.727+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:53:18.727+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:53:18.737+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-08-10T02:53:48.895+0000] {processor.py:157} INFO - Started process (PID=17864) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:53:48.898+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:53:48.900+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:53:48.900+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:53:48.913+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:53:48.928+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:53:48.928+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:53:48.938+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:53:48.938+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:53:48.948+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-10T02:54:19.153+0000] {processor.py:157} INFO - Started process (PID=17874) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:54:19.154+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:54:19.157+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:54:19.156+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:54:19.165+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:54:19.183+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:54:19.182+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:54:19.194+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:54:19.193+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:54:19.202+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-10T02:54:49.441+0000] {processor.py:157} INFO - Started process (PID=17884) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:54:49.442+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:54:49.447+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:54:49.447+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:54:49.464+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:54:49.493+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:54:49.493+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:54:49.506+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:54:49.506+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:54:49.516+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-08-10T02:55:19.783+0000] {processor.py:157} INFO - Started process (PID=17894) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:55:19.784+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:55:19.787+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:55:19.787+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:55:19.801+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:55:19.818+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:55:19.818+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:55:19.829+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:55:19.829+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:55:19.836+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-10T02:55:50.100+0000] {processor.py:157} INFO - Started process (PID=17904) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:55:50.101+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:55:50.104+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:55:50.104+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:55:50.120+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:55:50.142+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:55:50.142+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:55:50.152+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:55:50.152+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:55:50.161+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-10T02:56:20.420+0000] {processor.py:157} INFO - Started process (PID=17914) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:56:20.423+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:56:20.427+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:56:20.426+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:56:20.447+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:56:20.480+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:56:20.480+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:56:20.498+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:56:20.497+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:56:20.520+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-08-10T02:56:50.740+0000] {processor.py:157} INFO - Started process (PID=17924) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:56:50.743+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:56:50.747+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:56:50.746+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:56:50.765+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:56:50.800+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:56:50.800+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:56:50.813+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:56:50.813+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:56:50.824+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-08-10T02:57:21.018+0000] {processor.py:157} INFO - Started process (PID=17934) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:57:21.019+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:57:21.021+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:57:21.020+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:57:21.035+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:57:21.052+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:57:21.052+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:57:21.065+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:57:21.065+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:57:21.075+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-10T02:57:51.442+0000] {processor.py:157} INFO - Started process (PID=17944) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:57:51.444+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:57:51.448+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:57:51.447+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:57:51.468+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:57:51.514+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:57:51.514+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:57:51.530+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:57:51.530+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:57:51.542+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-08-10T02:58:22.049+0000] {processor.py:157} INFO - Started process (PID=17954) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:58:22.051+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:58:22.055+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:58:22.054+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:58:22.086+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:58:22.143+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:58:22.143+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:58:22.163+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:58:22.163+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:58:22.175+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-08-10T02:58:52.311+0000] {processor.py:157} INFO - Started process (PID=17964) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:58:52.312+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:58:52.314+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:58:52.314+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:58:52.327+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:58:52.348+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:58:52.348+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:58:52.359+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:58:52.359+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:58:52.369+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-10T02:59:22.689+0000] {processor.py:157} INFO - Started process (PID=17973) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:59:22.692+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:59:22.694+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:59:22.693+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:59:22.716+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:59:22.757+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:59:22.757+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:59:22.771+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:59:22.771+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:59:22.782+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-08-10T02:59:52.935+0000] {processor.py:157} INFO - Started process (PID=17984) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:59:52.936+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T02:59:52.939+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:59:52.938+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:59:52.955+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T02:59:52.972+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:59:52.972+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T02:59:52.981+0000] {logging_mixin.py:151} INFO - [2024-08-10T02:59:52.980+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T02:59:52.990+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-10T03:00:23.284+0000] {processor.py:157} INFO - Started process (PID=17994) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:00:23.288+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T03:00:23.296+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:00:23.296+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:00:23.339+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:00:23.409+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:00:23.409+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T03:00:23.433+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:00:23.433+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T03:00:23.461+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.185 seconds
[2024-08-10T03:00:53.787+0000] {processor.py:157} INFO - Started process (PID=18004) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:00:53.788+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T03:00:53.792+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:00:53.791+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:00:53.811+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:00:53.834+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:00:53.834+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T03:00:53.845+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:00:53.845+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T03:00:53.855+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-10T03:01:24.059+0000] {processor.py:157} INFO - Started process (PID=18014) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:01:24.061+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T03:01:24.063+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:01:24.063+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:01:24.074+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:01:24.094+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:01:24.094+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T03:01:24.110+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:01:24.109+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T03:01:24.119+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-10T03:01:54.398+0000] {processor.py:157} INFO - Started process (PID=18024) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:01:54.400+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T03:01:54.403+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:01:54.402+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:01:54.425+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:01:54.446+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:01:54.446+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T03:01:54.458+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:01:54.458+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T03:01:54.466+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-10T03:02:24.709+0000] {processor.py:157} INFO - Started process (PID=18034) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:02:24.711+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T03:02:24.714+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:02:24.714+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:02:24.727+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:02:24.753+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:02:24.753+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T03:02:24.769+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:02:24.769+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T03:02:24.779+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-10T03:02:55.015+0000] {processor.py:157} INFO - Started process (PID=18044) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:02:55.018+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T03:02:55.021+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:02:55.021+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:02:55.038+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:02:55.063+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:02:55.063+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T03:02:55.075+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:02:55.075+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T03:02:55.086+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-08-10T03:03:25.426+0000] {processor.py:157} INFO - Started process (PID=18054) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:03:25.427+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T03:03:25.433+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:03:25.433+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:03:25.458+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:03:25.493+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:03:25.492+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T03:03:25.509+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:03:25.509+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T03:03:25.522+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-08-10T03:03:59.077+0000] {processor.py:157} INFO - Started process (PID=18064) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:03:59.079+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T03:03:59.081+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:03:59.081+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:03:59.121+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:03:59.139+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:03:59.138+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T03:03:59.154+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:03:59.154+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T03:03:59.162+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-08-10T03:04:29.530+0000] {processor.py:157} INFO - Started process (PID=18075) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:04:29.530+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T03:04:29.531+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:04:29.531+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:04:29.538+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:04:29.552+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:04:29.552+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T03:04:29.560+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:04:29.560+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T03:04:29.568+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.040 seconds
[2024-08-10T03:20:27.744+0000] {processor.py:157} INFO - Started process (PID=18088) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:20:27.746+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T03:20:27.752+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:20:27.751+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:20:27.779+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:20:27.816+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:20:27.816+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T03:20:27.845+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:20:27.845+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T03:20:27.863+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-08-10T03:20:58.094+0000] {processor.py:157} INFO - Started process (PID=18097) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:20:58.096+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T03:20:58.101+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:20:58.100+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:20:58.129+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:20:58.159+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:20:58.159+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T03:20:58.179+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:20:58.179+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T03:20:58.194+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-08-10T03:21:28.532+0000] {processor.py:157} INFO - Started process (PID=18107) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:21:28.536+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T03:21:28.539+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:21:28.538+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:21:28.566+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:21:28.596+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:21:28.596+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T03:21:28.609+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:21:28.609+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T03:21:28.620+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-08-10T03:21:58.976+0000] {processor.py:157} INFO - Started process (PID=18118) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:21:58.976+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T03:21:58.978+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:21:58.978+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:21:58.991+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:21:59.007+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:21:59.007+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T03:21:59.019+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:21:59.019+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T03:21:59.028+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-10T03:22:29.397+0000] {processor.py:157} INFO - Started process (PID=18127) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:22:29.398+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T03:22:29.401+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:22:29.400+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:22:29.419+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:22:29.446+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:22:29.446+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T03:22:29.459+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:22:29.459+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T03:22:29.469+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-08-10T03:22:59.734+0000] {processor.py:157} INFO - Started process (PID=18138) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:22:59.737+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T03:22:59.741+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:22:59.741+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:22:59.759+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:22:59.780+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:22:59.780+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T03:22:59.792+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:22:59.792+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T03:22:59.800+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-10T03:23:30.109+0000] {processor.py:157} INFO - Started process (PID=18148) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:23:30.110+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T03:23:30.112+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:23:30.112+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:23:30.128+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:23:30.154+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:23:30.154+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T03:23:30.167+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:23:30.167+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T03:23:30.177+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-10T03:24:00.499+0000] {processor.py:157} INFO - Started process (PID=18158) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:24:00.500+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T03:24:00.502+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:24:00.502+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:24:00.514+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:24:00.532+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:24:00.532+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T03:24:00.545+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:24:00.545+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T03:24:00.556+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-10T03:24:30.930+0000] {processor.py:157} INFO - Started process (PID=18168) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:24:30.931+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T03:24:30.933+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:24:30.933+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:24:30.943+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:24:30.960+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:24:30.960+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T03:24:30.971+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:24:30.971+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T03:24:30.981+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-10T03:25:01.281+0000] {processor.py:157} INFO - Started process (PID=18178) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:25:01.283+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T03:25:01.285+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:25:01.285+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:25:01.295+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:25:01.314+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:25:01.313+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T03:25:01.324+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:25:01.324+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T03:25:01.333+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-10T03:25:31.654+0000] {processor.py:157} INFO - Started process (PID=18188) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:25:31.655+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T03:25:31.660+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:25:31.659+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:25:31.680+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:25:31.734+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:25:31.734+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T03:25:31.749+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:25:31.749+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T03:25:31.760+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-08-10T03:26:02.073+0000] {processor.py:157} INFO - Started process (PID=18198) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:26:02.073+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T03:26:02.076+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:26:02.076+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:26:02.086+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:26:02.101+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:26:02.101+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T03:26:02.110+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:26:02.110+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T03:26:02.119+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-10T03:26:32.450+0000] {processor.py:157} INFO - Started process (PID=18208) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:26:32.451+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T03:26:32.454+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:26:32.454+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:26:32.465+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:26:32.480+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:26:32.480+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T03:26:32.490+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:26:32.490+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T03:26:32.499+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-10T03:27:02.884+0000] {processor.py:157} INFO - Started process (PID=18218) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:27:02.888+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T03:27:02.890+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:27:02.890+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:27:02.900+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:27:02.912+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:27:02.912+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T03:27:02.922+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:27:02.922+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T03:27:02.931+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-10T03:27:33.334+0000] {processor.py:157} INFO - Started process (PID=18228) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:27:33.335+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T03:27:33.340+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:27:33.339+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:27:33.374+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:27:33.403+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:27:33.403+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T03:27:33.416+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:27:33.416+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T03:27:33.427+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-08-10T03:28:03.718+0000] {processor.py:157} INFO - Started process (PID=18238) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:28:03.721+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T03:28:03.723+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:28:03.722+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:28:03.732+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:28:03.748+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:28:03.748+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T03:28:03.758+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:28:03.758+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T03:28:03.767+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-10T03:28:34.217+0000] {processor.py:157} INFO - Started process (PID=18248) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:28:34.219+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T03:28:34.222+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:28:34.222+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:28:34.240+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:28:34.255+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:28:34.255+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T03:28:34.266+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:28:34.266+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T03:28:34.276+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-10T03:29:04.625+0000] {processor.py:157} INFO - Started process (PID=18258) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:29:04.627+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T03:29:04.629+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:29:04.629+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:29:04.643+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:29:04.666+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:29:04.665+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T03:29:04.678+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:29:04.678+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T03:29:04.688+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-10T03:29:34.980+0000] {processor.py:157} INFO - Started process (PID=18268) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:29:34.982+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T03:29:34.983+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:29:34.983+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:29:34.994+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:29:35.012+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:29:35.012+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T03:29:35.024+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:29:35.024+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T03:29:35.034+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-10T03:30:05.500+0000] {processor.py:157} INFO - Started process (PID=18278) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:30:05.501+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T03:30:05.503+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:30:05.502+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:30:05.513+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:30:05.530+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:30:05.530+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T03:30:05.540+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:30:05.539+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T03:30:05.549+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-10T03:30:35.901+0000] {processor.py:157} INFO - Started process (PID=18288) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:30:35.903+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T03:30:35.905+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:30:35.905+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:30:35.923+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:30:35.945+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:30:35.945+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T03:30:35.957+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:30:35.957+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T03:30:35.967+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-10T03:31:06.192+0000] {processor.py:157} INFO - Started process (PID=18298) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:31:06.193+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T03:31:06.195+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:31:06.194+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:31:06.207+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:31:06.223+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:31:06.223+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T03:31:06.233+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:31:06.233+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T03:31:06.245+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-10T03:31:36.527+0000] {processor.py:157} INFO - Started process (PID=18308) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:31:36.529+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T03:31:36.531+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:31:36.531+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:31:36.546+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:31:36.562+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:31:36.561+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T03:31:36.573+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:31:36.573+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T03:31:36.582+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-10T03:32:06.982+0000] {processor.py:157} INFO - Started process (PID=18318) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:32:06.983+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T03:32:06.985+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:32:06.985+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:32:06.995+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:32:07.013+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:32:07.013+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T03:32:07.029+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:32:07.029+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T03:32:07.037+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-10T03:32:37.380+0000] {processor.py:157} INFO - Started process (PID=18328) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:32:37.380+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T03:32:37.382+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:32:37.382+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:32:37.392+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:32:37.409+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:32:37.409+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T03:32:37.422+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:32:37.422+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T03:32:37.429+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-10T03:33:07.735+0000] {processor.py:157} INFO - Started process (PID=18338) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:33:07.736+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T03:33:07.739+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:33:07.739+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:33:07.757+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:33:07.780+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:33:07.780+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T03:33:07.795+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:33:07.795+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T03:33:07.803+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-10T03:33:38.190+0000] {processor.py:157} INFO - Started process (PID=18348) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:33:38.192+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T03:33:38.194+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:33:38.193+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:33:38.204+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:33:38.222+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:33:38.222+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T03:33:38.232+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:33:38.232+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T03:33:38.241+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-10T03:34:08.539+0000] {processor.py:157} INFO - Started process (PID=18358) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:34:08.540+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T03:34:08.542+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:34:08.542+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:34:08.552+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:34:08.568+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:34:08.568+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T03:34:08.579+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:34:08.579+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T03:34:08.588+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-10T03:34:38.940+0000] {processor.py:157} INFO - Started process (PID=18368) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:34:38.941+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T03:34:38.943+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:34:38.943+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:34:38.952+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:34:38.971+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:34:38.971+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T03:34:38.981+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:34:38.981+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T03:34:38.989+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-10T03:35:09.328+0000] {processor.py:157} INFO - Started process (PID=18378) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:35:09.330+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T03:35:09.333+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:35:09.333+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:35:09.350+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:35:09.373+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:35:09.373+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T03:35:09.385+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:35:09.385+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T03:35:09.394+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-10T03:35:39.664+0000] {processor.py:157} INFO - Started process (PID=18388) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:35:39.665+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T03:35:39.667+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:35:39.667+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:35:39.677+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:35:39.694+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:35:39.694+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T03:35:39.704+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:35:39.704+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T03:35:39.712+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-10T03:36:10.088+0000] {processor.py:157} INFO - Started process (PID=18398) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:36:10.089+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T03:36:10.093+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:36:10.093+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:36:10.110+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:36:10.129+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:36:10.129+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T03:36:10.138+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:36:10.138+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T03:36:10.146+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-10T03:36:40.570+0000] {processor.py:157} INFO - Started process (PID=18408) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:36:40.571+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T03:36:40.574+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:36:40.573+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:36:40.583+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:36:40.602+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:36:40.602+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T03:36:40.615+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:36:40.615+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T03:36:40.625+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-10T03:37:11.097+0000] {processor.py:157} INFO - Started process (PID=18418) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:37:11.098+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T03:37:11.100+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:37:11.100+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:37:11.109+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:37:11.125+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:37:11.125+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T03:37:11.135+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:37:11.135+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T03:37:11.143+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-10T03:37:41.492+0000] {processor.py:157} INFO - Started process (PID=18428) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:37:41.494+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T03:37:41.496+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:37:41.496+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:37:41.505+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:37:41.523+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:37:41.523+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T03:37:41.533+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:37:41.533+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T03:37:41.543+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-10T03:38:11.935+0000] {processor.py:157} INFO - Started process (PID=18438) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:38:11.935+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T03:38:11.938+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:38:11.938+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:38:11.951+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:38:11.968+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:38:11.968+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T03:38:11.978+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:38:11.978+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T03:38:11.988+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-10T03:38:42.378+0000] {processor.py:157} INFO - Started process (PID=18448) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:38:42.379+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T03:38:42.381+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:38:42.381+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:38:42.397+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:38:42.418+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:38:42.418+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T03:38:42.430+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:38:42.430+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T03:38:42.439+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-10T03:39:12.735+0000] {processor.py:157} INFO - Started process (PID=18458) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:39:12.735+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T03:39:12.737+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:39:12.736+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:39:12.748+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:39:12.764+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:39:12.764+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T03:39:12.776+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:39:12.776+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T03:39:12.788+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-10T03:39:43.173+0000] {processor.py:157} INFO - Started process (PID=18468) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:39:43.175+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T03:39:43.177+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:39:43.177+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:39:43.189+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:39:43.206+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:39:43.206+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T03:39:43.217+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:39:43.217+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T03:39:43.226+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-10T03:40:13.533+0000] {processor.py:157} INFO - Started process (PID=18478) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:40:13.536+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T03:40:13.539+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:40:13.539+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:40:13.558+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:40:13.580+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:40:13.580+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T03:40:13.591+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:40:13.591+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T03:40:13.600+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-10T03:40:43.960+0000] {processor.py:157} INFO - Started process (PID=18488) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:40:43.961+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T03:40:43.963+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:40:43.963+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:40:43.973+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:40:43.992+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:40:43.992+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T03:40:44.005+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:40:44.005+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T03:40:44.014+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-10T03:41:14.384+0000] {processor.py:157} INFO - Started process (PID=18498) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:41:14.385+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T03:41:14.387+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:41:14.387+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:41:14.398+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:41:14.415+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:41:14.415+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T03:41:14.425+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:41:14.425+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T03:41:14.435+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-10T03:41:44.736+0000] {processor.py:157} INFO - Started process (PID=18508) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:41:44.737+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T03:41:44.740+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:41:44.739+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:41:44.753+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:41:44.772+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:41:44.772+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T03:41:44.785+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:41:44.785+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T03:41:44.794+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-10T03:42:15.173+0000] {processor.py:157} INFO - Started process (PID=18518) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:42:15.174+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T03:42:15.176+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:42:15.176+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:42:15.195+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:42:15.221+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:42:15.221+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T03:42:15.241+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:42:15.241+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T03:42:15.253+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-08-10T03:42:45.616+0000] {processor.py:157} INFO - Started process (PID=18528) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:42:45.618+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T03:42:45.620+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:42:45.620+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:42:45.630+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:42:45.647+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:42:45.647+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T03:42:45.658+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:42:45.658+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T03:42:45.666+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-10T03:43:15.992+0000] {processor.py:157} INFO - Started process (PID=18538) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:43:15.995+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T03:43:15.997+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:43:15.997+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:43:16.011+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:43:16.029+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:43:16.029+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T03:43:16.040+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:43:16.040+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T03:43:16.050+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-10T03:43:46.403+0000] {processor.py:157} INFO - Started process (PID=18548) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:43:46.403+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T03:43:46.407+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:43:46.407+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:43:46.421+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:43:46.442+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:43:46.441+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T03:43:46.451+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:43:46.451+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T03:43:46.460+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-10T03:44:16.865+0000] {processor.py:157} INFO - Started process (PID=18558) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:44:16.866+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T03:44:16.868+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:44:16.868+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:44:16.885+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:44:16.901+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:44:16.900+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T03:44:16.910+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:44:16.910+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T03:44:16.920+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-10T03:44:47.332+0000] {processor.py:157} INFO - Started process (PID=18568) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:44:47.333+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T03:44:47.335+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:44:47.335+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:44:47.348+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:44:47.366+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:44:47.366+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T03:44:47.380+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:44:47.380+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T03:44:47.391+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-10T03:45:17.786+0000] {processor.py:157} INFO - Started process (PID=18578) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:45:17.789+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T03:45:17.791+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:45:17.791+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:45:17.800+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:45:17.818+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:45:17.818+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T03:45:17.828+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:45:17.828+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T03:45:17.838+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-10T03:45:48.176+0000] {processor.py:157} INFO - Started process (PID=18588) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:45:48.178+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T03:45:48.180+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:45:48.179+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:45:48.189+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:45:48.205+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:45:48.205+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T03:45:48.215+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:45:48.215+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T03:45:48.225+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-10T03:46:18.615+0000] {processor.py:157} INFO - Started process (PID=18598) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:46:18.616+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T03:46:18.620+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:46:18.619+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:46:18.632+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:46:18.651+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:46:18.651+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T03:46:18.662+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:46:18.662+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T03:46:18.669+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-10T03:46:49.004+0000] {processor.py:157} INFO - Started process (PID=18608) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:46:49.006+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T03:46:49.009+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:46:49.009+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:46:49.025+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:46:49.046+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:46:49.046+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T03:46:49.057+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:46:49.057+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T03:46:49.067+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-10T03:47:19.476+0000] {processor.py:157} INFO - Started process (PID=18618) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:47:19.477+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T03:47:19.479+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:47:19.479+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:47:19.495+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:47:19.515+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:47:19.515+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T03:47:19.525+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:47:19.525+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T03:47:19.534+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-10T03:47:49.873+0000] {processor.py:157} INFO - Started process (PID=18628) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:47:49.875+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T03:47:49.876+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:47:49.876+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:47:49.888+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:47:49.907+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:47:49.907+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T03:47:49.918+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:47:49.918+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T03:47:49.927+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-10T03:48:20.230+0000] {processor.py:157} INFO - Started process (PID=18638) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:48:20.232+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T03:48:20.235+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:48:20.234+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:48:20.252+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:48:20.272+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:48:20.272+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T03:48:20.285+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:48:20.285+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T03:48:20.297+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-10T03:48:50.653+0000] {processor.py:157} INFO - Started process (PID=18648) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:48:50.653+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T03:48:50.656+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:48:50.655+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:48:50.667+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:48:50.686+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:48:50.685+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T03:48:50.698+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:48:50.698+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T03:48:50.707+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-10T03:49:21.087+0000] {processor.py:157} INFO - Started process (PID=18658) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:49:21.088+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T03:49:21.089+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:49:21.089+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:49:21.100+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:49:21.117+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:49:21.117+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T03:49:21.128+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:49:21.128+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T03:49:21.137+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-10T03:49:51.471+0000] {processor.py:157} INFO - Started process (PID=18668) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:49:51.472+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T03:49:51.477+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:49:51.477+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:49:51.494+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:49:51.514+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:49:51.514+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T03:49:51.525+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:49:51.525+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T03:49:51.534+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-10T03:50:21.862+0000] {processor.py:157} INFO - Started process (PID=18678) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:50:21.863+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T03:50:21.865+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:50:21.865+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:50:21.880+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:50:21.904+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:50:21.904+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T03:50:21.918+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:50:21.918+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T03:50:21.928+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-10T03:50:52.217+0000] {processor.py:157} INFO - Started process (PID=18688) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:50:52.219+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T03:50:52.224+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:50:52.224+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:50:52.246+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:50:52.278+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:50:52.278+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T03:50:52.293+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:50:52.293+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T03:50:52.303+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-08-10T03:51:22.708+0000] {processor.py:157} INFO - Started process (PID=18698) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:51:22.710+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T03:51:22.715+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:51:22.715+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:51:22.743+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:51:22.781+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:51:22.781+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T03:51:22.798+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:51:22.798+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T03:51:22.811+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-08-10T03:51:52.986+0000] {processor.py:157} INFO - Started process (PID=18708) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:51:52.987+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T03:51:52.990+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:51:52.989+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:51:53.000+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:51:53.018+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:51:53.018+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T03:51:53.029+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:51:53.029+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T03:51:53.039+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-10T03:52:23.408+0000] {processor.py:157} INFO - Started process (PID=18718) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:52:23.412+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T03:52:23.416+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:52:23.415+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:52:23.430+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:52:23.452+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:52:23.451+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T03:52:23.464+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:52:23.463+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T03:52:23.472+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-10T03:52:53.815+0000] {processor.py:157} INFO - Started process (PID=18728) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:52:53.816+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T03:52:53.824+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:52:53.824+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:52:53.835+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:52:53.848+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:52:53.848+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T03:52:53.857+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:52:53.857+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T03:52:53.864+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-10T03:53:24.216+0000] {processor.py:157} INFO - Started process (PID=18738) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:53:24.218+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T03:53:24.220+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:53:24.220+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:53:24.231+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:53:24.246+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:53:24.246+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T03:53:24.257+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:53:24.257+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T03:53:24.266+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-10T03:53:54.649+0000] {processor.py:157} INFO - Started process (PID=18748) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:53:54.650+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T03:53:54.655+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:53:54.654+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:53:54.670+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:53:54.691+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:53:54.691+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T03:53:54.703+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:53:54.703+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T03:53:54.713+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-10T03:54:24.990+0000] {processor.py:157} INFO - Started process (PID=18758) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:54:24.992+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T03:54:24.994+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:54:24.994+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:54:25.004+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:54:25.020+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:54:25.020+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T03:54:25.030+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:54:25.030+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T03:54:25.040+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-10T03:54:55.422+0000] {processor.py:157} INFO - Started process (PID=18768) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:54:55.424+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T03:54:55.426+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:54:55.426+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:54:55.437+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:54:55.454+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:54:55.454+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T03:54:55.469+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:54:55.469+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T03:54:55.477+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-10T03:55:25.849+0000] {processor.py:157} INFO - Started process (PID=18778) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:55:25.850+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T03:55:25.855+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:55:25.854+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:55:25.871+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:55:25.897+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:55:25.897+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T03:55:25.909+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:55:25.909+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T03:55:25.918+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-08-10T03:55:56.233+0000] {processor.py:157} INFO - Started process (PID=18788) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:55:56.234+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T03:55:56.235+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:55:56.235+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:55:56.245+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:55:56.262+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:55:56.262+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T03:55:56.272+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:55:56.272+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T03:55:56.281+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-10T03:56:26.627+0000] {processor.py:157} INFO - Started process (PID=18798) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:56:26.628+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T03:56:26.630+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:56:26.630+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:56:26.647+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:56:26.676+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:56:26.676+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T03:56:26.696+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:56:26.696+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T03:56:26.707+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-08-10T03:56:57.099+0000] {processor.py:157} INFO - Started process (PID=18808) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:56:57.100+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T03:56:57.101+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:56:57.101+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:56:57.115+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:56:57.131+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:56:57.131+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T03:56:57.141+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:56:57.141+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T03:56:57.150+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-10T03:57:27.533+0000] {processor.py:157} INFO - Started process (PID=18818) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:57:27.533+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T03:57:27.535+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:57:27.535+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:57:27.546+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:57:27.561+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:57:27.561+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T03:57:27.572+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:57:27.572+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T03:57:27.582+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-10T03:57:57.927+0000] {processor.py:157} INFO - Started process (PID=18827) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:57:57.928+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T03:57:57.933+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:57:57.932+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:57:57.954+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:57:57.978+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:57:57.978+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T03:57:57.991+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:57:57.991+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T03:57:58.002+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-08-10T03:58:28.266+0000] {processor.py:157} INFO - Started process (PID=18838) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:58:28.268+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T03:58:28.269+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:58:28.269+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:58:28.279+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:58:28.297+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:58:28.297+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T03:58:28.307+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:58:28.307+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T03:58:28.316+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-10T03:58:58.691+0000] {processor.py:157} INFO - Started process (PID=18848) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:58:58.694+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T03:58:58.696+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:58:58.696+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:58:58.714+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:58:58.736+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:58:58.736+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T03:58:58.748+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:58:58.748+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T03:58:58.757+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-10T03:59:29.133+0000] {processor.py:157} INFO - Started process (PID=18858) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:59:29.134+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T03:59:29.136+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:59:29.136+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:59:29.146+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:59:29.164+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:59:29.164+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T03:59:29.175+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:59:29.175+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T03:59:29.183+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-10T03:59:59.470+0000] {processor.py:157} INFO - Started process (PID=18868) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:59:59.472+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T03:59:59.474+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:59:59.474+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:59:59.483+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T03:59:59.499+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:59:59.499+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T03:59:59.508+0000] {logging_mixin.py:151} INFO - [2024-08-10T03:59:59.508+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T03:59:59.518+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-10T04:00:29.910+0000] {processor.py:157} INFO - Started process (PID=18878) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:00:29.911+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T04:00:29.912+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:00:29.912+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:00:29.923+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:00:29.940+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:00:29.940+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T04:00:29.955+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:00:29.955+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T04:00:29.964+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-10T04:01:00.342+0000] {processor.py:157} INFO - Started process (PID=18887) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:01:00.344+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T04:01:00.349+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:01:00.349+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:01:00.369+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:01:00.394+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:01:00.394+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T04:01:00.408+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:01:00.408+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T04:01:00.426+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-08-10T04:01:30.821+0000] {processor.py:157} INFO - Started process (PID=18898) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:01:30.822+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T04:01:30.824+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:01:30.824+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:01:30.834+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:01:30.850+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:01:30.850+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T04:01:30.862+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:01:30.862+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T04:01:30.870+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-10T04:02:01.196+0000] {processor.py:157} INFO - Started process (PID=18908) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:02:01.198+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T04:02:01.200+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:02:01.200+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:02:01.208+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:02:01.229+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:02:01.229+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T04:02:01.239+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:02:01.239+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T04:02:01.247+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-10T04:02:31.529+0000] {processor.py:157} INFO - Started process (PID=18918) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:02:31.531+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T04:02:31.533+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:02:31.533+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:02:31.546+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:02:31.563+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:02:31.563+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T04:02:31.574+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:02:31.574+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T04:02:31.582+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-10T04:03:01.854+0000] {processor.py:157} INFO - Started process (PID=18928) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:03:01.858+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T04:03:01.862+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:03:01.862+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:03:01.882+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:03:01.899+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:03:01.899+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T04:03:01.915+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:03:01.915+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T04:03:01.924+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-08-10T04:03:32.294+0000] {processor.py:157} INFO - Started process (PID=18938) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:03:32.296+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T04:03:32.298+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:03:32.298+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:03:32.307+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:03:32.327+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:03:32.327+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T04:03:32.339+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:03:32.339+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T04:03:32.347+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-10T04:04:02.707+0000] {processor.py:157} INFO - Started process (PID=18948) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:04:02.709+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T04:04:02.712+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:04:02.711+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:04:02.721+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:04:02.737+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:04:02.737+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T04:04:02.748+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:04:02.748+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T04:04:02.757+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-10T04:04:33.130+0000] {processor.py:157} INFO - Started process (PID=18958) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:04:33.132+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T04:04:33.137+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:04:33.137+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:04:33.155+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:04:33.178+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:04:33.178+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T04:04:33.191+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:04:33.191+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T04:04:33.200+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-08-10T04:05:03.510+0000] {processor.py:157} INFO - Started process (PID=18968) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:05:03.511+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T04:05:03.513+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:05:03.512+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:05:03.523+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:05:03.538+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:05:03.538+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T04:05:03.550+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:05:03.550+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T04:05:03.560+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-10T04:05:33.936+0000] {processor.py:157} INFO - Started process (PID=18978) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:05:33.938+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T04:05:33.941+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:05:33.940+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:05:33.958+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:05:33.978+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:05:33.978+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T04:05:33.993+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:05:33.993+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T04:05:34.001+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-10T04:06:04.343+0000] {processor.py:157} INFO - Started process (PID=18988) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:06:04.344+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T04:06:04.346+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:06:04.346+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:06:04.359+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:06:04.374+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:06:04.374+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T04:06:04.386+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:06:04.386+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T04:06:04.394+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-10T04:06:34.726+0000] {processor.py:157} INFO - Started process (PID=18998) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:06:34.727+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T04:06:34.729+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:06:34.729+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:06:34.740+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:06:34.757+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:06:34.757+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T04:06:34.770+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:06:34.770+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T04:06:34.780+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-10T04:07:05.157+0000] {processor.py:157} INFO - Started process (PID=19008) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:07:05.159+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T04:07:05.160+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:07:05.160+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:07:05.170+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:07:05.187+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:07:05.187+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T04:07:05.199+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:07:05.199+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T04:07:05.208+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-10T04:07:35.581+0000] {processor.py:157} INFO - Started process (PID=19018) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:07:35.583+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T04:07:35.585+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:07:35.585+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:07:35.604+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:07:35.620+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:07:35.620+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T04:07:35.630+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:07:35.629+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T04:07:35.639+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-10T04:08:06.034+0000] {processor.py:157} INFO - Started process (PID=19028) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:08:06.035+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T04:08:06.038+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:08:06.038+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:08:06.058+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:08:06.074+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:08:06.074+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T04:08:06.088+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:08:06.088+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T04:08:06.098+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-10T04:08:36.502+0000] {processor.py:157} INFO - Started process (PID=19038) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:08:36.507+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T04:08:36.510+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:08:36.509+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:08:36.519+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:08:36.535+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:08:36.535+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T04:08:36.546+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:08:36.546+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T04:08:36.557+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-10T04:09:06.903+0000] {processor.py:157} INFO - Started process (PID=19048) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:09:06.905+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T04:09:06.908+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:09:06.908+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:09:06.930+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:09:06.955+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:09:06.955+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T04:09:06.968+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:09:06.967+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T04:09:06.980+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-08-10T04:09:37.205+0000] {processor.py:157} INFO - Started process (PID=19058) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:09:37.207+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T04:09:37.210+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:09:37.209+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:09:37.220+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:09:37.237+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:09:37.237+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T04:09:37.248+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:09:37.248+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T04:09:37.257+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-10T04:10:07.559+0000] {processor.py:157} INFO - Started process (PID=19068) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:10:07.560+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T04:10:07.562+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:10:07.562+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:10:07.575+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:10:07.589+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:10:07.589+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T04:10:07.599+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:10:07.599+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T04:10:07.608+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-10T04:10:38.027+0000] {processor.py:157} INFO - Started process (PID=19078) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:10:38.029+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T04:10:38.034+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:10:38.034+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:10:38.087+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:10:38.112+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:10:38.111+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T04:10:38.125+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:10:38.125+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T04:10:38.135+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-08-10T04:11:08.374+0000] {processor.py:157} INFO - Started process (PID=19088) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:11:08.376+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T04:11:08.378+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:11:08.378+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:11:08.388+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:11:08.406+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:11:08.406+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T04:11:08.419+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:11:08.419+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T04:11:08.427+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-10T04:11:38.857+0000] {processor.py:157} INFO - Started process (PID=19098) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:11:38.858+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T04:11:38.861+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:11:38.860+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:11:38.874+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:11:38.891+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:11:38.890+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T04:11:38.902+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:11:38.901+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T04:11:38.912+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-10T04:12:09.241+0000] {processor.py:157} INFO - Started process (PID=19108) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:12:09.245+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T04:12:09.250+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:12:09.249+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:12:09.266+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:12:09.285+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:12:09.285+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T04:12:09.298+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:12:09.298+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T04:12:09.308+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-10T04:12:39.614+0000] {processor.py:157} INFO - Started process (PID=19118) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:12:39.617+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T04:12:39.618+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:12:39.618+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:12:39.629+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:12:39.646+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:12:39.646+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T04:12:39.657+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:12:39.657+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T04:12:39.673+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-10T04:13:10.029+0000] {processor.py:157} INFO - Started process (PID=19128) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:13:10.030+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T04:13:10.032+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:13:10.032+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:13:10.047+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:13:10.063+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:13:10.063+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T04:13:10.073+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:13:10.073+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T04:13:10.081+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-10T04:13:40.404+0000] {processor.py:157} INFO - Started process (PID=19138) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:13:40.406+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T04:13:40.408+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:13:40.408+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:13:40.420+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:13:40.443+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:13:40.443+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T04:13:40.455+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:13:40.455+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T04:13:40.465+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-10T04:14:10.888+0000] {processor.py:157} INFO - Started process (PID=19148) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:14:10.889+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T04:14:10.891+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:14:10.890+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:14:10.901+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:14:10.922+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:14:10.922+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T04:14:10.932+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:14:10.932+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T04:14:10.941+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-10T04:14:41.232+0000] {processor.py:157} INFO - Started process (PID=19158) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:14:41.233+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T04:14:41.234+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:14:41.234+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:14:41.242+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:14:41.261+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:14:41.261+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T04:14:41.273+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:14:41.273+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T04:14:41.284+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-10T04:15:11.622+0000] {processor.py:157} INFO - Started process (PID=19168) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:15:11.623+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T04:15:11.626+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:15:11.626+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:15:11.647+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:15:11.664+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:15:11.664+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T04:15:11.675+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:15:11.675+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T04:15:11.685+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-10T04:15:42.078+0000] {processor.py:157} INFO - Started process (PID=19178) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:15:42.079+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T04:15:42.081+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:15:42.081+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:15:42.101+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:15:42.130+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:15:42.130+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T04:15:42.149+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:15:42.148+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T04:15:42.159+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-08-10T04:16:12.427+0000] {processor.py:157} INFO - Started process (PID=19188) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:16:12.428+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T04:16:12.430+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:16:12.430+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:16:12.440+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:16:12.458+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:16:12.458+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T04:16:12.469+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:16:12.469+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T04:16:12.477+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-10T04:16:42.924+0000] {processor.py:157} INFO - Started process (PID=19198) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:16:42.925+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T04:16:42.927+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:16:42.926+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:16:42.938+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:16:42.956+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:16:42.956+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T04:16:42.969+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:16:42.969+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T04:16:42.979+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-10T04:17:13.345+0000] {processor.py:157} INFO - Started process (PID=19208) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:17:13.349+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T04:17:13.351+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:17:13.351+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:17:13.366+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:17:13.383+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:17:13.383+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T04:17:13.392+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:17:13.392+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T04:17:13.399+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-10T04:17:43.743+0000] {processor.py:157} INFO - Started process (PID=19218) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:17:43.745+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T04:17:43.747+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:17:43.747+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:17:43.759+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:17:43.783+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:17:43.783+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T04:17:43.796+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:17:43.796+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T04:17:43.808+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-10T04:18:14.082+0000] {processor.py:157} INFO - Started process (PID=19228) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:18:14.083+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T04:18:14.085+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:18:14.085+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:18:14.099+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:18:14.114+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:18:14.114+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T04:18:14.130+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:18:14.130+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T04:18:14.140+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-10T04:18:44.454+0000] {processor.py:157} INFO - Started process (PID=19238) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:18:44.456+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T04:18:44.460+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:18:44.460+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:18:44.506+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:18:44.527+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:18:44.527+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T04:18:44.539+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:18:44.539+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T04:18:44.549+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-08-10T04:19:14.811+0000] {processor.py:157} INFO - Started process (PID=19248) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:19:14.815+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T04:19:14.818+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:19:14.817+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:19:14.844+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:19:14.864+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:19:14.864+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T04:19:14.878+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:19:14.878+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T04:19:14.888+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-08-10T04:19:45.180+0000] {processor.py:157} INFO - Started process (PID=19258) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:19:45.181+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T04:19:45.184+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:19:45.184+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:19:45.200+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:19:45.220+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:19:45.220+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T04:19:45.232+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:19:45.232+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T04:19:45.243+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-10T04:20:15.464+0000] {processor.py:157} INFO - Started process (PID=19268) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:20:15.466+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T04:20:15.469+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:20:15.469+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:20:15.484+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:20:15.501+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:20:15.501+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T04:20:15.512+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:20:15.512+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T04:20:15.520+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-10T04:20:45.879+0000] {processor.py:157} INFO - Started process (PID=19277) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:20:45.882+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T04:20:45.897+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:20:45.896+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:20:45.922+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:20:45.950+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:20:45.950+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T04:20:45.963+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:20:45.962+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T04:20:45.976+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-08-10T04:21:16.322+0000] {processor.py:157} INFO - Started process (PID=19288) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:21:16.325+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T04:21:16.327+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:21:16.327+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:21:16.338+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:21:16.355+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:21:16.355+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T04:21:16.368+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:21:16.367+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T04:21:16.379+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-10T04:21:49.200+0000] {processor.py:157} INFO - Started process (PID=19299) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:21:49.202+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T04:21:49.207+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:21:49.207+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:21:49.230+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:21:49.263+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:21:49.263+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T04:21:49.276+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:21:49.276+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T04:21:49.287+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-08-10T04:22:19.523+0000] {processor.py:157} INFO - Started process (PID=19310) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:22:19.524+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T04:22:19.526+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:22:19.526+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:22:19.537+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:22:19.553+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:22:19.553+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T04:22:19.563+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:22:19.563+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T04:22:19.572+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-10T04:22:49.932+0000] {processor.py:157} INFO - Started process (PID=19320) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:22:49.933+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T04:22:49.936+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:22:49.936+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:22:49.948+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:22:49.966+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:22:49.966+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T04:22:49.978+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:22:49.978+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T04:22:49.988+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-10T04:23:20.247+0000] {processor.py:157} INFO - Started process (PID=19330) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:23:20.249+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T04:23:20.253+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:23:20.253+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:23:20.272+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:23:20.292+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:23:20.292+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T04:23:20.304+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:23:20.304+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T04:23:20.312+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-10T04:23:50.600+0000] {processor.py:157} INFO - Started process (PID=19340) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:23:50.601+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T04:23:50.603+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:23:50.603+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:23:50.613+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:23:50.630+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:23:50.630+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T04:23:50.639+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:23:50.639+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T04:23:50.650+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-10T04:24:20.999+0000] {processor.py:157} INFO - Started process (PID=19350) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:24:21.001+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T04:24:21.004+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:24:21.004+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:24:21.014+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:24:21.032+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:24:21.032+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T04:24:21.044+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:24:21.044+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T04:24:21.053+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-10T04:24:51.730+0000] {processor.py:157} INFO - Started process (PID=19360) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:24:51.731+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T04:24:51.734+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:24:51.734+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:24:51.753+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:24:51.786+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:24:51.786+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T04:24:51.804+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:24:51.804+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T04:24:51.816+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-08-10T04:25:51.224+0000] {processor.py:157} INFO - Started process (PID=19372) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:25:51.228+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T04:25:51.231+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:25:51.231+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:25:51.272+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:25:51.300+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:25:51.300+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T04:25:51.314+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:25:51.314+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T04:25:51.325+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-08-10T04:29:23.952+0000] {processor.py:157} INFO - Started process (PID=19382) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:29:23.954+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T04:29:23.957+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:29:23.956+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:29:24.003+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:29:24.055+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:29:24.054+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T04:29:24.090+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:29:24.090+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T04:29:24.112+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.168 seconds
[2024-08-10T04:29:54.289+0000] {processor.py:157} INFO - Started process (PID=19392) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:29:54.292+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T04:29:54.295+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:29:54.295+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:29:54.313+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:29:54.339+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:29:54.339+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T04:29:54.351+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:29:54.350+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T04:29:54.361+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-08-10T04:30:52.176+0000] {processor.py:157} INFO - Started process (PID=19401) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:30:52.177+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T04:30:52.178+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:30:52.178+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:30:52.188+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:30:52.205+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:30:52.205+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T04:30:52.217+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:30:52.217+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T04:30:52.226+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-10T04:31:22.517+0000] {processor.py:157} INFO - Started process (PID=19412) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:31:22.518+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T04:31:22.519+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:31:22.519+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:31:22.528+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:31:22.546+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:31:22.546+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T04:31:22.558+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:31:22.558+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T04:31:22.568+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-10T04:31:52.939+0000] {processor.py:157} INFO - Started process (PID=19422) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:31:52.940+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T04:31:52.942+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:31:52.942+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:31:52.951+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:31:52.969+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:31:52.969+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T04:31:52.980+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:31:52.980+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T04:31:52.989+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-10T04:32:25.861+0000] {processor.py:157} INFO - Started process (PID=19432) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:32:25.862+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T04:32:25.865+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:32:25.865+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:32:25.882+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:32:25.899+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:32:25.899+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T04:32:25.910+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:32:25.910+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T04:32:25.918+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-10T04:33:06.388+0000] {processor.py:157} INFO - Started process (PID=19442) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:33:06.392+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T04:33:06.393+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:33:06.393+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:33:06.407+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:33:06.427+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:33:06.427+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T04:33:06.440+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:33:06.440+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T04:33:06.451+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-10T04:33:37.111+0000] {processor.py:157} INFO - Started process (PID=19452) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:33:37.113+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T04:33:37.117+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:33:37.117+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:33:37.140+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:33:37.180+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:33:37.180+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T04:33:37.193+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:33:37.193+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T04:33:37.203+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-08-10T04:34:18.239+0000] {processor.py:157} INFO - Started process (PID=19462) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:34:18.241+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T04:34:18.242+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:34:18.242+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:34:18.256+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:34:18.271+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:34:18.270+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T04:34:18.281+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:34:18.281+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T04:34:18.289+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-10T04:37:11.692+0000] {processor.py:157} INFO - Started process (PID=19472) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:37:11.696+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T04:37:11.705+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:37:11.702+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:37:11.734+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:37:11.781+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:37:11.781+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T04:37:11.804+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:37:11.804+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T04:37:11.998+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.318 seconds
[2024-08-10T04:37:42.380+0000] {processor.py:157} INFO - Started process (PID=19482) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:37:42.383+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T04:37:42.393+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:37:42.393+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:37:42.410+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:37:42.439+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:37:42.439+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T04:37:42.452+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:37:42.452+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T04:37:42.462+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-08-10T04:38:12.788+0000] {processor.py:157} INFO - Started process (PID=19492) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:38:12.790+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T04:38:12.793+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:38:12.792+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:38:12.803+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:38:12.818+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:38:12.817+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T04:38:12.828+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:38:12.828+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T04:38:12.839+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-10T04:38:43.190+0000] {processor.py:157} INFO - Started process (PID=19502) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:38:43.191+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T04:38:43.193+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:38:43.193+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:38:43.202+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:38:43.217+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:38:43.217+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T04:38:43.226+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:38:43.226+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T04:38:43.235+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-08-10T04:39:13.579+0000] {processor.py:157} INFO - Started process (PID=19512) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:39:13.580+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T04:39:13.583+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:39:13.582+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:39:13.591+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:39:13.608+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:39:13.608+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T04:39:13.620+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:39:13.620+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T04:39:13.627+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-10T04:39:43.980+0000] {processor.py:157} INFO - Started process (PID=19522) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:39:43.984+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T04:39:43.988+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:39:43.987+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:39:43.997+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:39:44.011+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:39:44.011+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T04:39:44.022+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:39:44.022+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T04:39:44.031+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-10T04:40:40.136+0000] {processor.py:157} INFO - Started process (PID=19534) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:40:40.138+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T04:40:40.142+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:40:40.141+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:40:40.158+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:40:40.182+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:40:40.182+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T04:40:40.196+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:40:40.196+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T04:40:40.207+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-08-10T04:49:07.163+0000] {processor.py:157} INFO - Started process (PID=19544) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:49:07.165+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T04:49:07.168+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:49:07.168+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:49:07.184+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:49:07.219+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:49:07.219+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T04:49:07.241+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:49:07.241+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T04:49:07.253+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-08-10T04:49:37.691+0000] {processor.py:157} INFO - Started process (PID=19554) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:49:37.694+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T04:49:37.698+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:49:37.698+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:49:37.714+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:49:37.743+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:49:37.743+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T04:49:37.757+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:49:37.757+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T04:49:37.766+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-08-10T04:50:08.022+0000] {processor.py:157} INFO - Started process (PID=19564) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:50:08.023+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T04:50:08.024+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:50:08.024+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:50:08.038+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:50:08.051+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:50:08.051+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T04:50:08.061+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:50:08.061+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T04:50:08.071+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-10T04:50:38.469+0000] {processor.py:157} INFO - Started process (PID=19574) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:50:38.472+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T04:50:38.474+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:50:38.473+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:50:38.488+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:50:38.502+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:50:38.502+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T04:50:38.513+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:50:38.513+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T04:50:38.521+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-10T04:51:08.920+0000] {processor.py:157} INFO - Started process (PID=19584) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:51:08.922+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T04:51:08.925+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:51:08.925+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:51:08.943+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:51:08.961+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:51:08.961+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T04:51:08.971+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:51:08.971+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T04:51:08.981+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-10T04:51:39.277+0000] {processor.py:157} INFO - Started process (PID=19594) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:51:39.279+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T04:51:39.283+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:51:39.283+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:51:39.299+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:51:39.320+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:51:39.320+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T04:51:39.333+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:51:39.333+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T04:51:39.340+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-10T04:52:09.536+0000] {processor.py:157} INFO - Started process (PID=19604) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:52:09.538+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T04:52:09.539+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:52:09.539+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:52:09.548+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:52:09.566+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:52:09.566+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T04:52:09.580+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:52:09.579+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T04:52:09.589+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-10T04:52:39.894+0000] {processor.py:157} INFO - Started process (PID=19614) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:52:39.895+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T04:52:39.896+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:52:39.896+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:52:39.907+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:52:39.928+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:52:39.928+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T04:52:39.940+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:52:39.940+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T04:52:39.951+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-10T04:53:10.254+0000] {processor.py:157} INFO - Started process (PID=19624) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:53:10.257+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T04:53:10.258+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:53:10.258+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:53:10.274+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:53:10.289+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:53:10.289+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T04:53:10.300+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:53:10.300+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T04:53:10.307+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-10T04:53:40.647+0000] {processor.py:157} INFO - Started process (PID=19634) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:53:40.648+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T04:53:40.650+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:53:40.650+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:53:40.660+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:53:40.677+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:53:40.677+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T04:53:40.689+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:53:40.689+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T04:53:40.700+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-10T04:54:11.057+0000] {processor.py:157} INFO - Started process (PID=19644) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:54:11.058+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T04:54:11.059+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:54:11.059+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:54:11.070+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:54:11.087+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:54:11.086+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T04:54:11.097+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:54:11.097+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T04:54:11.106+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-10T04:54:41.345+0000] {processor.py:157} INFO - Started process (PID=19654) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:54:41.347+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T04:54:41.350+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:54:41.349+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:54:41.363+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:54:41.381+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:54:41.381+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T04:54:41.394+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:54:41.394+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T04:54:41.402+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-10T04:55:11.732+0000] {processor.py:157} INFO - Started process (PID=19664) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:55:11.732+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T04:55:11.735+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:55:11.734+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:55:11.750+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:55:11.770+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:55:11.770+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T04:55:11.779+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:55:11.779+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T04:55:11.787+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-10T04:55:42.104+0000] {processor.py:157} INFO - Started process (PID=19674) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:55:42.105+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T04:55:42.107+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:55:42.107+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:55:42.122+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:55:42.143+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:55:42.143+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T04:55:42.155+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:55:42.155+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T04:55:42.165+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-10T04:56:12.410+0000] {processor.py:157} INFO - Started process (PID=19684) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:56:12.411+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T04:56:12.413+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:56:12.413+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:56:12.426+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:56:12.442+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:56:12.442+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T04:56:12.453+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:56:12.453+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T04:56:12.463+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-10T04:56:42.863+0000] {processor.py:157} INFO - Started process (PID=19694) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:56:42.864+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T04:56:42.866+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:56:42.866+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:56:42.875+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:56:42.892+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:56:42.892+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T04:56:42.902+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:56:42.902+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T04:56:42.909+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-10T04:57:13.204+0000] {processor.py:157} INFO - Started process (PID=19704) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:57:13.206+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T04:57:13.207+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:57:13.207+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:57:13.218+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:57:13.234+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:57:13.234+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T04:57:13.243+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:57:13.243+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T04:57:13.252+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-10T04:57:43.562+0000] {processor.py:157} INFO - Started process (PID=19714) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:57:43.564+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T04:57:43.566+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:57:43.566+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:57:43.576+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:57:43.594+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:57:43.594+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T04:57:43.606+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:57:43.606+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T04:57:43.616+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-10T04:58:13.999+0000] {processor.py:157} INFO - Started process (PID=19724) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:58:13.999+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T04:58:14.002+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:58:14.002+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:58:14.015+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:58:14.034+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:58:14.034+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T04:58:14.044+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:58:14.044+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T04:58:14.053+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-10T04:58:44.455+0000] {processor.py:157} INFO - Started process (PID=19734) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:58:44.456+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T04:58:44.459+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:58:44.459+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:58:44.473+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:58:44.494+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:58:44.494+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T04:58:44.506+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:58:44.506+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T04:58:44.514+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-10T04:59:14.843+0000] {processor.py:157} INFO - Started process (PID=19744) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:59:14.845+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T04:59:14.846+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:59:14.846+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:59:14.856+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:59:14.872+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:59:14.872+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T04:59:14.881+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:59:14.881+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T04:59:14.889+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-10T04:59:45.253+0000] {processor.py:157} INFO - Started process (PID=19754) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:59:45.255+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T04:59:45.257+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:59:45.256+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:59:45.269+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T04:59:45.287+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:59:45.287+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T04:59:45.298+0000] {logging_mixin.py:151} INFO - [2024-08-10T04:59:45.298+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T04:59:45.307+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-10T05:00:15.649+0000] {processor.py:157} INFO - Started process (PID=19764) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:00:15.651+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:00:15.653+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:00:15.652+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:00:15.662+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:00:15.676+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:00:15.676+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:00:15.687+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:00:15.687+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:00:15.694+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-10T05:00:46.058+0000] {processor.py:157} INFO - Started process (PID=19774) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:00:46.059+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:00:46.060+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:00:46.060+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:00:46.075+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:00:46.090+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:00:46.090+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:00:46.100+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:00:46.100+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:00:46.108+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-10T05:01:16.526+0000] {processor.py:157} INFO - Started process (PID=19784) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:01:16.528+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:01:16.530+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:01:16.530+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:01:16.541+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:01:16.557+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:01:16.557+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:01:16.567+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:01:16.567+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:01:16.575+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-10T05:01:46.882+0000] {processor.py:157} INFO - Started process (PID=19794) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:01:46.883+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:01:46.884+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:01:46.884+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:01:46.897+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:01:46.913+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:01:46.913+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:01:46.923+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:01:46.923+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:01:46.931+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-10T05:02:17.253+0000] {processor.py:157} INFO - Started process (PID=19804) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:02:17.255+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:02:17.258+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:02:17.258+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:02:17.278+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:02:17.304+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:02:17.304+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:02:17.320+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:02:17.320+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:02:17.331+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-08-10T05:02:47.628+0000] {processor.py:157} INFO - Started process (PID=19814) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:02:47.628+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:02:47.630+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:02:47.629+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:02:47.640+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:02:47.657+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:02:47.657+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:02:47.668+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:02:47.668+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:02:47.681+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-10T05:03:18.024+0000] {processor.py:157} INFO - Started process (PID=19824) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:03:18.024+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:03:18.026+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:03:18.026+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:03:18.037+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:03:18.053+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:03:18.053+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:03:18.064+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:03:18.064+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:03:18.071+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-10T05:03:48.455+0000] {processor.py:157} INFO - Started process (PID=19834) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:03:48.458+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:03:48.462+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:03:48.461+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:03:48.480+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:03:48.503+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:03:48.503+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:03:48.516+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:03:48.516+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:03:48.527+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-08-10T05:04:18.811+0000] {processor.py:157} INFO - Started process (PID=19844) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:04:18.811+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:04:18.813+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:04:18.813+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:04:18.823+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:04:18.840+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:04:18.840+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:04:18.851+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:04:18.851+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:04:18.859+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-10T05:04:49.191+0000] {processor.py:157} INFO - Started process (PID=19854) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:04:49.193+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:04:49.195+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:04:49.194+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:04:49.206+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:04:49.223+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:04:49.223+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:04:49.234+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:04:49.234+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:04:49.243+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-10T05:05:19.648+0000] {processor.py:157} INFO - Started process (PID=19864) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:05:19.648+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:05:19.650+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:05:19.650+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:05:19.661+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:05:19.676+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:05:19.676+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:05:19.687+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:05:19.687+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:05:19.695+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-10T05:05:50.024+0000] {processor.py:157} INFO - Started process (PID=19873) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:05:50.026+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:05:50.031+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:05:50.030+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:05:50.054+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:05:50.110+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:05:50.109+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:05:50.124+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:05:50.124+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:05:50.137+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-08-10T05:06:20.512+0000] {processor.py:157} INFO - Started process (PID=19884) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:06:20.514+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:06:20.516+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:06:20.516+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:06:20.527+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:06:20.543+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:06:20.543+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:06:20.553+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:06:20.553+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:06:20.563+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-10T05:06:50.912+0000] {processor.py:157} INFO - Started process (PID=19894) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:06:50.914+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:06:50.918+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:06:50.918+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:06:50.936+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:06:50.961+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:06:50.961+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:06:50.974+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:06:50.974+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:06:50.985+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-08-10T05:07:21.265+0000] {processor.py:157} INFO - Started process (PID=19904) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:07:21.270+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:07:21.272+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:07:21.272+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:07:21.281+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:07:21.294+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:07:21.294+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:07:21.303+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:07:21.303+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:07:21.313+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-10T05:07:51.609+0000] {processor.py:157} INFO - Started process (PID=19914) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:07:51.612+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:07:51.615+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:07:51.615+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:07:51.634+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:07:51.656+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:07:51.656+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:07:51.668+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:07:51.668+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:07:51.679+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-10T05:08:22.023+0000] {processor.py:157} INFO - Started process (PID=19924) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:08:22.024+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:08:22.026+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:08:22.026+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:08:22.038+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:08:22.055+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:08:22.055+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:08:22.066+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:08:22.066+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:08:22.076+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-10T05:08:52.433+0000] {processor.py:157} INFO - Started process (PID=19934) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:08:52.434+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:08:52.438+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:08:52.438+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:08:52.454+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:08:52.478+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:08:52.478+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:08:52.491+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:08:52.491+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:08:52.501+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-10T05:09:22.887+0000] {processor.py:157} INFO - Started process (PID=19944) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:09:22.888+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:09:22.890+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:09:22.889+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:09:22.899+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:09:22.917+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:09:22.917+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:09:22.930+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:09:22.930+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:09:22.941+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-10T05:09:53.387+0000] {processor.py:157} INFO - Started process (PID=19954) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:09:53.388+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:09:53.390+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:09:53.390+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:09:53.399+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:09:53.417+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:09:53.417+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:09:53.430+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:09:53.430+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:09:53.438+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-10T05:10:23.826+0000] {processor.py:157} INFO - Started process (PID=19964) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:10:23.828+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:10:23.830+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:10:23.830+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:10:23.841+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:10:23.859+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:10:23.859+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:10:23.872+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:10:23.872+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:10:23.882+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-10T05:10:54.182+0000] {processor.py:157} INFO - Started process (PID=19974) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:10:54.184+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:10:54.187+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:10:54.186+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:10:54.203+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:10:54.225+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:10:54.225+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:10:54.237+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:10:54.237+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:10:54.246+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-10T05:11:24.552+0000] {processor.py:157} INFO - Started process (PID=19984) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:11:24.552+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:11:24.554+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:11:24.554+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:11:24.566+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:11:24.582+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:11:24.582+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:11:24.592+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:11:24.592+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:11:24.601+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-10T05:11:54.991+0000] {processor.py:157} INFO - Started process (PID=19994) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:11:54.992+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:11:54.994+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:11:54.994+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:11:55.008+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:11:55.025+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:11:55.025+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:11:55.036+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:11:55.036+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:11:55.046+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-10T05:12:25.414+0000] {processor.py:157} INFO - Started process (PID=20004) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:12:25.416+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:12:25.417+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:12:25.417+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:12:25.426+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:12:25.442+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:12:25.441+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:12:25.452+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:12:25.452+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:12:25.461+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-10T05:12:55.893+0000] {processor.py:157} INFO - Started process (PID=20014) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:12:55.894+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:12:55.898+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:12:55.898+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:12:55.916+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:12:55.956+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:12:55.956+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:12:55.969+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:12:55.969+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:12:55.980+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-08-10T05:13:26.248+0000] {processor.py:157} INFO - Started process (PID=20024) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:13:26.249+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:13:26.250+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:13:26.250+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:13:26.259+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:13:26.275+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:13:26.275+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:13:26.285+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:13:26.285+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:13:26.295+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-10T05:13:56.664+0000] {processor.py:157} INFO - Started process (PID=20034) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:13:56.665+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:13:56.667+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:13:56.667+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:13:56.677+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:13:56.693+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:13:56.693+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:13:56.703+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:13:56.703+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:13:56.712+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-10T05:14:27.053+0000] {processor.py:157} INFO - Started process (PID=20044) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:14:27.055+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:14:27.058+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:14:27.058+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:14:27.073+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:14:27.095+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:14:27.095+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:14:27.107+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:14:27.107+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:14:27.116+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-10T05:14:57.341+0000] {processor.py:157} INFO - Started process (PID=20054) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:14:57.342+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:14:57.345+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:14:57.344+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:14:57.354+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:14:57.371+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:14:57.371+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:14:57.383+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:14:57.383+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:14:57.393+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-10T05:15:27.743+0000] {processor.py:157} INFO - Started process (PID=20064) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:15:27.744+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:15:27.746+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:15:27.746+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:15:27.754+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:15:27.770+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:15:27.770+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:15:27.783+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:15:27.783+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:15:27.793+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-10T05:15:58.186+0000] {processor.py:157} INFO - Started process (PID=20074) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:15:58.190+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:15:58.194+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:15:58.194+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:15:58.215+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:15:58.233+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:15:58.233+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:15:58.246+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:15:58.246+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:15:58.256+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-10T05:16:28.502+0000] {processor.py:157} INFO - Started process (PID=20084) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:16:28.503+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:16:28.505+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:16:28.504+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:16:28.520+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:16:28.535+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:16:28.535+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:16:28.546+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:16:28.546+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:16:28.557+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-10T05:16:58.950+0000] {processor.py:157} INFO - Started process (PID=20094) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:16:58.953+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:16:58.955+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:16:58.955+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:16:58.964+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:16:58.981+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:16:58.980+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:16:58.991+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:16:58.991+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:16:58.999+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-10T05:17:29.369+0000] {processor.py:157} INFO - Started process (PID=20104) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:17:29.370+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:17:29.375+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:17:29.374+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:17:29.392+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:17:29.409+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:17:29.409+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:17:29.418+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:17:29.418+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:17:29.427+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-10T05:17:59.772+0000] {processor.py:157} INFO - Started process (PID=20114) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:17:59.774+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:17:59.778+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:17:59.777+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:17:59.791+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:17:59.813+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:17:59.813+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:17:59.826+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:17:59.826+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:17:59.837+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-10T05:18:30.243+0000] {processor.py:157} INFO - Started process (PID=20124) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:18:30.243+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:18:30.246+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:18:30.246+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:18:30.254+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:18:30.271+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:18:30.271+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:18:30.282+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:18:30.282+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:18:30.291+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-10T05:19:00.660+0000] {processor.py:157} INFO - Started process (PID=20134) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:19:00.662+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:19:00.666+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:19:00.665+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:19:00.684+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:19:00.705+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:19:00.705+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:19:00.715+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:19:00.714+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:19:00.724+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-10T05:19:31.063+0000] {processor.py:157} INFO - Started process (PID=20144) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:19:31.064+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:19:31.066+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:19:31.066+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:19:31.084+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:19:31.099+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:19:31.099+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:19:31.111+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:19:31.111+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:19:31.121+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-10T05:20:01.374+0000] {processor.py:157} INFO - Started process (PID=20154) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:20:01.375+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:20:01.377+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:20:01.376+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:20:01.386+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:20:01.402+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:20:01.402+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:20:01.412+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:20:01.412+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:20:01.421+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-10T05:20:31.710+0000] {processor.py:157} INFO - Started process (PID=20164) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:20:31.711+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:20:31.713+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:20:31.713+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:20:31.729+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:20:31.744+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:20:31.743+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:20:31.753+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:20:31.753+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:20:31.764+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-10T05:21:02.045+0000] {processor.py:157} INFO - Started process (PID=20173) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:21:02.047+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:21:02.050+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:21:02.049+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:21:02.068+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:21:02.095+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:21:02.095+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:21:02.107+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:21:02.107+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:21:02.116+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-08-10T05:21:32.547+0000] {processor.py:157} INFO - Started process (PID=20184) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:21:32.549+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:21:32.551+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:21:32.550+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:21:32.560+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:21:32.576+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:21:32.576+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:21:32.586+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:21:32.586+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:21:32.596+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-10T05:22:02.930+0000] {processor.py:157} INFO - Started process (PID=20194) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:22:02.934+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:22:02.937+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:22:02.937+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:22:02.948+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:22:02.963+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:22:02.963+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:22:02.974+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:22:02.974+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:22:02.984+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-10T05:22:33.299+0000] {processor.py:157} INFO - Started process (PID=20204) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:22:33.301+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:22:33.303+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:22:33.302+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:22:33.312+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:22:33.329+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:22:33.329+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:22:33.339+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:22:33.339+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:22:33.346+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-10T05:23:03.704+0000] {processor.py:157} INFO - Started process (PID=20214) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:23:03.705+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:23:03.709+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:23:03.708+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:23:03.725+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:23:03.749+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:23:03.749+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:23:03.762+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:23:03.762+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:23:03.770+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-10T05:23:34.119+0000] {processor.py:157} INFO - Started process (PID=20224) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:23:34.120+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:23:34.122+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:23:34.122+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:23:34.132+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:23:34.163+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:23:34.163+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:23:34.174+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:23:34.174+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:23:34.187+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-10T05:24:04.604+0000] {processor.py:157} INFO - Started process (PID=20234) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:24:04.605+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:24:04.607+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:24:04.606+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:24:04.618+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:24:04.640+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:24:04.640+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:24:04.651+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:24:04.651+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:24:04.662+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-10T05:24:34.981+0000] {processor.py:157} INFO - Started process (PID=20244) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:24:34.982+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:24:34.993+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:24:34.993+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:24:35.007+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:24:35.029+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:24:35.029+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:24:35.039+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:24:35.039+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:24:35.050+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-10T05:25:05.428+0000] {processor.py:157} INFO - Started process (PID=20254) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:25:05.429+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:25:05.431+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:25:05.431+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:25:05.442+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:25:05.463+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:25:05.463+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:25:05.474+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:25:05.474+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:25:05.486+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-10T05:25:35.802+0000] {processor.py:157} INFO - Started process (PID=20264) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:25:35.803+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:25:35.806+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:25:35.805+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:25:35.814+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:25:35.831+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:25:35.831+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:25:35.842+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:25:35.842+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:25:35.851+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-10T05:26:06.240+0000] {processor.py:157} INFO - Started process (PID=20274) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:26:06.244+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:26:06.247+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:26:06.247+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:26:06.264+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:26:06.286+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:26:06.285+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:26:06.298+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:26:06.298+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:26:06.307+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-10T05:26:36.613+0000] {processor.py:157} INFO - Started process (PID=20284) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:26:36.614+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:26:36.616+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:26:36.616+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:26:36.628+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:26:36.648+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:26:36.648+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:26:36.658+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:26:36.658+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:26:36.667+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-10T05:27:07.026+0000] {processor.py:157} INFO - Started process (PID=20294) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:27:07.027+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:27:07.029+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:27:07.029+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:27:07.041+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:27:07.059+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:27:07.058+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:27:07.069+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:27:07.069+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:27:07.080+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-10T05:27:37.347+0000] {processor.py:157} INFO - Started process (PID=20304) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:27:37.349+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:27:37.352+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:27:37.351+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:27:37.368+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:27:37.387+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:27:37.387+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:27:37.399+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:27:37.399+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:27:37.410+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-10T05:28:07.783+0000] {processor.py:157} INFO - Started process (PID=20314) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:28:07.785+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:28:07.787+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:28:07.787+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:28:07.806+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:28:07.828+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:28:07.828+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:28:07.840+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:28:07.840+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:28:07.846+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-10T05:28:38.182+0000] {processor.py:157} INFO - Started process (PID=20324) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:28:38.183+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:28:38.185+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:28:38.185+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:28:38.196+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:28:38.210+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:28:38.210+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:28:38.220+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:28:38.220+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:28:38.228+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-10T05:29:08.564+0000] {processor.py:157} INFO - Started process (PID=20334) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:29:08.565+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:29:08.566+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:29:08.566+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:29:08.576+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:29:08.596+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:29:08.596+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:29:08.607+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:29:08.607+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:29:08.617+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-10T05:29:38.996+0000] {processor.py:157} INFO - Started process (PID=20344) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:29:38.998+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:29:39.001+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:29:39.001+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:29:39.019+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:29:39.042+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:29:39.042+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:29:39.054+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:29:39.054+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:29:39.065+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-10T05:30:09.385+0000] {processor.py:157} INFO - Started process (PID=20354) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:30:09.387+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:30:09.389+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:30:09.389+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:30:09.406+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:30:09.421+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:30:09.420+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:30:09.432+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:30:09.432+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:30:09.443+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-10T05:30:39.690+0000] {processor.py:157} INFO - Started process (PID=20364) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:30:39.692+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:30:39.693+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:30:39.693+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:30:39.710+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:30:39.725+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:30:39.725+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:30:39.738+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:30:39.738+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:30:39.746+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-10T05:31:10.096+0000] {processor.py:157} INFO - Started process (PID=20374) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:31:10.097+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:31:10.102+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:31:10.101+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:31:10.118+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:31:10.138+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:31:10.138+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:31:10.150+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:31:10.150+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:31:10.159+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-10T05:31:40.492+0000] {processor.py:157} INFO - Started process (PID=20384) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:31:40.493+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:31:40.495+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:31:40.495+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:31:40.512+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:31:40.530+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:31:40.530+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:31:40.541+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:31:40.541+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:31:40.551+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-10T05:32:10.848+0000] {processor.py:157} INFO - Started process (PID=20394) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:32:10.850+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:32:10.851+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:32:10.851+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:32:10.861+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:32:10.878+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:32:10.878+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:32:10.888+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:32:10.888+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:32:10.896+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-10T05:32:41.281+0000] {processor.py:157} INFO - Started process (PID=20404) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:32:41.285+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:32:41.287+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:32:41.287+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:32:41.309+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:32:41.340+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:32:41.340+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:32:41.354+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:32:41.354+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:32:41.366+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-08-10T05:33:11.652+0000] {processor.py:157} INFO - Started process (PID=20414) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:33:11.653+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:33:11.654+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:33:11.654+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:33:11.664+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:33:11.683+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:33:11.682+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:33:11.694+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:33:11.694+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:33:11.703+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-10T05:33:42.078+0000] {processor.py:157} INFO - Started process (PID=20423) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:33:42.079+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:33:42.084+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:33:42.084+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:33:42.120+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:33:42.147+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:33:42.147+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:33:42.163+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:33:42.163+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:33:42.174+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-08-10T05:34:12.507+0000] {processor.py:157} INFO - Started process (PID=20434) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:34:12.508+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:34:12.511+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:34:12.511+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:34:12.525+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:34:12.542+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:34:12.542+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:34:12.556+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:34:12.556+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:34:12.568+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-10T05:34:42.920+0000] {processor.py:157} INFO - Started process (PID=20444) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:34:42.922+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:34:42.927+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:34:42.926+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:34:42.942+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:34:42.960+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:34:42.960+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:34:42.970+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:34:42.970+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:34:42.979+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-10T05:35:13.276+0000] {processor.py:157} INFO - Started process (PID=20454) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:35:13.277+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:35:13.280+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:35:13.280+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:35:13.299+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:35:13.314+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:35:13.314+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:35:13.337+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:35:13.337+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:35:13.346+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-10T05:35:43.654+0000] {processor.py:157} INFO - Started process (PID=20464) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:35:43.656+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:35:43.659+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:35:43.659+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:35:43.673+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:35:43.691+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:35:43.690+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:35:43.702+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:35:43.702+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:35:43.711+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-10T05:36:13.989+0000] {processor.py:157} INFO - Started process (PID=20474) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:36:13.990+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:36:13.993+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:36:13.992+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:36:14.017+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:36:14.038+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:36:14.038+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:36:14.052+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:36:14.052+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:36:14.062+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-08-10T05:36:44.383+0000] {processor.py:157} INFO - Started process (PID=20483) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:36:44.385+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:36:44.389+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:36:44.389+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:36:44.411+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:36:44.456+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:36:44.456+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:36:44.471+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:36:44.471+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:36:44.481+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-08-10T05:37:14.767+0000] {processor.py:157} INFO - Started process (PID=20494) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:37:14.768+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:37:14.771+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:37:14.771+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:37:14.794+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:37:14.826+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:37:14.826+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:37:14.838+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:37:14.838+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:37:14.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-10T05:37:45.275+0000] {processor.py:157} INFO - Started process (PID=20504) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:37:45.278+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:37:45.279+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:37:45.279+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:37:45.290+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:37:45.306+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:37:45.306+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:37:45.319+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:37:45.319+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:37:45.329+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-10T05:38:15.642+0000] {processor.py:157} INFO - Started process (PID=20514) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:38:15.643+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:38:15.645+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:38:15.645+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:38:15.656+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:38:15.675+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:38:15.675+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:38:15.690+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:38:15.689+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:38:15.700+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-10T05:38:46.082+0000] {processor.py:157} INFO - Started process (PID=20523) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:38:46.084+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:38:46.087+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:38:46.086+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:38:46.138+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:38:46.171+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:38:46.171+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:38:46.187+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:38:46.187+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:38:46.199+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-08-10T05:39:16.524+0000] {processor.py:157} INFO - Started process (PID=20534) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:39:16.525+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:39:16.527+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:39:16.527+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:39:16.537+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:39:16.555+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:39:16.555+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:39:16.565+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:39:16.565+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:39:16.574+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-10T05:39:46.936+0000] {processor.py:157} INFO - Started process (PID=20544) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:39:46.937+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:39:46.938+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:39:46.938+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:39:46.949+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:39:46.965+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:39:46.965+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:39:46.975+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:39:46.975+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:39:46.982+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-10T05:40:17.384+0000] {processor.py:157} INFO - Started process (PID=20554) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:40:17.387+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:40:17.389+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:40:17.389+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:40:17.411+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:40:17.426+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:40:17.426+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:40:17.436+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:40:17.436+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:40:17.445+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-10T05:40:47.761+0000] {processor.py:157} INFO - Started process (PID=20564) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:40:47.762+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:40:47.764+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:40:47.764+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:40:47.779+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:40:47.802+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:40:47.802+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:40:47.817+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:40:47.817+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:40:47.826+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-10T05:41:18.129+0000] {processor.py:157} INFO - Started process (PID=20574) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:41:18.131+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:41:18.133+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:41:18.132+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:41:18.148+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:41:18.165+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:41:18.164+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:41:18.175+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:41:18.175+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:41:18.185+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-10T05:41:48.522+0000] {processor.py:157} INFO - Started process (PID=20584) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:41:48.524+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:41:48.526+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:41:48.525+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:41:48.541+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:41:48.558+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:41:48.558+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:41:48.569+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:41:48.569+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:41:48.576+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-10T05:42:18.938+0000] {processor.py:157} INFO - Started process (PID=20594) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:42:18.942+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:42:18.945+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:42:18.945+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:42:18.963+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:42:18.984+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:42:18.984+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:42:18.997+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:42:18.997+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:42:19.007+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-10T05:42:49.357+0000] {processor.py:157} INFO - Started process (PID=20604) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:42:49.360+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:42:49.362+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:42:49.362+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:42:49.371+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:42:49.388+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:42:49.388+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:42:49.400+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:42:49.400+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:42:49.408+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-10T05:43:19.672+0000] {processor.py:157} INFO - Started process (PID=20614) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:43:19.673+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:43:19.675+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:43:19.675+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:43:19.684+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:43:19.700+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:43:19.700+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:43:19.711+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:43:19.711+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:43:19.720+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-10T05:43:50.066+0000] {processor.py:157} INFO - Started process (PID=20624) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:43:50.068+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:43:50.072+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:43:50.072+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:43:50.089+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:43:50.106+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:43:50.106+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:43:50.115+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:43:50.115+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:43:50.126+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-10T05:44:20.532+0000] {processor.py:157} INFO - Started process (PID=20634) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:44:20.533+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:44:20.535+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:44:20.535+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:44:20.551+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:44:20.569+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:44:20.568+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:44:20.582+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:44:20.582+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:44:20.593+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-10T05:44:50.915+0000] {processor.py:157} INFO - Started process (PID=20644) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:44:50.916+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:44:50.917+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:44:50.917+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:44:50.927+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:44:50.946+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:44:50.946+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:44:50.958+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:44:50.958+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:44:50.965+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-10T05:45:21.297+0000] {processor.py:157} INFO - Started process (PID=20654) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:45:21.298+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:45:21.301+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:45:21.301+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:45:21.319+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:45:21.338+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:45:21.338+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:45:21.348+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:45:21.348+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:45:21.357+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-10T05:45:51.702+0000] {processor.py:157} INFO - Started process (PID=20664) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:45:51.702+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:45:51.704+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:45:51.704+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:45:51.715+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:45:51.736+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:45:51.736+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:45:51.749+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:45:51.749+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:45:51.759+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-10T05:46:22.154+0000] {processor.py:157} INFO - Started process (PID=20674) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:46:22.155+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:46:22.157+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:46:22.157+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:46:22.169+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:46:22.184+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:46:22.184+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:46:22.198+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:46:22.197+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:46:22.207+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-10T05:46:52.541+0000] {processor.py:157} INFO - Started process (PID=20684) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:46:52.541+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:46:52.544+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:46:52.544+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:46:52.560+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:46:52.576+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:46:52.576+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:46:52.586+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:46:52.586+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:46:52.594+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-10T05:47:22.957+0000] {processor.py:157} INFO - Started process (PID=20694) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:47:22.958+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:47:22.959+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:47:22.959+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:47:22.981+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:47:22.998+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:47:22.998+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:47:23.009+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:47:23.009+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:47:23.020+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-10T05:47:53.425+0000] {processor.py:157} INFO - Started process (PID=20704) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:47:53.426+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:47:53.428+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:47:53.427+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:47:53.439+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:47:53.456+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:47:53.456+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:47:53.467+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:47:53.467+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:47:53.476+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-10T05:48:23.771+0000] {processor.py:157} INFO - Started process (PID=20714) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:48:23.771+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:48:23.773+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:48:23.773+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:48:23.784+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:48:23.800+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:48:23.800+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:48:23.810+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:48:23.810+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:48:23.819+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-10T05:48:54.142+0000] {processor.py:157} INFO - Started process (PID=20724) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:48:54.144+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:48:54.147+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:48:54.147+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:48:54.165+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:48:54.184+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:48:54.184+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:48:54.194+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:48:54.194+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:48:54.202+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-10T05:49:24.702+0000] {processor.py:157} INFO - Started process (PID=20734) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:49:24.703+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T05:49:24.706+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:49:24.706+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:49:24.727+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T05:49:24.754+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:49:24.754+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T05:49:24.770+0000] {logging_mixin.py:151} INFO - [2024-08-10T05:49:24.769+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T05:49:24.780+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-08-10T06:05:58.007+0000] {processor.py:157} INFO - Started process (PID=20744) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T06:05:58.008+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T06:05:58.010+0000] {logging_mixin.py:151} INFO - [2024-08-10T06:05:58.010+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T06:05:58.022+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T06:05:58.038+0000] {logging_mixin.py:151} INFO - [2024-08-10T06:05:58.038+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T06:05:58.047+0000] {logging_mixin.py:151} INFO - [2024-08-10T06:05:58.047+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T06:05:58.055+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-10T06:06:32.044+0000] {processor.py:157} INFO - Started process (PID=20755) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T06:06:32.045+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T06:06:32.056+0000] {logging_mixin.py:151} INFO - [2024-08-10T06:06:32.054+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T06:06:32.078+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T06:06:32.113+0000] {logging_mixin.py:151} INFO - [2024-08-10T06:06:32.113+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T06:06:32.126+0000] {logging_mixin.py:151} INFO - [2024-08-10T06:06:32.126+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T06:06:32.138+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-08-10T06:07:02.355+0000] {processor.py:157} INFO - Started process (PID=20766) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T06:07:02.356+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T06:07:02.359+0000] {logging_mixin.py:151} INFO - [2024-08-10T06:07:02.359+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T06:07:02.373+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T06:07:02.390+0000] {logging_mixin.py:151} INFO - [2024-08-10T06:07:02.390+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T06:07:02.399+0000] {logging_mixin.py:151} INFO - [2024-08-10T06:07:02.399+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T06:07:02.406+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-10T06:24:47.213+0000] {processor.py:157} INFO - Started process (PID=20777) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T06:24:47.217+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T06:24:47.220+0000] {logging_mixin.py:151} INFO - [2024-08-10T06:24:47.220+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T06:24:47.246+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T06:24:47.291+0000] {logging_mixin.py:151} INFO - [2024-08-10T06:24:47.291+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T06:24:47.326+0000] {logging_mixin.py:151} INFO - [2024-08-10T06:24:47.325+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T06:24:47.352+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.142 seconds
[2024-08-10T06:25:17.719+0000] {processor.py:157} INFO - Started process (PID=20787) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T06:25:17.723+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T06:25:17.731+0000] {logging_mixin.py:151} INFO - [2024-08-10T06:25:17.730+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T06:25:17.758+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T06:25:17.794+0000] {logging_mixin.py:151} INFO - [2024-08-10T06:25:17.794+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T06:25:17.811+0000] {logging_mixin.py:151} INFO - [2024-08-10T06:25:17.811+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T06:25:17.822+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-08-10T06:25:48.010+0000] {processor.py:157} INFO - Started process (PID=20798) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T06:25:48.011+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T06:25:48.012+0000] {logging_mixin.py:151} INFO - [2024-08-10T06:25:48.012+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T06:25:48.026+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T06:25:48.040+0000] {logging_mixin.py:151} INFO - [2024-08-10T06:25:48.040+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T06:25:48.051+0000] {logging_mixin.py:151} INFO - [2024-08-10T06:25:48.051+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T06:25:48.061+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-10T06:38:23.709+0000] {processor.py:157} INFO - Started process (PID=20809) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T06:38:23.713+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T06:38:23.715+0000] {logging_mixin.py:151} INFO - [2024-08-10T06:38:23.715+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T06:38:23.734+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T06:38:23.762+0000] {logging_mixin.py:151} INFO - [2024-08-10T06:38:23.762+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T06:38:23.788+0000] {logging_mixin.py:151} INFO - [2024-08-10T06:38:23.788+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T06:38:23.804+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-08-10T06:38:54.158+0000] {processor.py:157} INFO - Started process (PID=20819) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T06:38:54.159+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T06:38:54.163+0000] {logging_mixin.py:151} INFO - [2024-08-10T06:38:54.163+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T06:38:54.183+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T06:38:54.216+0000] {logging_mixin.py:151} INFO - [2024-08-10T06:38:54.216+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T06:38:54.229+0000] {logging_mixin.py:151} INFO - [2024-08-10T06:38:54.229+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T06:38:54.239+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-08-10T06:50:13.097+0000] {processor.py:157} INFO - Started process (PID=20830) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T06:50:13.102+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T06:50:13.104+0000] {logging_mixin.py:151} INFO - [2024-08-10T06:50:13.104+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T06:50:13.126+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T06:50:13.159+0000] {logging_mixin.py:151} INFO - [2024-08-10T06:50:13.159+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T06:50:13.181+0000] {logging_mixin.py:151} INFO - [2024-08-10T06:50:13.181+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T06:50:13.198+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-08-10T06:51:11.078+0000] {processor.py:157} INFO - Started process (PID=20840) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T06:51:11.079+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T06:51:11.081+0000] {logging_mixin.py:151} INFO - [2024-08-10T06:51:11.081+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T06:51:11.095+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T06:51:11.116+0000] {logging_mixin.py:151} INFO - [2024-08-10T06:51:11.116+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T06:51:11.125+0000] {logging_mixin.py:151} INFO - [2024-08-10T06:51:11.125+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T06:51:11.134+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-10T06:51:41.474+0000] {processor.py:157} INFO - Started process (PID=20850) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T06:51:41.475+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T06:51:41.479+0000] {logging_mixin.py:151} INFO - [2024-08-10T06:51:41.478+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T06:51:41.494+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T06:51:41.525+0000] {logging_mixin.py:151} INFO - [2024-08-10T06:51:41.524+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T06:51:41.535+0000] {logging_mixin.py:151} INFO - [2024-08-10T06:51:41.535+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T06:51:41.545+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-08-10T07:08:09.587+0000] {processor.py:157} INFO - Started process (PID=20860) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T07:08:09.587+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T07:08:09.591+0000] {logging_mixin.py:151} INFO - [2024-08-10T07:08:09.590+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T07:08:09.603+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T07:08:09.622+0000] {logging_mixin.py:151} INFO - [2024-08-10T07:08:09.622+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T07:08:09.634+0000] {logging_mixin.py:151} INFO - [2024-08-10T07:08:09.634+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T07:08:09.642+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-10T07:23:57.974+0000] {processor.py:157} INFO - Started process (PID=20871) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T07:23:57.982+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T07:23:57.986+0000] {logging_mixin.py:151} INFO - [2024-08-10T07:23:57.986+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T07:23:58.008+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T07:23:58.042+0000] {logging_mixin.py:151} INFO - [2024-08-10T07:23:58.042+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T07:23:58.057+0000] {logging_mixin.py:151} INFO - [2024-08-10T07:23:58.057+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T07:23:58.074+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-08-10T07:24:28.455+0000] {processor.py:157} INFO - Started process (PID=20882) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T07:24:28.456+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T07:24:28.461+0000] {logging_mixin.py:151} INFO - [2024-08-10T07:24:28.461+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T07:24:28.477+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T07:24:28.500+0000] {logging_mixin.py:151} INFO - [2024-08-10T07:24:28.500+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T07:24:28.513+0000] {logging_mixin.py:151} INFO - [2024-08-10T07:24:28.513+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T07:24:28.524+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-10T07:24:58.885+0000] {processor.py:157} INFO - Started process (PID=20892) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T07:24:58.886+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T07:24:58.889+0000] {logging_mixin.py:151} INFO - [2024-08-10T07:24:58.889+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T07:24:58.913+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T07:24:58.930+0000] {logging_mixin.py:151} INFO - [2024-08-10T07:24:58.930+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T07:24:58.943+0000] {logging_mixin.py:151} INFO - [2024-08-10T07:24:58.943+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T07:24:58.951+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-10T07:25:29.263+0000] {processor.py:157} INFO - Started process (PID=20902) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T07:25:29.263+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T07:25:29.265+0000] {logging_mixin.py:151} INFO - [2024-08-10T07:25:29.264+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T07:25:29.281+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T07:25:29.293+0000] {logging_mixin.py:151} INFO - [2024-08-10T07:25:29.293+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T07:25:29.302+0000] {logging_mixin.py:151} INFO - [2024-08-10T07:25:29.302+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T07:25:29.310+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-10T07:25:59.563+0000] {processor.py:157} INFO - Started process (PID=20912) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T07:25:59.564+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T07:25:59.566+0000] {logging_mixin.py:151} INFO - [2024-08-10T07:25:59.565+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T07:25:59.575+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T07:25:59.592+0000] {logging_mixin.py:151} INFO - [2024-08-10T07:25:59.592+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T07:25:59.603+0000] {logging_mixin.py:151} INFO - [2024-08-10T07:25:59.603+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T07:25:59.610+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-10T07:26:29.940+0000] {processor.py:157} INFO - Started process (PID=20922) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T07:26:29.942+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T07:26:29.946+0000] {logging_mixin.py:151} INFO - [2024-08-10T07:26:29.946+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T07:26:29.963+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T07:26:29.986+0000] {logging_mixin.py:151} INFO - [2024-08-10T07:26:29.986+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T07:26:29.999+0000] {logging_mixin.py:151} INFO - [2024-08-10T07:26:29.999+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T07:26:30.010+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-08-10T07:27:00.298+0000] {processor.py:157} INFO - Started process (PID=20932) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T07:27:00.300+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T07:27:00.301+0000] {logging_mixin.py:151} INFO - [2024-08-10T07:27:00.301+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T07:27:00.310+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T07:27:00.326+0000] {logging_mixin.py:151} INFO - [2024-08-10T07:27:00.326+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T07:27:00.336+0000] {logging_mixin.py:151} INFO - [2024-08-10T07:27:00.336+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T07:27:00.348+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-10T07:44:14.127+0000] {processor.py:157} INFO - Started process (PID=20942) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T07:44:14.128+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T07:44:14.130+0000] {logging_mixin.py:151} INFO - [2024-08-10T07:44:14.130+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T07:44:14.143+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T07:44:14.190+0000] {logging_mixin.py:151} INFO - [2024-08-10T07:44:14.190+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T07:44:14.222+0000] {logging_mixin.py:151} INFO - [2024-08-10T07:44:14.222+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T07:44:14.245+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-08-10T08:02:18.357+0000] {processor.py:157} INFO - Started process (PID=20952) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:02:18.364+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T08:02:18.370+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:02:18.369+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:02:18.386+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:02:18.440+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:02:18.440+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T08:02:18.479+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:02:18.479+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T08:02:18.505+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.159 seconds
[2024-08-10T08:02:48.808+0000] {processor.py:157} INFO - Started process (PID=20961) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:02:48.810+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T08:02:48.821+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:02:48.821+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:02:48.842+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:02:48.865+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:02:48.865+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T08:02:48.887+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:02:48.887+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T08:02:48.898+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-08-10T08:15:00.950+0000] {processor.py:157} INFO - Started process (PID=20973) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:15:00.954+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T08:15:00.959+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:15:00.958+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:15:01.025+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:15:01.095+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:15:01.095+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T08:15:01.131+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:15:01.130+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T08:15:01.173+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.228 seconds
[2024-08-10T08:15:31.261+0000] {processor.py:157} INFO - Started process (PID=20983) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:15:31.262+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T08:15:31.266+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:15:31.266+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:15:31.285+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:15:31.323+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:15:31.323+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T08:15:31.338+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:15:31.337+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T08:15:31.349+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-08-10T08:16:01.702+0000] {processor.py:157} INFO - Started process (PID=20993) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:16:01.707+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T08:16:01.712+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:16:01.711+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:16:01.742+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:16:01.786+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:16:01.785+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T08:16:01.802+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:16:01.802+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T08:16:01.814+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-08-10T08:16:32.002+0000] {processor.py:157} INFO - Started process (PID=21003) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:16:32.003+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T08:16:32.007+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:16:32.007+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:16:32.028+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:16:32.059+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:16:32.059+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T08:16:32.077+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:16:32.077+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T08:16:32.091+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-08-10T08:17:02.315+0000] {processor.py:157} INFO - Started process (PID=21013) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:17:02.316+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T08:17:02.318+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:17:02.318+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:17:02.328+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:17:02.346+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:17:02.346+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T08:17:02.358+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:17:02.358+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T08:17:02.366+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-10T08:17:32.682+0000] {processor.py:157} INFO - Started process (PID=21023) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:17:32.686+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T08:17:32.692+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:17:32.690+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:17:32.713+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:17:32.754+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:17:32.754+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T08:17:32.770+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:17:32.770+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T08:17:32.781+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-08-10T08:18:02.981+0000] {processor.py:157} INFO - Started process (PID=21033) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:18:02.982+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T08:18:02.984+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:18:02.984+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:18:02.997+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:18:03.017+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:18:03.017+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T08:18:03.029+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:18:03.029+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T08:18:03.041+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-10T08:18:33.315+0000] {processor.py:157} INFO - Started process (PID=21042) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:18:33.317+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T08:18:33.323+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:18:33.322+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:18:33.343+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:18:33.382+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:18:33.382+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T08:18:33.399+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:18:33.399+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T08:18:33.410+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-08-10T08:19:03.554+0000] {processor.py:157} INFO - Started process (PID=21053) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:19:03.557+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T08:19:03.559+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:19:03.559+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:19:03.571+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:19:03.589+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:19:03.589+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T08:19:03.600+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:19:03.600+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T08:19:03.610+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-10T08:19:34.007+0000] {processor.py:157} INFO - Started process (PID=21063) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:19:34.008+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T08:19:34.013+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:19:34.013+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:19:34.047+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:19:34.077+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:19:34.077+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T08:19:34.093+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:19:34.092+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T08:19:34.103+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-08-10T08:20:04.373+0000] {processor.py:157} INFO - Started process (PID=21073) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:20:04.376+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T08:20:04.382+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:20:04.381+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:20:04.401+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:20:04.431+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:20:04.431+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T08:20:04.448+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:20:04.448+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T08:20:04.464+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-08-10T08:20:34.730+0000] {processor.py:157} INFO - Started process (PID=21083) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:20:34.732+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T08:20:34.738+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:20:34.738+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:20:34.759+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:20:34.788+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:20:34.787+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T08:20:34.800+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:20:34.800+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T08:20:34.812+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-10T08:21:05.100+0000] {processor.py:157} INFO - Started process (PID=21093) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:21:05.105+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T08:21:05.109+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:21:05.109+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:21:05.127+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:21:05.196+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:21:05.196+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T08:21:05.211+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:21:05.211+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T08:21:05.221+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-08-10T08:21:35.436+0000] {processor.py:157} INFO - Started process (PID=21103) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:21:35.438+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T08:21:35.440+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:21:35.440+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:21:35.458+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:21:35.480+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:21:35.480+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T08:21:35.497+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:21:35.497+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T08:21:35.508+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-08-10T08:22:05.872+0000] {processor.py:157} INFO - Started process (PID=21113) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:22:05.876+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T08:22:05.880+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:22:05.879+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:22:05.901+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:22:05.928+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:22:05.928+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T08:22:05.945+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:22:05.945+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T08:22:05.956+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-08-10T08:22:36.406+0000] {processor.py:157} INFO - Started process (PID=21123) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:22:36.408+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T08:22:36.414+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:22:36.413+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:22:36.453+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:22:36.493+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:22:36.493+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T08:22:36.512+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:22:36.512+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T08:22:36.525+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-08-10T08:23:06.755+0000] {processor.py:157} INFO - Started process (PID=21133) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:23:06.760+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T08:23:06.765+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:23:06.764+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:23:06.789+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:23:06.831+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:23:06.831+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T08:23:06.855+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:23:06.855+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T08:23:06.868+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-08-10T08:23:37.096+0000] {processor.py:157} INFO - Started process (PID=21143) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:23:37.099+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T08:23:37.103+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:23:37.102+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:23:37.126+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:23:37.163+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:23:37.163+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T08:23:37.179+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:23:37.179+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T08:23:37.191+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-08-10T08:24:07.468+0000] {processor.py:157} INFO - Started process (PID=21152) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:24:07.470+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T08:24:07.474+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:24:07.473+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:24:07.494+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:24:07.527+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:24:07.527+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T08:24:07.541+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:24:07.541+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T08:24:07.550+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-10T08:24:37.705+0000] {processor.py:157} INFO - Started process (PID=21163) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:24:37.707+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T08:24:37.708+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:24:37.708+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:24:37.717+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:24:37.734+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:24:37.734+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T08:24:37.745+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:24:37.745+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T08:24:37.753+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-10T08:25:08.167+0000] {processor.py:157} INFO - Started process (PID=21173) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:25:08.168+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T08:25:08.172+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:25:08.172+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:25:08.195+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:25:08.218+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:25:08.218+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T08:25:08.231+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:25:08.231+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T08:25:08.243+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-08-10T08:25:38.484+0000] {processor.py:157} INFO - Started process (PID=21183) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:25:38.485+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T08:25:38.487+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:25:38.486+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:25:38.503+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:25:38.517+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:25:38.517+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T08:25:38.528+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:25:38.528+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T08:25:38.537+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-10T08:26:08.819+0000] {processor.py:157} INFO - Started process (PID=21193) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:26:08.821+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T08:26:08.836+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:26:08.831+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:26:08.863+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:26:08.890+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:26:08.890+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T08:26:08.906+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:26:08.906+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T08:26:08.916+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-08-10T08:26:39.281+0000] {processor.py:157} INFO - Started process (PID=21203) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:26:39.288+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T08:26:39.292+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:26:39.291+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:26:39.314+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:26:39.341+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:26:39.341+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T08:26:39.355+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:26:39.355+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T08:26:39.368+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-08-10T08:27:09.688+0000] {processor.py:157} INFO - Started process (PID=21213) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:27:09.698+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T08:27:09.709+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:27:09.709+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:27:09.732+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:27:09.777+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:27:09.777+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T08:27:09.793+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:27:09.793+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T08:27:09.805+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-08-10T08:27:39.986+0000] {processor.py:157} INFO - Started process (PID=21223) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:27:39.987+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T08:27:39.990+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:27:39.990+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:27:40.012+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:27:40.043+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:27:40.042+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T08:27:40.057+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:27:40.057+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T08:27:40.070+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-08-10T08:28:10.377+0000] {processor.py:157} INFO - Started process (PID=21233) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:28:10.378+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T08:28:10.379+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:28:10.379+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:28:10.391+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:28:10.408+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:28:10.408+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T08:28:10.421+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:28:10.421+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T08:28:10.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-10T08:28:40.740+0000] {processor.py:157} INFO - Started process (PID=21243) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:28:40.744+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T08:28:40.748+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:28:40.747+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:28:40.763+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:28:40.784+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:28:40.784+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T08:28:40.796+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:28:40.796+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T08:28:40.804+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-10T08:29:11.194+0000] {processor.py:157} INFO - Started process (PID=21253) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:29:11.195+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T08:29:11.200+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:29:11.199+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:29:11.220+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:29:11.257+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:29:11.257+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T08:29:11.272+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:29:11.272+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T08:29:11.283+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-08-10T08:29:41.620+0000] {processor.py:157} INFO - Started process (PID=21263) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:29:41.625+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T08:29:41.629+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:29:41.629+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:29:41.653+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:29:41.684+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:29:41.684+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T08:29:41.701+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:29:41.701+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T08:29:41.711+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-08-10T08:30:11.927+0000] {processor.py:157} INFO - Started process (PID=21273) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:30:11.929+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T08:30:11.931+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:30:11.931+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:30:11.941+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:30:11.959+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:30:11.959+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T08:30:11.972+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:30:11.971+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T08:30:11.981+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-10T08:30:42.365+0000] {processor.py:157} INFO - Started process (PID=21283) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:30:42.368+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T08:30:42.373+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:30:42.372+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:30:42.393+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:30:42.420+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:30:42.420+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T08:30:42.437+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:30:42.437+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T08:30:42.448+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-08-10T08:31:12.697+0000] {processor.py:157} INFO - Started process (PID=21291) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:31:12.700+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T08:31:12.712+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:31:12.711+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:31:12.751+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:31:12.786+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:31:12.786+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T08:31:12.812+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:31:12.812+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T08:31:12.827+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.141 seconds
[2024-08-10T08:31:43.136+0000] {processor.py:157} INFO - Started process (PID=21303) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:31:43.137+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T08:31:43.139+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:31:43.139+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:31:43.156+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:31:43.170+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:31:43.170+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T08:31:43.180+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:31:43.180+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T08:31:43.188+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-10T08:32:13.505+0000] {processor.py:157} INFO - Started process (PID=21313) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:32:13.507+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T08:32:13.512+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:32:13.512+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:32:13.537+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:32:13.587+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:32:13.587+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T08:32:13.606+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:32:13.606+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T08:32:13.624+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-08-10T08:32:43.835+0000] {processor.py:157} INFO - Started process (PID=21323) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:32:43.839+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T08:32:43.846+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:32:43.844+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:32:43.882+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:32:43.921+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:32:43.921+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T08:32:43.937+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:32:43.937+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T08:32:43.949+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-08-10T08:33:14.183+0000] {processor.py:157} INFO - Started process (PID=21333) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:33:14.185+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T08:33:14.199+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:33:14.197+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:33:14.220+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:33:14.246+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:33:14.246+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T08:33:14.282+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:33:14.282+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T08:33:14.342+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.165 seconds
[2024-08-10T08:33:44.546+0000] {processor.py:157} INFO - Started process (PID=21343) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:33:44.551+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T08:33:44.559+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:33:44.558+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:33:44.596+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:33:44.664+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:33:44.664+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T08:33:44.682+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:33:44.681+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T08:33:44.694+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.169 seconds
[2024-08-10T08:34:14.899+0000] {processor.py:157} INFO - Started process (PID=21352) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:34:14.904+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T08:34:14.913+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:34:14.912+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:34:14.944+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:34:14.975+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:34:14.974+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T08:34:14.997+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:34:14.997+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T08:34:15.007+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-08-10T08:34:45.189+0000] {processor.py:157} INFO - Started process (PID=21363) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:34:45.190+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T08:34:45.191+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:34:45.191+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:34:45.202+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:34:45.220+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:34:45.220+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T08:34:45.232+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:34:45.232+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T08:34:45.241+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-10T08:35:15.600+0000] {processor.py:157} INFO - Started process (PID=21373) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:35:15.608+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T08:35:15.614+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:35:15.614+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:35:15.641+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:35:15.689+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:35:15.689+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T08:35:15.712+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:35:15.712+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T08:35:15.723+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-08-10T08:35:45.922+0000] {processor.py:157} INFO - Started process (PID=21382) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:35:45.924+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T08:35:45.928+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:35:45.927+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:35:45.954+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:35:45.980+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:35:45.980+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T08:35:45.995+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:35:45.995+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T08:35:46.005+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-10T08:36:16.254+0000] {processor.py:157} INFO - Started process (PID=21393) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:36:16.259+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T08:36:16.266+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:36:16.263+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:36:16.292+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:36:16.348+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:36:16.347+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T08:36:16.361+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:36:16.361+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T08:36:16.372+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-08-10T08:36:46.765+0000] {processor.py:157} INFO - Started process (PID=21403) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:36:46.769+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T08:36:46.774+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:36:46.774+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:36:46.839+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:36:46.870+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:36:46.870+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T08:36:46.889+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:36:46.889+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T08:36:46.902+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.143 seconds
[2024-08-10T08:37:17.151+0000] {processor.py:157} INFO - Started process (PID=21413) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:37:17.153+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T08:37:17.157+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:37:17.156+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:37:17.176+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:37:17.207+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:37:17.207+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T08:37:17.221+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:37:17.221+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T08:37:17.233+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-08-10T08:37:47.482+0000] {processor.py:157} INFO - Started process (PID=21423) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:37:47.484+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T08:37:47.486+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:37:47.486+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:37:47.503+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:37:47.527+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:37:47.527+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T08:37:47.542+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:37:47.542+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T08:37:47.553+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-08-10T08:38:17.851+0000] {processor.py:157} INFO - Started process (PID=21431) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:38:17.854+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T08:38:17.858+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:38:17.857+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:38:17.879+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:38:17.904+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:38:17.904+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T08:38:17.928+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:38:17.928+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T08:38:17.937+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-08-10T08:38:48.233+0000] {processor.py:157} INFO - Started process (PID=21442) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:38:48.235+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T08:38:48.239+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:38:48.239+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:38:48.258+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:38:48.292+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:38:48.292+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T08:38:48.332+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:38:48.332+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T08:38:48.343+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-08-10T08:39:18.677+0000] {processor.py:157} INFO - Started process (PID=21452) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:39:18.679+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T08:39:18.683+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:39:18.682+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:39:18.703+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:39:18.728+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:39:18.728+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T08:39:18.741+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:39:18.741+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T08:39:18.752+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-08-10T08:39:48.994+0000] {processor.py:157} INFO - Started process (PID=21462) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:39:48.996+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T08:39:49.001+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:39:49.000+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:39:49.026+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:39:49.065+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:39:49.065+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T08:39:49.080+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:39:49.080+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T08:39:49.094+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-08-10T08:40:19.317+0000] {processor.py:157} INFO - Started process (PID=21473) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:40:19.320+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T08:40:19.324+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:40:19.323+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:40:19.344+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:40:19.372+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:40:19.372+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T08:40:19.389+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:40:19.389+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T08:40:19.401+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-08-10T08:40:49.664+0000] {processor.py:157} INFO - Started process (PID=21483) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:40:49.673+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T08:40:49.689+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:40:49.689+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:40:49.707+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:40:49.740+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:40:49.740+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T08:40:49.754+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:40:49.754+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T08:40:49.765+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-08-10T08:41:20.118+0000] {processor.py:157} INFO - Started process (PID=21492) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:41:20.123+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T08:41:20.127+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:41:20.127+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:41:20.145+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:41:20.173+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:41:20.173+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T08:41:20.195+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:41:20.195+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T08:41:20.205+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-08-10T08:41:50.527+0000] {processor.py:157} INFO - Started process (PID=21503) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:41:50.529+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T08:41:50.534+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:41:50.533+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:41:50.551+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:41:50.579+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:41:50.579+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T08:41:50.594+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:41:50.594+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T08:41:50.604+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-08-10T08:42:20.872+0000] {processor.py:157} INFO - Started process (PID=21513) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:42:20.874+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T08:42:20.884+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:42:20.879+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:42:20.914+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:42:20.941+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:42:20.941+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T08:42:20.955+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:42:20.954+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T08:42:20.965+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-08-10T08:42:51.228+0000] {processor.py:157} INFO - Started process (PID=21523) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:42:51.271+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T08:42:51.285+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:42:51.283+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:42:51.396+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:42:51.432+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:42:51.432+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T08:42:51.447+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:42:51.447+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T08:42:51.458+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.242 seconds
[2024-08-10T08:43:21.558+0000] {processor.py:157} INFO - Started process (PID=21533) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:43:21.566+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T08:43:21.571+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:43:21.571+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:43:21.595+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:43:21.627+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:43:21.627+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T08:43:21.651+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:43:21.651+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T08:43:21.664+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-08-10T08:43:51.948+0000] {processor.py:157} INFO - Started process (PID=21543) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:43:51.952+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T08:43:51.961+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:43:51.961+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:43:51.997+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:43:52.060+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:43:52.060+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T08:43:52.080+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:43:52.080+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T08:43:52.094+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.153 seconds
[2024-08-10T08:44:22.322+0000] {processor.py:157} INFO - Started process (PID=21552) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:44:22.329+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T08:44:22.339+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:44:22.339+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:44:22.357+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:44:22.396+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:44:22.396+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T08:44:22.412+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:44:22.412+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T08:44:22.422+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-08-10T08:44:52.691+0000] {processor.py:157} INFO - Started process (PID=21563) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:44:52.697+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T08:44:52.702+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:44:52.701+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:44:52.728+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:44:52.778+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:44:52.778+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T08:44:52.794+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:44:52.794+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T08:44:52.804+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.144 seconds
[2024-08-10T08:45:23.072+0000] {processor.py:157} INFO - Started process (PID=21573) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:45:23.074+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T08:45:23.077+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:45:23.077+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:45:23.100+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:45:23.143+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:45:23.142+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T08:45:23.160+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:45:23.160+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T08:45:23.172+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-08-10T08:45:53.384+0000] {processor.py:157} INFO - Started process (PID=21583) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:45:53.388+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T08:45:53.392+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:45:53.391+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:45:53.412+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:45:53.471+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:45:53.471+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T08:45:53.490+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:45:53.490+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T08:45:53.503+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-08-10T08:46:23.688+0000] {processor.py:157} INFO - Started process (PID=21593) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:46:23.692+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T08:46:23.696+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:46:23.696+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:46:23.720+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:46:23.756+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:46:23.756+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T08:46:23.770+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:46:23.770+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T08:46:23.780+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-08-10T08:46:54.071+0000] {processor.py:157} INFO - Started process (PID=21603) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:46:54.075+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T08:46:54.078+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:46:54.078+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:46:54.096+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:46:54.130+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:46:54.129+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T08:46:54.144+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:46:54.144+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T08:46:54.153+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-08-10T08:47:24.443+0000] {processor.py:157} INFO - Started process (PID=21613) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:47:24.449+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T08:47:24.459+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:47:24.455+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:47:24.498+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:47:24.535+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:47:24.535+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T08:47:24.572+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:47:24.572+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T08:47:24.592+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.156 seconds
[2024-08-10T08:47:54.779+0000] {processor.py:157} INFO - Started process (PID=21623) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:47:54.782+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T08:47:54.786+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:47:54.786+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:47:54.817+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:47:54.841+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:47:54.841+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T08:47:54.873+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:47:54.872+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T08:47:54.885+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-08-10T08:48:25.170+0000] {processor.py:157} INFO - Started process (PID=21633) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:48:25.173+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T08:48:25.177+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:48:25.177+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:48:25.217+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:48:25.265+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:48:25.265+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T08:48:25.282+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:48:25.281+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T08:48:25.293+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-08-10T08:48:55.518+0000] {processor.py:157} INFO - Started process (PID=21643) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:48:55.523+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T08:48:55.527+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:48:55.526+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:48:55.547+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:48:55.579+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:48:55.579+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T08:48:55.593+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:48:55.593+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T08:48:55.606+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-08-10T08:49:25.832+0000] {processor.py:157} INFO - Started process (PID=21653) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:49:25.839+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T08:49:25.854+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:49:25.849+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:49:25.876+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:49:25.901+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:49:25.901+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T08:49:25.916+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:49:25.916+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T08:49:25.927+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-08-10T08:49:56.216+0000] {processor.py:157} INFO - Started process (PID=21663) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:49:56.218+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T08:49:56.221+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:49:56.220+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:49:56.236+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:49:56.260+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:49:56.260+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T08:49:56.276+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:49:56.276+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T08:49:56.286+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-08-10T08:50:26.575+0000] {processor.py:157} INFO - Started process (PID=21673) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:50:26.578+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T08:50:26.584+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:50:26.583+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:50:26.642+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:50:26.672+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:50:26.672+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T08:50:26.692+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:50:26.692+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T08:50:26.706+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-08-10T08:50:56.975+0000] {processor.py:157} INFO - Started process (PID=21682) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:50:56.980+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T08:50:56.986+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:50:56.985+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:50:57.007+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:50:57.051+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:50:57.051+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T08:50:57.067+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:50:57.067+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T08:50:57.080+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-08-10T08:51:27.382+0000] {processor.py:157} INFO - Started process (PID=21693) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:51:27.385+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T08:51:27.390+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:51:27.389+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:51:27.432+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:51:27.473+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:51:27.473+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T08:51:27.502+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:51:27.502+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T08:51:27.514+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.141 seconds
[2024-08-10T08:51:57.720+0000] {processor.py:157} INFO - Started process (PID=21703) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:51:57.724+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T08:51:57.728+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:51:57.728+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:51:57.749+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:51:57.779+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:51:57.779+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T08:51:57.794+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:51:57.794+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T08:51:57.806+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-08-10T08:52:28.141+0000] {processor.py:157} INFO - Started process (PID=21713) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:52:28.144+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T08:52:28.148+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:52:28.147+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:52:28.170+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:52:28.200+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:52:28.200+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T08:52:28.214+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:52:28.214+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T08:52:28.225+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-08-10T08:52:58.601+0000] {processor.py:157} INFO - Started process (PID=21723) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:52:58.606+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T08:52:58.610+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:52:58.610+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:52:58.634+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:52:58.677+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:52:58.677+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T08:52:58.691+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:52:58.691+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T08:52:58.702+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-08-10T08:53:28.955+0000] {processor.py:157} INFO - Started process (PID=21731) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:53:28.958+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T08:53:28.966+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:53:28.966+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:53:28.988+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:53:29.028+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:53:29.028+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T08:53:29.041+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:53:29.041+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T08:53:29.050+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-08-10T08:53:59.384+0000] {processor.py:157} INFO - Started process (PID=21742) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:53:59.387+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T08:53:59.392+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:53:59.391+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:53:59.416+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:53:59.445+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:53:59.445+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T08:53:59.462+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:53:59.462+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T08:53:59.473+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-08-10T08:54:29.719+0000] {processor.py:157} INFO - Started process (PID=21753) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:54:29.724+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T08:54:29.727+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:54:29.727+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:54:29.746+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:54:29.779+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:54:29.779+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T08:54:29.793+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:54:29.793+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T08:54:29.803+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-08-10T08:55:00.065+0000] {processor.py:157} INFO - Started process (PID=21763) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:55:00.067+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T08:55:00.074+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:55:00.073+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:55:00.093+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:55:00.127+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:55:00.127+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T08:55:00.141+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:55:00.141+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T08:55:00.154+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-08-10T08:55:30.380+0000] {processor.py:157} INFO - Started process (PID=21773) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:55:30.383+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T08:55:30.386+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:55:30.386+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:55:30.403+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:55:30.427+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:55:30.427+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T08:55:30.441+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:55:30.441+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T08:55:30.451+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-08-10T08:56:00.763+0000] {processor.py:157} INFO - Started process (PID=21783) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:56:00.765+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T08:56:00.771+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:56:00.771+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:56:00.797+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:56:00.826+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:56:00.826+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T08:56:00.852+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:56:00.852+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T08:56:00.864+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-08-10T08:56:31.140+0000] {processor.py:157} INFO - Started process (PID=21793) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:56:31.145+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T08:56:31.150+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:56:31.149+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:56:31.190+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:56:31.225+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:56:31.225+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T08:56:31.247+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:56:31.247+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T08:56:31.264+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-08-10T08:57:01.454+0000] {processor.py:157} INFO - Started process (PID=21803) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:57:01.457+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T08:57:01.461+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:57:01.460+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:57:01.483+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:57:01.503+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:57:01.503+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T08:57:01.520+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:57:01.520+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T08:57:01.531+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-08-10T08:57:31.780+0000] {processor.py:157} INFO - Started process (PID=21813) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:57:31.782+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T08:57:31.785+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:57:31.784+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:57:31.803+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:57:31.824+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:57:31.824+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T08:57:31.837+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:57:31.837+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T08:57:31.849+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-10T08:58:02.132+0000] {processor.py:157} INFO - Started process (PID=21823) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:58:02.135+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T08:58:02.137+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:58:02.137+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:58:02.148+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:58:02.167+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:58:02.167+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T08:58:02.179+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:58:02.179+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T08:58:02.197+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-10T08:58:32.501+0000] {processor.py:157} INFO - Started process (PID=21833) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:58:32.505+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T08:58:32.523+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:58:32.522+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:58:32.542+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:58:32.567+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:58:32.567+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T08:58:32.581+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:58:32.581+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T08:58:32.591+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-08-10T08:59:02.885+0000] {processor.py:157} INFO - Started process (PID=21843) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:59:02.888+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T08:59:02.892+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:59:02.891+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:59:02.922+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:59:02.944+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:59:02.944+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T08:59:02.960+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:59:02.960+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T08:59:02.972+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-08-10T08:59:33.332+0000] {processor.py:157} INFO - Started process (PID=21853) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:59:33.339+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T08:59:33.348+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:59:33.348+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:59:33.380+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T08:59:33.419+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:59:33.419+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T08:59:33.437+0000] {logging_mixin.py:151} INFO - [2024-08-10T08:59:33.437+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T08:59:33.449+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-08-10T09:00:03.626+0000] {processor.py:157} INFO - Started process (PID=21862) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:00:03.629+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:00:03.633+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:00:03.633+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:00:03.670+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:00:03.715+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:00:03.715+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:00:03.736+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:00:03.736+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:00:03.747+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-08-10T09:00:33.920+0000] {processor.py:157} INFO - Started process (PID=21873) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:00:33.922+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:00:33.926+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:00:33.926+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:00:33.945+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:00:33.974+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:00:33.974+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:00:33.993+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:00:33.993+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:00:34.004+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-08-10T09:01:04.262+0000] {processor.py:157} INFO - Started process (PID=21883) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:01:04.266+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:01:04.269+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:01:04.269+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:01:04.322+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:01:04.396+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:01:04.396+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:01:04.415+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:01:04.415+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:01:04.427+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.168 seconds
[2024-08-10T09:01:34.768+0000] {processor.py:157} INFO - Started process (PID=21892) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:01:34.769+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:01:34.783+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:01:34.776+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:01:34.820+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:01:34.867+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:01:34.867+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:01:34.885+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:01:34.885+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:01:34.898+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.137 seconds
[2024-08-10T09:02:05.056+0000] {processor.py:157} INFO - Started process (PID=21903) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:02:05.061+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:02:05.070+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:02:05.068+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:02:05.094+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:02:05.141+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:02:05.140+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:02:05.161+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:02:05.161+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:02:05.174+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-08-10T09:02:35.435+0000] {processor.py:157} INFO - Started process (PID=21913) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:02:35.437+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:02:35.442+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:02:35.442+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:02:35.500+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:02:35.541+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:02:35.540+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:02:35.560+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:02:35.560+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:02:35.572+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.144 seconds
[2024-08-10T09:03:05.830+0000] {processor.py:157} INFO - Started process (PID=21922) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:03:05.834+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:03:05.844+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:03:05.843+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:03:05.872+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:03:05.916+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:03:05.916+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:03:05.937+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:03:05.936+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:03:05.952+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-08-10T09:03:36.142+0000] {processor.py:157} INFO - Started process (PID=21933) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:03:36.146+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:03:36.151+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:03:36.151+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:03:36.182+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:03:36.220+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:03:36.220+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:03:36.237+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:03:36.237+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:03:36.256+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-08-10T09:04:06.504+0000] {processor.py:157} INFO - Started process (PID=21942) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:04:06.509+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:04:06.513+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:04:06.513+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:04:06.533+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:04:06.564+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:04:06.564+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:04:06.586+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:04:06.586+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:04:06.601+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-08-10T09:04:36.893+0000] {processor.py:157} INFO - Started process (PID=21953) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:04:36.897+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:04:36.901+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:04:36.901+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:04:36.918+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:04:36.943+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:04:36.943+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:04:36.961+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:04:36.961+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:04:36.974+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-08-10T09:05:07.229+0000] {processor.py:157} INFO - Started process (PID=21963) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:05:07.232+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:05:07.248+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:05:07.248+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:05:07.269+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:05:07.297+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:05:07.297+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:05:07.324+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:05:07.324+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:05:07.335+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-08-10T09:05:37.597+0000] {processor.py:157} INFO - Started process (PID=21973) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:05:37.607+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:05:37.628+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:05:37.628+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:05:37.650+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:05:37.685+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:05:37.685+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:05:37.702+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:05:37.701+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:05:37.715+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-08-10T09:06:07.916+0000] {processor.py:157} INFO - Started process (PID=21983) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:06:07.917+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:06:07.921+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:06:07.921+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:06:07.937+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:06:07.960+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:06:07.960+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:06:07.973+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:06:07.973+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:06:07.983+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-10T09:06:38.347+0000] {processor.py:157} INFO - Started process (PID=21993) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:06:38.351+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:06:38.356+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:06:38.356+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:06:38.378+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:06:38.405+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:06:38.405+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:06:38.419+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:06:38.419+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:06:38.429+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-10T09:07:08.704+0000] {processor.py:157} INFO - Started process (PID=22003) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:07:08.705+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:07:08.731+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:07:08.731+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:07:08.756+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:07:08.775+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:07:08.775+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:07:08.789+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:07:08.789+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:07:08.805+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-08-10T09:07:39.059+0000] {processor.py:157} INFO - Started process (PID=22013) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:07:39.061+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:07:39.066+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:07:39.066+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:07:39.093+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:07:39.138+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:07:39.138+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:07:39.153+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:07:39.153+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:07:39.165+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-08-10T09:08:09.387+0000] {processor.py:157} INFO - Started process (PID=22023) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:08:09.395+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:08:09.398+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:08:09.398+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:08:09.415+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:08:09.439+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:08:09.439+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:08:09.459+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:08:09.459+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:08:09.468+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-08-10T09:08:39.745+0000] {processor.py:157} INFO - Started process (PID=22033) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:08:39.748+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:08:39.752+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:08:39.751+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:08:39.767+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:08:39.788+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:08:39.788+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:08:39.801+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:08:39.801+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:08:39.811+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-10T09:09:10.236+0000] {processor.py:157} INFO - Started process (PID=22042) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:09:10.238+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:09:10.246+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:09:10.245+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:09:10.271+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:09:10.306+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:09:10.306+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:09:10.322+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:09:10.322+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:09:10.333+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-08-10T09:09:40.714+0000] {processor.py:157} INFO - Started process (PID=22053) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:09:40.719+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:09:40.723+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:09:40.723+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:09:40.749+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:09:40.797+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:09:40.797+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:09:40.818+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:09:40.818+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:09:40.833+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-08-10T09:10:11.060+0000] {processor.py:157} INFO - Started process (PID=22061) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:10:11.064+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:10:11.068+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:10:11.067+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:10:11.088+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:10:11.122+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:10:11.122+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:10:11.137+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:10:11.137+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:10:11.150+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-08-10T09:10:41.479+0000] {processor.py:157} INFO - Started process (PID=22073) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:10:41.481+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:10:41.485+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:10:41.484+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:10:41.514+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:10:41.577+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:10:41.577+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:10:41.597+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:10:41.597+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:10:41.611+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-08-10T09:11:11.765+0000] {processor.py:157} INFO - Started process (PID=22082) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:11:11.768+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:11:11.772+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:11:11.772+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:11:11.796+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:11:11.824+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:11:11.824+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:11:11.838+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:11:11.838+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:11:11.849+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-08-10T09:11:42.154+0000] {processor.py:157} INFO - Started process (PID=22093) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:11:42.155+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:11:42.160+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:11:42.159+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:11:42.193+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:11:42.220+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:11:42.220+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:11:42.237+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:11:42.237+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:11:42.249+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-08-10T09:12:12.427+0000] {processor.py:157} INFO - Started process (PID=22103) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:12:12.435+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:12:12.457+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:12:12.456+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:12:12.538+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:12:12.615+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:12:12.614+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:12:12.653+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:12:12.653+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:12:12.681+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.265 seconds
[2024-08-10T09:12:43.037+0000] {processor.py:157} INFO - Started process (PID=22113) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:12:43.042+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:12:43.047+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:12:43.047+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:12:43.069+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:12:43.108+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:12:43.108+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:12:43.128+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:12:43.128+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:12:43.140+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-08-10T09:13:13.463+0000] {processor.py:157} INFO - Started process (PID=22123) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:13:13.466+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:13:13.475+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:13:13.473+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:13:13.508+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:13:13.553+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:13:13.553+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:13:13.578+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:13:13.578+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:13:13.594+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-08-10T09:13:43.778+0000] {processor.py:157} INFO - Started process (PID=22133) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:13:43.783+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:13:43.789+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:13:43.788+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:13:43.818+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:13:43.864+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:13:43.864+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:13:43.882+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:13:43.882+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:13:43.894+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.148 seconds
[2024-08-10T09:14:14.165+0000] {processor.py:157} INFO - Started process (PID=22143) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:14:14.170+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:14:14.174+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:14:14.174+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:14:14.203+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:14:14.244+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:14:14.244+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:14:14.267+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:14:14.267+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:14:14.309+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.156 seconds
[2024-08-10T09:14:44.475+0000] {processor.py:157} INFO - Started process (PID=22152) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:14:44.477+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:14:44.484+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:14:44.484+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:14:44.507+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:14:44.548+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:14:44.548+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:14:44.573+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:14:44.573+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:14:44.587+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-08-10T09:15:14.929+0000] {processor.py:157} INFO - Started process (PID=22163) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:15:14.932+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:15:14.952+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:15:14.950+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:15:15.003+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:15:15.034+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:15:15.034+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:15:15.050+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:15:15.050+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:15:15.065+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.143 seconds
[2024-08-10T09:15:45.402+0000] {processor.py:157} INFO - Started process (PID=22173) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:15:45.406+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:15:45.414+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:15:45.414+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:15:45.440+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:15:45.492+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:15:45.492+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:15:45.513+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:15:45.513+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:15:45.525+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-08-10T09:16:15.717+0000] {processor.py:157} INFO - Started process (PID=22183) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:16:15.724+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:16:15.729+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:16:15.729+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:16:15.759+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:16:15.811+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:16:15.811+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:16:15.832+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:16:15.831+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:16:15.845+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-08-10T09:16:46.106+0000] {processor.py:157} INFO - Started process (PID=22193) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:16:46.111+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:16:46.132+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:16:46.131+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:16:46.154+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:16:46.203+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:16:46.203+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:16:46.218+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:16:46.218+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:16:46.231+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-08-10T09:17:16.472+0000] {processor.py:157} INFO - Started process (PID=22203) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:17:16.475+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:17:16.483+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:17:16.483+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:17:16.526+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:17:16.561+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:17:16.561+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:17:16.589+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:17:16.589+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:17:16.603+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.146 seconds
[2024-08-10T09:17:46.855+0000] {processor.py:157} INFO - Started process (PID=22213) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:17:46.857+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:17:46.869+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:17:46.868+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:17:46.916+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:17:46.948+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:17:46.948+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:17:46.969+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:17:46.969+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:17:46.981+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-08-10T09:18:17.149+0000] {processor.py:157} INFO - Started process (PID=22223) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:18:17.155+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:18:17.160+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:18:17.160+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:18:17.173+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:18:17.222+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:18:17.221+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:18:17.240+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:18:17.240+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:18:17.247+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-08-10T09:18:47.526+0000] {processor.py:157} INFO - Started process (PID=22233) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:18:47.527+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:18:47.531+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:18:47.530+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:18:47.556+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:18:47.590+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:18:47.590+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:18:47.612+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:18:47.612+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:18:47.629+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-08-10T09:19:17.824+0000] {processor.py:157} INFO - Started process (PID=22243) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:19:17.831+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:19:17.833+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:19:17.833+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:19:17.855+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:19:17.886+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:19:17.886+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:19:17.905+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:19:17.905+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:19:17.919+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-08-10T09:19:48.193+0000] {processor.py:157} INFO - Started process (PID=22253) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:19:48.200+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:19:48.203+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:19:48.203+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:19:48.235+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:19:48.310+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:19:48.309+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:19:48.371+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:19:48.370+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:19:48.386+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.202 seconds
[2024-08-10T09:20:18.538+0000] {processor.py:157} INFO - Started process (PID=22263) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:20:18.547+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:20:18.556+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:20:18.555+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:20:18.583+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:20:18.612+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:20:18.612+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:20:18.648+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:20:18.648+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:20:18.662+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.167 seconds
[2024-08-10T09:20:48.858+0000] {processor.py:157} INFO - Started process (PID=22273) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:20:48.861+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:20:48.865+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:20:48.864+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:20:48.898+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:20:48.943+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:20:48.943+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:20:48.966+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:20:48.965+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:20:48.985+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-08-10T09:21:19.257+0000] {processor.py:157} INFO - Started process (PID=22283) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:21:19.260+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:21:19.267+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:21:19.266+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:21:19.305+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:21:19.337+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:21:19.337+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:21:19.362+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:21:19.362+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:21:19.378+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-08-10T09:21:49.581+0000] {processor.py:157} INFO - Started process (PID=22293) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:21:49.583+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:21:49.588+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:21:49.588+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:21:49.608+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:21:49.642+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:21:49.642+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:21:49.662+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:21:49.662+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:21:49.672+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-08-10T09:22:19.941+0000] {processor.py:157} INFO - Started process (PID=22303) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:22:19.944+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:22:19.951+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:22:19.950+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:22:19.981+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:22:20.040+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:22:20.040+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:22:20.060+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:22:20.060+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:22:20.076+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-08-10T09:22:50.342+0000] {processor.py:157} INFO - Started process (PID=22313) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:22:50.347+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:22:50.359+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:22:50.358+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:22:50.387+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:22:50.423+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:22:50.423+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:22:50.443+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:22:50.443+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:22:50.465+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.141 seconds
[2024-08-10T09:23:20.672+0000] {processor.py:157} INFO - Started process (PID=22322) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:23:20.674+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:23:20.681+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:23:20.680+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:23:20.716+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:23:20.763+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:23:20.763+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:23:20.782+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:23:20.781+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:23:20.795+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-08-10T09:23:51.007+0000] {processor.py:157} INFO - Started process (PID=22333) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:23:51.011+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:23:51.017+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:23:51.016+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:23:51.066+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:23:51.105+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:23:51.105+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:23:51.143+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:23:51.143+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:23:51.161+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.159 seconds
[2024-08-10T09:24:21.393+0000] {processor.py:157} INFO - Started process (PID=22343) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:24:21.396+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:24:21.402+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:24:21.401+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:24:21.442+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:24:21.475+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:24:21.475+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:24:21.491+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:24:21.491+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:24:21.506+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-08-10T09:24:51.859+0000] {processor.py:157} INFO - Started process (PID=22353) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:24:51.864+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:24:51.868+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:24:51.868+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:24:51.884+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:24:51.920+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:24:51.920+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:24:51.936+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:24:51.936+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:24:51.948+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-08-10T09:25:22.207+0000] {processor.py:157} INFO - Started process (PID=22363) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:25:22.213+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:25:22.218+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:25:22.218+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:25:22.238+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:25:22.271+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:25:22.271+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:25:22.301+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:25:22.301+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:25:22.331+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-08-10T09:25:52.600+0000] {processor.py:157} INFO - Started process (PID=22372) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:25:52.603+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:25:52.612+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:25:52.611+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:25:52.644+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:25:52.702+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:25:52.702+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:25:52.724+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:25:52.724+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:25:52.738+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.154 seconds
[2024-08-10T09:26:22.900+0000] {processor.py:157} INFO - Started process (PID=22383) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:26:22.910+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:26:22.925+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:26:22.924+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:26:22.964+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:26:23.008+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:26:23.008+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:26:23.029+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:26:23.029+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:26:23.041+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.161 seconds
[2024-08-10T09:26:53.244+0000] {processor.py:157} INFO - Started process (PID=22392) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:26:53.246+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:26:53.252+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:26:53.251+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:26:53.269+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:26:53.311+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:26:53.311+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:26:53.330+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:26:53.330+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:26:53.347+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-08-10T09:27:23.561+0000] {processor.py:157} INFO - Started process (PID=22403) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:27:23.568+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:27:23.573+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:27:23.573+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:27:23.594+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:27:23.624+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:27:23.624+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:27:23.640+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:27:23.640+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:27:23.661+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-08-10T09:27:53.892+0000] {processor.py:157} INFO - Started process (PID=22413) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:27:53.897+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:27:53.902+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:27:53.901+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:27:53.926+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:27:53.963+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:27:53.963+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:27:53.981+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:27:53.981+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:27:53.995+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-08-10T09:28:24.199+0000] {processor.py:157} INFO - Started process (PID=22423) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:28:24.202+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:28:24.209+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:28:24.208+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:28:24.236+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:28:24.346+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:28:24.346+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:28:24.372+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:28:24.372+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:28:24.388+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.195 seconds
[2024-08-10T09:28:54.738+0000] {processor.py:157} INFO - Started process (PID=22433) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:28:54.739+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:28:54.749+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:28:54.748+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:28:54.772+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:28:54.816+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:28:54.816+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:28:54.836+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:28:54.836+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:28:54.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-08-10T09:29:25.123+0000] {processor.py:157} INFO - Started process (PID=22443) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:29:25.129+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:29:25.134+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:29:25.134+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:29:25.155+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:29:25.185+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:29:25.185+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:29:25.203+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:29:25.203+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:29:25.216+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-08-10T09:29:55.480+0000] {processor.py:157} INFO - Started process (PID=22453) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:29:55.483+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:29:55.491+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:29:55.491+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:29:55.528+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:29:55.565+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:29:55.565+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:29:55.585+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:29:55.585+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:29:55.601+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-08-10T09:30:25.841+0000] {processor.py:157} INFO - Started process (PID=22463) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:30:25.848+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:30:25.854+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:30:25.853+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:30:25.872+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:30:25.905+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:30:25.905+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:30:25.922+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:30:25.922+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:30:25.935+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-08-10T09:30:56.170+0000] {processor.py:157} INFO - Started process (PID=22473) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:30:56.175+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:30:56.179+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:30:56.179+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:30:56.207+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:30:56.249+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:30:56.249+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:30:56.327+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:30:56.327+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:30:56.396+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.233 seconds
[2024-08-10T09:31:26.671+0000] {processor.py:157} INFO - Started process (PID=22483) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:31:26.675+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:31:26.680+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:31:26.679+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:31:26.704+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:31:26.740+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:31:26.740+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:31:26.762+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:31:26.762+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:31:26.775+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-08-10T09:31:56.958+0000] {processor.py:157} INFO - Started process (PID=22493) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:31:56.959+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:31:56.961+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:31:56.960+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:31:56.978+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:31:56.995+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:31:56.995+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:31:57.006+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:31:57.006+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:31:57.016+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-10T09:32:27.329+0000] {processor.py:157} INFO - Started process (PID=22503) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:32:27.333+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:32:27.349+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:32:27.346+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:32:27.384+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:32:27.423+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:32:27.422+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:32:27.462+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:32:27.462+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:32:27.477+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.162 seconds
[2024-08-10T09:32:57.595+0000] {processor.py:157} INFO - Started process (PID=22513) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:32:57.597+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:32:57.601+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:32:57.600+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:32:57.622+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:32:57.648+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:32:57.648+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:32:57.667+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:32:57.666+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:32:57.683+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-08-10T09:33:28.021+0000] {processor.py:157} INFO - Started process (PID=22523) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:33:28.023+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:33:28.030+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:33:28.029+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:33:28.060+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:33:28.104+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:33:28.104+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:33:28.140+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:33:28.140+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:33:28.162+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.148 seconds
[2024-08-10T09:33:58.321+0000] {processor.py:157} INFO - Started process (PID=22533) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:33:58.323+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:33:58.327+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:33:58.327+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:33:58.358+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:33:58.388+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:33:58.388+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:33:58.404+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:33:58.404+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:33:58.417+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-08-10T09:34:28.681+0000] {processor.py:157} INFO - Started process (PID=22543) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:34:28.683+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:34:28.686+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:34:28.686+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:34:28.717+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:34:28.767+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:34:28.767+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:34:28.788+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:34:28.788+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:34:28.803+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-08-10T09:34:58.917+0000] {processor.py:157} INFO - Started process (PID=22553) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:34:58.919+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:34:58.923+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:34:58.923+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:34:58.938+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:34:58.957+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:34:58.956+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:34:58.971+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:34:58.971+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:34:58.982+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-10T09:35:29.292+0000] {processor.py:157} INFO - Started process (PID=22563) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:35:29.293+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:35:29.296+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:35:29.296+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:35:29.341+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:35:29.383+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:35:29.382+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:35:29.401+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:35:29.401+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:35:29.417+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-08-10T09:35:59.592+0000] {processor.py:157} INFO - Started process (PID=22573) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:35:59.593+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:35:59.595+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:35:59.595+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:35:59.614+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:35:59.634+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:35:59.634+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:35:59.652+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:35:59.652+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:35:59.665+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-08-10T09:36:29.953+0000] {processor.py:157} INFO - Started process (PID=22582) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:36:29.954+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:36:29.957+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:36:29.956+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:36:29.972+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:36:29.996+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:36:29.996+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:36:30.012+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:36:30.012+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:36:30.024+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-10T09:37:00.334+0000] {processor.py:157} INFO - Started process (PID=22593) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:37:00.335+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:37:00.337+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:37:00.337+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:37:00.350+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:37:00.373+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:37:00.373+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:37:00.389+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:37:00.389+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:37:00.400+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-10T09:37:30.600+0000] {processor.py:157} INFO - Started process (PID=22603) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:37:30.601+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:37:30.604+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:37:30.604+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:37:30.622+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:37:30.651+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:37:30.650+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:37:30.668+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:37:30.667+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:37:30.681+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-08-10T09:38:00.901+0000] {processor.py:157} INFO - Started process (PID=22613) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:38:00.903+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:38:00.905+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:38:00.905+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:38:00.924+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:38:00.946+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:38:00.946+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:38:00.964+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:38:00.964+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:38:00.976+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-08-10T09:38:31.182+0000] {processor.py:157} INFO - Started process (PID=22623) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:38:31.186+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:38:31.191+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:38:31.190+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:38:31.206+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:38:31.233+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:38:31.233+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:38:31.249+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:38:31.249+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:38:31.260+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-08-10T09:39:01.441+0000] {processor.py:157} INFO - Started process (PID=22633) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:39:01.443+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:39:01.447+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:39:01.446+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:39:01.467+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:39:01.495+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:39:01.495+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:39:01.514+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:39:01.514+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:39:01.527+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-08-10T09:39:31.729+0000] {processor.py:157} INFO - Started process (PID=22643) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:39:31.730+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:39:31.733+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:39:31.733+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:39:31.750+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:39:31.769+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:39:31.769+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:39:31.781+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:39:31.781+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:39:31.795+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-10T09:40:01.994+0000] {processor.py:157} INFO - Started process (PID=22653) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:40:01.998+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:40:02.001+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:40:02.000+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:40:02.014+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:40:02.035+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:40:02.035+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:40:02.049+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:40:02.049+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:40:02.061+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-10T09:40:32.242+0000] {processor.py:157} INFO - Started process (PID=22663) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:40:32.246+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:40:32.250+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:40:32.250+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:40:32.294+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:40:32.330+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:40:32.330+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:40:32.349+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:40:32.348+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:40:32.361+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-08-10T09:41:02.680+0000] {processor.py:157} INFO - Started process (PID=22673) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:41:02.683+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:41:02.685+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:41:02.685+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:41:02.699+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:41:02.723+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:41:02.723+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:41:02.737+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:41:02.737+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:41:02.750+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-10T09:41:32.960+0000] {processor.py:157} INFO - Started process (PID=22683) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:41:32.961+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:41:32.964+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:41:32.964+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:41:32.979+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:41:33.007+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:41:33.007+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:41:33.023+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:41:33.023+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:41:33.035+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-08-10T09:42:03.230+0000] {processor.py:157} INFO - Started process (PID=22693) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:42:03.234+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:42:03.237+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:42:03.236+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:42:03.256+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:42:03.276+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:42:03.276+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:42:03.288+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:42:03.288+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:42:03.299+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-10T09:42:33.500+0000] {processor.py:157} INFO - Started process (PID=22703) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:42:33.502+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:42:33.504+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:42:33.503+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:42:33.517+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:42:33.539+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:42:33.539+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:42:33.555+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:42:33.555+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:42:33.565+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-10T09:43:03.810+0000] {processor.py:157} INFO - Started process (PID=22713) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:43:03.812+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:43:03.814+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:43:03.814+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:43:03.841+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:43:03.874+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:43:03.874+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:43:03.892+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:43:03.892+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:43:03.905+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-08-10T09:43:34.110+0000] {processor.py:157} INFO - Started process (PID=22723) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:43:34.112+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:43:34.114+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:43:34.114+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:43:34.128+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:43:34.155+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:43:34.155+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:43:34.170+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:43:34.170+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:43:34.183+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-08-10T09:44:04.431+0000] {processor.py:157} INFO - Started process (PID=22733) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:44:04.433+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:44:04.438+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:44:04.437+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:44:04.467+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:44:04.526+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:44:04.526+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:44:04.548+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:44:04.547+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:44:04.572+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.147 seconds
[2024-08-10T09:44:34.688+0000] {processor.py:157} INFO - Started process (PID=22743) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:44:34.692+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:44:34.696+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:44:34.696+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:44:34.710+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:44:34.731+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:44:34.731+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:44:34.744+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:44:34.744+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:44:34.754+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-10T09:45:05.053+0000] {processor.py:157} INFO - Started process (PID=22753) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:45:05.054+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:45:05.058+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:45:05.058+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:45:05.092+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:45:05.125+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:45:05.125+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:45:05.141+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:45:05.141+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:45:05.152+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-08-10T09:45:35.442+0000] {processor.py:157} INFO - Started process (PID=22763) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:45:35.445+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:45:35.448+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:45:35.447+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:45:35.467+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:45:35.494+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:45:35.494+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:45:35.513+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:45:35.513+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:45:35.530+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-08-10T09:46:05.773+0000] {processor.py:157} INFO - Started process (PID=22773) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:46:05.774+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:46:05.777+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:46:05.777+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:46:05.803+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:46:05.846+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:46:05.846+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:46:05.890+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:46:05.889+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:46:05.905+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-08-10T09:46:36.145+0000] {processor.py:157} INFO - Started process (PID=22782) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:46:36.152+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:46:36.157+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:46:36.157+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:46:36.186+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:46:36.286+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:46:36.286+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:46:36.305+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:46:36.305+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:46:36.317+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.177 seconds
[2024-08-10T09:47:06.425+0000] {processor.py:157} INFO - Started process (PID=22793) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:47:06.432+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:47:06.441+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:47:06.441+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:47:06.482+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:47:06.528+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:47:06.528+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:47:06.547+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:47:06.547+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:47:06.559+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.141 seconds
[2024-08-10T09:47:36.859+0000] {processor.py:157} INFO - Started process (PID=22803) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:47:36.861+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:47:36.874+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:47:36.870+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:47:36.895+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:47:36.925+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:47:36.925+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:47:36.941+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:47:36.941+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:47:36.960+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-08-10T09:48:07.273+0000] {processor.py:157} INFO - Started process (PID=22813) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:48:07.275+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:48:07.279+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:48:07.278+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:48:07.297+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:48:07.336+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:48:07.336+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:48:07.352+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:48:07.352+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:48:07.367+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-08-10T09:48:37.580+0000] {processor.py:157} INFO - Started process (PID=22823) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:48:37.581+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:48:37.583+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:48:37.583+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:48:37.604+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:48:37.640+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:48:37.640+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:48:37.659+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:48:37.659+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:48:37.683+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-08-10T09:49:07.909+0000] {processor.py:157} INFO - Started process (PID=22833) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:49:07.913+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:49:07.917+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:49:07.916+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:49:07.940+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:49:07.989+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:49:07.989+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:49:08.010+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:49:08.010+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:49:08.027+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-08-10T09:49:38.214+0000] {processor.py:157} INFO - Started process (PID=22843) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:49:38.222+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:49:38.227+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:49:38.227+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:49:38.253+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:49:38.293+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:49:38.293+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:49:38.312+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:49:38.312+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:49:38.326+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-08-10T09:50:08.644+0000] {processor.py:157} INFO - Started process (PID=22853) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:50:08.652+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:50:08.660+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:50:08.659+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:50:08.678+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:50:08.713+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:50:08.713+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:50:08.732+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:50:08.732+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:50:08.746+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-08-10T09:50:38.962+0000] {processor.py:157} INFO - Started process (PID=22863) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:50:38.965+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:50:38.979+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:50:38.978+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:50:39.012+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:50:39.053+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:50:39.053+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:50:39.077+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:50:39.077+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:50:39.090+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-08-10T09:51:09.283+0000] {processor.py:157} INFO - Started process (PID=22873) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:51:09.285+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:51:09.290+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:51:09.290+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:51:09.330+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:51:09.363+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:51:09.362+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:51:09.387+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:51:09.387+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:51:09.399+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-08-10T09:51:39.630+0000] {processor.py:157} INFO - Started process (PID=22883) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:51:39.632+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:51:39.637+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:51:39.637+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:51:39.663+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:51:39.701+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:51:39.701+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:51:39.730+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:51:39.730+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:51:39.747+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-08-10T09:52:10.044+0000] {processor.py:157} INFO - Started process (PID=22893) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:52:10.049+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:52:10.053+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:52:10.053+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:52:10.075+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:52:10.111+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:52:10.110+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:52:10.132+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:52:10.132+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:52:10.150+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-08-10T09:52:40.350+0000] {processor.py:157} INFO - Started process (PID=22903) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:52:40.352+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:52:40.355+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:52:40.354+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:52:40.381+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:52:40.406+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:52:40.406+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:52:40.435+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:52:40.435+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:52:40.449+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-08-10T09:53:10.735+0000] {processor.py:157} INFO - Started process (PID=22913) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:53:10.738+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:53:10.742+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:53:10.741+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:53:10.764+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:53:10.788+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:53:10.788+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:53:10.806+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:53:10.806+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:53:10.820+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-10T09:53:41.009+0000] {processor.py:157} INFO - Started process (PID=22923) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:53:41.010+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:53:41.013+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:53:41.013+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:53:41.034+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:53:41.064+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:53:41.064+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:53:41.084+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:53:41.083+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:53:41.099+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-08-10T09:54:11.394+0000] {processor.py:157} INFO - Started process (PID=22933) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:54:11.396+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:54:11.400+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:54:11.400+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:54:11.426+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:54:11.464+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:54:11.464+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:54:11.488+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:54:11.488+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:54:11.502+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-08-10T09:54:41.683+0000] {processor.py:157} INFO - Started process (PID=22943) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:54:41.688+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:54:41.694+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:54:41.693+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:54:41.714+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:54:41.752+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:54:41.752+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:54:41.776+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:54:41.776+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:54:41.789+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-08-10T09:55:11.971+0000] {processor.py:157} INFO - Started process (PID=22953) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:55:11.972+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:55:11.975+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:55:11.975+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:55:11.993+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:55:12.017+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:55:12.017+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:55:12.033+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:55:12.033+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:55:12.046+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-08-10T09:55:42.320+0000] {processor.py:157} INFO - Started process (PID=22963) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:55:42.326+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:55:42.342+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:55:42.342+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:55:42.367+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:55:42.414+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:55:42.414+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:55:42.442+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:55:42.442+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:55:42.457+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.142 seconds
[2024-08-10T09:56:12.577+0000] {processor.py:157} INFO - Started process (PID=22973) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:56:12.578+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:56:12.581+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:56:12.580+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:56:12.601+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:56:12.621+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:56:12.621+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:56:12.636+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:56:12.636+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:56:12.648+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-10T09:56:42.910+0000] {processor.py:157} INFO - Started process (PID=22983) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:56:42.911+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:56:42.913+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:56:42.913+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:56:42.924+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:56:42.950+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:56:42.950+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:56:42.966+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:56:42.965+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:56:42.982+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-08-10T09:57:13.323+0000] {processor.py:157} INFO - Started process (PID=22993) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:57:13.324+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:57:13.328+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:57:13.328+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:57:13.351+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:57:13.381+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:57:13.381+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:57:13.397+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:57:13.397+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:57:13.411+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-08-10T09:57:43.741+0000] {processor.py:157} INFO - Started process (PID=23002) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:57:43.744+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:57:43.749+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:57:43.748+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:57:43.775+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:57:43.826+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:57:43.826+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:57:43.846+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:57:43.846+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:57:43.862+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-08-10T09:58:14.017+0000] {processor.py:157} INFO - Started process (PID=23013) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:58:14.020+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:58:14.023+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:58:14.023+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:58:14.042+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:58:14.074+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:58:14.073+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:58:14.094+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:58:14.094+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:58:14.108+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-08-10T09:58:44.395+0000] {processor.py:157} INFO - Started process (PID=23023) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:58:44.398+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:58:44.409+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:58:44.408+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:58:44.442+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:58:44.481+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:58:44.480+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:58:44.518+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:58:44.518+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:58:44.539+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.157 seconds
[2024-08-10T09:59:14.705+0000] {processor.py:157} INFO - Started process (PID=23033) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:59:14.707+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:59:14.712+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:59:14.711+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:59:14.735+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:59:14.792+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:59:14.792+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:59:14.815+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:59:14.815+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:59:14.831+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-08-10T09:59:45.073+0000] {processor.py:157} INFO - Started process (PID=23041) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:59:45.076+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T09:59:45.083+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:59:45.083+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:59:45.104+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T09:59:45.141+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:59:45.141+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T09:59:45.182+0000] {logging_mixin.py:151} INFO - [2024-08-10T09:59:45.182+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T09:59:45.196+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-08-10T10:00:15.416+0000] {processor.py:157} INFO - Started process (PID=23053) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:00:15.422+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:00:15.440+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:00:15.440+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:00:15.458+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:00:15.490+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:00:15.490+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:00:15.508+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:00:15.508+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:00:15.521+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-08-10T10:00:45.813+0000] {processor.py:157} INFO - Started process (PID=23063) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:00:45.816+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:00:45.821+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:00:45.821+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:00:45.851+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:00:45.891+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:00:45.891+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:00:45.910+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:00:45.909+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:00:45.927+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-08-10T10:01:16.284+0000] {processor.py:157} INFO - Started process (PID=23073) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:01:16.285+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:01:16.291+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:01:16.290+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:01:16.327+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:01:16.359+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:01:16.359+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:01:16.376+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:01:16.376+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:01:16.387+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-08-10T10:01:46.629+0000] {processor.py:157} INFO - Started process (PID=23083) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:01:46.631+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:01:46.638+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:01:46.637+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:01:46.658+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:01:46.695+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:01:46.695+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:01:46.724+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:01:46.724+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:01:46.744+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-08-10T10:02:16.905+0000] {processor.py:157} INFO - Started process (PID=23093) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:02:16.911+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:02:16.918+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:02:16.917+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:02:16.946+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:02:17.000+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:02:17.000+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:02:17.022+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:02:17.022+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:02:17.036+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.145 seconds
[2024-08-10T10:02:47.227+0000] {processor.py:157} INFO - Started process (PID=23103) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:02:47.229+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:02:47.234+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:02:47.234+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:02:47.257+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:02:47.311+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:02:47.311+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:02:47.331+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:02:47.330+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:02:47.346+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-08-10T10:03:17.530+0000] {processor.py:157} INFO - Started process (PID=23113) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:03:17.532+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:03:17.537+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:03:17.537+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:03:17.559+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:03:17.587+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:03:17.587+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:03:17.611+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:03:17.611+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:03:17.622+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-08-10T10:03:47.834+0000] {processor.py:157} INFO - Started process (PID=23123) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:03:47.841+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:03:47.844+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:03:47.844+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:03:47.864+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:03:47.895+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:03:47.895+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:03:47.915+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:03:47.915+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:03:47.929+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-08-10T10:04:18.266+0000] {processor.py:157} INFO - Started process (PID=23133) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:04:18.276+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:04:18.282+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:04:18.281+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:04:18.307+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:04:18.355+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:04:18.355+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:04:18.382+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:04:18.382+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:04:18.397+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.153 seconds
[2024-08-10T10:04:48.706+0000] {processor.py:157} INFO - Started process (PID=23143) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:04:48.708+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:04:48.716+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:04:48.714+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:04:48.739+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:04:48.784+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:04:48.783+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:04:48.800+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:04:48.800+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:04:48.813+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-08-10T10:05:19.083+0000] {processor.py:157} INFO - Started process (PID=23153) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:05:19.085+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:05:19.088+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:05:19.088+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:05:19.120+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:05:19.165+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:05:19.165+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:05:19.185+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:05:19.185+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:05:19.196+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-08-10T10:05:49.402+0000] {processor.py:157} INFO - Started process (PID=23163) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:05:49.404+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:05:49.406+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:05:49.406+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:05:49.427+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:05:49.470+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:05:49.470+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:05:49.488+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:05:49.487+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:05:49.498+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-08-10T10:06:19.727+0000] {processor.py:157} INFO - Started process (PID=23172) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:06:19.731+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:06:19.741+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:06:19.740+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:06:19.758+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:06:19.800+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:06:19.800+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:06:19.821+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:06:19.821+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:06:19.836+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-08-10T10:06:50.042+0000] {processor.py:157} INFO - Started process (PID=23183) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:06:50.044+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:06:50.046+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:06:50.046+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:06:50.074+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:06:50.113+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:06:50.113+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:06:50.140+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:06:50.139+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:06:50.156+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-08-10T10:07:20.406+0000] {processor.py:157} INFO - Started process (PID=23193) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:07:20.409+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:07:20.413+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:07:20.412+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:07:20.444+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:07:20.478+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:07:20.478+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:07:20.497+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:07:20.497+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:07:20.513+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-08-10T10:07:50.761+0000] {processor.py:157} INFO - Started process (PID=23203) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:07:50.764+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:07:50.785+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:07:50.782+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:07:50.821+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:07:50.906+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:07:50.906+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:07:50.943+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:07:50.943+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:07:50.960+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.202 seconds
[2024-08-10T10:08:21.102+0000] {processor.py:157} INFO - Started process (PID=23213) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:08:21.104+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:08:21.109+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:08:21.109+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:08:21.133+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:08:21.182+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:08:21.181+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:08:21.212+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:08:21.211+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:08:21.228+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-08-10T10:08:51.513+0000] {processor.py:157} INFO - Started process (PID=23223) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:08:51.515+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:08:51.521+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:08:51.521+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:08:51.554+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:08:51.609+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:08:51.609+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:08:51.633+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:08:51.633+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:08:51.652+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.143 seconds
[2024-08-10T10:09:21.815+0000] {processor.py:157} INFO - Started process (PID=23233) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:09:21.819+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:09:21.821+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:09:21.821+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:09:21.847+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:09:21.882+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:09:21.881+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:09:21.912+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:09:21.912+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:09:21.924+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-08-10T10:09:52.151+0000] {processor.py:157} INFO - Started process (PID=23243) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:09:52.157+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:09:52.159+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:09:52.159+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:09:52.181+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:09:52.217+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:09:52.217+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:09:52.237+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:09:52.237+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:09:52.275+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-08-10T10:10:22.458+0000] {processor.py:157} INFO - Started process (PID=23253) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:10:22.459+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:10:22.463+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:10:22.462+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:10:22.489+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:10:22.533+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:10:22.533+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:10:22.555+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:10:22.554+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:10:22.570+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-08-10T10:10:52.845+0000] {processor.py:157} INFO - Started process (PID=23262) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:10:52.849+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:10:52.852+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:10:52.852+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:10:52.878+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:10:52.931+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:10:52.931+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:10:52.950+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:10:52.950+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:10:52.961+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-08-10T10:11:23.188+0000] {processor.py:157} INFO - Started process (PID=23273) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:11:23.190+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:11:23.195+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:11:23.194+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:11:23.216+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:11:23.249+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:11:23.249+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:11:23.277+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:11:23.276+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:11:23.290+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-08-10T10:11:53.488+0000] {processor.py:157} INFO - Started process (PID=23283) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:11:53.493+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:11:53.496+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:11:53.495+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:11:53.537+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:11:53.577+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:11:53.577+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:11:53.598+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:11:53.598+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:11:53.622+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-08-10T10:12:23.897+0000] {processor.py:157} INFO - Started process (PID=23293) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:12:23.899+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:12:23.908+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:12:23.906+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:12:23.937+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:12:23.973+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:12:23.972+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:12:23.990+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:12:23.990+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:12:24.010+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-08-10T10:12:54.232+0000] {processor.py:157} INFO - Started process (PID=23303) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:12:54.239+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:12:54.246+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:12:54.243+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:12:54.288+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:12:54.351+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:12:54.351+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:12:54.385+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:12:54.385+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:12:54.406+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.184 seconds
[2024-08-10T10:13:24.726+0000] {processor.py:157} INFO - Started process (PID=23313) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:13:24.731+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:13:24.736+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:13:24.736+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:13:24.768+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:13:24.807+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:13:24.806+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:13:24.830+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:13:24.830+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:13:24.846+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-08-10T10:13:55.173+0000] {processor.py:157} INFO - Started process (PID=23323) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:13:55.177+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:13:55.180+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:13:55.180+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:13:55.196+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:13:55.218+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:13:55.218+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:13:55.233+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:13:55.232+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:13:55.245+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-08-10T10:14:25.444+0000] {processor.py:157} INFO - Started process (PID=23333) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:14:25.445+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:14:25.447+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:14:25.447+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:14:25.463+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:14:25.487+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:14:25.487+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:14:25.505+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:14:25.505+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:14:25.517+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-08-10T10:14:55.855+0000] {processor.py:157} INFO - Started process (PID=23343) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:14:55.856+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:14:55.863+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:14:55.862+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:14:55.885+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:14:55.924+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:14:55.924+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:14:55.941+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:14:55.941+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:14:55.956+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-08-10T10:15:26.160+0000] {processor.py:157} INFO - Started process (PID=23353) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:15:26.163+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:15:26.167+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:15:26.166+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:15:26.186+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:15:26.215+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:15:26.215+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:15:26.233+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:15:26.233+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:15:26.245+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-08-10T10:15:56.491+0000] {processor.py:157} INFO - Started process (PID=23363) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:15:56.493+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:15:56.498+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:15:56.497+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:15:56.523+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:15:56.580+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:15:56.579+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:15:56.601+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:15:56.601+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:15:56.616+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-08-10T10:16:26.789+0000] {processor.py:157} INFO - Started process (PID=23373) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:16:26.791+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:16:26.795+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:16:26.794+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:16:26.813+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:16:26.857+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:16:26.857+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:16:26.871+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:16:26.871+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:16:26.884+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-08-10T10:16:57.118+0000] {processor.py:157} INFO - Started process (PID=23382) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:16:57.120+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:16:57.125+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:16:57.125+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:16:57.148+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:16:57.192+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:16:57.192+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:16:57.224+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:16:57.224+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:16:57.236+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-08-10T10:17:27.445+0000] {processor.py:157} INFO - Started process (PID=23393) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:17:27.447+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:17:27.449+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:17:27.449+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:17:27.466+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:17:27.498+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:17:27.498+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:17:27.515+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:17:27.515+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:17:27.530+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-08-10T10:17:57.842+0000] {processor.py:157} INFO - Started process (PID=23403) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:17:57.843+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:17:57.846+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:17:57.846+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:17:57.861+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:17:57.884+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:17:57.884+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:17:57.898+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:17:57.898+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:17:57.908+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-10T10:18:28.264+0000] {processor.py:157} INFO - Started process (PID=23411) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:18:28.266+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:18:28.270+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:18:28.269+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:18:28.297+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:18:28.337+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:18:28.337+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:18:28.360+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:18:28.360+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:18:28.376+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-08-10T10:18:58.512+0000] {processor.py:157} INFO - Started process (PID=23423) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:18:58.513+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:18:58.515+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:18:58.515+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:18:58.527+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:18:58.547+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:18:58.547+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:18:58.560+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:18:58.560+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:18:58.569+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-10T10:19:28.856+0000] {processor.py:157} INFO - Started process (PID=23433) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:19:28.856+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:19:28.858+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:19:28.858+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:19:28.868+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:19:28.887+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:19:28.887+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:19:28.896+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:19:28.896+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:19:28.904+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-10T10:19:59.242+0000] {processor.py:157} INFO - Started process (PID=23443) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:19:59.244+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:19:59.247+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:19:59.247+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:19:59.263+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:19:59.282+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:19:59.282+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:19:59.294+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:19:59.294+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:19:59.302+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-10T10:20:29.619+0000] {processor.py:157} INFO - Started process (PID=23453) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:20:29.620+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:20:29.623+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:20:29.623+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:20:29.640+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:20:29.669+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:20:29.669+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:20:29.683+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:20:29.683+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:20:29.694+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-08-10T10:20:59.932+0000] {processor.py:157} INFO - Started process (PID=23463) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:20:59.934+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:20:59.938+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:20:59.938+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:20:59.959+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:20:59.988+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:20:59.987+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:21:00.003+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:21:00.003+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:21:00.016+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-08-10T10:21:30.358+0000] {processor.py:157} INFO - Started process (PID=23473) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:21:30.360+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:21:30.366+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:21:30.366+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:21:30.417+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:21:30.450+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:21:30.450+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:21:30.465+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:21:30.464+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:21:30.475+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-08-10T10:22:00.604+0000] {processor.py:157} INFO - Started process (PID=23483) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:22:00.604+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:22:00.606+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:22:00.606+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:22:00.619+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:22:00.640+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:22:00.640+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:22:00.653+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:22:00.653+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:22:00.662+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-10T10:22:30.972+0000] {processor.py:157} INFO - Started process (PID=23493) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:22:30.973+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:22:30.976+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:22:30.976+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:22:30.992+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:22:31.014+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:22:31.014+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:22:31.027+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:22:31.026+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:22:31.035+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-10T10:23:01.371+0000] {processor.py:157} INFO - Started process (PID=23503) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:23:01.373+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:23:01.376+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:23:01.375+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:23:01.396+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:23:01.415+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:23:01.415+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:23:01.427+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:23:01.427+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:23:01.436+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-10T10:23:31.688+0000] {processor.py:157} INFO - Started process (PID=23513) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:23:31.689+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:23:31.691+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:23:31.691+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:23:31.701+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:23:31.719+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:23:31.719+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:23:31.731+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:23:31.731+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:23:31.741+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-10T10:24:02.092+0000] {processor.py:157} INFO - Started process (PID=23523) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:24:02.093+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:24:02.097+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:24:02.096+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:24:02.111+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:24:02.134+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:24:02.133+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:24:02.147+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:24:02.147+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:24:02.156+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-10T10:24:32.396+0000] {processor.py:157} INFO - Started process (PID=23533) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:24:32.396+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:24:32.399+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:24:32.399+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:24:32.408+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:24:32.427+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:24:32.427+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:24:32.440+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:24:32.440+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:24:32.452+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-10T10:25:02.743+0000] {processor.py:157} INFO - Started process (PID=23543) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:25:02.745+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:25:02.747+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:25:02.747+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:25:02.757+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:25:02.779+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:25:02.779+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:25:02.790+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:25:02.790+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:25:02.799+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-10T10:25:33.154+0000] {processor.py:157} INFO - Started process (PID=23553) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:25:33.155+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:25:33.158+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:25:33.158+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:25:33.175+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:25:33.196+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:25:33.196+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:25:33.208+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:25:33.208+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:25:33.218+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-10T10:26:03.495+0000] {processor.py:157} INFO - Started process (PID=23563) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:26:03.497+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:26:03.498+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:26:03.498+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:26:03.516+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:26:03.534+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:26:03.534+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:26:03.545+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:26:03.545+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:26:03.556+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-10T10:26:33.859+0000] {processor.py:157} INFO - Started process (PID=23573) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:26:33.860+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:26:33.862+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:26:33.862+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:26:33.871+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:26:33.891+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:26:33.891+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:26:33.903+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:26:33.902+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:26:33.911+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-10T10:27:04.325+0000] {processor.py:157} INFO - Started process (PID=23582) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:27:04.330+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:27:04.360+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:27:04.353+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:27:04.451+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:27:04.526+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:27:04.526+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:27:04.635+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:27:04.635+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:27:04.655+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.359 seconds
[2024-08-10T10:27:34.935+0000] {processor.py:157} INFO - Started process (PID=23593) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:27:34.936+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:27:34.940+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:27:34.940+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:27:34.957+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:27:34.985+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:27:34.985+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:27:34.999+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:27:34.999+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:27:35.010+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-08-10T10:28:05.270+0000] {processor.py:157} INFO - Started process (PID=23603) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:28:05.274+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:28:05.276+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:28:05.276+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:28:05.293+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:28:05.345+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:28:05.344+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:28:05.361+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:28:05.361+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:28:05.371+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-08-10T10:28:35.553+0000] {processor.py:157} INFO - Started process (PID=23613) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:28:35.554+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:28:35.556+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:28:35.556+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:28:35.568+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:28:35.588+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:28:35.588+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:28:35.602+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:28:35.601+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:28:35.611+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-10T10:29:05.898+0000] {processor.py:157} INFO - Started process (PID=23623) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:29:05.899+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:29:05.902+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:29:05.901+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:29:05.916+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:29:05.938+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:29:05.938+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:29:05.952+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:29:05.952+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:29:05.962+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-10T10:29:36.193+0000] {processor.py:157} INFO - Started process (PID=23633) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:29:36.194+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:29:36.196+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:29:36.196+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:29:36.208+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:29:36.227+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:29:36.227+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:29:36.240+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:29:36.240+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:29:36.250+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-10T10:30:06.499+0000] {processor.py:157} INFO - Started process (PID=23643) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:30:06.500+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:30:06.502+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:30:06.501+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:30:06.512+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:30:06.531+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:30:06.531+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:30:06.543+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:30:06.543+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:30:06.555+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-10T10:30:36.874+0000] {processor.py:157} INFO - Started process (PID=23653) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:30:36.877+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:30:36.879+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:30:36.878+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:30:36.894+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:30:36.914+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:30:36.914+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:30:36.927+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:30:36.927+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:30:36.938+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-10T10:31:07.210+0000] {processor.py:157} INFO - Started process (PID=23663) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:31:07.211+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:31:07.214+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:31:07.214+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:31:07.228+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:31:07.247+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:31:07.247+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:31:07.261+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:31:07.261+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:31:07.270+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-10T10:31:37.570+0000] {processor.py:157} INFO - Started process (PID=23673) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:31:37.571+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:31:37.573+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:31:37.573+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:31:37.586+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:31:37.602+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:31:37.601+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:31:37.613+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:31:37.613+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:31:37.621+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-10T10:32:07.922+0000] {processor.py:157} INFO - Started process (PID=23683) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:32:07.923+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:32:07.927+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:32:07.927+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:32:07.943+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:32:07.966+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:32:07.966+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:32:07.980+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:32:07.980+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:32:07.989+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-08-10T10:32:38.229+0000] {processor.py:157} INFO - Started process (PID=23693) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:32:38.232+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:32:38.235+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:32:38.235+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:32:38.250+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:32:38.275+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:32:38.275+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:32:38.311+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:32:38.311+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:32:38.325+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-08-10T10:33:08.554+0000] {processor.py:157} INFO - Started process (PID=23703) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:33:08.557+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:33:08.560+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:33:08.560+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:33:08.572+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:33:08.592+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:33:08.592+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:33:08.605+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:33:08.605+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:33:08.616+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-10T10:33:38.972+0000] {processor.py:157} INFO - Started process (PID=23713) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:33:38.974+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:33:38.977+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:33:38.977+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:33:38.993+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:33:39.037+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:33:39.037+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:33:39.053+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:33:39.053+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:33:39.064+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-08-10T10:34:09.433+0000] {processor.py:157} INFO - Started process (PID=23723) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:34:09.435+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:34:09.438+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:34:09.437+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:34:09.449+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:34:09.470+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:34:09.470+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:34:09.482+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:34:09.482+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:34:09.491+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-10T10:34:39.891+0000] {processor.py:157} INFO - Started process (PID=23733) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:34:39.895+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:34:39.898+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:34:39.897+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:34:39.913+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:34:39.929+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:34:39.929+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:34:39.941+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:34:39.940+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:34:39.950+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-10T10:35:10.264+0000] {processor.py:157} INFO - Started process (PID=23743) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:35:10.266+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:35:10.279+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:35:10.279+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:35:10.327+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:35:10.354+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:35:10.354+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:35:10.368+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:35:10.368+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:35:10.378+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-08-10T10:35:40.615+0000] {processor.py:157} INFO - Started process (PID=23753) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:35:40.617+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:35:40.622+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:35:40.621+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:35:40.647+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:35:40.669+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:35:40.669+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:35:40.681+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:35:40.681+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:35:40.690+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-08-10T10:36:10.992+0000] {processor.py:157} INFO - Started process (PID=23763) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:36:10.994+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:36:10.995+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:36:10.995+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:36:11.009+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:36:11.033+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:36:11.033+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:36:11.045+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:36:11.045+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:36:11.055+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-10T10:36:41.317+0000] {processor.py:157} INFO - Started process (PID=23773) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:36:41.320+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:36:41.322+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:36:41.322+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:36:41.338+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:36:41.374+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:36:41.374+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:36:41.387+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:36:41.387+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:36:41.397+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-08-10T10:37:11.641+0000] {processor.py:157} INFO - Started process (PID=23783) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:37:11.644+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:37:11.646+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:37:11.646+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:37:11.664+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:37:11.693+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:37:11.693+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:37:11.707+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:37:11.707+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:37:11.718+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-08-10T10:37:42.086+0000] {processor.py:157} INFO - Started process (PID=23793) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:37:42.088+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:37:42.090+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:37:42.090+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:37:42.104+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:37:42.139+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:37:42.139+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:37:42.152+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:37:42.152+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:37:42.161+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-08-10T10:38:12.529+0000] {processor.py:157} INFO - Started process (PID=23803) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:38:12.532+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:38:12.534+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:38:12.534+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:38:12.559+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:38:12.590+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:38:12.590+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:38:12.619+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:38:12.618+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:38:12.631+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-08-10T10:38:42.858+0000] {processor.py:157} INFO - Started process (PID=23813) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:38:42.861+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:38:42.863+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:38:42.863+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:38:42.879+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:38:42.903+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:38:42.903+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:38:42.917+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:38:42.917+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:38:42.928+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-10T10:39:13.246+0000] {processor.py:157} INFO - Started process (PID=23823) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:39:13.251+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:39:13.257+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:39:13.255+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:39:13.283+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:39:13.304+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:39:13.304+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:39:13.314+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:39:13.314+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:39:13.323+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-08-10T10:39:43.554+0000] {processor.py:157} INFO - Started process (PID=23833) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:39:43.555+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:39:43.557+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:39:43.557+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:39:43.574+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:39:43.597+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:39:43.597+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:39:43.609+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:39:43.609+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:39:43.618+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-10T10:40:13.894+0000] {processor.py:157} INFO - Started process (PID=23843) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:40:13.895+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:40:13.896+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:40:13.896+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:40:13.907+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:40:13.929+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:40:13.928+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:40:13.945+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:40:13.945+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:40:13.953+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-10T10:40:44.302+0000] {processor.py:157} INFO - Started process (PID=23853) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:40:44.304+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:40:44.306+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:40:44.306+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:40:44.321+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:40:44.343+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:40:44.343+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:40:44.356+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:40:44.356+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:40:44.366+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-10T10:41:14.730+0000] {processor.py:157} INFO - Started process (PID=23862) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:41:14.732+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:41:14.734+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:41:14.734+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:41:14.744+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:41:14.763+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:41:14.763+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:41:14.775+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:41:14.775+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:41:14.785+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-10T10:41:45.079+0000] {processor.py:157} INFO - Started process (PID=23873) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:41:45.080+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:41:45.085+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:41:45.084+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:41:45.118+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:41:45.143+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:41:45.143+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:41:45.168+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:41:45.168+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:41:45.181+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-08-10T10:42:15.559+0000] {processor.py:157} INFO - Started process (PID=23883) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:42:15.562+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:42:15.565+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:42:15.564+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:42:15.574+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:42:15.598+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:42:15.598+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:42:15.611+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:42:15.611+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:42:15.621+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-10T10:42:45.909+0000] {processor.py:157} INFO - Started process (PID=23893) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:42:45.910+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:42:45.914+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:42:45.914+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:42:45.936+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:42:45.963+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:42:45.962+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:42:45.976+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:42:45.976+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:42:45.987+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-08-10T10:43:16.257+0000] {processor.py:157} INFO - Started process (PID=23903) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:43:16.258+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:43:16.260+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:43:16.260+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:43:16.275+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:43:16.294+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:43:16.293+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:43:16.305+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:43:16.305+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:43:16.312+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-10T10:43:46.681+0000] {processor.py:157} INFO - Started process (PID=23913) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:43:46.685+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:43:46.687+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:43:46.687+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:43:46.720+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:43:46.744+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:43:46.744+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:43:46.757+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:43:46.757+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:43:46.767+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-08-10T10:44:17.088+0000] {processor.py:157} INFO - Started process (PID=23923) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:44:17.089+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:44:17.091+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:44:17.091+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:44:17.103+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:44:17.127+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:44:17.127+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:44:17.143+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:44:17.143+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:44:17.155+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-10T10:44:47.439+0000] {processor.py:157} INFO - Started process (PID=23933) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:44:47.442+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:44:47.444+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:44:47.444+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:44:47.460+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:44:47.489+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:44:47.488+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:44:47.504+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:44:47.504+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:44:47.514+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-08-10T10:45:17.830+0000] {processor.py:157} INFO - Started process (PID=23943) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:45:17.830+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:45:17.833+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:45:17.832+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:45:17.841+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:45:17.864+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:45:17.864+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:45:17.879+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:45:17.879+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:45:17.888+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-10T10:45:48.242+0000] {processor.py:157} INFO - Started process (PID=23953) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:45:48.245+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:45:48.248+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:45:48.248+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:45:48.267+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:45:48.292+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:45:48.292+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:45:48.304+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:45:48.304+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:45:48.319+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-08-10T10:46:18.616+0000] {processor.py:157} INFO - Started process (PID=23963) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:46:18.617+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:46:18.618+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:46:18.618+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:46:18.627+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:46:18.646+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:46:18.646+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:46:18.656+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:46:18.656+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:46:18.666+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-10T10:46:49.078+0000] {processor.py:157} INFO - Started process (PID=23973) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:46:49.082+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:46:49.085+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:46:49.085+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:46:49.112+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:46:49.149+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:46:49.149+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:46:49.162+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:46:49.162+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:46:49.171+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-08-10T10:47:19.453+0000] {processor.py:157} INFO - Started process (PID=23983) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:47:19.454+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:47:19.456+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:47:19.455+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:47:19.470+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:47:19.490+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:47:19.490+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:47:19.501+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:47:19.501+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:47:19.510+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-10T10:47:49.766+0000] {processor.py:157} INFO - Started process (PID=23993) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:47:49.767+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:47:49.771+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:47:49.770+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:47:49.792+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:47:49.818+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:47:49.818+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:47:49.832+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:47:49.832+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:47:49.841+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-08-10T10:48:20.240+0000] {processor.py:157} INFO - Started process (PID=24003) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:48:20.242+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:48:20.245+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:48:20.244+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:48:20.256+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:48:20.280+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:48:20.280+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:48:20.292+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:48:20.291+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:48:20.301+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-10T10:48:50.546+0000] {processor.py:157} INFO - Started process (PID=24013) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:48:50.550+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:48:50.552+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:48:50.552+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:48:50.567+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:48:50.618+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:48:50.618+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:48:50.631+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:48:50.630+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:48:50.641+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-08-10T10:49:20.912+0000] {processor.py:157} INFO - Started process (PID=24023) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:49:20.913+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:49:20.915+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:49:20.915+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:49:20.932+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:49:20.974+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:49:20.974+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:49:20.989+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:49:20.989+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:49:21.001+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-08-10T10:49:51.396+0000] {processor.py:157} INFO - Started process (PID=24033) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:49:51.398+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:49:51.400+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:49:51.400+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:49:51.415+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:49:51.439+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:49:51.439+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:49:51.450+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:49:51.450+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:49:51.460+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-10T10:50:21.735+0000] {processor.py:157} INFO - Started process (PID=24043) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:50:21.737+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:50:21.741+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:50:21.740+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:50:21.758+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:50:21.781+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:50:21.781+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:50:21.795+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:50:21.795+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:50:21.808+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-08-10T10:50:52.058+0000] {processor.py:157} INFO - Started process (PID=24053) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:50:52.062+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:50:52.073+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:50:52.073+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:50:52.089+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:50:52.114+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:50:52.114+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:50:52.128+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:50:52.128+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:50:52.138+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-08-10T10:51:22.493+0000] {processor.py:157} INFO - Started process (PID=24063) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:51:22.496+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:51:22.513+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:51:22.512+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:51:22.530+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:51:22.569+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:51:22.568+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:51:22.585+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:51:22.585+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:51:22.597+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-08-10T10:51:52.805+0000] {processor.py:157} INFO - Started process (PID=24073) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:51:52.807+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:51:52.810+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:51:52.809+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:51:52.827+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:51:52.853+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:51:52.853+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:51:52.868+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:51:52.868+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:51:52.880+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-08-10T10:52:23.163+0000] {processor.py:157} INFO - Started process (PID=24083) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:52:23.165+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:52:23.167+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:52:23.167+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:52:23.176+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:52:23.200+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:52:23.200+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:52:23.213+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:52:23.213+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:52:23.224+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-10T10:52:53.460+0000] {processor.py:157} INFO - Started process (PID=24093) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:52:53.461+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:52:53.464+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:52:53.463+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:52:53.478+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:52:53.501+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:52:53.501+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:52:53.515+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:52:53.515+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:52:53.523+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-10T10:53:23.897+0000] {processor.py:157} INFO - Started process (PID=24103) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:53:23.898+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:53:23.901+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:53:23.900+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:53:23.909+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:53:23.932+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:53:23.932+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:53:23.946+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:53:23.946+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:53:23.956+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-10T10:53:54.229+0000] {processor.py:157} INFO - Started process (PID=24112) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:53:54.231+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:53:54.241+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:53:54.237+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:53:54.266+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:53:54.292+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:53:54.292+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:53:54.307+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:53:54.307+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:53:54.317+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-08-10T10:54:24.652+0000] {processor.py:157} INFO - Started process (PID=24123) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:54:24.657+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:54:24.661+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:54:24.661+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:54:24.673+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:54:24.692+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:54:24.692+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:54:24.704+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:54:24.704+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:54:24.712+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-10T10:54:55.023+0000] {processor.py:157} INFO - Started process (PID=24133) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:54:55.026+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:54:55.029+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:54:55.029+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:54:55.043+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:54:55.060+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:54:55.060+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:54:55.070+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:54:55.070+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:54:55.076+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-10T10:55:25.395+0000] {processor.py:157} INFO - Started process (PID=24143) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:55:25.396+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:55:25.398+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:55:25.397+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:55:25.413+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:55:25.432+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:55:25.432+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:55:25.446+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:55:25.446+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:55:25.456+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-10T10:55:55.738+0000] {processor.py:157} INFO - Started process (PID=24153) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:55:55.738+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:55:55.740+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:55:55.740+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:55:55.756+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:55:55.777+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:55:55.777+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:55:55.787+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:55:55.787+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:55:55.795+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-10T10:56:26.118+0000] {processor.py:157} INFO - Started process (PID=24163) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:56:26.119+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:56:26.121+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:56:26.121+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:56:26.138+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:56:26.160+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:56:26.160+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:56:26.174+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:56:26.174+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:56:26.185+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-10T10:56:56.532+0000] {processor.py:157} INFO - Started process (PID=24173) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:56:56.545+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:56:56.558+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:56:56.555+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:56:56.575+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:56:56.600+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:56:56.600+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:56:56.619+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:56:56.618+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:56:56.632+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-08-10T10:57:26.892+0000] {processor.py:157} INFO - Started process (PID=24183) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:57:26.896+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:57:26.900+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:57:26.900+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:57:26.917+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:57:26.962+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:57:26.962+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:57:26.976+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:57:26.975+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:57:26.987+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-08-10T10:57:57.226+0000] {processor.py:157} INFO - Started process (PID=24193) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:57:57.228+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:57:57.229+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:57:57.229+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:57:57.238+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:57:57.258+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:57:57.258+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:57:57.271+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:57:57.271+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:57:57.280+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-10T10:58:27.553+0000] {processor.py:157} INFO - Started process (PID=24203) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:58:27.554+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:58:27.556+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:58:27.556+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:58:27.567+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:58:27.584+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:58:27.584+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:58:27.596+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:58:27.596+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:58:27.603+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-10T10:58:57.915+0000] {processor.py:157} INFO - Started process (PID=24213) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:58:57.918+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:58:57.920+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:58:57.920+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:58:57.943+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:58:57.962+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:58:57.962+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:58:57.975+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:58:57.975+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:58:57.985+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-10T10:59:28.289+0000] {processor.py:157} INFO - Started process (PID=24223) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:59:28.290+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:59:28.292+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:59:28.291+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:59:28.303+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:59:28.336+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:59:28.336+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:59:28.348+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:59:28.348+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:59:28.359+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-10T10:59:58.682+0000] {processor.py:157} INFO - Started process (PID=24233) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:59:58.683+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T10:59:58.684+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:59:58.684+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:59:58.696+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T10:59:58.713+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:59:58.713+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T10:59:58.723+0000] {logging_mixin.py:151} INFO - [2024-08-10T10:59:58.723+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T10:59:58.732+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-10T11:00:29.123+0000] {processor.py:157} INFO - Started process (PID=24243) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:00:29.125+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:00:29.127+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:00:29.127+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:00:29.141+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:00:29.161+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:00:29.161+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:00:29.172+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:00:29.172+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:00:29.181+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-10T11:00:59.478+0000] {processor.py:157} INFO - Started process (PID=24253) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:00:59.485+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:00:59.488+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:00:59.488+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:00:59.498+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:00:59.516+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:00:59.516+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:00:59.527+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:00:59.527+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:00:59.539+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-10T11:01:29.867+0000] {processor.py:157} INFO - Started process (PID=24263) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:01:29.871+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:01:29.873+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:01:29.873+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:01:29.893+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:01:29.911+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:01:29.911+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:01:29.923+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:01:29.923+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:01:29.933+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-10T11:02:00.211+0000] {processor.py:157} INFO - Started process (PID=24273) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:02:00.212+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:02:00.214+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:02:00.214+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:02:00.223+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:02:00.246+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:02:00.246+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:02:00.257+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:02:00.257+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:02:00.267+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-10T11:02:30.479+0000] {processor.py:157} INFO - Started process (PID=24283) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:02:30.480+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:02:30.482+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:02:30.482+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:02:30.492+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:02:30.508+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:02:30.508+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:02:30.521+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:02:30.521+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:02:30.531+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-10T11:03:00.899+0000] {processor.py:157} INFO - Started process (PID=24293) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:03:00.903+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:03:00.912+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:03:00.911+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:03:00.929+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:03:00.953+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:03:00.953+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:03:00.967+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:03:00.967+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:03:00.977+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-08-10T11:03:31.206+0000] {processor.py:157} INFO - Started process (PID=24303) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:03:31.207+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:03:31.209+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:03:31.209+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:03:31.218+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:03:31.237+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:03:31.237+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:03:31.247+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:03:31.247+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:03:31.255+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-10T11:04:01.492+0000] {processor.py:157} INFO - Started process (PID=24313) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:04:01.498+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:04:01.502+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:04:01.501+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:04:01.510+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:04:01.523+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:04:01.523+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:04:01.532+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:04:01.532+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:04:01.542+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-10T11:04:31.859+0000] {processor.py:157} INFO - Started process (PID=24323) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:04:31.860+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:04:31.862+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:04:31.862+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:04:31.872+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:04:31.889+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:04:31.889+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:04:31.902+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:04:31.902+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:04:31.909+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-10T11:05:02.182+0000] {processor.py:157} INFO - Started process (PID=24333) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:05:02.185+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:05:02.188+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:05:02.188+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:05:02.201+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:05:02.219+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:05:02.219+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:05:02.230+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:05:02.230+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:05:02.238+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-10T11:05:32.554+0000] {processor.py:157} INFO - Started process (PID=24343) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:05:32.555+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:05:32.556+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:05:32.556+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:05:32.567+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:05:32.591+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:05:32.591+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:05:32.610+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:05:32.610+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:05:32.618+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-10T11:06:02.933+0000] {processor.py:157} INFO - Started process (PID=24353) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:06:02.935+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:06:02.936+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:06:02.936+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:06:02.947+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:06:02.969+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:06:02.969+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:06:02.983+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:06:02.983+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:06:02.993+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-10T11:06:33.365+0000] {processor.py:157} INFO - Started process (PID=24363) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:06:33.366+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:06:33.368+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:06:33.367+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:06:33.376+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:06:33.394+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:06:33.394+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:06:33.404+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:06:33.404+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:06:33.412+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-10T11:07:03.729+0000] {processor.py:157} INFO - Started process (PID=24373) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:07:03.730+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:07:03.732+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:07:03.731+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:07:03.744+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:07:03.763+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:07:03.763+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:07:03.773+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:07:03.773+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:07:03.781+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-10T11:07:34.136+0000] {processor.py:157} INFO - Started process (PID=24383) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:07:34.137+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:07:34.140+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:07:34.140+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:07:34.155+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:07:34.178+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:07:34.178+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:07:34.192+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:07:34.192+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:07:34.204+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-10T11:08:04.517+0000] {processor.py:157} INFO - Started process (PID=24393) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:08:04.518+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:08:04.520+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:08:04.520+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:08:04.529+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:08:04.548+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:08:04.548+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:08:04.559+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:08:04.559+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:08:04.568+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-10T11:08:34.875+0000] {processor.py:157} INFO - Started process (PID=24403) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:08:34.876+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:08:34.877+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:08:34.877+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:08:34.889+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:08:34.907+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:08:34.907+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:08:34.919+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:08:34.919+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:08:34.929+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-10T11:09:05.181+0000] {processor.py:157} INFO - Started process (PID=24413) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:09:05.184+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:09:05.186+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:09:05.186+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:09:05.195+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:09:05.213+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:09:05.212+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:09:05.222+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:09:05.222+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:09:05.232+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-10T11:09:35.507+0000] {processor.py:157} INFO - Started process (PID=24423) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:09:35.508+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:09:35.510+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:09:35.510+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:09:35.521+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:09:35.539+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:09:35.539+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:09:35.553+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:09:35.552+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:09:35.561+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-10T11:10:05.919+0000] {processor.py:157} INFO - Started process (PID=24433) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:10:05.923+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:10:05.926+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:10:05.925+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:10:05.940+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:10:05.958+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:10:05.958+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:10:05.969+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:10:05.969+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:10:05.979+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-10T11:10:36.341+0000] {processor.py:157} INFO - Started process (PID=24443) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:10:36.343+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:10:36.345+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:10:36.345+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:10:36.356+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:10:36.380+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:10:36.380+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:10:36.394+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:10:36.394+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:10:36.403+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-10T11:11:06.742+0000] {processor.py:157} INFO - Started process (PID=24453) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:11:06.747+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:11:06.750+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:11:06.750+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:11:06.759+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:11:06.774+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:11:06.774+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:11:06.785+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:11:06.785+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:11:06.795+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-10T11:11:37.150+0000] {processor.py:157} INFO - Started process (PID=24463) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:11:37.151+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:11:37.152+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:11:37.152+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:11:37.162+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:11:37.178+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:11:37.178+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:11:37.192+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:11:37.192+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:11:37.201+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-10T11:12:07.619+0000] {processor.py:157} INFO - Started process (PID=24473) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:12:07.620+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:12:07.623+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:12:07.623+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:12:07.633+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:12:07.648+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:12:07.648+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:12:07.659+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:12:07.659+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:12:07.668+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-10T11:12:37.979+0000] {processor.py:157} INFO - Started process (PID=24483) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:12:37.982+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:12:37.983+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:12:37.983+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:12:37.998+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:12:38.020+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:12:38.020+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:12:38.033+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:12:38.033+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:12:38.043+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-10T11:13:08.359+0000] {processor.py:157} INFO - Started process (PID=24493) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:13:08.361+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:13:08.363+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:13:08.363+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:13:08.375+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:13:08.408+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:13:08.408+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:13:08.421+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:13:08.421+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:13:08.430+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-08-10T11:13:38.723+0000] {processor.py:157} INFO - Started process (PID=24503) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:13:38.724+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:13:38.727+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:13:38.726+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:13:38.744+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:13:38.764+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:13:38.764+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:13:38.774+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:13:38.773+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:13:38.783+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-10T11:14:09.045+0000] {processor.py:157} INFO - Started process (PID=24513) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:14:09.047+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:14:09.049+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:14:09.049+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:14:09.059+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:14:09.080+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:14:09.080+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:14:09.096+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:14:09.096+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:14:09.106+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-10T11:14:39.452+0000] {processor.py:157} INFO - Started process (PID=24523) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:14:39.454+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:14:39.455+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:14:39.455+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:14:39.464+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:14:39.482+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:14:39.482+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:14:39.494+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:14:39.494+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:14:39.503+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-10T11:15:09.869+0000] {processor.py:157} INFO - Started process (PID=24533) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:15:09.870+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:15:09.871+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:15:09.871+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:15:09.880+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:15:09.898+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:15:09.898+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:15:09.909+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:15:09.909+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:15:09.917+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-10T11:15:40.235+0000] {processor.py:157} INFO - Started process (PID=24543) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:15:40.237+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:15:40.241+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:15:40.241+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:15:40.259+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:15:40.288+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:15:40.287+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:15:40.300+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:15:40.299+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:15:40.311+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-08-10T11:16:10.692+0000] {processor.py:157} INFO - Started process (PID=24552) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:16:10.695+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:16:10.698+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:16:10.698+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:16:10.714+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:16:10.735+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:16:10.735+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:16:10.747+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:16:10.746+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:16:10.757+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-10T11:16:41.009+0000] {processor.py:157} INFO - Started process (PID=24563) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:16:41.012+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:16:41.013+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:16:41.013+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:16:41.023+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:16:41.046+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:16:41.046+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:16:41.060+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:16:41.060+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:16:41.068+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-10T11:17:11.340+0000] {processor.py:157} INFO - Started process (PID=24573) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:17:11.343+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:17:11.345+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:17:11.345+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:17:11.362+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:17:11.384+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:17:11.384+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:17:11.394+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:17:11.394+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:17:12.287+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.951 seconds
[2024-08-10T11:17:42.621+0000] {processor.py:157} INFO - Started process (PID=24583) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:17:42.624+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:17:42.626+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:17:42.626+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:17:42.642+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:17:42.666+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:17:42.666+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:17:42.681+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:17:42.680+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:17:42.694+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-08-10T11:18:12.975+0000] {processor.py:157} INFO - Started process (PID=24593) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:18:12.976+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:18:12.978+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:18:12.978+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:18:12.987+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:18:13.010+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:18:13.010+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:18:13.022+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:18:13.022+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:18:13.031+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-10T11:18:43.309+0000] {processor.py:157} INFO - Started process (PID=24603) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:18:43.310+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:18:43.312+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:18:43.312+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:18:43.322+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:18:43.339+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:18:43.339+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:18:43.352+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:18:43.352+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:18:43.361+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-10T11:19:13.686+0000] {processor.py:157} INFO - Started process (PID=24613) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:19:13.689+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:19:13.693+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:19:13.693+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:19:13.709+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:19:13.733+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:19:13.733+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:19:13.750+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:19:13.750+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:19:13.758+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-08-10T11:19:44.050+0000] {processor.py:157} INFO - Started process (PID=24623) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:19:44.052+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:19:44.054+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:19:44.054+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:19:44.060+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:19:44.078+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:19:44.077+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:19:44.087+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:19:44.087+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:19:44.096+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-08-10T11:20:14.765+0000] {processor.py:157} INFO - Started process (PID=24632) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:20:14.767+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:20:14.771+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:20:14.771+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:20:14.790+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:20:14.815+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:20:14.815+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:20:14.838+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:20:14.838+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:20:14.991+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.233 seconds
[2024-08-10T11:20:45.125+0000] {processor.py:157} INFO - Started process (PID=24643) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:20:45.127+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:20:45.132+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:20:45.132+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:20:45.155+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:20:45.186+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:20:45.186+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:20:45.202+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:20:45.202+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:20:45.214+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-08-10T11:21:15.448+0000] {processor.py:157} INFO - Started process (PID=24653) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:21:15.451+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:21:15.455+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:21:15.455+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:21:15.474+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:21:15.518+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:21:15.518+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:21:15.534+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:21:15.534+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:21:15.545+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-08-10T11:21:45.779+0000] {processor.py:157} INFO - Started process (PID=24663) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:21:45.782+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:21:45.786+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:21:45.786+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:21:45.803+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:21:45.827+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:21:45.827+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:21:45.841+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:21:45.841+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:21:45.851+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-08-10T11:22:16.173+0000] {processor.py:157} INFO - Started process (PID=24673) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:22:16.173+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:22:16.175+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:22:16.175+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:22:16.185+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:22:16.209+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:22:16.209+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:22:16.220+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:22:16.220+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:22:16.229+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-10T11:22:46.513+0000] {processor.py:157} INFO - Started process (PID=24683) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:22:46.514+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:22:46.516+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:22:46.516+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:22:46.526+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:22:46.545+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:22:46.545+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:22:46.556+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:22:46.556+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:22:46.566+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-10T11:23:16.834+0000] {processor.py:157} INFO - Started process (PID=24693) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:23:16.836+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:23:16.838+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:23:16.838+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:23:16.859+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:23:16.877+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:23:16.877+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:23:16.893+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:23:16.893+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:23:16.903+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-10T11:23:47.146+0000] {processor.py:157} INFO - Started process (PID=24703) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:23:47.147+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:23:47.149+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:23:47.149+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:23:47.162+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:23:47.182+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:23:47.182+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:23:47.193+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:23:47.193+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:23:47.203+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-10T11:24:17.497+0000] {processor.py:157} INFO - Started process (PID=24713) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:24:17.498+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:24:17.500+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:24:17.500+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:24:17.508+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:24:17.525+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:24:17.525+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:24:17.536+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:24:17.536+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:24:17.544+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-10T11:24:47.837+0000] {processor.py:157} INFO - Started process (PID=24723) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:24:47.838+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:24:47.840+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:24:47.839+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:24:47.849+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:24:47.868+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:24:47.868+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:24:47.880+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:24:47.880+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:24:47.889+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-10T11:25:18.155+0000] {processor.py:157} INFO - Started process (PID=24733) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:25:18.158+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:25:18.160+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:25:18.159+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:25:18.178+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:25:18.203+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:25:18.203+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:25:18.219+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:25:18.219+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:25:18.228+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-08-10T11:25:48.538+0000] {processor.py:157} INFO - Started process (PID=24743) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:25:48.539+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:25:48.541+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:25:48.540+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:25:48.551+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:25:48.569+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:25:48.568+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:25:48.583+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:25:48.583+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:25:48.594+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-10T11:26:18.944+0000] {processor.py:157} INFO - Started process (PID=24753) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:26:18.946+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:26:18.948+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:26:18.948+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:26:18.963+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:26:18.985+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:26:18.985+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:26:19.000+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:26:19.000+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:26:19.010+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-10T11:26:49.258+0000] {processor.py:157} INFO - Started process (PID=24763) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:26:49.259+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:26:49.260+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:26:49.260+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:26:49.272+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:26:49.290+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:26:49.290+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:26:49.307+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:26:49.307+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:26:49.318+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-10T11:27:19.737+0000] {processor.py:157} INFO - Started process (PID=24773) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:27:19.740+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:27:19.742+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:27:19.742+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:27:19.786+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:27:19.822+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:27:19.822+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:27:19.862+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:27:19.862+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:27:19.879+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.146 seconds
[2024-08-10T11:27:50.058+0000] {processor.py:157} INFO - Started process (PID=24783) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:27:50.061+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:27:50.063+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:27:50.063+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:27:50.075+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:27:50.092+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:27:50.092+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:27:50.104+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:27:50.104+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:27:50.113+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-10T11:28:20.451+0000] {processor.py:157} INFO - Started process (PID=24793) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:28:20.452+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:28:20.455+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:28:20.455+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:28:20.469+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:28:20.492+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:28:20.492+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:28:20.505+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:28:20.505+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:28:20.517+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-10T11:28:50.860+0000] {processor.py:157} INFO - Started process (PID=24803) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:28:50.863+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:28:50.865+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:28:50.865+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:28:50.877+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:28:50.896+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:28:50.895+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:28:50.907+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:28:50.907+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:28:50.919+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-10T11:29:21.220+0000] {processor.py:157} INFO - Started process (PID=24813) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:29:21.223+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:29:21.226+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:29:21.226+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:29:21.239+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:29:21.263+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:29:21.263+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:29:21.276+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:29:21.276+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:29:21.287+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-10T11:29:51.649+0000] {processor.py:157} INFO - Started process (PID=24823) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:29:51.651+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:29:51.654+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:29:51.653+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:29:51.665+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:29:51.685+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:29:51.685+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:29:51.698+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:29:51.698+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:29:51.710+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-10T11:30:22.010+0000] {processor.py:157} INFO - Started process (PID=24833) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:30:22.013+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:30:22.021+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:30:22.020+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:30:22.053+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:30:22.077+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:30:22.077+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:30:22.090+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:30:22.090+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:30:22.102+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-08-10T11:30:52.409+0000] {processor.py:157} INFO - Started process (PID=24843) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:30:52.411+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:30:52.413+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:30:52.413+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:30:52.424+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:30:52.443+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:30:52.443+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:30:52.458+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:30:52.458+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:30:52.470+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-10T11:31:22.760+0000] {processor.py:157} INFO - Started process (PID=24852) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:31:22.761+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:31:22.764+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:31:22.763+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:31:22.782+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:31:22.808+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:31:22.808+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:31:22.825+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:31:22.825+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:31:22.835+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-08-10T11:31:53.169+0000] {processor.py:157} INFO - Started process (PID=24863) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:31:53.170+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:31:53.172+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:31:53.171+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:31:53.185+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:31:53.206+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:31:53.206+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:31:53.220+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:31:53.220+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:31:53.230+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-10T11:32:23.575+0000] {processor.py:157} INFO - Started process (PID=24873) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:32:23.577+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:32:23.579+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:32:23.579+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:32:23.594+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:32:23.613+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:32:23.613+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:32:23.625+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:32:23.625+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:32:23.636+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-10T11:32:53.970+0000] {processor.py:157} INFO - Started process (PID=24883) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:32:53.972+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:32:53.974+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:32:53.973+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:32:53.988+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:32:54.019+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:32:54.018+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:32:54.039+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:32:54.039+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:32:54.049+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-08-10T11:33:24.328+0000] {processor.py:157} INFO - Started process (PID=24893) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:33:24.331+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:33:24.334+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:33:24.334+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:33:24.352+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:33:24.379+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:33:24.379+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:33:24.393+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:33:24.393+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:33:24.404+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-08-10T11:33:54.609+0000] {processor.py:157} INFO - Started process (PID=24903) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:33:54.610+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:33:54.612+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:33:54.611+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:33:54.626+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:33:54.644+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:33:54.644+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:33:54.657+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:33:54.657+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:33:54.667+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-10T11:34:24.939+0000] {processor.py:157} INFO - Started process (PID=24913) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:34:24.940+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:34:24.942+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:34:24.942+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:34:24.955+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:34:24.976+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:34:24.975+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:34:24.987+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:34:24.987+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:34:24.998+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-10T11:34:55.326+0000] {processor.py:157} INFO - Started process (PID=24923) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:34:55.328+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:34:55.330+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:34:55.330+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:34:55.342+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:34:55.358+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:34:55.358+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:34:55.369+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:34:55.369+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:34:55.381+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-10T11:35:25.835+0000] {processor.py:157} INFO - Started process (PID=24933) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:35:25.836+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:35:25.838+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:35:25.838+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:35:25.851+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:35:25.872+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:35:25.872+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:35:25.886+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:35:25.885+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:35:25.898+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-10T11:35:56.161+0000] {processor.py:157} INFO - Started process (PID=24943) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:35:56.164+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:35:56.166+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:35:56.166+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:35:56.181+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:35:56.200+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:35:56.200+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:35:56.211+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:35:56.211+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:35:56.221+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-10T11:36:26.508+0000] {processor.py:157} INFO - Started process (PID=24953) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:36:26.509+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:36:26.512+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:36:26.512+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:36:26.525+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:36:26.549+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:36:26.548+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:36:26.562+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:36:26.562+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:36:26.574+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-10T11:36:56.955+0000] {processor.py:157} INFO - Started process (PID=24963) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:36:56.957+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:36:56.960+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:36:56.959+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:36:56.976+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:36:56.996+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:36:56.996+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:36:57.008+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:36:57.008+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:36:57.019+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-10T11:37:27.276+0000] {processor.py:157} INFO - Started process (PID=24973) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:37:27.277+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:37:27.279+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:37:27.279+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:37:27.297+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:37:27.313+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:37:27.313+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:37:27.327+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:37:27.327+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:37:27.336+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-10T11:37:57.718+0000] {processor.py:157} INFO - Started process (PID=24983) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:37:57.721+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:37:57.723+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:37:57.723+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:37:57.736+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:37:57.758+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:37:57.758+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:37:57.773+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:37:57.773+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:37:57.957+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.242 seconds
[2024-08-10T11:38:28.084+0000] {processor.py:157} INFO - Started process (PID=24993) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:38:28.085+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:38:28.090+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:38:28.089+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:38:28.101+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:38:28.125+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:38:28.125+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:38:28.136+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:38:28.136+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:38:28.148+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-08-10T11:38:58.486+0000] {processor.py:157} INFO - Started process (PID=25003) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:38:58.487+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:38:58.489+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:38:58.489+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:38:58.502+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:38:58.524+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:38:58.523+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:38:58.539+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:38:58.538+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:38:58.549+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-10T11:39:28.794+0000] {processor.py:157} INFO - Started process (PID=25013) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:39:28.795+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:39:28.798+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:39:28.798+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:39:28.812+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:39:28.834+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:39:28.834+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:39:28.850+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:39:28.850+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:39:28.860+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-10T11:39:59.193+0000] {processor.py:157} INFO - Started process (PID=25023) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:39:59.195+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:39:59.197+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:39:59.197+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:39:59.207+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:39:59.223+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:39:59.223+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:39:59.233+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:39:59.233+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:39:59.242+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-10T11:40:29.582+0000] {processor.py:157} INFO - Started process (PID=25033) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:40:29.584+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:40:29.587+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:40:29.587+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:40:29.600+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:40:29.616+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:40:29.616+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:40:29.631+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:40:29.631+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:40:29.642+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-10T11:40:59.919+0000] {processor.py:157} INFO - Started process (PID=25043) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:40:59.920+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:40:59.922+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:40:59.922+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:40:59.933+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:40:59.954+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:40:59.954+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:40:59.969+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:40:59.969+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:41:00.173+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.257 seconds
[2024-08-10T11:41:30.275+0000] {processor.py:157} INFO - Started process (PID=25053) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:41:30.277+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:41:30.280+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:41:30.280+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:41:30.296+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:41:30.322+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:41:30.321+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:41:30.337+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:41:30.337+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:41:30.347+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-08-10T11:42:00.590+0000] {processor.py:157} INFO - Started process (PID=25063) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:42:00.591+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:42:00.593+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:42:00.593+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:42:00.609+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:42:00.626+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:42:00.626+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:42:00.638+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:42:00.638+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:42:00.647+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-10T11:42:30.901+0000] {processor.py:157} INFO - Started process (PID=25073) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:42:30.905+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:42:30.907+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:42:30.907+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:42:30.920+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:42:30.942+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:42:30.942+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:42:30.955+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:42:30.955+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:42:30.964+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-10T11:43:01.216+0000] {processor.py:157} INFO - Started process (PID=25083) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:43:01.217+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:43:01.219+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:43:01.219+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:43:01.237+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:43:01.256+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:43:01.256+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:43:01.282+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:43:01.282+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:43:01.297+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-08-10T11:43:31.592+0000] {processor.py:157} INFO - Started process (PID=25093) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:43:31.593+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:43:31.596+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:43:31.596+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:43:31.611+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:43:31.635+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:43:31.635+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:43:31.649+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:43:31.649+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:43:31.660+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-10T11:44:02.042+0000] {processor.py:157} INFO - Started process (PID=25103) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:44:02.043+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:44:02.046+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:44:02.045+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:44:02.070+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:44:02.091+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:44:02.091+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:44:02.107+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:44:02.106+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:44:02.288+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.248 seconds
[2024-08-10T11:44:32.632+0000] {processor.py:157} INFO - Started process (PID=25113) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:44:32.633+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:44:32.636+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:44:32.636+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:44:32.652+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:44:32.678+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:44:32.678+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:44:32.691+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:44:32.691+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:44:32.701+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-10T11:45:02.994+0000] {processor.py:157} INFO - Started process (PID=25123) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:45:02.995+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:45:02.997+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:45:02.997+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:45:03.008+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:45:03.027+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:45:03.027+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:45:03.039+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:45:03.039+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:45:03.052+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-10T11:45:33.373+0000] {processor.py:157} INFO - Started process (PID=25133) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:45:33.373+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:45:33.376+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:45:33.376+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:45:33.393+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:45:33.410+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:45:33.410+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:45:33.425+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:45:33.425+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:45:33.435+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-10T11:46:03.836+0000] {processor.py:157} INFO - Started process (PID=25143) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:46:03.838+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:46:03.841+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:46:03.841+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:46:03.870+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:46:03.896+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:46:03.896+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:46:03.911+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:46:03.910+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:46:03.920+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-10T11:46:34.159+0000] {processor.py:157} INFO - Started process (PID=25153) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:46:34.160+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:46:34.162+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:46:34.162+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:46:34.171+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:46:34.189+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:46:34.189+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:46:34.199+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:46:34.199+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:46:34.210+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-10T11:47:04.485+0000] {processor.py:157} INFO - Started process (PID=25163) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:47:04.486+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:47:04.488+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:47:04.488+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:47:04.497+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:47:04.514+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:47:04.514+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:47:04.659+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:47:04.659+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:47:04.666+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.183 seconds
[2024-08-10T11:47:34.793+0000] {processor.py:157} INFO - Started process (PID=25173) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:47:34.797+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:47:34.800+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:47:34.799+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:47:34.813+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:47:34.835+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:47:34.835+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:47:34.848+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:47:34.848+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:47:34.858+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-10T11:48:05.094+0000] {processor.py:157} INFO - Started process (PID=25183) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:48:05.100+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:48:05.102+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:48:05.102+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:48:05.112+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:48:05.127+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:48:05.127+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:48:05.138+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:48:05.138+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:48:05.146+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-10T11:48:35.430+0000] {processor.py:157} INFO - Started process (PID=25193) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:48:35.430+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:48:35.432+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:48:35.432+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:48:35.442+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:48:35.459+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:48:35.459+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:48:35.471+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:48:35.471+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:48:35.479+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-10T11:49:05.861+0000] {processor.py:157} INFO - Started process (PID=25203) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:49:05.863+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:49:05.866+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:49:05.866+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:49:05.878+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:49:05.897+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:49:05.897+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:49:05.910+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:49:05.910+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:49:05.921+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-10T11:49:36.191+0000] {processor.py:157} INFO - Started process (PID=25213) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:49:36.192+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:49:36.196+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:49:36.196+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:49:36.226+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:49:36.253+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:49:36.253+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:49:36.268+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:49:36.268+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:49:36.279+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-08-10T11:50:06.459+0000] {processor.py:157} INFO - Started process (PID=25223) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:50:06.464+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:50:06.466+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:50:06.466+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:50:06.475+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:50:06.489+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:50:06.489+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:50:06.650+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:50:06.650+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:50:06.659+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.203 seconds
[2024-08-10T11:50:36.821+0000] {processor.py:157} INFO - Started process (PID=25233) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:50:36.822+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:50:36.824+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:50:36.824+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:50:36.835+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:50:36.852+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:50:36.852+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:50:36.864+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:50:36.864+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:50:36.873+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-10T11:51:07.210+0000] {processor.py:157} INFO - Started process (PID=25243) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:51:07.214+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:51:07.216+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:51:07.215+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:51:07.242+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:51:07.290+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:51:07.290+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:51:07.307+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:51:07.307+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:51:07.319+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-08-10T11:51:37.602+0000] {processor.py:157} INFO - Started process (PID=25253) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:51:37.603+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:51:37.606+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:51:37.606+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:51:37.622+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:51:37.645+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:51:37.645+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:51:37.659+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:51:37.659+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:51:37.667+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-10T11:52:08.014+0000] {processor.py:157} INFO - Started process (PID=25263) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:52:08.015+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:52:08.016+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:52:08.016+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:52:08.026+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:52:08.042+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:52:08.042+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:52:08.054+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:52:08.054+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:52:08.062+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-10T11:52:38.404+0000] {processor.py:157} INFO - Started process (PID=25273) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:52:38.405+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:52:38.407+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:52:38.406+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:52:38.417+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:52:38.433+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:52:38.432+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:52:38.443+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:52:38.443+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:52:38.452+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-10T11:53:08.748+0000] {processor.py:157} INFO - Started process (PID=25283) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:53:08.749+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:53:08.751+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:53:08.751+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:53:08.767+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:53:08.790+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:53:08.790+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:53:08.956+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:53:08.956+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:53:08.965+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.221 seconds
[2024-08-10T11:53:39.128+0000] {processor.py:157} INFO - Started process (PID=25293) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:53:39.129+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:53:39.131+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:53:39.131+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:53:39.143+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:53:39.159+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:53:39.159+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:53:39.172+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:53:39.172+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:53:39.181+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-10T11:54:09.501+0000] {processor.py:157} INFO - Started process (PID=25303) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:54:09.503+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:54:09.505+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:54:09.505+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:54:09.516+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:54:09.533+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:54:09.533+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:54:09.544+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:54:09.544+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:54:09.554+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-10T11:54:39.872+0000] {processor.py:157} INFO - Started process (PID=25313) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:54:39.874+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:54:39.877+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:54:39.877+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:54:39.892+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:54:39.909+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:54:39.909+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:54:39.920+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:54:39.920+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:54:39.931+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-10T11:55:10.250+0000] {processor.py:157} INFO - Started process (PID=25323) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:55:10.252+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:55:10.254+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:55:10.253+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:55:10.264+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:55:10.286+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:55:10.286+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:55:10.300+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:55:10.300+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:55:10.308+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-10T11:55:40.576+0000] {processor.py:157} INFO - Started process (PID=25333) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:55:40.578+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:55:40.580+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:55:40.579+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:55:40.589+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:55:40.605+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:55:40.605+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:55:40.615+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:55:40.615+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:55:40.752+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.178 seconds
[2024-08-10T11:56:10.912+0000] {processor.py:157} INFO - Started process (PID=25343) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:56:10.914+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:56:10.917+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:56:10.916+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:56:10.933+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:56:10.949+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:56:10.948+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:56:11.028+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:56:11.028+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:56:11.036+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-08-10T11:56:41.396+0000] {processor.py:157} INFO - Started process (PID=25353) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:56:41.398+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:56:41.401+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:56:41.401+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:56:41.416+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:56:41.438+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:56:41.438+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:56:41.451+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:56:41.451+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:56:41.461+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-10T11:57:11.838+0000] {processor.py:157} INFO - Started process (PID=25363) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:57:11.840+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:57:11.842+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:57:11.842+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:57:11.851+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:57:11.867+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:57:11.867+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:57:11.877+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:57:11.877+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:57:11.885+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-10T11:57:42.295+0000] {processor.py:157} INFO - Started process (PID=25373) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:57:42.296+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:57:42.299+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:57:42.299+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:57:42.312+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:57:42.326+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:57:42.326+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:57:42.338+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:57:42.337+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:57:42.348+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-10T11:58:12.688+0000] {processor.py:157} INFO - Started process (PID=25383) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:58:12.691+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:58:12.694+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:58:12.693+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:58:12.702+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:58:12.717+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:58:12.717+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:58:12.727+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:58:12.727+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:58:12.735+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-10T11:58:42.816+0000] {processor.py:157} INFO - Started process (PID=25393) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:58:42.817+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:58:42.819+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:58:42.819+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:58:42.829+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:58:42.849+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:58:42.849+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:58:42.861+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:58:42.861+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:58:43.005+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.192 seconds
[2024-08-10T11:59:13.168+0000] {processor.py:157} INFO - Started process (PID=25403) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:59:13.169+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:59:13.172+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:59:13.172+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:59:13.187+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:59:13.233+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:59:13.233+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:59:13.319+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:59:13.319+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:59:13.326+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.164 seconds
[2024-08-10T11:59:43.540+0000] {processor.py:157} INFO - Started process (PID=25413) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:59:43.541+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T11:59:43.543+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:59:43.543+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:59:43.557+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T11:59:43.573+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:59:43.573+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T11:59:43.584+0000] {logging_mixin.py:151} INFO - [2024-08-10T11:59:43.584+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T11:59:43.592+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-10T12:00:13.908+0000] {processor.py:157} INFO - Started process (PID=25423) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:00:13.910+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:00:13.912+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:00:13.911+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:00:13.922+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:00:13.939+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:00:13.939+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:00:13.950+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:00:13.950+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:00:13.959+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-10T12:00:44.317+0000] {processor.py:157} INFO - Started process (PID=25433) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:00:44.318+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:00:44.319+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:00:44.319+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:00:44.330+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:00:44.347+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:00:44.347+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:00:44.358+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:00:44.358+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:00:44.367+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-10T12:01:14.708+0000] {processor.py:157} INFO - Started process (PID=25443) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:01:14.709+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:01:14.711+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:01:14.711+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:01:14.725+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:01:14.746+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:01:14.746+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:01:14.758+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:01:14.758+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:01:14.769+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-10T12:01:45.073+0000] {processor.py:157} INFO - Started process (PID=25453) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:01:45.073+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:01:45.075+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:01:45.075+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:01:45.084+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:01:45.100+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:01:45.100+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:01:45.110+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:01:45.110+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:01:45.274+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.203 seconds
[2024-08-10T12:02:15.702+0000] {processor.py:157} INFO - Started process (PID=25463) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:02:15.703+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:02:15.704+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:02:15.704+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:02:15.717+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:02:15.735+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:02:15.735+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:02:15.815+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:02:15.815+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:02:15.822+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-08-10T12:02:46.165+0000] {processor.py:157} INFO - Started process (PID=25473) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:02:46.167+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:02:46.169+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:02:46.169+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:02:46.180+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:02:46.198+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:02:46.198+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:02:46.209+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:02:46.209+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:02:46.218+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-10T12:03:16.506+0000] {processor.py:157} INFO - Started process (PID=25483) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:03:16.507+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:03:16.509+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:03:16.509+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:03:16.526+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:03:16.547+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:03:16.547+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:03:16.559+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:03:16.559+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:03:16.569+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-10T12:03:46.838+0000] {processor.py:157} INFO - Started process (PID=25493) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:03:46.838+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:03:46.840+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:03:46.840+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:03:46.848+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:03:46.868+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:03:46.867+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:03:46.878+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:03:46.877+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:03:46.886+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-10T12:04:17.234+0000] {processor.py:157} INFO - Started process (PID=25503) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:04:17.236+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:04:17.238+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:04:17.238+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:04:17.249+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:04:17.264+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:04:17.264+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:04:17.274+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:04:17.274+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:04:17.284+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-10T12:04:47.691+0000] {processor.py:157} INFO - Started process (PID=25513) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:04:47.692+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:04:47.695+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:04:47.695+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:04:47.705+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:04:47.723+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:04:47.723+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:04:47.734+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:04:47.734+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:04:47.913+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.225 seconds
[2024-08-10T12:05:18.296+0000] {processor.py:157} INFO - Started process (PID=25523) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:05:18.299+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:05:18.301+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:05:18.301+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:05:18.314+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:05:18.335+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:05:18.335+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:05:18.415+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:05:18.415+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:05:18.422+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-08-10T12:05:48.634+0000] {processor.py:157} INFO - Started process (PID=25533) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:05:48.636+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:05:48.639+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:05:48.639+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:05:48.654+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:05:48.670+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:05:48.670+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:05:48.681+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:05:48.681+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:05:48.691+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-10T12:06:19.022+0000] {processor.py:157} INFO - Started process (PID=25543) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:06:19.024+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:06:19.026+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:06:19.026+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:06:19.038+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:06:19.057+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:06:19.057+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:06:19.068+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:06:19.068+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:06:19.076+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-10T12:06:49.401+0000] {processor.py:157} INFO - Started process (PID=25553) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:06:49.403+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:06:49.415+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:06:49.409+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:06:49.438+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:06:49.459+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:06:49.459+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:06:49.472+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:06:49.472+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:06:49.482+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-08-10T12:07:19.821+0000] {processor.py:157} INFO - Started process (PID=25563) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:07:19.822+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:07:19.823+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:07:19.823+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:07:19.832+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:07:19.849+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:07:19.849+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:07:19.857+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:07:19.857+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:07:19.868+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-10T12:07:50.193+0000] {processor.py:157} INFO - Started process (PID=25573) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:07:50.195+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:07:50.197+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:07:50.197+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:07:50.209+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:07:50.229+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:07:50.229+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:07:50.379+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:07:50.378+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:07:50.386+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.197 seconds
[2024-08-10T12:08:20.726+0000] {processor.py:157} INFO - Started process (PID=25583) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:08:20.727+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:08:20.729+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:08:20.729+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:08:20.743+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:08:20.765+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:08:20.765+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:08:20.778+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:08:20.778+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:08:20.788+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-10T12:08:51.095+0000] {processor.py:157} INFO - Started process (PID=25593) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:08:51.098+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:08:51.101+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:08:51.101+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:08:51.134+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:08:51.162+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:08:51.162+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:08:51.179+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:08:51.179+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:08:51.189+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-08-10T12:09:21.390+0000] {processor.py:157} INFO - Started process (PID=25603) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:09:21.393+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:09:21.395+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:09:21.395+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:09:21.410+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:09:21.433+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:09:21.432+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:09:21.446+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:09:21.446+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:09:21.457+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-10T12:09:51.827+0000] {processor.py:157} INFO - Started process (PID=25613) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:09:51.829+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:09:51.830+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:09:51.830+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:09:51.839+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:09:51.856+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:09:51.856+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:09:51.866+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:09:51.866+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:09:51.875+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-10T12:10:22.196+0000] {processor.py:157} INFO - Started process (PID=25623) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:10:22.199+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:10:22.200+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:10:22.200+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:10:22.219+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:10:22.238+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:10:22.237+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:10:22.250+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:10:22.250+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:10:22.262+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-10T12:10:52.594+0000] {processor.py:157} INFO - Started process (PID=25633) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:10:52.595+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:10:52.597+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:10:52.597+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:10:52.609+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:10:52.623+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:10:52.623+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:10:52.763+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:10:52.763+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:10:52.778+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.187 seconds
[2024-08-10T12:11:23.155+0000] {processor.py:157} INFO - Started process (PID=25643) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:11:23.157+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:11:23.159+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:11:23.159+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:11:23.182+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:11:23.217+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:11:23.217+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:11:23.232+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:11:23.232+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:11:23.242+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-08-10T12:11:53.625+0000] {processor.py:157} INFO - Started process (PID=25653) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:11:53.632+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:11:53.643+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:11:53.642+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:11:53.670+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:11:53.695+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:11:53.695+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:11:53.709+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:11:53.709+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:11:53.719+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-08-10T12:12:24.055+0000] {processor.py:157} INFO - Started process (PID=25663) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:12:24.060+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:12:24.065+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:12:24.064+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:12:24.083+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:12:24.129+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:12:24.129+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:12:24.145+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:12:24.145+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:12:24.157+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-08-10T12:12:54.351+0000] {processor.py:157} INFO - Started process (PID=25673) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:12:54.353+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:12:54.357+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:12:54.356+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:12:54.372+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:12:54.395+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:12:54.395+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:12:54.407+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:12:54.407+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:12:54.416+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-10T12:13:24.712+0000] {processor.py:157} INFO - Started process (PID=25683) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:13:24.714+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:13:24.716+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:13:24.716+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:13:24.725+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:13:24.744+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:13:24.744+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:13:24.760+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:13:24.760+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:13:24.916+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.207 seconds
[2024-08-10T12:13:55.231+0000] {processor.py:157} INFO - Started process (PID=25693) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:13:55.232+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:13:55.233+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:13:55.233+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:13:55.247+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:13:55.261+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:13:55.261+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:13:55.342+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:13:55.342+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:13:55.350+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-08-10T12:14:25.557+0000] {processor.py:157} INFO - Started process (PID=25703) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:14:25.559+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:14:25.561+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:14:25.561+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:14:25.575+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:14:25.590+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:14:25.590+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:14:25.667+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:14:25.666+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:14:25.677+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-08-10T12:14:56.022+0000] {processor.py:157} INFO - Started process (PID=25713) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:14:56.025+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:14:56.028+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:14:56.027+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:14:56.037+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:14:56.053+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:14:56.053+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:14:56.063+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:14:56.063+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:14:56.071+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-10T12:15:26.362+0000] {processor.py:157} INFO - Started process (PID=25723) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:15:26.363+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:15:26.366+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:15:26.365+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:15:26.374+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:15:26.391+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:15:26.391+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:15:26.401+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:15:26.401+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:15:26.410+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-10T12:15:56.763+0000] {processor.py:157} INFO - Started process (PID=25733) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:15:56.765+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:15:56.770+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:15:56.769+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:15:56.822+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:15:56.860+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:15:56.860+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:15:56.879+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:15:56.879+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:15:56.894+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-08-10T12:16:27.071+0000] {processor.py:157} INFO - Started process (PID=25743) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:16:27.072+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:16:27.074+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:16:27.074+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:16:27.090+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:16:27.105+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:16:27.105+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:16:27.118+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:16:27.117+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:16:27.260+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.192 seconds
[2024-08-10T12:16:57.380+0000] {processor.py:157} INFO - Started process (PID=25753) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:16:57.382+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:16:57.383+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:16:57.383+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:16:57.394+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:16:57.409+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:16:57.408+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:16:57.488+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:16:57.488+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:16:57.496+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-08-10T12:17:27.809+0000] {processor.py:157} INFO - Started process (PID=25763) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:17:27.814+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:17:27.817+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:17:27.816+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:17:27.827+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:17:27.843+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:17:27.843+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:17:27.852+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:17:27.852+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:17:27.861+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-10T12:17:58.113+0000] {processor.py:157} INFO - Started process (PID=25773) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:17:58.115+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:17:58.117+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:17:58.117+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:17:58.131+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:17:58.150+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:17:58.150+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:17:58.162+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:17:58.162+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:17:58.172+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-10T12:18:28.436+0000] {processor.py:157} INFO - Started process (PID=25783) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:18:28.437+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:18:28.438+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:18:28.438+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:18:28.448+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:18:28.465+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:18:28.465+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:18:28.477+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:18:28.477+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:18:28.485+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-10T12:18:58.890+0000] {processor.py:157} INFO - Started process (PID=25793) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:18:58.892+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:18:58.893+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:18:58.893+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:18:58.914+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:18:58.932+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:18:58.932+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:18:58.943+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:18:58.943+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:18:58.954+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-10T12:19:29.278+0000] {processor.py:157} INFO - Started process (PID=25803) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:19:29.280+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:19:29.283+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:19:29.282+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:19:29.302+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:19:29.319+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:19:29.319+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:19:29.333+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:19:29.333+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:19:29.510+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.236 seconds
[2024-08-10T12:19:59.582+0000] {processor.py:157} INFO - Started process (PID=25813) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:19:59.584+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:19:59.586+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:19:59.586+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:19:59.606+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:19:59.634+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:19:59.634+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:19:59.790+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:19:59.790+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:19:59.799+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.226 seconds
[2024-08-10T12:20:30.106+0000] {processor.py:157} INFO - Started process (PID=25822) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:20:30.108+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:20:30.114+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:20:30.114+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:20:30.140+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:20:30.179+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:20:30.179+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:20:30.200+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:20:30.200+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:20:30.210+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-08-10T12:21:00.426+0000] {processor.py:157} INFO - Started process (PID=25832) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:21:00.429+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:21:00.432+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:21:00.432+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:21:00.448+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:21:00.467+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:21:00.467+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:21:00.482+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:21:00.482+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:21:00.492+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-10T12:21:30.760+0000] {processor.py:157} INFO - Started process (PID=25843) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:21:30.762+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:21:30.766+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:21:30.765+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:21:30.782+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:21:30.811+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:21:30.811+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:21:30.826+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:21:30.826+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:21:30.838+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-08-10T12:22:01.184+0000] {processor.py:157} INFO - Started process (PID=25853) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:22:01.186+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:22:01.190+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:22:01.190+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:22:01.210+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:22:01.249+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:22:01.249+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:22:01.272+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:22:01.272+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:22:01.282+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-08-10T12:22:31.614+0000] {processor.py:157} INFO - Started process (PID=25863) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:22:31.616+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:22:31.625+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:22:31.624+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:22:31.647+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:22:31.693+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:22:31.693+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:22:31.711+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:22:31.711+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:22:31.905+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.310 seconds
[2024-08-10T12:23:02.000+0000] {processor.py:157} INFO - Started process (PID=25873) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:23:02.005+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:23:02.008+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:23:02.008+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:23:02.026+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:23:02.059+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:23:02.059+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:23:02.231+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:23:02.231+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:23:02.239+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.244 seconds
[2024-08-10T12:23:32.567+0000] {processor.py:157} INFO - Started process (PID=25883) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:23:32.570+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:23:32.575+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:23:32.574+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:23:32.593+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:23:32.635+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:23:32.635+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:23:32.652+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:23:32.652+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:23:32.663+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-08-10T12:24:02.930+0000] {processor.py:157} INFO - Started process (PID=25893) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:24:02.936+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:24:02.944+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:24:02.943+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:24:02.961+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:24:02.998+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:24:02.998+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:24:03.015+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:24:03.015+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:24:03.033+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-08-10T12:24:33.253+0000] {processor.py:157} INFO - Started process (PID=25903) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:24:33.261+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:24:33.268+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:24:33.268+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:24:33.292+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:24:33.326+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:24:33.326+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:24:33.348+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:24:33.348+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:24:33.368+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-08-10T12:25:03.685+0000] {processor.py:157} INFO - Started process (PID=25912) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:25:03.688+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:25:03.692+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:25:03.692+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:25:03.714+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:25:03.757+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:25:03.757+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:25:03.772+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:25:03.772+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:25:03.782+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-08-10T12:25:34.256+0000] {processor.py:157} INFO - Started process (PID=25923) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:25:34.262+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:25:34.274+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:25:34.273+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:25:34.303+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:25:34.360+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:25:34.360+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:25:34.563+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:25:34.563+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:25:34.573+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.329 seconds
[2024-08-10T12:26:04.871+0000] {processor.py:157} INFO - Started process (PID=25933) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:26:04.874+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:26:04.878+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:26:04.878+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:26:04.895+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:26:04.936+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:26:04.936+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:26:05.138+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:26:05.138+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:26:05.148+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.284 seconds
[2024-08-10T12:26:35.424+0000] {processor.py:157} INFO - Started process (PID=25943) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:26:35.426+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:26:35.427+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:26:35.427+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:26:35.449+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:26:35.475+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:26:35.475+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:26:35.490+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:26:35.489+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:26:35.508+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-08-10T12:27:05.729+0000] {processor.py:157} INFO - Started process (PID=25952) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:27:05.731+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:27:05.734+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:27:05.734+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:27:05.775+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:27:05.808+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:27:05.808+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:27:05.821+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:27:05.821+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:27:05.834+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-08-10T12:27:36.148+0000] {processor.py:157} INFO - Started process (PID=25963) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:27:36.151+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:27:36.153+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:27:36.153+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:27:36.169+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:27:36.191+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:27:36.191+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:27:36.208+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:27:36.208+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:27:36.218+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-10T12:28:06.575+0000] {processor.py:157} INFO - Started process (PID=25973) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:28:06.576+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:28:06.578+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:28:06.578+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:28:06.595+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:28:06.623+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:28:06.623+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:28:06.642+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:28:06.642+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:28:06.655+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-08-10T12:28:37.022+0000] {processor.py:157} INFO - Started process (PID=25983) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:28:37.024+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:28:37.027+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:28:37.027+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:28:37.060+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:28:37.090+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:28:37.090+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:28:37.287+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:28:37.287+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:28:37.296+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.279 seconds
[2024-08-10T12:29:07.548+0000] {processor.py:157} INFO - Started process (PID=25993) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:29:07.550+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:29:07.556+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:29:07.555+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:29:07.583+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:29:07.652+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:29:07.652+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:29:07.857+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:29:07.857+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:29:07.866+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.325 seconds
[2024-08-10T12:29:38.249+0000] {processor.py:157} INFO - Started process (PID=26003) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:29:38.252+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:29:38.254+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:29:38.254+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:29:38.270+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:29:38.304+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:29:38.304+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:29:38.320+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:29:38.320+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:29:38.331+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-08-10T12:30:08.735+0000] {processor.py:157} INFO - Started process (PID=26013) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:30:08.737+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:30:08.740+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:30:08.740+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:30:08.757+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:30:08.797+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:30:08.797+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:30:08.812+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:30:08.812+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:30:08.823+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-08-10T12:30:39.063+0000] {processor.py:157} INFO - Started process (PID=26023) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:30:39.065+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:30:39.068+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:30:39.067+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:30:39.085+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:30:39.129+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:30:39.129+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:30:39.151+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:30:39.151+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:30:39.160+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-08-10T12:31:09.375+0000] {processor.py:157} INFO - Started process (PID=26033) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:31:09.378+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:31:09.379+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:31:09.379+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:31:09.394+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:31:09.419+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:31:09.419+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:31:09.433+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:31:09.433+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:31:09.603+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.231 seconds
[2024-08-10T12:31:39.722+0000] {processor.py:157} INFO - Started process (PID=26043) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:31:39.728+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:31:39.734+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:31:39.734+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:31:39.753+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:31:39.789+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:31:39.789+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:31:39.958+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:31:39.958+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:31:39.967+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.254 seconds
[2024-08-10T12:32:10.318+0000] {processor.py:157} INFO - Started process (PID=26052) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:32:10.321+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:32:10.327+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:32:10.327+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:32:10.351+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:32:10.389+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:32:10.389+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:32:10.695+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:32:10.695+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:32:10.713+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.458 seconds
[2024-08-10T12:32:41.048+0000] {processor.py:157} INFO - Started process (PID=26062) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:32:41.052+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:32:41.056+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:32:41.055+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:32:41.078+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:32:41.126+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:32:41.126+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:32:41.141+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:32:41.141+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:32:41.152+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-08-10T12:33:11.474+0000] {processor.py:157} INFO - Started process (PID=26072) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:33:11.481+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:33:11.507+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:33:11.506+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:33:11.531+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:33:11.578+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:33:11.578+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:33:11.595+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:33:11.595+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:33:11.606+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.145 seconds
[2024-08-10T12:33:41.869+0000] {processor.py:157} INFO - Started process (PID=26083) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:33:41.873+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:33:41.899+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:33:41.898+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:33:41.920+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:33:41.968+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:33:41.967+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:33:41.986+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:33:41.986+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:33:41.997+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-08-10T12:34:12.249+0000] {processor.py:157} INFO - Started process (PID=26092) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:34:12.251+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:34:12.254+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:34:12.254+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:34:12.278+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:34:12.305+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:34:12.305+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:34:12.323+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:34:12.323+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:34:12.480+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.235 seconds
[2024-08-10T12:34:42.619+0000] {processor.py:157} INFO - Started process (PID=26103) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:34:42.623+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:34:42.627+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:34:42.626+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:34:42.650+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:34:42.693+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:34:42.693+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:34:42.883+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:34:42.883+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:34:42.891+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.282 seconds
[2024-08-10T12:35:13.056+0000] {processor.py:157} INFO - Started process (PID=26113) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:35:13.060+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:35:13.063+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:35:13.062+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:35:13.075+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:35:13.105+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:35:13.105+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:35:13.207+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:35:13.207+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:35:13.216+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.164 seconds
[2024-08-10T12:35:43.474+0000] {processor.py:157} INFO - Started process (PID=26123) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:35:43.475+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:35:43.476+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:35:43.476+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:35:43.485+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:35:43.503+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:35:43.503+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:35:43.514+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:35:43.514+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:35:43.523+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-10T12:36:13.914+0000] {processor.py:157} INFO - Started process (PID=26133) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:36:13.915+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:36:13.917+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:36:13.917+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:36:13.934+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:36:13.959+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:36:13.959+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:36:13.974+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:36:13.973+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:36:13.986+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-08-10T12:36:44.300+0000] {processor.py:157} INFO - Started process (PID=26143) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:36:44.302+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:36:44.306+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:36:44.306+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:36:44.331+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:36:44.390+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:36:44.390+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:36:44.410+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:36:44.410+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:36:44.424+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-08-10T12:37:14.708+0000] {processor.py:157} INFO - Started process (PID=26153) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:37:14.711+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:37:14.716+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:37:14.716+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:37:14.738+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:37:14.777+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:37:14.777+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:37:14.797+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:37:14.797+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:37:14.986+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.285 seconds
[2024-08-10T12:37:45.129+0000] {processor.py:157} INFO - Started process (PID=26163) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:37:45.132+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:37:45.134+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:37:45.134+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:37:45.160+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:37:45.195+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:37:45.194+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:37:45.394+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:37:45.394+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:37:45.403+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.278 seconds
[2024-08-10T12:38:15.605+0000] {processor.py:157} INFO - Started process (PID=26173) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:38:15.607+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:38:15.611+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:38:15.611+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:38:15.645+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:38:15.710+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:38:15.710+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:38:15.933+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:38:15.933+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:38:15.945+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.349 seconds
[2024-08-10T12:38:46.211+0000] {processor.py:157} INFO - Started process (PID=26183) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:38:46.217+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:38:46.222+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:38:46.222+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:38:46.252+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:38:46.285+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:38:46.284+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:38:46.299+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:38:46.299+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:38:46.310+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-08-10T12:39:16.639+0000] {processor.py:157} INFO - Started process (PID=26193) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:39:16.641+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:39:16.646+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:39:16.646+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:39:16.700+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:39:16.738+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:39:16.737+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:39:16.758+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:39:16.758+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:39:16.774+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.143 seconds
[2024-08-10T12:39:47.087+0000] {processor.py:157} INFO - Started process (PID=26203) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:39:47.091+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:39:47.102+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:39:47.098+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:39:47.183+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:39:47.232+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:39:47.232+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:39:47.253+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:39:47.253+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:39:47.267+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.187 seconds
[2024-08-10T12:40:17.643+0000] {processor.py:157} INFO - Started process (PID=26213) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:40:17.645+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:40:17.649+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:40:17.647+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:40:17.693+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:40:17.728+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:40:17.728+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:40:17.764+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:40:17.764+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:40:17.961+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.322 seconds
[2024-08-10T12:40:48.247+0000] {processor.py:157} INFO - Started process (PID=26223) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:40:48.250+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:40:48.253+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:40:48.253+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:40:48.298+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:40:48.336+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:40:48.336+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:40:48.568+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:40:48.568+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:40:48.579+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.340 seconds
[2024-08-10T12:41:18.885+0000] {processor.py:157} INFO - Started process (PID=26233) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:41:18.888+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:41:18.890+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:41:18.890+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:41:18.926+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:41:18.955+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:41:18.954+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:41:19.120+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:41:19.120+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:41:19.128+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.249 seconds
[2024-08-10T12:41:49.262+0000] {processor.py:157} INFO - Started process (PID=26243) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:41:49.271+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:41:49.276+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:41:49.275+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:41:49.295+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:41:49.336+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:41:49.336+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:41:49.360+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:41:49.360+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:41:49.370+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-08-10T12:42:19.570+0000] {processor.py:157} INFO - Started process (PID=26253) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:42:19.573+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:42:19.576+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:42:19.576+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:42:19.595+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:42:19.640+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:42:19.640+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:42:19.655+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:42:19.655+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:42:19.665+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-08-10T12:42:49.997+0000] {processor.py:157} INFO - Started process (PID=26263) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:42:50.001+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:42:50.005+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:42:50.004+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:42:50.034+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:42:50.091+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:42:50.091+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:42:50.142+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:42:50.142+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:42:50.161+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.176 seconds
[2024-08-10T12:43:20.310+0000] {processor.py:157} INFO - Started process (PID=26273) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:43:20.313+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:43:20.324+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:43:20.323+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:43:20.342+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:43:20.376+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:43:20.376+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:43:20.394+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:43:20.394+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:43:20.568+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.270 seconds
[2024-08-10T12:43:50.691+0000] {processor.py:157} INFO - Started process (PID=26282) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:43:50.695+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:43:50.697+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:43:50.697+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:43:50.713+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:43:50.740+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:43:50.740+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:43:50.897+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:43:50.897+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:43:50.905+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.230 seconds
[2024-08-10T12:44:21.262+0000] {processor.py:157} INFO - Started process (PID=26293) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:44:21.263+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:44:21.265+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:44:21.265+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:44:21.281+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:44:21.314+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:44:21.313+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:44:21.493+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:44:21.493+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:44:21.504+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.246 seconds
[2024-08-10T12:44:51.627+0000] {processor.py:157} INFO - Started process (PID=26303) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:44:51.629+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:44:51.632+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:44:51.631+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:44:51.649+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:44:51.674+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:44:51.674+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:44:51.693+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:44:51.693+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:44:51.704+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-08-10T12:45:22.084+0000] {processor.py:157} INFO - Started process (PID=26313) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:45:22.087+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:45:22.090+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:45:22.090+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:45:22.111+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:45:22.143+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:45:22.142+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:45:22.158+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:45:22.158+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:45:22.169+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-08-10T12:45:52.423+0000] {processor.py:157} INFO - Started process (PID=26323) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:45:52.424+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:45:52.426+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:45:52.426+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:45:52.443+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:45:52.468+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:45:52.468+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:45:52.482+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:45:52.482+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:45:52.492+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-10T12:46:22.705+0000] {processor.py:157} INFO - Started process (PID=26333) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:46:22.706+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:46:22.708+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:46:22.707+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:46:22.718+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:46:22.739+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:46:22.739+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:46:22.750+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:46:22.750+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:46:22.916+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.213 seconds
[2024-08-10T12:46:52.992+0000] {processor.py:157} INFO - Started process (PID=26343) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:46:52.995+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:46:52.998+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:46:52.998+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:46:53.017+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:46:53.042+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:46:53.042+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:46:53.141+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:46:53.141+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:46:53.150+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.163 seconds
[2024-08-10T12:47:23.415+0000] {processor.py:157} INFO - Started process (PID=26353) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:47:23.415+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:47:23.417+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:47:23.417+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:47:23.428+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:47:23.514+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:47:23.514+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:47:23.522+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:47:23.522+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:47:23.529+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-08-10T12:47:53.788+0000] {processor.py:157} INFO - Started process (PID=26363) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:47:53.791+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:47:53.793+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:47:53.793+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:47:53.805+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:47:53.822+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:47:53.822+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:47:53.834+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:47:53.834+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:47:53.842+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-10T12:48:24.191+0000] {processor.py:157} INFO - Started process (PID=26373) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:48:24.193+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:48:24.195+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:48:24.195+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:48:24.204+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:48:24.220+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:48:24.220+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:48:24.230+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:48:24.230+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:48:24.240+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-10T12:48:54.547+0000] {processor.py:157} INFO - Started process (PID=26383) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:48:54.548+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:48:54.550+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:48:54.549+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:48:54.559+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:48:54.576+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:48:54.576+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:48:54.586+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:48:54.585+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:48:54.593+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-08-10T12:49:24.905+0000] {processor.py:157} INFO - Started process (PID=26393) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:49:24.907+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:49:24.909+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:49:24.909+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:49:24.923+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:49:24.943+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:49:24.943+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:49:25.091+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:49:25.091+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:49:25.099+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.198 seconds
[2024-08-10T12:49:55.416+0000] {processor.py:157} INFO - Started process (PID=26403) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:49:55.417+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:49:55.420+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:49:55.420+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:49:55.433+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:49:55.449+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:49:55.449+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:49:55.530+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:49:55.530+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:49:55.538+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-08-10T12:50:25.812+0000] {processor.py:157} INFO - Started process (PID=26413) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:50:25.816+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:50:25.818+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:50:25.818+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:50:25.828+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:50:25.919+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:50:25.919+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:50:25.927+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:50:25.927+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:50:25.936+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-08-10T12:50:56.104+0000] {processor.py:157} INFO - Started process (PID=26423) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:50:56.107+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:50:56.110+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:50:56.110+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:50:56.119+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:50:56.130+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:50:56.130+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:50:56.140+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:50:56.140+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:50:56.149+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-08-10T12:51:26.488+0000] {processor.py:157} INFO - Started process (PID=26433) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:51:26.492+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:51:26.495+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:51:26.495+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:51:26.515+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:51:26.544+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:51:26.544+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:51:26.560+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:51:26.559+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:51:26.573+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-10T12:51:56.841+0000] {processor.py:157} INFO - Started process (PID=26443) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:51:56.844+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:51:56.845+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:51:56.845+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:51:56.862+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:51:56.893+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:51:56.892+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:51:56.906+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:51:56.906+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:51:56.918+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-08-10T12:52:27.180+0000] {processor.py:157} INFO - Started process (PID=26453) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:52:27.181+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:52:27.183+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:52:27.183+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:52:27.235+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:52:27.281+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:52:27.281+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:52:27.468+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:52:27.468+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:52:27.477+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.302 seconds
[2024-08-10T12:52:57.685+0000] {processor.py:157} INFO - Started process (PID=26463) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:52:57.687+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:52:57.691+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:52:57.691+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:52:57.720+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:52:57.762+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:52:57.762+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:52:57.978+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:52:57.978+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:52:57.995+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.339 seconds
[2024-08-10T12:53:28.261+0000] {processor.py:157} INFO - Started process (PID=26473) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:53:28.263+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:53:28.265+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:53:28.265+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:53:28.276+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:53:28.362+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:53:28.362+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:53:28.370+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:53:28.370+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:53:28.378+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-08-10T12:53:58.644+0000] {processor.py:157} INFO - Started process (PID=26483) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:53:58.647+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:53:58.649+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:53:58.649+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:53:58.663+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:53:58.681+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:53:58.681+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:53:58.691+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:53:58.691+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:53:58.699+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-10T12:54:29.196+0000] {processor.py:157} INFO - Started process (PID=26493) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:54:29.198+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:54:29.201+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:54:29.201+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:54:29.226+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:54:29.251+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:54:29.251+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:54:29.275+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:54:29.275+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:54:29.284+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-08-10T12:55:08.435+0000] {processor.py:157} INFO - Started process (PID=26505) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:55:08.436+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:55:08.440+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:55:08.439+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:55:08.446+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:55:08.459+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:55:08.459+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:55:08.470+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:55:08.470+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:55:08.481+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-08-10T12:56:07.327+0000] {processor.py:157} INFO - Started process (PID=26515) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:56:07.328+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:56:07.330+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:56:07.330+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:56:07.339+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:56:07.356+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:56:07.356+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:56:07.367+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:56:07.367+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:56:07.516+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.192 seconds
[2024-08-10T12:56:37.855+0000] {processor.py:157} INFO - Started process (PID=26525) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:56:37.857+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T12:56:37.863+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:56:37.862+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:56:37.892+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T12:56:37.913+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:56:37.913+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T12:56:38.021+0000] {logging_mixin.py:151} INFO - [2024-08-10T12:56:38.021+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T12:56:38.029+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.179 seconds
[2024-08-10T13:01:05.432+0000] {processor.py:157} INFO - Started process (PID=26534) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:01:05.441+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:01:05.451+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:01:05.450+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:01:05.489+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:01:05.541+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:01:05.541+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:01:05.907+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:01:05.907+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:01:05.934+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.517 seconds
[2024-08-10T13:01:36.273+0000] {processor.py:157} INFO - Started process (PID=26543) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:01:36.275+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:01:36.278+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:01:36.278+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:01:36.300+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:01:36.471+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:01:36.471+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:01:36.480+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:01:36.480+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:01:36.489+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.221 seconds
[2024-08-10T13:02:06.835+0000] {processor.py:157} INFO - Started process (PID=26555) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:02:06.837+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:02:06.840+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:02:06.840+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:02:06.856+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:02:06.872+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:02:06.872+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:02:06.883+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:02:06.883+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:02:06.892+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-10T13:02:37.129+0000] {processor.py:157} INFO - Started process (PID=26565) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:02:37.135+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:02:37.142+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:02:37.140+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:02:37.157+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:02:37.180+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:02:37.180+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:02:37.194+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:02:37.194+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:02:37.205+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-08-10T13:03:07.443+0000] {processor.py:157} INFO - Started process (PID=26575) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:03:07.444+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:03:07.447+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:03:07.447+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:03:07.462+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:03:07.486+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:03:07.486+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:03:07.499+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:03:07.499+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:03:07.641+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.202 seconds
[2024-08-10T13:03:37.728+0000] {processor.py:157} INFO - Started process (PID=26585) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:03:37.730+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:03:37.731+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:03:37.730+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:03:37.738+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:03:37.751+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:03:37.751+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:03:37.836+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:03:37.836+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:03:37.843+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-08-10T13:04:08.199+0000] {processor.py:157} INFO - Started process (PID=26594) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:04:08.201+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:04:08.204+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:04:08.204+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:04:08.222+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:04:08.256+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:04:08.256+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:04:08.419+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:04:08.419+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:04:08.427+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.232 seconds
[2024-08-10T13:04:38.532+0000] {processor.py:157} INFO - Started process (PID=26605) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:04:38.533+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:04:38.535+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:04:38.535+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:04:38.560+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:04:38.705+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:04:38.705+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:04:38.714+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:04:38.714+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:04:38.722+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.196 seconds
[2024-08-10T13:05:09.019+0000] {processor.py:157} INFO - Started process (PID=26615) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:05:09.020+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:05:09.022+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:05:09.022+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:05:09.039+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:05:09.054+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:05:09.054+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:05:09.066+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:05:09.066+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:05:09.076+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-10T13:05:39.379+0000] {processor.py:157} INFO - Started process (PID=26625) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:05:39.380+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:05:39.383+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:05:39.382+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:05:39.403+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:05:39.421+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:05:39.421+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:05:39.435+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:05:39.435+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:05:39.444+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-10T13:06:09.816+0000] {processor.py:157} INFO - Started process (PID=26635) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:06:09.818+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:06:09.820+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:06:09.820+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:06:09.831+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:06:09.852+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:06:09.852+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:06:09.865+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:06:09.865+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:06:10.018+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.205 seconds
[2024-08-10T13:06:40.096+0000] {processor.py:157} INFO - Started process (PID=26644) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:06:40.099+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:06:40.109+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:06:40.108+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:06:40.140+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:06:40.164+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:06:40.164+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:06:40.252+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:06:40.252+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:06:40.260+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.169 seconds
[2024-08-10T13:07:10.541+0000] {processor.py:157} INFO - Started process (PID=26655) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:07:10.542+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:07:10.544+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:07:10.544+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:07:10.555+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:07:10.735+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:07:10.735+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:07:10.745+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:07:10.745+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:07:10.754+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.217 seconds
[2024-08-10T13:07:41.066+0000] {processor.py:157} INFO - Started process (PID=26665) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:07:41.069+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:07:41.073+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:07:41.073+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:07:41.090+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:07:41.185+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:07:41.185+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:07:41.194+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:07:41.194+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:07:41.200+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-08-10T13:08:11.386+0000] {processor.py:157} INFO - Started process (PID=26675) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:08:11.389+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:08:11.392+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:08:11.392+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:08:11.406+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:08:11.427+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:08:11.427+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:08:11.441+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:08:11.441+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:08:11.450+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-10T13:08:41.795+0000] {processor.py:157} INFO - Started process (PID=26685) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:08:41.797+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:08:41.804+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:08:41.803+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:08:41.860+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:08:41.921+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:08:41.921+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:08:42.004+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:08:42.004+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:08:42.026+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.239 seconds
[2024-08-10T13:09:12.123+0000] {processor.py:157} INFO - Started process (PID=26695) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:09:12.128+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:09:12.143+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:09:12.143+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:09:12.164+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:09:12.195+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:09:12.195+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:09:12.360+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:09:12.360+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:09:12.370+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.253 seconds
[2024-08-10T13:09:42.584+0000] {processor.py:157} INFO - Started process (PID=26705) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:09:42.588+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:09:42.595+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:09:42.594+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:09:42.616+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:09:42.635+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:09:42.635+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:09:42.752+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:09:42.752+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:09:42.761+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.182 seconds
[2024-08-10T13:10:12.935+0000] {processor.py:157} INFO - Started process (PID=26715) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:10:12.937+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:10:12.939+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:10:12.939+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:10:12.952+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:10:13.088+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:10:13.088+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:10:13.098+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:10:13.098+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:10:13.108+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.176 seconds
[2024-08-10T13:10:43.425+0000] {processor.py:157} INFO - Started process (PID=26725) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:10:43.426+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:10:43.431+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:10:43.430+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:10:43.447+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:10:43.646+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:10:43.646+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:10:43.656+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:10:43.656+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:10:43.665+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.244 seconds
[2024-08-10T13:11:13.963+0000] {processor.py:157} INFO - Started process (PID=26735) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:11:13.965+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:11:13.968+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:11:13.967+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:11:13.986+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:11:14.010+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:11:14.010+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:11:14.023+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:11:14.023+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:11:14.037+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-08-10T13:11:44.252+0000] {processor.py:157} INFO - Started process (PID=26745) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:11:44.254+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:11:44.256+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:11:44.256+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:11:44.283+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:11:44.312+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:11:44.312+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:11:44.328+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:11:44.328+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:11:44.342+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-08-10T13:12:14.604+0000] {processor.py:157} INFO - Started process (PID=26755) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:12:14.605+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:12:14.608+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:12:14.608+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:12:14.626+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:12:14.648+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:12:14.648+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:12:14.842+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:12:14.842+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:12:14.849+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.249 seconds
[2024-08-10T13:12:44.943+0000] {processor.py:157} INFO - Started process (PID=26765) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:12:44.945+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:12:44.948+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:12:44.948+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:12:44.966+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:12:44.989+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:12:44.989+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:12:45.133+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:12:45.133+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:12:45.142+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.204 seconds
[2024-08-10T13:13:15.375+0000] {processor.py:157} INFO - Started process (PID=26775) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:13:15.376+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:13:15.377+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:13:15.377+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:13:15.389+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:13:15.478+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:13:15.478+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:13:15.487+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:13:15.487+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:13:15.494+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-08-10T13:13:45.694+0000] {processor.py:157} INFO - Started process (PID=26785) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:13:45.695+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:13:45.696+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:13:45.696+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:13:45.795+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:13:45.806+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:13:45.806+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:13:45.815+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:13:45.815+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:13:45.824+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-08-10T13:14:16.152+0000] {processor.py:157} INFO - Started process (PID=26795) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:14:16.157+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:14:16.163+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:14:16.162+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:14:16.181+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:14:16.206+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:14:16.206+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:14:16.218+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:14:16.218+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:14:16.228+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-08-10T13:14:46.450+0000] {processor.py:157} INFO - Started process (PID=26805) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:14:46.451+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:14:46.454+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:14:46.453+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:14:46.470+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:14:46.497+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:14:46.497+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:14:46.511+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:14:46.511+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:14:46.521+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-08-10T13:15:16.866+0000] {processor.py:157} INFO - Started process (PID=26815) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:15:16.867+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:15:16.870+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:15:16.870+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:15:16.889+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:15:16.909+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:15:16.909+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:15:17.094+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:15:17.094+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:15:17.104+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.242 seconds
[2024-08-10T13:15:47.136+0000] {processor.py:157} INFO - Started process (PID=26825) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:15:47.137+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:15:47.138+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:15:47.138+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:15:47.150+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:15:47.170+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:15:47.169+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:15:47.258+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:15:47.258+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:15:47.266+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-08-10T13:16:17.647+0000] {processor.py:157} INFO - Started process (PID=26835) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:16:17.648+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:16:17.650+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:16:17.650+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:16:17.670+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:16:17.789+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:16:17.789+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:16:17.797+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:16:17.797+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:16:17.806+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.162 seconds
[2024-08-10T13:16:47.963+0000] {processor.py:157} INFO - Started process (PID=26845) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:16:47.965+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:16:47.967+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:16:47.966+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:16:48.081+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:16:48.093+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:16:48.093+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:16:48.100+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:16:48.100+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:16:48.108+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.149 seconds
[2024-08-10T13:17:18.479+0000] {processor.py:157} INFO - Started process (PID=26855) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:17:18.480+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:17:18.484+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:17:18.484+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:17:18.503+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:17:18.524+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:17:18.523+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:17:18.537+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:17:18.537+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:17:18.550+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-08-10T13:17:48.806+0000] {processor.py:157} INFO - Started process (PID=26864) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:17:48.807+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:17:48.812+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:17:48.812+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:17:48.840+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:17:48.866+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:17:48.866+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:17:48.882+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:17:48.881+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:17:48.892+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-08-10T13:18:19.178+0000] {processor.py:157} INFO - Started process (PID=26875) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:18:19.180+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:18:19.181+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:18:19.181+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:18:19.195+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:18:19.215+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:18:19.215+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:18:19.226+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:18:19.226+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:18:19.236+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-10T13:18:49.470+0000] {processor.py:157} INFO - Started process (PID=26885) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:18:49.471+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:18:49.476+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:18:49.476+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:18:49.495+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:18:49.515+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:18:49.515+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:18:49.530+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:18:49.530+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:18:49.539+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-10T13:19:19.784+0000] {processor.py:157} INFO - Started process (PID=26895) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:19:19.786+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:19:19.789+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:19:19.788+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:19:19.804+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:19:19.823+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:19:19.822+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:19:19.833+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:19:19.833+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:19:19.844+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-10T13:19:50.180+0000] {processor.py:157} INFO - Started process (PID=26905) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:19:50.181+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:19:50.196+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:19:50.193+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:19:50.224+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:19:50.262+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:19:50.262+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:19:50.286+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:19:50.286+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:19:50.310+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-08-10T13:20:20.454+0000] {processor.py:157} INFO - Started process (PID=26915) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:20:20.455+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:20:20.460+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:20:20.459+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:20:20.472+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:20:20.492+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:20:20.492+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:20:20.504+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:20:20.504+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:20:20.514+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-10T13:20:50.755+0000] {processor.py:157} INFO - Started process (PID=26925) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:20:50.756+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:20:50.769+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:20:50.766+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:20:50.816+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:20:50.849+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:20:50.849+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:20:50.868+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:20:50.868+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:20:50.879+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-08-10T13:21:21.087+0000] {processor.py:157} INFO - Started process (PID=26935) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:21:21.089+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:21:21.091+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:21:21.091+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:21:21.102+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:21:21.119+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:21:21.119+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:21:21.132+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:21:21.132+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:21:21.140+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-10T13:21:51.442+0000] {processor.py:157} INFO - Started process (PID=26945) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:21:51.447+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:21:51.452+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:21:51.452+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:21:51.473+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:21:51.500+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:21:51.500+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:21:51.518+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:21:51.518+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:21:51.533+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-08-10T13:22:21.773+0000] {processor.py:157} INFO - Started process (PID=26954) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:22:21.775+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:22:21.779+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:22:21.779+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:22:21.798+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:22:21.821+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:22:21.821+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:22:21.834+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:22:21.834+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:22:21.844+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-08-10T13:22:52.075+0000] {processor.py:157} INFO - Started process (PID=26965) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:22:52.076+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:22:52.079+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:22:52.079+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:22:52.097+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:22:52.118+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:22:52.118+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:22:52.131+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:22:52.131+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:22:52.141+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-10T13:23:22.368+0000] {processor.py:157} INFO - Started process (PID=26975) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:23:22.369+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:23:22.371+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:23:22.371+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:23:22.382+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:23:22.401+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:23:22.401+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:23:22.412+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:23:22.412+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:23:22.424+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-10T13:23:52.662+0000] {processor.py:157} INFO - Started process (PID=26985) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:23:52.667+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:23:52.669+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:23:52.668+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:23:52.698+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:23:52.736+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:23:52.736+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:23:52.751+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:23:52.751+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:23:52.761+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-08-10T13:24:22.973+0000] {processor.py:157} INFO - Started process (PID=26995) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:24:22.975+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:24:22.977+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:24:22.976+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:24:22.993+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:24:23.010+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:24:23.010+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:24:23.030+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:24:23.030+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:24:23.040+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-10T13:24:53.216+0000] {processor.py:157} INFO - Started process (PID=27004) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:24:53.219+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:24:53.225+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:24:53.225+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:24:53.248+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:24:53.280+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:24:53.280+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:24:53.299+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:24:53.299+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:24:53.313+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-08-10T13:25:23.484+0000] {processor.py:157} INFO - Started process (PID=27015) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:25:23.485+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:25:23.487+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:25:23.487+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:25:23.500+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:25:23.513+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:25:23.513+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:25:23.524+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:25:23.524+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:25:23.534+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-10T13:25:53.825+0000] {processor.py:157} INFO - Started process (PID=27025) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:25:53.829+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:25:53.831+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:25:53.831+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:25:53.845+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:25:53.866+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:25:53.866+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:25:53.880+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:25:53.880+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:25:53.890+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-10T13:26:24.250+0000] {processor.py:157} INFO - Started process (PID=27035) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:26:24.251+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:26:24.257+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:26:24.257+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:26:24.297+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:26:24.403+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:26:24.403+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:26:24.429+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:26:24.429+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:26:24.448+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.205 seconds
[2024-08-10T13:26:54.574+0000] {processor.py:157} INFO - Started process (PID=27044) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:26:54.580+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:26:54.586+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:26:54.585+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:26:54.607+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:26:54.633+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:26:54.632+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:26:54.660+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:26:54.659+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:26:54.671+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-08-10T13:27:24.982+0000] {processor.py:157} INFO - Started process (PID=27055) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:27:24.985+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:27:24.987+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:27:24.987+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:27:25.003+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:27:25.027+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:27:25.027+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:27:25.041+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:27:25.041+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:27:25.053+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-08-10T13:27:55.302+0000] {processor.py:157} INFO - Started process (PID=27065) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:27:55.304+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:27:55.307+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:27:55.307+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:27:55.322+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:27:55.349+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:27:55.349+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:27:55.363+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:27:55.362+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:27:55.372+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-10T13:28:25.578+0000] {processor.py:157} INFO - Started process (PID=27075) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:28:25.579+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:28:25.581+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:28:25.581+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:28:25.592+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:28:25.608+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:28:25.608+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:28:25.618+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:28:25.618+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:28:25.627+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-10T13:28:55.908+0000] {processor.py:157} INFO - Started process (PID=27084) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:28:55.909+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:28:55.914+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:28:55.914+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:28:55.936+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:28:55.980+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:28:55.980+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:28:55.996+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:28:55.996+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:28:56.007+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-08-10T13:29:26.174+0000] {processor.py:157} INFO - Started process (PID=27095) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:29:26.175+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:29:26.178+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:29:26.177+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:29:26.195+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:29:26.210+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:29:26.210+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:29:26.220+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:29:26.220+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:29:26.233+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-10T13:29:56.543+0000] {processor.py:157} INFO - Started process (PID=27105) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:29:56.544+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:29:56.546+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:29:56.546+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:29:56.558+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:29:56.575+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:29:56.575+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:29:56.589+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:29:56.588+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:29:56.598+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-10T13:30:26.929+0000] {processor.py:157} INFO - Started process (PID=27115) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:30:26.931+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:30:26.934+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:30:26.934+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:30:26.954+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:30:26.979+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:30:26.979+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:30:26.997+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:30:26.997+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:30:27.010+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-08-10T13:30:57.336+0000] {processor.py:157} INFO - Started process (PID=27125) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:30:57.338+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:30:57.340+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:30:57.340+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:30:57.350+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:30:57.367+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:30:57.367+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:30:57.378+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:30:57.378+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:30:57.389+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-10T13:31:27.721+0000] {processor.py:157} INFO - Started process (PID=27135) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:31:27.724+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:31:27.727+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:31:27.727+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:31:27.749+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:31:27.775+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:31:27.775+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:31:27.790+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:31:27.790+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:31:27.801+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-08-10T13:31:58.043+0000] {processor.py:157} INFO - Started process (PID=27145) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:31:58.044+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:31:58.045+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:31:58.045+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:31:58.057+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:31:58.075+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:31:58.075+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:31:58.086+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:31:58.086+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:31:58.095+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-10T13:32:28.453+0000] {processor.py:157} INFO - Started process (PID=27155) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:32:28.454+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:32:28.464+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:32:28.463+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:32:28.483+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:32:28.511+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:32:28.510+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:32:28.525+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:32:28.525+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:32:28.537+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-10T13:32:58.713+0000] {processor.py:157} INFO - Started process (PID=27165) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:32:58.714+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:32:58.717+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:32:58.717+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:32:58.726+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:32:58.744+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:32:58.744+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:32:58.757+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:32:58.757+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:32:58.767+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-10T13:33:29.062+0000] {processor.py:157} INFO - Started process (PID=27175) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:33:29.063+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:33:29.066+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:33:29.066+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:33:29.084+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:33:29.106+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:33:29.106+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:33:29.119+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:33:29.119+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:33:29.130+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-10T13:33:59.376+0000] {processor.py:157} INFO - Started process (PID=27185) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:33:59.378+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:33:59.380+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:33:59.380+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:33:59.392+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:33:59.408+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:33:59.408+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:33:59.419+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:33:59.419+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:33:59.431+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-10T13:34:29.727+0000] {processor.py:157} INFO - Started process (PID=27195) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:34:29.728+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:34:29.730+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:34:29.730+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:34:29.738+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:34:29.754+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:34:29.754+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:34:29.765+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:34:29.765+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:34:29.775+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-10T13:35:00.069+0000] {processor.py:157} INFO - Started process (PID=27205) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:35:00.070+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:35:00.071+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:35:00.071+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:35:00.083+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:35:00.101+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:35:00.101+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:35:00.113+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:35:00.113+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:35:00.122+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-10T13:35:30.438+0000] {processor.py:157} INFO - Started process (PID=27215) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:35:30.444+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:35:30.461+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:35:30.461+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:35:30.482+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:35:30.507+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:35:30.507+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:35:30.520+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:35:30.520+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:35:30.530+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-08-10T13:36:00.744+0000] {processor.py:157} INFO - Started process (PID=27225) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:36:00.745+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:36:00.747+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:36:00.747+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:36:00.759+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:36:00.779+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:36:00.779+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:36:00.790+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:36:00.790+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:36:00.798+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-10T13:36:31.146+0000] {processor.py:157} INFO - Started process (PID=27235) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:36:31.149+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:36:31.152+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:36:31.151+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:36:31.170+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:36:31.192+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:36:31.192+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:36:31.205+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:36:31.205+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:36:31.214+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-10T13:37:01.473+0000] {processor.py:157} INFO - Started process (PID=27245) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:37:01.475+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:37:01.477+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:37:01.477+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:37:01.489+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:37:01.506+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:37:01.506+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:37:01.516+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:37:01.516+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:37:01.524+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-10T13:37:31.848+0000] {processor.py:157} INFO - Started process (PID=27255) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:37:31.851+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:37:31.853+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:37:31.853+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:37:31.870+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:37:31.893+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:37:31.893+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:37:31.905+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:37:31.905+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:37:31.914+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-10T13:38:02.129+0000] {processor.py:157} INFO - Started process (PID=27265) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:38:02.130+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:38:02.133+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:38:02.133+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:38:02.146+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:38:02.171+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:38:02.171+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:38:02.184+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:38:02.184+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:38:02.196+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-10T13:38:32.606+0000] {processor.py:157} INFO - Started process (PID=27275) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:38:32.607+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:38:32.612+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:38:32.611+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:38:32.636+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:38:32.682+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:38:32.681+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:38:32.698+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:38:32.698+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:38:32.710+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-08-10T13:39:02.883+0000] {processor.py:157} INFO - Started process (PID=27285) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:39:02.884+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:39:02.886+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:39:02.886+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:39:02.894+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:39:02.913+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:39:02.913+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:39:02.923+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:39:02.923+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:39:02.934+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-10T13:39:33.240+0000] {processor.py:157} INFO - Started process (PID=27295) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:39:33.241+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:39:33.245+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:39:33.245+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:39:33.263+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:39:33.288+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:39:33.288+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:39:33.304+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:39:33.304+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:39:33.317+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-08-10T13:40:03.671+0000] {processor.py:157} INFO - Started process (PID=27304) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:40:03.673+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:40:03.677+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:40:03.677+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:40:03.697+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:40:03.727+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:40:03.727+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:40:03.741+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:40:03.740+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:40:03.752+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-08-10T13:40:33.994+0000] {processor.py:157} INFO - Started process (PID=27315) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:40:33.995+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:40:34.001+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:40:34.000+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:40:34.031+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:40:34.067+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:40:34.067+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:40:34.084+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:40:34.084+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:40:34.096+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-08-10T13:41:04.316+0000] {processor.py:157} INFO - Started process (PID=27325) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:41:04.319+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:41:04.322+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:41:04.322+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:41:04.369+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:41:04.403+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:41:04.403+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:41:04.417+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:41:04.417+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:41:04.428+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-08-10T13:41:34.712+0000] {processor.py:157} INFO - Started process (PID=27335) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:41:34.714+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:41:34.718+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:41:34.718+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:41:34.735+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:41:34.753+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:41:34.753+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:41:34.763+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:41:34.762+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:41:34.770+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-10T13:42:05.076+0000] {processor.py:157} INFO - Started process (PID=27345) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:42:05.077+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:42:05.084+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:42:05.084+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:42:05.095+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:42:05.111+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:42:05.111+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:42:05.125+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:42:05.124+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:42:05.135+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-10T13:42:35.387+0000] {processor.py:157} INFO - Started process (PID=27355) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:42:35.388+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:42:35.390+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:42:35.389+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:42:35.399+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:42:35.416+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:42:35.416+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:42:35.426+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:42:35.426+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:42:35.434+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-10T13:43:05.768+0000] {processor.py:157} INFO - Started process (PID=27365) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:43:05.771+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:43:05.772+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:43:05.772+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:43:05.783+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:43:05.799+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:43:05.799+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:43:05.808+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:43:05.808+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:43:05.816+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-10T13:43:36.106+0000] {processor.py:157} INFO - Started process (PID=27375) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:43:36.110+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:43:36.112+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:43:36.111+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:43:36.122+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:43:36.137+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:43:36.137+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:43:36.147+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:43:36.147+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:43:36.159+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-10T13:44:06.388+0000] {processor.py:157} INFO - Started process (PID=27385) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:44:06.389+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:44:06.390+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:44:06.390+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:44:06.404+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:44:06.418+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:44:06.418+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:44:06.428+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:44:06.428+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:44:06.439+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-10T13:44:36.754+0000] {processor.py:157} INFO - Started process (PID=27395) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:44:36.755+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:44:36.758+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:44:36.758+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:44:36.767+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:44:36.783+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:44:36.783+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:44:36.793+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:44:36.793+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:44:36.803+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-10T13:45:07.104+0000] {processor.py:157} INFO - Started process (PID=27405) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:45:07.105+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:45:07.109+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:45:07.109+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:45:07.127+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:45:07.147+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:45:07.147+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:45:07.160+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:45:07.160+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:45:07.170+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-10T13:45:37.471+0000] {processor.py:157} INFO - Started process (PID=27415) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:45:37.472+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:45:37.474+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:45:37.474+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:45:37.484+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:45:37.500+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:45:37.500+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:45:37.512+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:45:37.512+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:45:37.520+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-10T13:46:07.823+0000] {processor.py:157} INFO - Started process (PID=27425) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:46:07.825+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:46:07.828+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:46:07.828+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:46:07.850+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:46:07.878+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:46:07.878+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:46:07.890+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:46:07.890+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:46:07.899+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-08-10T13:46:38.214+0000] {processor.py:157} INFO - Started process (PID=27435) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:46:38.217+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:46:38.220+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:46:38.220+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:46:38.231+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:46:38.251+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:46:38.251+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:46:38.264+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:46:38.264+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:46:38.274+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-10T13:47:08.511+0000] {processor.py:157} INFO - Started process (PID=27445) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:47:08.512+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:47:08.513+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:47:08.513+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:47:08.525+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:47:08.541+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:47:08.541+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:47:08.552+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:47:08.552+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:47:08.564+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-10T13:47:38.809+0000] {processor.py:157} INFO - Started process (PID=27455) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:47:38.810+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:47:38.813+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:47:38.813+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:47:38.830+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:47:38.850+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:47:38.850+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:47:38.865+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:47:38.865+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:47:38.871+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-10T13:48:09.142+0000] {processor.py:157} INFO - Started process (PID=27465) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:48:09.144+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:48:09.145+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:48:09.145+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:48:09.152+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:48:09.167+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:48:09.167+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:48:09.176+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:48:09.176+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:48:09.186+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-08-10T13:48:39.479+0000] {processor.py:157} INFO - Started process (PID=27475) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:48:39.480+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:48:39.483+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:48:39.482+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:48:39.491+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:48:39.507+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:48:39.507+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:48:39.518+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:48:39.517+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:48:39.527+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-10T13:49:09.836+0000] {processor.py:157} INFO - Started process (PID=27485) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:49:09.837+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:49:09.838+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:49:09.838+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:49:09.849+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:49:09.865+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:49:09.865+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:49:09.876+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:49:09.875+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:49:09.883+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-10T13:49:40.130+0000] {processor.py:157} INFO - Started process (PID=27495) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:49:40.132+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:49:40.134+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:49:40.134+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:49:40.146+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:49:40.159+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:49:40.159+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:49:40.169+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:49:40.169+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:49:40.177+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-10T13:50:10.507+0000] {processor.py:157} INFO - Started process (PID=27505) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:50:10.508+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:50:10.510+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:50:10.510+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:50:10.521+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:50:10.543+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:50:10.543+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:50:10.556+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:50:10.556+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:50:10.567+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-10T13:50:40.815+0000] {processor.py:157} INFO - Started process (PID=27515) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:50:40.816+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:50:40.819+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:50:40.819+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:50:40.828+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:50:40.854+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:50:40.853+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:50:40.878+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:50:40.878+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:50:40.896+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-08-10T13:51:11.092+0000] {processor.py:157} INFO - Started process (PID=27525) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:51:11.095+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:51:11.098+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:51:11.097+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:51:11.123+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:51:11.144+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:51:11.144+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:51:11.156+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:51:11.156+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:51:11.167+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-08-10T13:51:41.410+0000] {processor.py:157} INFO - Started process (PID=27535) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:51:41.413+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:51:41.416+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:51:41.415+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:51:41.425+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:51:41.442+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:51:41.442+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:51:41.452+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:51:41.451+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:51:41.461+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-10T13:52:11.736+0000] {processor.py:157} INFO - Started process (PID=27545) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:52:11.740+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:52:11.742+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:52:11.742+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:52:11.753+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:52:11.774+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:52:11.774+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:52:11.789+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:52:11.789+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:52:11.799+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-10T13:52:42.106+0000] {processor.py:157} INFO - Started process (PID=27555) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:52:42.112+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:52:42.114+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:52:42.114+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:52:42.123+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:52:42.137+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:52:42.137+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:52:42.148+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:52:42.148+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:52:42.158+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-10T13:53:12.429+0000] {processor.py:157} INFO - Started process (PID=27565) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:53:12.430+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:53:12.432+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:53:12.431+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:53:12.444+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:53:12.459+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:53:12.459+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:53:12.468+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:53:12.468+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:53:12.479+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-10T13:53:42.774+0000] {processor.py:157} INFO - Started process (PID=27575) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:53:42.775+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:53:42.778+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:53:42.778+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:53:42.787+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:53:42.803+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:53:42.803+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:53:42.813+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:53:42.813+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:53:42.824+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-10T13:54:13.114+0000] {processor.py:157} INFO - Started process (PID=27585) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:54:13.115+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:54:13.117+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:54:13.117+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:54:13.128+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:54:13.144+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:54:13.144+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:54:13.154+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:54:13.154+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:54:13.164+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-10T13:54:43.422+0000] {processor.py:157} INFO - Started process (PID=27595) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:54:43.423+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:54:43.426+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:54:43.426+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:54:43.445+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:54:43.463+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:54:43.463+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:54:43.473+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:54:43.473+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:54:43.482+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-10T13:55:13.697+0000] {processor.py:157} INFO - Started process (PID=27605) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:55:13.698+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:55:13.700+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:55:13.700+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:55:13.710+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:55:13.726+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:55:13.726+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:55:13.736+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:55:13.736+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:55:13.745+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-10T13:55:44.031+0000] {processor.py:157} INFO - Started process (PID=27615) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:55:44.032+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:55:44.034+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:55:44.034+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:55:44.046+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:55:44.062+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:55:44.062+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:55:44.073+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:55:44.073+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:55:44.082+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-10T13:56:14.381+0000] {processor.py:157} INFO - Started process (PID=27625) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:56:14.383+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:56:14.385+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:56:14.385+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:56:14.396+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:56:14.412+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:56:14.412+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:56:14.423+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:56:14.423+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:56:14.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-10T13:56:44.753+0000] {processor.py:157} INFO - Started process (PID=27635) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:56:44.761+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:56:44.764+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:56:44.764+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:56:44.772+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:56:44.787+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:56:44.787+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:56:44.800+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:56:44.800+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:56:44.811+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-10T13:57:15.160+0000] {processor.py:157} INFO - Started process (PID=27645) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:57:15.161+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:57:15.163+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:57:15.163+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:57:15.172+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:57:15.190+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:57:15.189+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:57:15.199+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:57:15.199+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:57:15.209+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-10T13:57:45.514+0000] {processor.py:157} INFO - Started process (PID=27655) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:57:45.515+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:57:45.517+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:57:45.517+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:57:45.526+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:57:45.542+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:57:45.542+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:57:45.552+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:57:45.552+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:57:45.562+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-10T13:58:15.939+0000] {processor.py:157} INFO - Started process (PID=27665) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:58:15.941+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:58:15.944+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:58:15.944+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:58:15.952+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:58:15.968+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:58:15.968+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:58:15.977+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:58:15.977+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:58:15.986+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-10T13:58:46.352+0000] {processor.py:157} INFO - Started process (PID=27675) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:58:46.355+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:58:46.358+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:58:46.357+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:58:46.367+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:58:46.384+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:58:46.384+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:58:46.393+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:58:46.393+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:58:46.402+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-10T13:59:16.684+0000] {processor.py:157} INFO - Started process (PID=27685) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:59:16.687+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:59:16.691+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:59:16.691+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:59:16.709+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:59:16.732+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:59:16.732+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:59:16.746+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:59:16.746+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:59:16.756+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-08-10T13:59:46.992+0000] {processor.py:157} INFO - Started process (PID=27695) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:59:46.994+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T13:59:46.997+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:59:46.996+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:59:47.008+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T13:59:47.026+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:59:47.026+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T13:59:47.039+0000] {logging_mixin.py:151} INFO - [2024-08-10T13:59:47.039+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T13:59:47.050+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-10T14:00:17.356+0000] {processor.py:157} INFO - Started process (PID=27705) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:00:17.357+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:00:17.359+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:00:17.358+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:00:17.371+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:00:17.389+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:00:17.389+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:00:17.402+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:00:17.402+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:00:17.413+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-10T14:00:47.629+0000] {processor.py:157} INFO - Started process (PID=27715) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:00:47.630+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:00:47.631+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:00:47.631+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:00:47.645+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:00:47.664+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:00:47.664+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:00:47.673+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:00:47.673+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:00:47.683+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-10T14:01:18.022+0000] {processor.py:157} INFO - Started process (PID=27725) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:01:18.023+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:01:18.025+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:01:18.025+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:01:18.036+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:01:18.050+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:01:18.050+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:01:18.060+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:01:18.060+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:01:18.069+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-10T14:01:48.404+0000] {processor.py:157} INFO - Started process (PID=27735) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:01:48.406+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:01:48.407+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:01:48.407+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:01:48.416+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:01:48.433+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:01:48.433+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:01:48.444+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:01:48.444+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:01:48.456+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-10T14:02:18.728+0000] {processor.py:157} INFO - Started process (PID=27745) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:02:18.729+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:02:18.733+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:02:18.732+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:02:18.747+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:02:18.764+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:02:18.764+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:02:18.775+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:02:18.775+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:02:18.784+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-10T14:02:49.085+0000] {processor.py:157} INFO - Started process (PID=27755) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:02:49.088+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:02:49.090+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:02:49.089+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:02:49.099+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:02:49.114+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:02:49.114+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:02:49.125+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:02:49.125+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:02:49.135+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-10T14:03:19.358+0000] {processor.py:157} INFO - Started process (PID=27765) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:03:19.360+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:03:19.363+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:03:19.362+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:03:19.371+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:03:19.389+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:03:19.389+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:03:19.400+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:03:19.400+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:03:19.410+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-10T14:03:49.669+0000] {processor.py:157} INFO - Started process (PID=27775) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:03:49.670+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:03:49.672+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:03:49.672+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:03:49.682+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:03:49.702+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:03:49.702+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:03:49.715+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:03:49.715+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:03:49.725+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-10T14:04:19.920+0000] {processor.py:157} INFO - Started process (PID=27785) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:04:19.922+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:04:19.924+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:04:19.923+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:04:19.939+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:04:19.955+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:04:19.955+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:04:19.965+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:04:19.965+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:04:19.975+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-10T14:04:50.275+0000] {processor.py:157} INFO - Started process (PID=27795) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:04:50.277+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:04:50.281+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:04:50.280+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:04:50.301+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:04:50.319+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:04:50.319+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:04:50.335+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:04:50.335+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:04:50.351+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-08-10T14:05:20.666+0000] {processor.py:157} INFO - Started process (PID=27805) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:05:20.668+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:05:20.670+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:05:20.670+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:05:20.679+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:05:20.699+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:05:20.699+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:05:20.713+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:05:20.713+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:05:20.723+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-10T14:05:51.013+0000] {processor.py:157} INFO - Started process (PID=27815) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:05:51.016+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:05:51.018+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:05:51.018+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:05:51.029+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:05:51.046+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:05:51.046+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:05:51.056+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:05:51.056+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:05:51.064+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-10T14:06:21.381+0000] {processor.py:157} INFO - Started process (PID=27825) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:06:21.383+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:06:21.385+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:06:21.385+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:06:21.398+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:06:21.415+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:06:21.415+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:06:21.425+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:06:21.425+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:06:21.432+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-10T14:06:51.796+0000] {processor.py:157} INFO - Started process (PID=27835) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:06:51.798+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:06:51.806+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:06:51.805+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:06:51.831+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:06:51.858+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:06:51.857+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:06:51.873+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:06:51.873+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:06:51.897+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-08-10T14:07:22.261+0000] {processor.py:157} INFO - Started process (PID=27845) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:07:22.263+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:07:22.268+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:07:22.267+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:07:22.286+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:07:22.321+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:07:22.321+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:07:22.363+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:07:22.363+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:07:22.374+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-08-10T14:07:52.697+0000] {processor.py:157} INFO - Started process (PID=27854) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:07:52.698+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:07:52.700+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:07:52.700+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:07:52.709+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:07:52.725+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:07:52.725+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:07:52.735+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:07:52.735+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:07:52.745+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-10T14:08:23.099+0000] {processor.py:157} INFO - Started process (PID=27865) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:08:23.102+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:08:23.110+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:08:23.109+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:08:23.140+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:08:23.198+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:08:23.197+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:08:23.222+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:08:23.222+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:08:23.232+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.141 seconds
[2024-08-10T14:08:53.493+0000] {processor.py:157} INFO - Started process (PID=27875) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:08:53.498+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:08:53.504+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:08:53.503+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:08:53.524+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:08:53.549+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:08:53.549+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:08:53.564+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:08:53.564+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:08:53.574+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-08-10T14:09:23.812+0000] {processor.py:157} INFO - Started process (PID=27885) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:09:23.813+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:09:23.815+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:09:23.815+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:09:23.826+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:09:23.843+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:09:23.843+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:09:23.854+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:09:23.854+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:09:23.863+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-10T14:09:54.166+0000] {processor.py:157} INFO - Started process (PID=27895) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:09:54.168+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:09:54.172+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:09:54.171+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:09:54.189+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:09:54.211+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:09:54.211+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:09:54.224+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:09:54.224+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:09:54.234+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-10T14:10:24.683+0000] {processor.py:157} INFO - Started process (PID=27905) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:10:24.685+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:10:24.692+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:10:24.691+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:10:24.727+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:10:24.788+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:10:24.788+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:10:24.809+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:10:24.809+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:10:24.823+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.172 seconds
[2024-08-10T14:10:54.998+0000] {processor.py:157} INFO - Started process (PID=27915) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:10:55.000+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:10:55.006+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:10:55.006+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:10:55.032+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:10:55.057+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:10:55.057+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:10:55.075+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:10:55.075+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:10:55.086+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-08-10T14:11:25.345+0000] {processor.py:157} INFO - Started process (PID=27924) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:11:25.347+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:11:25.363+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:11:25.358+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:11:25.393+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:11:25.424+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:11:25.424+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:11:25.443+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:11:25.443+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:11:25.457+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-08-10T14:11:55.641+0000] {processor.py:157} INFO - Started process (PID=27935) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:11:55.642+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:11:55.645+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:11:55.644+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:11:55.661+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:11:55.676+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:11:55.676+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:11:55.686+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:11:55.686+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:11:55.696+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-10T14:12:26.009+0000] {processor.py:157} INFO - Started process (PID=27945) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:12:26.011+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:12:26.015+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:12:26.014+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:12:26.064+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:12:26.094+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:12:26.094+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:12:26.110+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:12:26.110+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:12:26.125+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-08-10T14:12:56.314+0000] {processor.py:157} INFO - Started process (PID=27954) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:12:56.319+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:12:56.322+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:12:56.322+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:12:56.362+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:12:56.384+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:12:56.384+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:12:56.396+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:12:56.396+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:12:56.407+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-08-10T14:13:26.611+0000] {processor.py:157} INFO - Started process (PID=27965) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:13:26.612+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:13:26.613+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:13:26.613+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:13:26.623+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:13:26.639+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:13:26.639+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:13:26.649+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:13:26.649+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:13:26.659+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-10T14:13:56.986+0000] {processor.py:157} INFO - Started process (PID=27975) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:13:56.987+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:13:56.993+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:13:56.992+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:13:57.014+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:13:57.045+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:13:57.045+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:13:57.059+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:13:57.059+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:13:57.069+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-08-10T14:14:27.296+0000] {processor.py:157} INFO - Started process (PID=27984) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:14:27.297+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:14:27.301+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:14:27.301+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:14:27.336+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:14:27.364+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:14:27.364+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:14:27.383+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:14:27.383+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:14:27.393+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-08-10T14:14:57.586+0000] {processor.py:157} INFO - Started process (PID=27995) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:14:57.587+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:14:57.588+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:14:57.588+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:14:57.597+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:14:57.614+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:14:57.614+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:14:57.623+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:14:57.623+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:14:57.632+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-08-10T14:15:27.930+0000] {processor.py:157} INFO - Started process (PID=28004) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:15:27.932+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:15:27.937+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:15:27.937+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:15:27.957+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:15:27.988+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:15:27.988+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:15:28.001+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:15:28.001+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:15:28.012+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-08-10T14:15:58.183+0000] {processor.py:157} INFO - Started process (PID=28015) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:15:58.184+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:15:58.186+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:15:58.186+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:15:58.196+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:15:58.213+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:15:58.213+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:15:58.223+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:15:58.223+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:15:58.234+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-10T14:16:28.518+0000] {processor.py:157} INFO - Started process (PID=28025) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:16:28.519+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:16:28.521+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:16:28.521+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:16:28.532+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:16:28.550+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:16:28.549+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:16:28.562+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:16:28.562+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:16:28.572+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-10T14:16:58.882+0000] {processor.py:157} INFO - Started process (PID=28035) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:16:58.883+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:16:58.887+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:16:58.886+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:16:58.904+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:16:58.924+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:16:58.924+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:16:58.935+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:16:58.935+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:16:58.942+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-10T14:17:29.261+0000] {processor.py:157} INFO - Started process (PID=28045) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:17:29.262+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:17:29.264+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:17:29.264+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:17:29.276+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:17:29.296+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:17:29.296+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:17:29.312+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:17:29.312+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:17:29.324+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-10T14:17:59.582+0000] {processor.py:157} INFO - Started process (PID=28055) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:17:59.583+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:17:59.587+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:17:59.587+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:17:59.604+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:17:59.625+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:17:59.625+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:17:59.635+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:17:59.635+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:17:59.642+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-10T14:18:29.958+0000] {processor.py:157} INFO - Started process (PID=28065) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:18:29.959+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:18:29.961+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:18:29.961+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:18:29.972+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:18:29.990+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:18:29.990+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:18:30.001+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:18:30.001+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:18:30.010+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-10T14:19:00.333+0000] {processor.py:157} INFO - Started process (PID=28075) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:19:00.335+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:19:00.336+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:19:00.336+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:19:00.345+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:19:00.365+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:19:00.365+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:19:00.379+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:19:00.379+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:19:00.389+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-10T14:19:30.664+0000] {processor.py:157} INFO - Started process (PID=28085) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:19:30.665+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:19:30.667+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:19:30.667+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:19:30.682+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:19:30.696+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:19:30.696+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:19:30.716+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:19:30.716+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:19:30.730+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-10T14:20:01.024+0000] {processor.py:157} INFO - Started process (PID=28095) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:20:01.026+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:20:01.030+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:20:01.030+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:20:01.052+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:20:01.073+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:20:01.073+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:20:01.084+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:20:01.083+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:20:01.092+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-10T14:20:31.277+0000] {processor.py:157} INFO - Started process (PID=28105) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:20:31.278+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:20:31.279+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:20:31.279+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:20:31.290+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:20:31.308+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:20:31.308+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:20:31.322+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:20:31.322+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:20:31.330+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-10T14:21:01.627+0000] {processor.py:157} INFO - Started process (PID=28115) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:21:01.629+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:21:01.631+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:21:01.631+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:21:01.644+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:21:01.659+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:21:01.659+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:21:01.671+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:21:01.671+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:21:01.681+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-10T14:21:31.995+0000] {processor.py:157} INFO - Started process (PID=28125) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:21:31.997+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:21:32.001+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:21:32.001+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:21:32.018+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:21:32.037+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:21:32.037+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:21:32.047+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:21:32.047+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:21:32.056+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-10T14:22:02.259+0000] {processor.py:157} INFO - Started process (PID=28135) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:22:02.261+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:22:02.263+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:22:02.262+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:22:02.273+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:22:02.292+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:22:02.291+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:22:02.302+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:22:02.302+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:22:02.311+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-10T14:22:32.605+0000] {processor.py:157} INFO - Started process (PID=28145) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:22:32.608+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:22:32.611+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:22:32.611+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:22:32.630+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:22:32.662+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:22:32.662+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:22:32.678+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:22:32.678+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:22:32.690+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-08-10T14:23:03.026+0000] {processor.py:157} INFO - Started process (PID=28155) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:23:03.027+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:23:03.031+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:23:03.031+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:23:03.048+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:23:03.070+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:23:03.070+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:23:03.084+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:23:03.084+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:23:03.095+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-10T14:23:33.332+0000] {processor.py:157} INFO - Started process (PID=28165) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:23:33.334+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:23:33.335+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:23:33.335+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:23:33.346+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:23:33.362+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:23:33.362+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:23:33.375+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:23:33.375+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:23:33.382+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-10T14:24:03.666+0000] {processor.py:157} INFO - Started process (PID=28175) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:24:03.668+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:24:03.670+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:24:03.670+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:24:03.680+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:24:03.697+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:24:03.697+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:24:03.707+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:24:03.707+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:24:03.716+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-10T14:24:33.974+0000] {processor.py:157} INFO - Started process (PID=28185) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:24:33.975+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:24:33.977+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:24:33.977+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:24:33.987+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:24:34.005+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:24:34.005+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:24:34.015+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:24:34.015+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:24:34.026+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-10T14:25:04.333+0000] {processor.py:157} INFO - Started process (PID=28195) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:25:04.336+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:25:04.338+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:25:04.338+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:25:04.348+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:25:04.363+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:25:04.363+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:25:04.373+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:25:04.373+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:25:04.380+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-10T14:25:34.641+0000] {processor.py:157} INFO - Started process (PID=28205) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:25:34.644+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:25:34.646+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:25:34.646+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:25:34.654+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:25:34.669+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:25:34.669+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:25:34.679+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:25:34.679+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:25:34.689+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-10T14:26:05.009+0000] {processor.py:157} INFO - Started process (PID=28215) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:26:05.010+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:26:05.012+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:26:05.011+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:26:05.020+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:26:05.038+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:26:05.038+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:26:05.049+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:26:05.049+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:26:05.059+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-10T14:26:35.297+0000] {processor.py:157} INFO - Started process (PID=28225) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:26:35.298+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:26:35.300+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:26:35.300+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:26:35.308+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:26:35.324+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:26:35.324+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:26:35.334+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:26:35.334+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:26:35.342+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-08-10T14:27:05.605+0000] {processor.py:157} INFO - Started process (PID=28235) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:27:05.606+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:27:05.607+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:27:05.607+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:27:05.618+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:27:05.633+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:27:05.632+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:27:05.642+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:27:05.642+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:27:05.649+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-08-10T14:27:36.086+0000] {processor.py:157} INFO - Started process (PID=28245) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:27:36.088+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:27:36.092+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:27:36.091+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:27:36.109+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:27:36.141+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:27:36.141+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:27:36.157+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:27:36.157+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:27:36.165+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-08-10T14:28:06.468+0000] {processor.py:157} INFO - Started process (PID=28255) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:28:06.472+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:28:06.474+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:28:06.474+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:28:06.483+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:28:06.497+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:28:06.496+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:28:06.505+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:28:06.505+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:28:06.514+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-10T14:28:36.685+0000] {processor.py:157} INFO - Started process (PID=28265) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:28:36.686+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:28:36.687+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:28:36.687+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:28:36.702+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:28:36.716+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:28:36.716+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:28:36.726+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:28:36.726+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:28:36.736+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-10T14:29:07.073+0000] {processor.py:157} INFO - Started process (PID=28275) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:29:07.075+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:29:07.077+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:29:07.077+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:29:07.086+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:29:07.103+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:29:07.103+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:29:07.113+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:29:07.113+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:29:07.121+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-10T14:29:37.457+0000] {processor.py:157} INFO - Started process (PID=28285) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:29:37.458+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:29:37.459+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:29:37.459+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:29:37.470+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:29:37.485+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:29:37.485+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:29:37.495+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:29:37.495+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:29:37.504+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-10T14:30:07.766+0000] {processor.py:157} INFO - Started process (PID=28295) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:30:07.768+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:30:07.771+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:30:07.771+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:30:07.788+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:30:07.810+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:30:07.810+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:30:07.823+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:30:07.823+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:30:07.833+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-10T14:30:38.140+0000] {processor.py:157} INFO - Started process (PID=28305) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:30:38.141+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:30:38.142+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:30:38.142+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:30:38.152+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:30:38.168+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:30:38.168+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:30:38.178+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:30:38.178+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:30:38.188+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-10T14:31:08.503+0000] {processor.py:157} INFO - Started process (PID=28315) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:31:08.504+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:31:08.506+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:31:08.505+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:31:08.515+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:31:08.532+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:31:08.532+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:31:08.542+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:31:08.542+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:31:08.551+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-10T14:31:38.739+0000] {processor.py:157} INFO - Started process (PID=28325) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:31:38.739+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:31:38.741+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:31:38.740+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:31:38.754+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:31:38.768+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:31:38.768+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:31:38.779+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:31:38.779+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:31:38.788+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-10T14:32:09.078+0000] {processor.py:157} INFO - Started process (PID=28335) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:32:09.080+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:32:09.082+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:32:09.082+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:32:09.092+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:32:09.111+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:32:09.111+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:32:09.124+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:32:09.124+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:32:09.134+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-10T14:32:39.446+0000] {processor.py:157} INFO - Started process (PID=28345) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:32:39.448+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:32:39.450+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:32:39.450+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:32:39.460+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:32:39.477+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:32:39.477+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:32:39.487+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:32:39.487+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:32:39.498+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-10T14:33:09.780+0000] {processor.py:157} INFO - Started process (PID=28355) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:33:09.780+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:33:09.782+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:33:09.782+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:33:09.798+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:33:09.812+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:33:09.812+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:33:09.823+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:33:09.823+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:33:09.834+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-10T14:33:40.200+0000] {processor.py:157} INFO - Started process (PID=28365) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:33:40.201+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:33:40.203+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:33:40.203+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:33:40.213+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:33:40.228+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:33:40.228+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:33:40.240+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:33:40.240+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:33:40.248+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-10T14:34:10.601+0000] {processor.py:157} INFO - Started process (PID=28375) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:34:10.603+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:34:10.607+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:34:10.606+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:34:10.622+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:34:10.644+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:34:10.644+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:34:10.657+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:34:10.657+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:34:10.666+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-10T14:34:40.907+0000] {processor.py:157} INFO - Started process (PID=28385) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:34:40.908+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:34:40.910+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:34:40.910+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:34:40.921+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:34:40.938+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:34:40.938+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:34:40.950+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:34:40.950+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:34:40.960+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-10T14:35:11.294+0000] {processor.py:157} INFO - Started process (PID=28395) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:35:11.295+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:35:11.297+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:35:11.297+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:35:11.311+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:35:11.326+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:35:11.326+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:35:11.337+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:35:11.337+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:35:11.346+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-10T14:35:41.694+0000] {processor.py:157} INFO - Started process (PID=28405) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:35:41.696+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:35:41.698+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:35:41.698+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:35:41.708+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:35:41.724+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:35:41.724+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:35:41.733+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:35:41.733+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:35:41.743+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-10T14:36:12.085+0000] {processor.py:157} INFO - Started process (PID=28415) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:36:12.086+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:36:12.088+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:36:12.088+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:36:12.098+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:36:12.116+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:36:12.115+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:36:12.127+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:36:12.127+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:36:12.138+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-10T14:36:42.451+0000] {processor.py:157} INFO - Started process (PID=28425) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:36:42.453+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:36:42.455+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:36:42.454+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:36:42.464+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:36:42.480+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:36:42.480+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:36:42.489+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:36:42.489+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:36:42.498+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-10T14:37:12.799+0000] {processor.py:157} INFO - Started process (PID=28435) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:37:12.800+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:37:12.801+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:37:12.801+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:37:12.812+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:37:12.826+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:37:12.826+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:37:12.836+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:37:12.836+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:37:12.847+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-10T14:37:43.159+0000] {processor.py:157} INFO - Started process (PID=28445) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:37:43.162+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:37:43.165+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:37:43.165+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:37:43.180+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:37:43.201+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:37:43.201+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:37:43.214+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:37:43.214+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:37:43.225+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-10T14:38:13.473+0000] {processor.py:157} INFO - Started process (PID=28455) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:38:13.475+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:38:13.477+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:38:13.476+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:38:13.487+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:38:13.503+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:38:13.503+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:38:13.513+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:38:13.513+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:38:13.523+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-10T14:38:43.842+0000] {processor.py:157} INFO - Started process (PID=28465) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:38:43.845+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:38:43.847+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:38:43.847+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:38:43.858+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:38:43.874+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:38:43.874+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:38:43.884+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:38:43.884+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:38:43.893+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-10T14:39:14.225+0000] {processor.py:157} INFO - Started process (PID=28475) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:39:14.227+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:39:14.229+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:39:14.229+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:39:14.244+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:39:14.260+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:39:14.260+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:39:14.268+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:39:14.268+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:39:14.277+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-10T14:39:44.629+0000] {processor.py:157} INFO - Started process (PID=28485) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:39:44.632+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:39:44.634+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:39:44.634+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:39:44.643+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:39:44.660+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:39:44.660+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:39:44.669+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:39:44.669+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:39:44.676+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-10T14:40:15.039+0000] {processor.py:157} INFO - Started process (PID=28495) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:40:15.040+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:40:15.041+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:40:15.041+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:40:15.051+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:40:15.065+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:40:15.065+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:40:15.076+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:40:15.076+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:40:15.086+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-08-10T14:40:45.386+0000] {processor.py:157} INFO - Started process (PID=28505) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:40:45.388+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:40:45.390+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:40:45.389+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:40:45.399+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:40:45.417+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:40:45.417+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:40:45.430+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:40:45.430+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:40:45.438+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-10T14:41:15.786+0000] {processor.py:157} INFO - Started process (PID=28515) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:41:15.789+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:41:15.791+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:41:15.790+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:41:15.799+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:41:15.815+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:41:15.815+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:41:15.825+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:41:15.825+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:41:15.836+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-10T14:41:46.165+0000] {processor.py:157} INFO - Started process (PID=28525) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:41:46.166+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:41:46.167+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:41:46.167+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:41:46.177+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:41:46.194+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:41:46.194+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:41:46.204+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:41:46.204+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:41:46.213+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-10T14:42:16.539+0000] {processor.py:157} INFO - Started process (PID=28535) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:42:16.541+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:42:16.544+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:42:16.543+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:42:16.561+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:42:16.584+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:42:16.584+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:42:16.598+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:42:16.598+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:42:16.607+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-10T14:42:46.935+0000] {processor.py:157} INFO - Started process (PID=28545) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:42:46.936+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:42:46.938+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:42:46.938+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:42:46.955+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:42:46.970+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:42:46.970+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:42:46.981+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:42:46.981+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:42:46.990+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-10T14:43:17.303+0000] {processor.py:157} INFO - Started process (PID=28555) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:43:17.305+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:43:17.307+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:43:17.307+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:43:17.316+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:43:17.334+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:43:17.334+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:43:17.346+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:43:17.346+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:43:17.356+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-10T14:43:47.709+0000] {processor.py:157} INFO - Started process (PID=28565) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:43:47.716+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:43:47.718+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:43:47.718+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:43:47.728+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:43:47.743+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:43:47.743+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:43:47.753+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:43:47.753+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:43:47.762+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-10T14:44:18.068+0000] {processor.py:157} INFO - Started process (PID=28575) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:44:18.068+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:44:18.069+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:44:18.069+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:44:18.079+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:44:18.095+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:44:18.095+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:44:18.109+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:44:18.109+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:44:18.119+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-10T14:44:48.470+0000] {processor.py:157} INFO - Started process (PID=28585) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:44:48.471+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:44:48.472+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:44:48.472+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:44:48.488+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:44:48.502+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:44:48.502+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:44:48.512+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:44:48.512+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:44:48.520+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-10T14:45:18.861+0000] {processor.py:157} INFO - Started process (PID=28595) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:45:18.862+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:45:18.863+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:45:18.863+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:45:18.875+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:45:18.889+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:45:18.889+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:45:18.899+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:45:18.899+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:45:18.908+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-10T14:45:49.180+0000] {processor.py:157} INFO - Started process (PID=28605) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:45:49.185+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:45:49.193+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:45:49.193+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:45:49.224+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:45:49.248+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:45:49.248+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:45:49.260+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:45:49.260+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:45:49.269+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-08-10T14:46:19.588+0000] {processor.py:157} INFO - Started process (PID=28615) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:46:19.596+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:46:19.599+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:46:19.599+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:46:19.607+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:46:19.621+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:46:19.621+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:46:19.632+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:46:19.632+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:46:19.641+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-10T14:46:49.953+0000] {processor.py:157} INFO - Started process (PID=28625) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:46:49.954+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:46:49.956+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:46:49.956+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:46:49.967+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:46:49.983+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:46:49.983+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:46:49.993+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:46:49.993+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:46:50.003+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-10T14:47:20.363+0000] {processor.py:157} INFO - Started process (PID=28635) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:47:20.365+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:47:20.367+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:47:20.366+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:47:20.376+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:47:20.392+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:47:20.392+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:47:20.402+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:47:20.402+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:47:20.410+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-10T14:47:50.726+0000] {processor.py:157} INFO - Started process (PID=28645) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:47:50.727+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:47:50.728+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:47:50.728+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:47:50.744+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:47:50.759+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:47:50.759+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:47:50.771+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:47:50.771+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:47:50.778+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-10T14:48:21.088+0000] {processor.py:157} INFO - Started process (PID=28655) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:48:21.089+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:48:21.092+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:48:21.092+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:48:21.101+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:48:21.118+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:48:21.117+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:48:21.127+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:48:21.127+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:48:21.137+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-10T14:48:51.477+0000] {processor.py:157} INFO - Started process (PID=28665) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:48:51.478+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:48:51.480+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:48:51.479+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:48:51.489+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:48:51.505+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:48:51.505+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:48:51.516+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:48:51.516+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:48:51.523+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-08-10T14:49:21.876+0000] {processor.py:157} INFO - Started process (PID=28675) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:49:21.879+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:49:21.882+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:49:21.881+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:49:21.892+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:49:21.909+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:49:21.909+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:49:21.920+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:49:21.920+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:49:21.928+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-10T14:49:52.247+0000] {processor.py:157} INFO - Started process (PID=28685) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:49:52.250+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:49:52.253+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:49:52.253+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:49:52.284+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:49:52.310+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:49:52.310+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:49:52.328+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:49:52.328+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:49:52.344+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-08-10T14:50:22.629+0000] {processor.py:157} INFO - Started process (PID=28695) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:50:22.630+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:50:22.632+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:50:22.632+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:50:22.645+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:50:22.661+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:50:22.661+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:50:22.672+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:50:22.672+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:50:22.682+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-10T14:50:53.009+0000] {processor.py:157} INFO - Started process (PID=28705) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:50:53.011+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:50:53.014+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:50:53.014+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:50:53.035+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:50:53.060+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:50:53.060+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:50:53.074+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:50:53.074+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:50:53.086+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-08-10T14:51:23.330+0000] {processor.py:157} INFO - Started process (PID=28715) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:51:23.333+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:51:23.337+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:51:23.337+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:51:23.355+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:51:23.383+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:51:23.383+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:51:23.399+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:51:23.399+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:51:23.413+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-10T14:51:53.676+0000] {processor.py:157} INFO - Started process (PID=28725) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:51:53.680+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:51:53.686+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:51:53.686+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:51:53.706+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:51:53.728+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:51:53.728+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:51:53.742+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:51:53.742+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:51:53.754+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-08-10T14:52:23.964+0000] {processor.py:157} INFO - Started process (PID=28735) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:52:23.965+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:52:23.966+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:52:23.966+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:52:23.976+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:52:23.993+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:52:23.993+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:52:24.003+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:52:24.003+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:52:24.012+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-10T14:52:54.362+0000] {processor.py:157} INFO - Started process (PID=28745) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:52:54.364+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:52:54.367+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:52:54.367+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:52:54.389+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:52:54.410+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:52:54.410+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:52:54.424+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:52:54.423+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:52:54.435+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-08-10T14:53:24.667+0000] {processor.py:157} INFO - Started process (PID=28755) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:53:24.667+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:53:24.669+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:53:24.669+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:53:24.678+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:53:24.695+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:53:24.695+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:53:24.705+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:53:24.705+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:53:24.715+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-10T14:53:54.949+0000] {processor.py:157} INFO - Started process (PID=28765) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:53:54.953+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:53:54.957+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:53:54.957+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:53:54.977+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:53:55.001+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:53:55.001+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:53:55.019+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:53:55.018+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:53:55.030+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-08-10T14:54:25.237+0000] {processor.py:157} INFO - Started process (PID=28775) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:54:25.239+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:54:25.241+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:54:25.241+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:54:25.251+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:54:25.272+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:54:25.272+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:54:25.285+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:54:25.285+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:54:25.296+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-10T14:54:55.548+0000] {processor.py:157} INFO - Started process (PID=28785) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:54:55.549+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:54:55.553+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:54:55.552+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:54:55.570+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:54:55.592+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:54:55.592+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:54:55.605+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:54:55.605+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:54:55.616+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-10T14:55:25.918+0000] {processor.py:157} INFO - Started process (PID=28795) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:55:25.919+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:55:25.921+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:55:25.921+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:55:25.938+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:55:25.956+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:55:25.956+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:55:25.974+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:55:25.974+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:55:25.986+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-10T14:55:56.280+0000] {processor.py:157} INFO - Started process (PID=28805) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:55:56.281+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:55:56.283+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:55:56.283+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:55:56.292+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:55:56.308+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:55:56.308+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:55:56.318+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:55:56.318+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:55:56.326+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-10T14:56:26.658+0000] {processor.py:157} INFO - Started process (PID=28815) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:56:26.659+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:56:26.664+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:56:26.664+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:56:26.677+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:56:26.696+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:56:26.696+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:56:26.706+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:56:26.706+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:56:26.714+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-10T14:56:56.892+0000] {processor.py:157} INFO - Started process (PID=28825) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:56:56.893+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:56:56.895+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:56:56.895+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:56:56.908+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:56:56.932+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:56:56.932+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:56:56.946+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:56:56.946+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:56:56.959+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-10T14:57:27.184+0000] {processor.py:157} INFO - Started process (PID=28835) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:57:27.189+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:57:27.194+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:57:27.193+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:57:27.211+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:57:27.235+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:57:27.235+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:57:27.250+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:57:27.250+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:57:27.265+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-08-10T14:57:57.561+0000] {processor.py:157} INFO - Started process (PID=28845) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:57:57.562+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:57:57.564+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:57:57.563+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:57:57.579+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:57:57.599+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:57:57.599+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:57:57.615+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:57:57.615+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:57:57.627+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-10T14:58:27.914+0000] {processor.py:157} INFO - Started process (PID=28855) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:58:27.915+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:58:27.919+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:58:27.919+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:58:27.944+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:58:27.968+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:58:27.968+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:58:27.983+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:58:27.983+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:58:27.992+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-08-10T14:58:58.344+0000] {processor.py:157} INFO - Started process (PID=28865) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:58:58.345+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:58:58.349+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:58:58.348+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:58:58.364+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:58:58.382+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:58:58.382+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:58:58.397+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:58:58.397+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:58:58.406+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-10T14:59:28.782+0000] {processor.py:157} INFO - Started process (PID=28875) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:59:28.784+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:59:28.787+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:59:28.786+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:59:28.799+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:59:28.820+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:59:28.820+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:59:28.835+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:59:28.835+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:59:28.846+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-10T14:59:59.121+0000] {processor.py:157} INFO - Started process (PID=28885) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:59:59.121+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T14:59:59.123+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:59:59.123+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:59:59.132+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T14:59:59.151+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:59:59.151+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T14:59:59.161+0000] {logging_mixin.py:151} INFO - [2024-08-10T14:59:59.161+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T14:59:59.169+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-10T15:00:29.487+0000] {processor.py:157} INFO - Started process (PID=28895) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:00:29.493+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T15:00:29.496+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:00:29.496+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:00:29.517+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:00:29.539+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:00:29.539+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T15:00:29.551+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:00:29.551+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T15:00:29.562+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-08-10T15:00:59.797+0000] {processor.py:157} INFO - Started process (PID=28905) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:00:59.799+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T15:00:59.801+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:00:59.801+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:00:59.811+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:00:59.829+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:00:59.829+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T15:00:59.841+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:00:59.841+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T15:00:59.851+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-10T15:01:30.138+0000] {processor.py:157} INFO - Started process (PID=28915) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:01:30.141+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T15:01:30.146+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:01:30.145+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:01:30.163+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:01:30.205+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:01:30.205+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T15:01:30.223+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:01:30.223+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T15:01:30.235+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-08-10T15:02:00.543+0000] {processor.py:157} INFO - Started process (PID=28925) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:02:00.544+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T15:02:00.546+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:02:00.546+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:02:00.565+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:02:00.579+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:02:00.579+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T15:02:00.591+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:02:00.591+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T15:02:00.600+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-10T15:02:30.876+0000] {processor.py:157} INFO - Started process (PID=28935) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:02:30.879+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T15:02:30.897+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:02:30.895+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:02:30.917+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:02:30.944+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:02:30.944+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T15:02:30.959+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:02:30.959+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T15:02:30.979+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-08-10T15:03:01.161+0000] {processor.py:157} INFO - Started process (PID=28945) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:03:01.167+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T15:03:01.173+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:03:01.171+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:03:01.201+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:03:01.246+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:03:01.246+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T15:03:01.262+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:03:01.262+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T15:03:01.275+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-08-10T15:03:31.509+0000] {processor.py:157} INFO - Started process (PID=28955) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:03:31.512+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T15:03:31.515+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:03:31.515+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:03:31.530+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:03:31.552+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:03:31.552+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T15:03:31.569+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:03:31.569+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T15:03:31.580+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-08-10T15:04:01.824+0000] {processor.py:157} INFO - Started process (PID=28965) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:04:01.825+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T15:04:01.827+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:04:01.827+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:04:01.840+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:04:01.855+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:04:01.855+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T15:04:01.866+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:04:01.866+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T15:04:01.876+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-10T15:04:32.279+0000] {processor.py:157} INFO - Started process (PID=28975) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:04:32.283+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T15:04:32.289+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:04:32.289+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:04:32.315+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:04:32.340+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:04:32.340+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T15:04:32.353+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:04:32.353+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T15:04:32.364+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-08-10T15:05:02.690+0000] {processor.py:157} INFO - Started process (PID=28985) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:05:02.693+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T15:05:02.696+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:05:02.695+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:05:02.707+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:05:02.723+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:05:02.723+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T15:05:02.733+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:05:02.733+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T15:05:02.742+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-10T15:05:33.078+0000] {processor.py:157} INFO - Started process (PID=28995) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:05:33.079+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T15:05:33.082+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:05:33.081+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:05:33.097+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:05:33.118+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:05:33.118+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T15:05:33.131+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:05:33.131+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T15:05:33.141+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-10T15:06:03.345+0000] {processor.py:157} INFO - Started process (PID=29005) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:06:03.347+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T15:06:03.349+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:06:03.349+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:06:03.358+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:06:03.374+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:06:03.374+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T15:06:03.384+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:06:03.384+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T15:06:03.393+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-10T15:06:33.738+0000] {processor.py:157} INFO - Started process (PID=29015) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:06:33.739+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T15:06:33.741+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:06:33.741+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:06:33.750+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:06:33.768+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:06:33.768+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T15:06:33.780+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:06:33.780+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T15:06:33.790+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-10T15:07:04.094+0000] {processor.py:157} INFO - Started process (PID=29025) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:07:04.096+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T15:07:04.098+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:07:04.098+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:07:04.107+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:07:04.122+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:07:04.122+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T15:07:04.133+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:07:04.133+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T15:07:04.141+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-10T15:07:34.367+0000] {processor.py:157} INFO - Started process (PID=29035) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:07:34.368+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T15:07:34.373+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:07:34.372+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:07:34.389+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:07:34.410+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:07:34.409+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T15:07:34.423+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:07:34.423+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T15:07:34.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-10T15:08:04.644+0000] {processor.py:157} INFO - Started process (PID=29045) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:08:04.646+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T15:08:04.648+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:08:04.648+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:08:04.659+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:08:04.678+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:08:04.678+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T15:08:04.690+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:08:04.690+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T15:08:04.701+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-10T15:08:35.010+0000] {processor.py:157} INFO - Started process (PID=29055) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:08:35.013+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T15:08:35.015+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:08:35.015+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:08:35.026+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:08:35.044+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:08:35.044+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T15:08:35.055+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:08:35.055+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T15:08:35.065+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-10T15:09:05.399+0000] {processor.py:157} INFO - Started process (PID=29065) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:09:05.401+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T15:09:05.404+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:09:05.404+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:09:05.421+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:09:05.435+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:09:05.435+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T15:09:05.447+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:09:05.447+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T15:09:05.456+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-10T15:09:35.769+0000] {processor.py:157} INFO - Started process (PID=29075) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:09:35.772+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T15:09:35.774+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:09:35.774+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:09:35.790+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:09:35.812+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:09:35.812+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T15:09:35.824+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:09:35.824+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T15:09:35.835+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-10T15:10:06.165+0000] {processor.py:157} INFO - Started process (PID=29085) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:10:06.166+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T15:10:06.168+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:10:06.168+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:10:06.179+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:10:06.196+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:10:06.196+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T15:10:06.207+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:10:06.206+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T15:10:06.214+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-10T15:10:36.536+0000] {processor.py:157} INFO - Started process (PID=29095) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:10:36.536+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T15:10:36.538+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:10:36.538+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:10:36.549+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:10:36.565+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:10:36.565+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T15:10:36.576+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:10:36.576+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T15:10:36.584+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-10T15:11:06.964+0000] {processor.py:157} INFO - Started process (PID=29105) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:11:06.965+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T15:11:06.969+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:11:06.969+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:11:06.986+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:11:07.007+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:11:07.007+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T15:11:07.020+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:11:07.020+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T15:11:07.031+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-10T15:11:37.398+0000] {processor.py:157} INFO - Started process (PID=29115) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:11:37.400+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T15:11:37.402+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:11:37.402+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:11:37.416+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:11:37.433+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:11:37.433+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T15:11:37.443+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:11:37.443+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T15:11:37.453+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-10T15:12:07.722+0000] {processor.py:157} INFO - Started process (PID=29125) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:12:07.724+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T15:12:07.727+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:12:07.726+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:12:07.744+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:12:07.765+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:12:07.765+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T15:12:07.779+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:12:07.779+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T15:12:07.789+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-10T15:12:38.136+0000] {processor.py:157} INFO - Started process (PID=29135) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:12:38.137+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T15:12:38.140+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:12:38.140+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:12:38.159+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:12:38.179+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:12:38.179+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T15:12:38.192+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:12:38.192+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T15:12:38.204+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-10T15:13:08.435+0000] {processor.py:157} INFO - Started process (PID=29145) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:13:08.436+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T15:13:08.438+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:13:08.438+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:13:08.447+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:13:08.463+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:13:08.463+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T15:13:08.473+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:13:08.473+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T15:13:08.482+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-10T15:13:38.801+0000] {processor.py:157} INFO - Started process (PID=29155) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:13:38.802+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T15:13:38.804+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:13:38.804+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:13:38.819+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:13:38.836+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:13:38.836+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T15:13:38.848+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:13:38.848+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T15:13:38.860+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-10T15:14:09.227+0000] {processor.py:157} INFO - Started process (PID=29165) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:14:09.229+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T15:14:09.232+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:14:09.231+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:14:09.248+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:14:09.285+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:14:09.285+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T15:14:09.298+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:14:09.298+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T15:14:09.310+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-08-10T15:14:39.549+0000] {processor.py:157} INFO - Started process (PID=29175) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:14:39.550+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T15:14:39.555+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:14:39.554+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:14:39.566+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:14:39.587+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:14:39.587+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T15:14:39.598+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:14:39.598+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T15:14:39.606+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-10T15:15:09.889+0000] {processor.py:157} INFO - Started process (PID=29185) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:15:09.890+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T15:15:09.893+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:15:09.893+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:15:09.909+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:15:09.945+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:15:09.945+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T15:15:09.956+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:15:09.956+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T15:15:09.965+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-08-10T15:15:40.270+0000] {processor.py:157} INFO - Started process (PID=29195) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:15:40.272+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T15:15:40.276+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:15:40.276+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:15:40.312+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:15:40.330+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:15:40.330+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T15:15:40.344+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:15:40.344+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T15:15:40.352+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-08-10T15:16:10.651+0000] {processor.py:157} INFO - Started process (PID=29205) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:16:10.653+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T15:16:10.659+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:16:10.658+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:16:10.700+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:16:10.733+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:16:10.733+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T15:16:10.748+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:16:10.748+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T15:16:10.759+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-08-10T15:16:41.070+0000] {processor.py:157} INFO - Started process (PID=29215) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:16:41.076+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T15:16:41.083+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:16:41.083+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:16:41.119+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:16:41.155+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:16:41.155+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T15:16:41.176+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:16:41.176+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T15:16:41.188+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-08-10T15:17:11.444+0000] {processor.py:157} INFO - Started process (PID=29225) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:17:11.451+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T15:17:11.456+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:17:11.456+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:17:11.500+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:17:11.544+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:17:11.544+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T15:17:11.561+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:17:11.561+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T15:17:11.573+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-08-10T15:17:41.822+0000] {processor.py:157} INFO - Started process (PID=29235) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:17:41.827+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T15:17:41.832+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:17:41.832+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:17:41.855+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:17:41.974+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:17:41.974+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T15:17:42.003+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:17:42.003+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T15:17:42.019+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.203 seconds
[2024-08-10T15:18:34.570+0000] {processor.py:157} INFO - Started process (PID=29246) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:18:34.572+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T15:18:34.577+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:18:34.577+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:18:34.611+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:18:34.638+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:18:34.638+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T15:18:34.657+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:18:34.657+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T15:18:34.667+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-08-10T15:19:04.981+0000] {processor.py:157} INFO - Started process (PID=29257) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:19:04.984+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T15:19:04.988+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:19:04.987+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:19:05.008+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:19:05.028+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:19:05.028+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T15:19:05.042+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:19:05.042+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T15:19:05.053+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-08-10T15:19:41.348+0000] {processor.py:157} INFO - Started process (PID=29267) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:19:41.349+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T15:19:41.350+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:19:41.350+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:19:41.366+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:19:41.379+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:19:41.379+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T15:19:41.389+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:19:41.389+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T15:19:41.399+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-10T15:35:36.042+0000] {processor.py:157} INFO - Started process (PID=29279) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:35:36.047+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T15:35:36.054+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:35:36.053+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:35:36.078+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:35:36.145+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:35:36.145+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T15:35:36.175+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:35:36.175+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T15:35:36.200+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.168 seconds
[2024-08-10T15:36:06.629+0000] {processor.py:157} INFO - Started process (PID=29288) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:36:06.634+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T15:36:06.638+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:36:06.637+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:36:06.660+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:36:06.685+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:36:06.685+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T15:36:06.699+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:36:06.699+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T15:36:06.712+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-08-10T15:36:36.973+0000] {processor.py:157} INFO - Started process (PID=29299) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:36:36.979+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T15:36:36.983+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:36:36.982+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:36:36.991+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:36:37.004+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:36:37.004+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T15:36:37.015+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:36:37.014+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T15:36:37.022+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-10T15:37:07.402+0000] {processor.py:157} INFO - Started process (PID=29309) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:37:07.404+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T15:37:07.408+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:37:07.407+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:37:07.427+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:37:07.444+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:37:07.444+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T15:37:07.457+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:37:07.457+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T15:37:07.467+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-10T15:37:37.789+0000] {processor.py:157} INFO - Started process (PID=29319) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:37:37.790+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T15:37:37.792+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:37:37.792+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:37:37.806+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:37:37.824+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:37:37.824+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T15:37:37.834+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:37:37.834+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T15:37:37.845+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-10T15:38:08.211+0000] {processor.py:157} INFO - Started process (PID=29329) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:38:08.213+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T15:38:08.215+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:38:08.215+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:38:08.224+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:38:08.239+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:38:08.239+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T15:38:08.249+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:38:08.249+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T15:38:08.260+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-10T15:55:01.486+0000] {processor.py:157} INFO - Started process (PID=29340) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:55:01.488+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T15:55:01.492+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:55:01.491+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:55:01.519+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:55:01.548+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:55:01.548+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T15:55:01.563+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:55:01.563+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T15:55:01.573+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-08-10T15:55:31.860+0000] {processor.py:157} INFO - Started process (PID=29351) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:55:31.861+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T15:55:31.868+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:55:31.868+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:55:31.889+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:55:31.913+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:55:31.913+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T15:55:31.929+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:55:31.929+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T15:55:31.942+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-08-10T15:56:02.188+0000] {processor.py:157} INFO - Started process (PID=29361) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:56:02.191+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T15:56:02.199+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:56:02.198+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:56:02.218+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:56:02.240+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:56:02.240+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T15:56:02.253+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:56:02.253+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T15:56:02.263+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-08-10T15:56:32.496+0000] {processor.py:157} INFO - Started process (PID=29371) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:56:32.497+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T15:56:32.499+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:56:32.499+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:56:32.508+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:56:32.523+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:56:32.523+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T15:56:32.534+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:56:32.534+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T15:56:32.543+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-08-10T15:57:02.799+0000] {processor.py:157} INFO - Started process (PID=29381) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:57:02.801+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T15:57:02.805+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:57:02.805+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:57:02.821+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:57:02.841+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:57:02.841+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T15:57:02.854+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:57:02.854+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T15:57:02.863+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-10T15:57:33.290+0000] {processor.py:157} INFO - Started process (PID=29391) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:57:33.291+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T15:57:33.293+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:57:33.293+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:57:33.304+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:57:33.323+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:57:33.323+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T15:57:33.334+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:57:33.334+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T15:57:33.343+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-10T15:58:03.685+0000] {processor.py:157} INFO - Started process (PID=29401) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:58:03.689+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T15:58:03.692+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:58:03.692+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:58:03.721+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:58:03.743+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:58:03.743+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T15:58:03.756+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:58:03.756+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T15:58:03.767+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-08-10T15:58:34.211+0000] {processor.py:157} INFO - Started process (PID=29411) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:58:34.211+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T15:58:34.215+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:58:34.214+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:58:34.230+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:58:34.244+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:58:34.244+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T15:58:34.255+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:58:34.255+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T15:58:34.264+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-10T15:59:04.592+0000] {processor.py:157} INFO - Started process (PID=29421) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:59:04.593+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T15:59:04.595+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:59:04.595+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:59:04.616+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:59:04.638+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:59:04.638+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T15:59:04.649+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:59:04.649+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T15:59:04.659+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-10T15:59:34.988+0000] {processor.py:157} INFO - Started process (PID=29431) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:59:34.990+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T15:59:34.992+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:59:34.991+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:59:35.006+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T15:59:35.029+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:59:35.029+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T15:59:35.044+0000] {logging_mixin.py:151} INFO - [2024-08-10T15:59:35.044+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T15:59:35.054+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-10T16:00:05.461+0000] {processor.py:157} INFO - Started process (PID=29441) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:00:05.465+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T16:00:05.468+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:00:05.468+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:00:05.485+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:00:05.506+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:00:05.506+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T16:00:05.517+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:00:05.517+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T16:00:05.530+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-10T16:00:35.906+0000] {processor.py:157} INFO - Started process (PID=29451) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:00:35.908+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T16:00:35.910+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:00:35.910+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:00:35.925+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:00:35.969+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:00:35.969+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T16:00:35.986+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:00:35.985+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T16:00:35.997+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-08-10T16:01:06.241+0000] {processor.py:157} INFO - Started process (PID=29461) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:01:06.244+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T16:01:06.247+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:01:06.247+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:01:06.259+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:01:06.276+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:01:06.276+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T16:01:06.286+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:01:06.286+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T16:01:06.296+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-10T16:01:36.699+0000] {processor.py:157} INFO - Started process (PID=29471) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:01:36.702+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T16:01:36.704+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:01:36.704+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:01:36.718+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:01:36.740+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:01:36.739+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T16:01:36.752+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:01:36.752+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T16:01:36.763+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-10T16:02:07.108+0000] {processor.py:157} INFO - Started process (PID=29481) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:02:07.109+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T16:02:07.112+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:02:07.111+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:02:07.125+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:02:07.143+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:02:07.143+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T16:02:07.153+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:02:07.153+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T16:02:07.161+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-10T16:02:37.561+0000] {processor.py:157} INFO - Started process (PID=29491) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:02:37.566+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T16:02:37.577+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:02:37.576+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:02:37.597+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:02:37.621+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:02:37.621+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T16:02:37.634+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:02:37.634+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T16:02:37.642+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-08-10T16:03:07.895+0000] {processor.py:157} INFO - Started process (PID=29501) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:03:07.897+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T16:03:07.900+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:03:07.899+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:03:07.913+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:03:07.931+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:03:07.930+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T16:03:07.941+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:03:07.941+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T16:03:07.951+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-10T16:03:38.202+0000] {processor.py:157} INFO - Started process (PID=29511) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:03:38.205+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T16:03:38.209+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:03:38.208+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:03:38.223+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:03:38.244+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:03:38.244+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T16:03:38.257+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:03:38.257+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T16:03:38.267+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-10T16:04:08.546+0000] {processor.py:157} INFO - Started process (PID=29521) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:04:08.548+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T16:04:08.553+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:04:08.553+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:04:08.569+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:04:08.602+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:04:08.602+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T16:04:08.614+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:04:08.614+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T16:04:08.627+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-08-10T16:04:39.011+0000] {processor.py:157} INFO - Started process (PID=29531) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:04:39.012+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T16:04:39.014+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:04:39.014+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:04:39.025+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:04:39.042+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:04:39.042+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T16:04:39.054+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:04:39.054+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T16:04:39.065+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-10T16:05:09.520+0000] {processor.py:157} INFO - Started process (PID=29541) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:05:09.524+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T16:05:09.532+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:05:09.532+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:05:09.549+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:05:09.583+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:05:09.583+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T16:05:09.596+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:05:09.596+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T16:05:09.607+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-08-10T16:05:39.878+0000] {processor.py:157} INFO - Started process (PID=29551) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:05:39.879+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T16:05:39.881+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:05:39.881+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:05:39.891+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:05:39.912+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:05:39.912+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T16:05:39.924+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:05:39.924+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T16:05:39.933+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-10T16:06:10.251+0000] {processor.py:157} INFO - Started process (PID=29561) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:06:10.252+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T16:06:10.254+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:06:10.254+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:06:10.264+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:06:10.281+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:06:10.281+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T16:06:10.293+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:06:10.293+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T16:06:10.304+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-10T16:06:40.665+0000] {processor.py:157} INFO - Started process (PID=29571) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:06:40.666+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T16:06:40.668+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:06:40.668+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:06:40.677+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:06:40.694+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:06:40.694+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T16:06:40.706+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:06:40.706+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T16:06:40.715+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-10T16:07:11.098+0000] {processor.py:157} INFO - Started process (PID=29581) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:07:11.099+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T16:07:11.100+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:07:11.100+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:07:11.114+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:07:11.127+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:07:11.127+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T16:07:11.138+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:07:11.138+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T16:07:11.147+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-10T16:07:41.435+0000] {processor.py:157} INFO - Started process (PID=29591) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:07:41.436+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T16:07:41.440+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:07:41.440+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:07:41.458+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:07:41.483+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:07:41.483+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T16:07:41.496+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:07:41.495+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T16:07:41.505+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-10T16:08:11.881+0000] {processor.py:157} INFO - Started process (PID=29601) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:08:11.882+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T16:08:11.883+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:08:11.883+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:08:11.894+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:08:11.911+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:08:11.911+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T16:08:11.923+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:08:11.923+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T16:08:11.933+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-10T16:08:42.241+0000] {processor.py:157} INFO - Started process (PID=29611) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:08:42.243+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T16:08:42.245+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:08:42.245+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:08:42.254+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:08:42.270+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:08:42.270+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T16:08:42.280+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:08:42.280+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T16:08:42.288+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-10T16:09:12.708+0000] {processor.py:157} INFO - Started process (PID=29620) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:09:12.710+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T16:09:12.717+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:09:12.716+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:09:12.744+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:09:12.780+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:09:12.780+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T16:09:12.799+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:09:12.799+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T16:09:12.811+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-08-10T16:09:43.036+0000] {processor.py:157} INFO - Started process (PID=29631) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:09:43.038+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T16:09:43.040+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:09:43.040+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:09:43.054+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:09:43.066+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:09:43.066+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T16:09:43.076+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:09:43.076+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T16:09:43.085+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-10T16:10:13.601+0000] {processor.py:157} INFO - Started process (PID=29640) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:10:13.602+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T16:10:13.606+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:10:13.605+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:10:13.626+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:10:13.641+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:10:13.641+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T16:10:13.652+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:10:13.652+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T16:10:13.663+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-10T16:10:44.012+0000] {processor.py:157} INFO - Started process (PID=29651) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:10:44.015+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T16:10:44.017+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:10:44.016+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:10:44.029+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:10:44.044+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:10:44.044+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T16:10:44.054+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:10:44.054+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T16:10:44.064+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-10T16:11:14.366+0000] {processor.py:157} INFO - Started process (PID=29661) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:11:14.367+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T16:11:14.368+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:11:14.368+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:11:14.378+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:11:14.393+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:11:14.393+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T16:11:14.402+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:11:14.402+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T16:11:14.409+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-08-10T16:11:44.714+0000] {processor.py:157} INFO - Started process (PID=29671) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:11:44.716+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T16:11:44.717+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:11:44.717+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:11:44.732+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:11:44.746+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:11:44.746+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T16:11:44.757+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:11:44.757+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T16:11:44.769+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-10T16:12:15.087+0000] {processor.py:157} INFO - Started process (PID=29681) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:12:15.088+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T16:12:15.093+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:12:15.092+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:12:15.108+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:12:15.129+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:12:15.129+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T16:12:15.141+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:12:15.141+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T16:12:15.152+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-10T16:12:45.397+0000] {processor.py:157} INFO - Started process (PID=29691) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:12:45.398+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T16:12:45.405+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:12:45.405+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:12:45.413+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:12:45.427+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:12:45.427+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T16:12:45.437+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:12:45.437+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T16:12:45.446+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-10T16:13:15.650+0000] {processor.py:157} INFO - Started process (PID=29701) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:13:15.651+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T16:13:15.653+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:13:15.653+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:13:15.662+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:13:15.679+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:13:15.679+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T16:13:15.689+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:13:15.689+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T16:13:15.697+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-10T16:13:46.078+0000] {processor.py:157} INFO - Started process (PID=29711) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:13:46.079+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T16:13:46.085+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:13:46.085+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:13:46.094+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:13:46.107+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:13:46.107+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T16:13:46.116+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:13:46.116+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T16:13:46.124+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-08-10T16:14:16.470+0000] {processor.py:157} INFO - Started process (PID=29721) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:14:16.472+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T16:14:16.482+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:14:16.477+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:14:16.508+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:14:16.533+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:14:16.533+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T16:14:16.548+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:14:16.548+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T16:14:16.561+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-08-10T16:14:46.816+0000] {processor.py:157} INFO - Started process (PID=29731) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:14:46.822+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T16:14:46.823+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:14:46.823+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:14:46.831+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:14:46.844+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:14:46.844+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T16:14:46.853+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:14:46.853+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T16:14:46.864+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-10T16:15:17.212+0000] {processor.py:157} INFO - Started process (PID=29740) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:15:17.214+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T16:15:17.218+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:15:17.217+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:15:17.234+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:15:17.252+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:15:17.252+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T16:15:17.266+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:15:17.266+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T16:15:17.275+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-10T16:15:47.615+0000] {processor.py:157} INFO - Started process (PID=29751) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:15:47.616+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T16:15:47.617+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:15:47.617+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:15:47.625+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:15:47.640+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:15:47.640+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T16:15:47.649+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:15:47.649+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T16:15:47.658+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-08-10T16:16:18.056+0000] {processor.py:157} INFO - Started process (PID=29761) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:16:18.057+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T16:16:18.064+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:16:18.064+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:16:18.071+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:16:18.085+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:16:18.085+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T16:16:18.095+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:16:18.095+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T16:16:18.103+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-08-10T16:16:48.461+0000] {processor.py:157} INFO - Started process (PID=29771) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:16:48.462+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T16:16:48.464+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:16:48.464+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:16:48.474+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:16:48.490+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:16:48.490+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T16:16:48.499+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:16:48.499+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T16:16:48.508+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-10T16:17:18.906+0000] {processor.py:157} INFO - Started process (PID=29781) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:17:18.907+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T16:17:18.910+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:17:18.910+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:17:18.926+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:17:18.946+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:17:18.946+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T16:17:18.961+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:17:18.961+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T16:17:18.971+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-10T16:17:49.302+0000] {processor.py:157} INFO - Started process (PID=29791) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:17:49.303+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T16:17:49.305+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:17:49.304+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:17:49.318+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:17:49.335+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:17:49.335+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T16:17:49.365+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:17:49.365+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T16:17:49.380+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-08-10T16:18:19.717+0000] {processor.py:157} INFO - Started process (PID=29801) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:18:19.717+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T16:18:19.719+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:18:19.719+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:18:19.727+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:18:19.744+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:18:19.744+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T16:18:19.758+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:18:19.758+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T16:18:19.767+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-10T16:18:50.188+0000] {processor.py:157} INFO - Started process (PID=29811) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:18:50.189+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T16:18:50.192+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:18:50.192+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:18:50.210+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:18:50.232+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:18:50.232+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T16:18:50.246+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:18:50.246+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T16:18:50.258+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-10T16:19:20.514+0000] {processor.py:157} INFO - Started process (PID=29821) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:19:20.515+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T16:19:20.520+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:19:20.520+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:19:20.530+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:19:20.544+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:19:20.544+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T16:19:20.553+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:19:20.553+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T16:19:20.562+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-10T16:19:50.989+0000] {processor.py:157} INFO - Started process (PID=29831) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:19:50.992+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T16:19:50.995+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:19:50.994+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:19:51.010+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:19:51.030+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:19:51.030+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T16:19:51.042+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:19:51.042+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T16:19:51.053+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-10T16:20:21.323+0000] {processor.py:157} INFO - Started process (PID=29841) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:20:21.325+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T16:20:21.328+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:20:21.327+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:20:21.342+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:20:21.363+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:20:21.362+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T16:20:21.375+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:20:21.375+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T16:20:21.386+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-10T16:20:51.759+0000] {processor.py:157} INFO - Started process (PID=29851) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:20:51.760+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T16:20:51.765+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:20:51.764+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:20:51.780+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:20:51.801+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:20:51.801+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T16:20:51.815+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:20:51.815+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T16:20:51.826+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-10T16:21:22.031+0000] {processor.py:157} INFO - Started process (PID=29861) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:21:22.034+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T16:21:22.035+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:21:22.035+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:21:22.049+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:21:22.061+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:21:22.061+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T16:21:22.071+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:21:22.071+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T16:21:22.080+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-10T16:21:52.431+0000] {processor.py:157} INFO - Started process (PID=29871) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:21:52.432+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T16:21:52.437+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:21:52.437+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:21:52.453+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:21:52.472+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:21:52.471+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T16:21:52.485+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:21:52.485+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T16:21:52.496+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-10T16:22:22.828+0000] {processor.py:157} INFO - Started process (PID=29881) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:22:22.828+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T16:22:22.830+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:22:22.830+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:22:22.846+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:22:22.859+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:22:22.859+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T16:22:22.869+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:22:22.869+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T16:22:22.878+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-10T16:22:53.251+0000] {processor.py:157} INFO - Started process (PID=29891) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:22:53.251+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T16:22:53.254+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:22:53.254+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:22:53.271+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:22:53.284+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:22:53.284+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T16:22:53.296+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:22:53.296+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T16:22:53.307+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-10T16:23:23.635+0000] {processor.py:157} INFO - Started process (PID=29901) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:23:23.639+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T16:23:23.642+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:23:23.642+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:23:23.663+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:23:23.680+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:23:23.680+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T16:23:23.692+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:23:23.692+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T16:23:23.701+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-10T16:23:54.033+0000] {processor.py:157} INFO - Started process (PID=29911) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:23:54.033+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T16:23:54.040+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:23:54.040+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:23:54.047+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:23:54.061+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:23:54.061+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T16:23:54.073+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:23:54.073+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T16:23:54.082+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-10T16:24:24.438+0000] {processor.py:157} INFO - Started process (PID=29921) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:24:24.439+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T16:24:24.445+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:24:24.444+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:24:24.454+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:24:24.467+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:24:24.467+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T16:24:24.478+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:24:24.478+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T16:24:24.485+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-10T16:24:54.810+0000] {processor.py:157} INFO - Started process (PID=29931) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:24:54.811+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T16:24:54.812+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:24:54.812+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:24:54.822+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:24:54.841+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:24:54.840+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T16:24:54.851+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:24:54.851+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T16:24:54.860+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-10T16:25:25.160+0000] {processor.py:157} INFO - Started process (PID=29941) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:25:25.161+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T16:25:25.164+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:25:25.164+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:25:25.180+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:25:25.200+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:25:25.200+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T16:25:25.213+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:25:25.213+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T16:25:25.224+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-10T16:25:55.618+0000] {processor.py:157} INFO - Started process (PID=29951) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:25:55.619+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T16:25:55.622+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:25:55.622+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:25:55.634+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:25:55.667+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:25:55.667+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T16:25:55.685+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:25:55.685+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T16:25:55.698+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-08-10T16:26:26.059+0000] {processor.py:157} INFO - Started process (PID=29961) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:26:26.060+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T16:26:26.064+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:26:26.063+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:26:26.079+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:26:26.099+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:26:26.099+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T16:26:26.112+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:26:26.112+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T16:26:26.122+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-10T16:26:56.425+0000] {processor.py:157} INFO - Started process (PID=29971) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:26:56.425+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T16:26:56.433+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:26:56.432+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:26:56.441+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:26:56.454+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:26:56.454+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T16:26:56.465+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:26:56.465+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T16:26:56.475+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-10T16:27:26.804+0000] {processor.py:157} INFO - Started process (PID=29981) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:27:26.805+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T16:27:26.806+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:27:26.806+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:27:26.820+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:27:26.835+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:27:26.835+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T16:27:26.845+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:27:26.844+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T16:27:26.855+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-10T16:27:57.172+0000] {processor.py:157} INFO - Started process (PID=29991) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:27:57.172+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T16:27:57.175+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:27:57.175+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:27:57.191+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:27:57.212+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:27:57.212+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T16:27:57.224+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:27:57.224+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T16:27:57.235+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-10T16:28:27.496+0000] {processor.py:157} INFO - Started process (PID=30001) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:28:27.498+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T16:28:27.499+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:28:27.499+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:28:27.511+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:28:27.529+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:28:27.529+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T16:28:27.539+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:28:27.539+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T16:28:27.549+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-10T16:28:57.852+0000] {processor.py:157} INFO - Started process (PID=30011) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:28:57.853+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T16:28:57.855+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:28:57.854+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:28:57.865+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:28:57.882+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:28:57.882+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T16:28:57.893+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:28:57.893+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T16:28:57.903+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-10T16:29:28.186+0000] {processor.py:157} INFO - Started process (PID=30021) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:29:28.187+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T16:29:28.189+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:29:28.189+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:29:28.200+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:29:28.216+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:29:28.216+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T16:29:28.228+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:29:28.228+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T16:29:28.238+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-10T16:29:58.625+0000] {processor.py:157} INFO - Started process (PID=30031) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:29:58.626+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T16:29:58.630+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:29:58.630+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:29:58.645+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:29:58.665+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:29:58.665+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T16:29:58.677+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:29:58.677+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T16:29:58.688+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-10T16:30:28.968+0000] {processor.py:157} INFO - Started process (PID=30041) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:30:28.969+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T16:30:28.974+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:30:28.974+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:30:28.985+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:30:28.998+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:30:28.998+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T16:30:29.009+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:30:29.009+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T16:30:29.018+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-10T16:30:59.360+0000] {processor.py:157} INFO - Started process (PID=30051) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:30:59.361+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T16:30:59.365+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:30:59.365+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:30:59.378+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:30:59.400+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:30:59.399+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T16:30:59.413+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:30:59.413+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T16:30:59.424+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-10T16:31:29.781+0000] {processor.py:157} INFO - Started process (PID=30061) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:31:29.785+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T16:31:29.788+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:31:29.788+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:31:29.796+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:31:29.810+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:31:29.810+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T16:31:29.821+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:31:29.820+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T16:31:29.830+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-10T16:32:00.159+0000] {processor.py:157} INFO - Started process (PID=30071) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:32:00.159+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T16:32:00.167+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:32:00.166+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:32:00.176+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:32:00.189+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:32:00.189+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T16:32:00.199+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:32:00.199+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T16:32:00.209+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-10T16:32:30.593+0000] {processor.py:157} INFO - Started process (PID=30081) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:32:30.593+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T16:32:30.597+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:32:30.596+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:32:30.612+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:32:30.629+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:32:30.629+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T16:32:30.643+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:32:30.643+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T16:32:30.652+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-10T16:33:00.974+0000] {processor.py:157} INFO - Started process (PID=30091) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:33:00.975+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T16:33:00.977+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:33:00.976+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:33:00.984+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:33:01.001+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:33:01.001+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T16:33:01.012+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:33:01.012+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T16:33:01.021+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-10T16:33:31.356+0000] {processor.py:157} INFO - Started process (PID=30101) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:33:31.357+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T16:33:31.360+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:33:31.359+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:33:31.367+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:33:31.383+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:33:31.383+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T16:33:31.393+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:33:31.393+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T16:33:31.402+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-10T16:34:01.770+0000] {processor.py:157} INFO - Started process (PID=30111) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:34:01.772+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T16:34:01.773+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:34:01.773+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:34:01.788+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:34:01.802+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:34:01.802+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T16:34:01.812+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:34:01.812+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T16:34:01.822+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-10T16:34:32.220+0000] {processor.py:157} INFO - Started process (PID=30119) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:34:32.221+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T16:34:32.224+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:34:32.224+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:34:32.240+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:34:32.277+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:34:32.277+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T16:34:32.290+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:34:32.290+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T16:34:32.300+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-08-10T16:35:02.528+0000] {processor.py:157} INFO - Started process (PID=30131) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:35:02.529+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T16:35:02.531+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:35:02.531+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:35:02.544+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:35:02.561+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:35:02.560+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T16:35:02.572+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:35:02.572+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T16:35:02.583+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-10T16:35:32.863+0000] {processor.py:157} INFO - Started process (PID=30141) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:35:32.864+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T16:35:32.868+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:35:32.868+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:35:32.878+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:35:32.891+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:35:32.891+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T16:35:32.900+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:35:32.900+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T16:35:32.909+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-10T16:36:03.233+0000] {processor.py:157} INFO - Started process (PID=30150) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:36:03.234+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T16:36:03.237+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:36:03.237+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:36:03.252+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:36:03.272+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:36:03.272+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T16:36:03.287+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:36:03.287+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T16:36:03.296+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-10T16:36:33.659+0000] {processor.py:157} INFO - Started process (PID=30161) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:36:33.660+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T16:36:33.662+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:36:33.661+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:36:33.671+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:36:33.688+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:36:33.688+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T16:36:33.699+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:36:33.699+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T16:36:33.709+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-10T16:37:04.124+0000] {processor.py:157} INFO - Started process (PID=30171) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:37:04.125+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T16:37:04.128+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:37:04.128+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:37:04.143+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:37:04.163+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:37:04.163+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T16:37:04.176+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:37:04.176+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T16:37:04.188+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-10T16:37:34.552+0000] {processor.py:157} INFO - Started process (PID=30181) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:37:34.552+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T16:37:34.554+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:37:34.554+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:37:34.569+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:37:34.582+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:37:34.582+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T16:37:34.592+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:37:34.591+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T16:37:34.599+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-10T16:38:04.893+0000] {processor.py:157} INFO - Started process (PID=30191) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:38:04.894+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T16:38:04.895+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:38:04.895+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:38:04.910+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:38:04.923+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:38:04.923+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T16:38:04.933+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:38:04.933+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T16:38:04.943+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-10T16:38:35.369+0000] {processor.py:157} INFO - Started process (PID=30201) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:38:35.370+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T16:38:35.371+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:38:35.371+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:38:35.379+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:38:35.396+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:38:35.396+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T16:38:35.409+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:38:35.409+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T16:38:35.418+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-10T16:39:05.809+0000] {processor.py:157} INFO - Started process (PID=30210) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:39:05.811+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T16:39:05.816+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:39:05.815+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:39:05.834+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:39:05.854+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:39:05.854+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T16:39:05.871+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:39:05.871+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T16:39:05.882+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-08-10T16:39:36.133+0000] {processor.py:157} INFO - Started process (PID=30221) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:39:36.134+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T16:39:36.136+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:39:36.136+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:39:36.146+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:39:36.169+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:39:36.169+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T16:39:36.179+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:39:36.179+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T16:39:36.190+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-10T16:40:06.562+0000] {processor.py:157} INFO - Started process (PID=30231) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:40:06.563+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T16:40:06.570+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:40:06.570+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:40:06.579+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:40:06.592+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:40:06.592+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T16:40:06.602+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:40:06.602+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T16:40:06.612+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-10T16:40:36.905+0000] {processor.py:157} INFO - Started process (PID=30240) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:40:36.905+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T16:40:36.910+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:40:36.910+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:40:36.932+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:40:36.952+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:40:36.952+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T16:40:36.966+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:40:36.965+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T16:40:36.976+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-08-10T16:41:07.225+0000] {processor.py:157} INFO - Started process (PID=30251) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:41:07.227+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T16:41:07.229+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:41:07.229+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:41:07.241+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:41:07.259+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:41:07.259+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T16:41:07.270+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:41:07.270+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T16:41:07.278+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-10T16:41:37.624+0000] {processor.py:157} INFO - Started process (PID=30261) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:41:37.625+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T16:41:37.627+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:41:37.627+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:41:37.641+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:41:37.657+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:41:37.657+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T16:41:37.668+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:41:37.668+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T16:41:37.676+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-10T16:42:07.989+0000] {processor.py:157} INFO - Started process (PID=30271) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:42:07.990+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T16:42:07.994+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:42:07.993+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:42:08.008+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:42:08.027+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:42:08.027+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T16:42:08.039+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:42:08.039+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T16:42:08.050+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-10T16:42:38.372+0000] {processor.py:157} INFO - Started process (PID=30281) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:42:38.373+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T16:42:38.374+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:42:38.374+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:42:38.390+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:42:38.404+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:42:38.404+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T16:42:38.415+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:42:38.415+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T16:42:38.422+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-10T16:43:08.759+0000] {processor.py:157} INFO - Started process (PID=30291) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:43:08.761+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T16:43:08.768+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:43:08.768+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:43:08.778+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:43:08.799+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:43:08.799+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T16:43:08.811+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:43:08.811+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T16:43:08.821+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-10T16:43:39.167+0000] {processor.py:157} INFO - Started process (PID=30301) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:43:39.168+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T16:43:39.169+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:43:39.169+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:43:39.175+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:43:39.196+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:43:39.196+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T16:43:39.209+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:43:39.209+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T16:43:39.220+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-10T16:44:09.940+0000] {processor.py:157} INFO - Started process (PID=30310) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:44:09.942+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T16:44:09.947+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:44:09.946+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:44:09.969+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:44:10.004+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:44:10.004+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T16:44:10.020+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:44:10.020+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T16:44:10.030+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-08-10T16:44:40.242+0000] {processor.py:157} INFO - Started process (PID=30321) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:44:40.243+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T16:44:40.245+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:44:40.245+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:44:40.258+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T16:44:40.272+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:44:40.272+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T16:44:40.285+0000] {logging_mixin.py:151} INFO - [2024-08-10T16:44:40.285+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T16:44:40.293+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-10T17:01:01.672+0000] {processor.py:157} INFO - Started process (PID=30332) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T17:01:01.675+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T17:01:01.681+0000] {logging_mixin.py:151} INFO - [2024-08-10T17:01:01.680+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T17:01:01.706+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T17:01:01.730+0000] {logging_mixin.py:151} INFO - [2024-08-10T17:01:01.729+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T17:01:01.744+0000] {logging_mixin.py:151} INFO - [2024-08-10T17:01:01.744+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T17:01:01.756+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-08-10T17:01:31.940+0000] {processor.py:157} INFO - Started process (PID=30343) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T17:01:31.942+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T17:01:31.946+0000] {logging_mixin.py:151} INFO - [2024-08-10T17:01:31.945+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T17:01:31.966+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T17:01:31.992+0000] {logging_mixin.py:151} INFO - [2024-08-10T17:01:31.991+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T17:01:32.008+0000] {logging_mixin.py:151} INFO - [2024-08-10T17:01:32.008+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T17:01:32.017+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-08-10T17:11:22.279+0000] {processor.py:157} INFO - Started process (PID=30353) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T17:11:22.283+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T17:11:22.295+0000] {logging_mixin.py:151} INFO - [2024-08-10T17:11:22.293+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T17:11:22.312+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T17:11:22.348+0000] {logging_mixin.py:151} INFO - [2024-08-10T17:11:22.348+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T17:11:22.379+0000] {logging_mixin.py:151} INFO - [2024-08-10T17:11:22.378+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T17:11:22.394+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-08-10T17:11:52.565+0000] {processor.py:157} INFO - Started process (PID=30363) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T17:11:52.567+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T17:11:52.570+0000] {logging_mixin.py:151} INFO - [2024-08-10T17:11:52.570+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T17:11:52.589+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T17:11:52.609+0000] {logging_mixin.py:151} INFO - [2024-08-10T17:11:52.609+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T17:11:52.624+0000] {logging_mixin.py:151} INFO - [2024-08-10T17:11:52.624+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T17:11:52.633+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-10T17:12:22.956+0000] {processor.py:157} INFO - Started process (PID=30373) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T17:12:22.957+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T17:12:22.958+0000] {logging_mixin.py:151} INFO - [2024-08-10T17:12:22.958+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T17:12:22.973+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T17:12:22.992+0000] {logging_mixin.py:151} INFO - [2024-08-10T17:12:22.992+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T17:12:23.004+0000] {logging_mixin.py:151} INFO - [2024-08-10T17:12:23.004+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T17:12:23.015+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-10T17:12:53.278+0000] {processor.py:157} INFO - Started process (PID=30383) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T17:12:53.280+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T17:12:53.281+0000] {logging_mixin.py:151} INFO - [2024-08-10T17:12:53.281+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T17:12:53.291+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T17:12:53.309+0000] {logging_mixin.py:151} INFO - [2024-08-10T17:12:53.309+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T17:12:53.321+0000] {logging_mixin.py:151} INFO - [2024-08-10T17:12:53.321+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T17:12:53.330+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-10T17:13:23.624+0000] {processor.py:157} INFO - Started process (PID=30393) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T17:13:23.625+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T17:13:23.627+0000] {logging_mixin.py:151} INFO - [2024-08-10T17:13:23.626+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T17:13:23.636+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T17:13:23.652+0000] {logging_mixin.py:151} INFO - [2024-08-10T17:13:23.652+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T17:13:23.663+0000] {logging_mixin.py:151} INFO - [2024-08-10T17:13:23.663+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T17:13:23.677+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-10T17:30:12.483+0000] {processor.py:157} INFO - Started process (PID=30405) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T17:30:12.484+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T17:30:12.487+0000] {logging_mixin.py:151} INFO - [2024-08-10T17:30:12.487+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T17:30:12.497+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T17:30:12.514+0000] {logging_mixin.py:151} INFO - [2024-08-10T17:30:12.514+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T17:30:12.526+0000] {logging_mixin.py:151} INFO - [2024-08-10T17:30:12.525+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T17:30:12.534+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-10T17:30:42.866+0000] {processor.py:157} INFO - Started process (PID=30415) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T17:30:42.870+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T17:30:42.874+0000] {logging_mixin.py:151} INFO - [2024-08-10T17:30:42.874+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T17:30:42.889+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T17:30:42.913+0000] {logging_mixin.py:151} INFO - [2024-08-10T17:30:42.913+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T17:30:42.926+0000] {logging_mixin.py:151} INFO - [2024-08-10T17:30:42.926+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T17:30:42.936+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-10T17:48:15.855+0000] {processor.py:157} INFO - Started process (PID=30427) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T17:48:15.856+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T17:48:15.859+0000] {logging_mixin.py:151} INFO - [2024-08-10T17:48:15.859+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T17:48:15.890+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T17:48:15.958+0000] {logging_mixin.py:151} INFO - [2024-08-10T17:48:15.958+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T17:48:15.987+0000] {logging_mixin.py:151} INFO - [2024-08-10T17:48:15.987+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T17:48:16.008+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.156 seconds
[2024-08-10T18:05:19.134+0000] {processor.py:157} INFO - Started process (PID=30437) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:05:19.137+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:05:19.142+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:05:19.141+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:05:19.168+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:05:19.220+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:05:19.220+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:05:19.251+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:05:19.251+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:05:19.271+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.144 seconds
[2024-08-10T18:05:49.505+0000] {processor.py:157} INFO - Started process (PID=30447) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:05:49.506+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:05:49.510+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:05:49.509+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:05:49.532+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:05:49.561+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:05:49.560+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:05:49.575+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:05:49.575+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:05:49.586+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-08-10T18:06:19.876+0000] {processor.py:157} INFO - Started process (PID=30457) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:06:19.880+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:06:19.883+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:06:19.882+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:06:19.905+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:06:19.942+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:06:19.942+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:06:19.956+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:06:19.956+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:06:19.966+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-08-10T18:06:50.206+0000] {processor.py:157} INFO - Started process (PID=30467) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:06:50.208+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:06:50.209+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:06:50.209+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:06:50.220+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:06:50.236+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:06:50.236+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:06:50.245+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:06:50.245+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:06:50.256+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-10T18:07:20.553+0000] {processor.py:157} INFO - Started process (PID=30476) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:07:20.554+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:07:20.559+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:07:20.558+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:07:20.602+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:07:20.627+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:07:20.627+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:07:20.641+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:07:20.641+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:07:20.651+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-08-10T18:07:50.870+0000] {processor.py:157} INFO - Started process (PID=30487) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:07:50.871+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:07:50.873+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:07:50.873+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:07:50.883+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:07:50.901+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:07:50.901+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:07:50.913+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:07:50.913+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:07:50.924+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-10T18:08:21.255+0000] {processor.py:157} INFO - Started process (PID=30497) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:08:21.257+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:08:21.260+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:08:21.260+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:08:21.282+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:08:21.298+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:08:21.298+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:08:21.314+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:08:21.313+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:08:21.325+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-10T18:08:51.669+0000] {processor.py:157} INFO - Started process (PID=30507) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:08:51.671+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:08:51.673+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:08:51.672+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:08:51.696+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:08:51.717+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:08:51.717+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:08:51.731+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:08:51.731+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:08:51.742+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-08-10T18:09:21.981+0000] {processor.py:157} INFO - Started process (PID=30517) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:09:21.981+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:09:21.983+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:09:21.983+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:09:21.993+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:09:22.009+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:09:22.009+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:09:22.021+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:09:22.021+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:09:22.030+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-10T18:09:52.368+0000] {processor.py:157} INFO - Started process (PID=30527) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:09:52.369+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:09:52.370+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:09:52.370+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:09:52.380+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:09:52.396+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:09:52.396+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:09:52.406+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:09:52.406+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:09:52.414+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-10T18:10:22.821+0000] {processor.py:157} INFO - Started process (PID=30535) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:10:22.823+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:10:22.828+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:10:22.827+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:10:22.874+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:10:22.897+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:10:22.896+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:10:22.909+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:10:22.908+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:10:22.919+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-08-10T18:10:53.092+0000] {processor.py:157} INFO - Started process (PID=30547) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:10:53.093+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:10:53.095+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:10:53.094+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:10:53.105+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:10:53.121+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:10:53.121+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:10:53.131+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:10:53.131+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:10:53.140+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-10T18:11:23.484+0000] {processor.py:157} INFO - Started process (PID=30557) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:11:23.485+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:11:23.486+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:11:23.486+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:11:23.497+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:11:23.511+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:11:23.511+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:11:23.521+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:11:23.521+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:11:23.530+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-08-10T18:11:53.886+0000] {processor.py:157} INFO - Started process (PID=30567) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:11:53.891+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:11:53.895+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:11:53.895+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:11:53.932+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:11:53.956+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:11:53.956+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:11:53.970+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:11:53.970+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:11:53.980+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-08-10T18:12:24.158+0000] {processor.py:157} INFO - Started process (PID=30577) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:12:24.160+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:12:24.163+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:12:24.162+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:12:24.173+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:12:24.196+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:12:24.196+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:12:24.207+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:12:24.207+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:12:24.216+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-10T18:12:54.476+0000] {processor.py:157} INFO - Started process (PID=30587) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:12:54.477+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:12:54.479+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:12:54.479+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:12:54.490+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:12:54.505+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:12:54.505+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:12:54.515+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:12:54.515+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:12:54.523+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-10T18:13:24.902+0000] {processor.py:157} INFO - Started process (PID=30597) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:13:24.904+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:13:24.909+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:13:24.909+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:13:24.926+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:13:24.947+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:13:24.947+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:13:24.960+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:13:24.960+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:13:24.969+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-10T18:13:55.179+0000] {processor.py:157} INFO - Started process (PID=30607) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:13:55.179+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:13:55.181+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:13:55.181+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:13:55.190+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:13:55.205+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:13:55.205+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:13:55.214+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:13:55.214+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:13:55.223+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-08-10T18:14:25.546+0000] {processor.py:157} INFO - Started process (PID=30617) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:14:25.548+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:14:25.550+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:14:25.550+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:14:25.561+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:14:25.575+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:14:25.575+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:14:25.585+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:14:25.585+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:14:25.594+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-10T18:14:55.969+0000] {processor.py:157} INFO - Started process (PID=30627) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:14:55.972+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:14:55.986+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:14:55.985+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:14:56.004+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:14:56.032+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:14:56.032+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:14:56.047+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:14:56.047+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:14:56.056+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-08-10T18:15:26.371+0000] {processor.py:157} INFO - Started process (PID=30637) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:15:26.372+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:15:26.373+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:15:26.373+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:15:26.386+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:15:26.402+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:15:26.402+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:15:26.412+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:15:26.412+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:15:26.421+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-10T18:15:56.755+0000] {processor.py:157} INFO - Started process (PID=30647) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:15:56.756+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:15:56.759+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:15:56.759+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:15:56.775+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:15:56.797+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:15:56.797+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:15:56.809+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:15:56.809+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:15:56.820+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-10T18:16:27.056+0000] {processor.py:157} INFO - Started process (PID=30657) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:16:27.056+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:16:27.058+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:16:27.058+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:16:27.073+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:16:27.088+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:16:27.087+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:16:27.100+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:16:27.100+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:16:27.109+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-10T18:16:57.449+0000] {processor.py:157} INFO - Started process (PID=30667) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:16:57.449+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:16:57.451+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:16:57.451+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:16:57.464+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:16:57.477+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:16:57.477+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:16:57.488+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:16:57.488+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:16:57.498+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-10T18:17:27.817+0000] {processor.py:157} INFO - Started process (PID=30677) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:17:27.818+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:17:27.819+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:17:27.819+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:17:27.828+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:17:27.843+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:17:27.843+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:17:27.853+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:17:27.853+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:17:27.863+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-08-10T18:17:58.137+0000] {processor.py:157} INFO - Started process (PID=30687) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:17:58.141+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:17:58.144+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:17:58.144+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:17:58.162+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:17:58.182+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:17:58.182+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:17:58.194+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:17:58.194+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:17:58.203+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-10T18:18:28.488+0000] {processor.py:157} INFO - Started process (PID=30697) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:18:28.488+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:18:28.490+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:18:28.490+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:18:28.501+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:18:28.517+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:18:28.517+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:18:28.526+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:18:28.526+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:18:28.534+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-08-10T18:18:58.898+0000] {processor.py:157} INFO - Started process (PID=30707) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:18:58.902+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:18:58.908+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:18:58.907+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:18:58.945+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:18:58.969+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:18:58.969+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:18:58.982+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:18:58.982+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:18:58.992+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-08-10T18:19:29.313+0000] {processor.py:157} INFO - Started process (PID=30717) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:19:29.314+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:19:29.315+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:19:29.315+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:19:29.330+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:19:29.348+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:19:29.348+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:19:29.361+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:19:29.361+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:19:29.370+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-10T18:19:59.703+0000] {processor.py:157} INFO - Started process (PID=30727) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:19:59.707+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:19:59.710+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:19:59.710+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:19:59.726+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:19:59.750+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:19:59.749+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:19:59.766+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:19:59.766+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:19:59.775+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-08-10T18:20:30.040+0000] {processor.py:157} INFO - Started process (PID=30737) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:20:30.046+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:20:30.050+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:20:30.050+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:20:30.070+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:20:30.086+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:20:30.086+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:20:30.096+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:20:30.096+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:20:30.104+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-10T18:21:00.442+0000] {processor.py:157} INFO - Started process (PID=30747) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:21:00.445+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:21:00.447+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:21:00.447+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:21:00.460+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:21:00.476+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:21:00.476+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:21:00.486+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:21:00.486+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:21:00.494+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-10T18:21:30.764+0000] {processor.py:157} INFO - Started process (PID=30757) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:21:30.766+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:21:30.768+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:21:30.768+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:21:30.783+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:21:30.805+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:21:30.805+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:21:30.818+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:21:30.818+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:21:30.826+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-10T18:22:01.058+0000] {processor.py:157} INFO - Started process (PID=30767) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:22:01.059+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:22:01.061+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:22:01.061+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:22:01.071+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:22:01.088+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:22:01.088+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:22:01.099+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:22:01.099+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:22:01.108+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-10T18:22:31.417+0000] {processor.py:157} INFO - Started process (PID=30777) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:22:31.418+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:22:31.420+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:22:31.420+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:22:31.429+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:22:31.446+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:22:31.446+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:22:31.459+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:22:31.459+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:22:31.469+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-10T18:23:01.767+0000] {processor.py:157} INFO - Started process (PID=30786) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:23:01.771+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:23:01.774+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:23:01.774+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:23:01.789+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:23:01.810+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:23:01.810+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:23:01.823+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:23:01.823+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:23:01.832+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-10T18:23:32.123+0000] {processor.py:157} INFO - Started process (PID=30797) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:23:32.124+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:23:32.125+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:23:32.125+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:23:32.138+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:23:32.154+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:23:32.154+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:23:32.168+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:23:32.168+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:23:32.179+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-10T18:24:02.494+0000] {processor.py:157} INFO - Started process (PID=30807) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:24:02.495+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:24:02.497+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:24:02.497+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:24:02.507+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:24:02.525+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:24:02.524+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:24:02.535+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:24:02.535+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:24:02.544+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-10T18:24:32.879+0000] {processor.py:157} INFO - Started process (PID=30817) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:24:32.880+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:24:32.882+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:24:32.882+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:24:32.891+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:24:32.908+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:24:32.908+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:24:32.918+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:24:32.918+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:24:32.928+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-10T18:25:03.261+0000] {processor.py:157} INFO - Started process (PID=30827) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:25:03.264+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:25:03.273+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:25:03.273+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:25:03.296+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:25:03.320+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:25:03.320+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:25:03.333+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:25:03.333+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:25:03.344+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-10T18:25:33.702+0000] {processor.py:157} INFO - Started process (PID=30837) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:25:33.703+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:25:33.705+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:25:33.705+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:25:33.715+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:25:33.733+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:25:33.733+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:25:33.745+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:25:33.744+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:25:33.753+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-10T18:26:04.005+0000] {processor.py:157} INFO - Started process (PID=30847) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:26:04.009+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:26:04.011+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:26:04.011+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:26:04.027+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:26:04.047+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:26:04.047+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:26:04.060+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:26:04.060+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:26:04.070+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-10T18:26:34.418+0000] {processor.py:157} INFO - Started process (PID=30857) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:26:34.419+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:26:34.421+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:26:34.420+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:26:34.433+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:26:34.448+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:26:34.448+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:26:34.459+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:26:34.459+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:26:34.470+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-10T18:27:04.803+0000] {processor.py:157} INFO - Started process (PID=30867) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:27:04.804+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:27:04.806+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:27:04.805+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:27:04.820+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:27:04.837+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:27:04.837+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:27:04.848+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:27:04.848+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:27:04.854+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-10T18:27:35.162+0000] {processor.py:157} INFO - Started process (PID=30877) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:27:35.164+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:27:35.166+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:27:35.166+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:27:35.175+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:27:35.193+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:27:35.193+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:27:35.204+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:27:35.204+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:27:35.212+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-10T18:28:05.482+0000] {processor.py:157} INFO - Started process (PID=30887) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:28:05.486+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:28:05.490+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:28:05.489+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:28:05.507+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:28:05.528+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:28:05.528+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:28:05.544+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:28:05.544+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:28:05.555+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-08-10T18:28:35.734+0000] {processor.py:157} INFO - Started process (PID=30897) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:28:35.737+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:28:35.739+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:28:35.738+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:28:35.747+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:28:35.763+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:28:35.763+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:28:35.773+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:28:35.773+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:28:35.783+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-10T18:29:06.026+0000] {processor.py:157} INFO - Started process (PID=30907) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:29:06.027+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:29:06.029+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:29:06.029+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:29:06.038+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:29:06.053+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:29:06.053+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:29:06.063+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:29:06.063+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:29:06.074+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-10T18:29:36.429+0000] {processor.py:157} INFO - Started process (PID=30917) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:29:36.430+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:29:36.432+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:29:36.432+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:29:36.444+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:29:36.462+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:29:36.462+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:29:36.474+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:29:36.474+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:29:36.483+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-10T18:30:06.860+0000] {processor.py:157} INFO - Started process (PID=30927) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:30:06.864+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:30:06.869+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:30:06.868+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:30:06.885+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:30:06.935+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:30:06.935+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:30:06.949+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:30:06.949+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:30:06.958+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-08-10T18:30:37.185+0000] {processor.py:157} INFO - Started process (PID=30937) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:30:37.186+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:30:37.188+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:30:37.187+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:30:37.197+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:30:37.213+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:30:37.212+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:30:37.223+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:30:37.223+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:30:37.232+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-10T18:31:07.592+0000] {processor.py:157} INFO - Started process (PID=30947) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:31:07.594+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:31:07.598+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:31:07.597+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:31:07.615+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:31:07.635+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:31:07.635+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:31:07.649+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:31:07.648+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:31:07.657+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-10T18:31:37.911+0000] {processor.py:157} INFO - Started process (PID=30957) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:31:37.913+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:31:37.915+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:31:37.915+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:31:37.925+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:31:37.942+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:31:37.942+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:31:37.953+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:31:37.953+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:31:37.963+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-10T18:32:08.269+0000] {processor.py:157} INFO - Started process (PID=30967) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:32:08.270+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:32:08.272+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:32:08.272+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:32:08.282+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:32:08.299+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:32:08.299+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:32:08.311+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:32:08.310+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:32:08.318+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-10T18:32:38.577+0000] {processor.py:157} INFO - Started process (PID=30976) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:32:38.579+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:32:38.580+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:32:38.580+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:32:38.589+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:32:38.604+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:32:38.604+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:32:38.614+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:32:38.614+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:32:38.623+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-10T18:33:08.950+0000] {processor.py:157} INFO - Started process (PID=30987) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:33:08.952+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:33:08.956+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:33:08.955+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:33:08.979+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:33:09.008+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:33:09.008+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:33:09.022+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:33:09.022+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:33:09.031+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-08-10T18:33:39.246+0000] {processor.py:157} INFO - Started process (PID=30997) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:33:39.249+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:33:39.251+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:33:39.251+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:33:39.263+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:33:39.279+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:33:39.279+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:33:39.291+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:33:39.291+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:33:39.301+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-10T18:34:09.542+0000] {processor.py:157} INFO - Started process (PID=31007) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:34:09.545+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:34:09.546+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:34:09.546+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:34:09.556+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:34:09.572+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:34:09.571+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:34:09.581+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:34:09.581+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:34:09.592+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-10T18:34:39.887+0000] {processor.py:157} INFO - Started process (PID=31017) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:34:39.889+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:34:39.894+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:34:39.894+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:34:39.925+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:34:39.954+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:34:39.954+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:34:39.969+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:34:39.969+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:34:39.981+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-08-10T18:35:10.182+0000] {processor.py:157} INFO - Started process (PID=31027) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:35:10.183+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:35:10.185+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:35:10.185+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:35:10.197+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:35:10.214+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:35:10.213+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:35:10.225+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:35:10.225+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:35:10.234+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-10T18:35:40.582+0000] {processor.py:157} INFO - Started process (PID=31037) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:35:40.585+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:35:40.594+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:35:40.593+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:35:40.629+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:35:40.651+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:35:40.651+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:35:40.664+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:35:40.664+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:35:40.673+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-08-10T18:36:11.020+0000] {processor.py:157} INFO - Started process (PID=31047) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:36:11.023+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:36:11.026+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:36:11.026+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:36:11.043+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:36:11.072+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:36:11.072+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:36:11.086+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:36:11.086+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:36:11.096+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-08-10T18:36:41.336+0000] {processor.py:157} INFO - Started process (PID=31056) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:36:41.338+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:36:41.341+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:36:41.341+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:36:41.356+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:36:41.377+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:36:41.377+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:36:41.390+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:36:41.389+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:36:41.398+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-10T18:37:11.738+0000] {processor.py:157} INFO - Started process (PID=31067) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:37:11.739+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:37:11.743+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:37:11.742+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:37:11.755+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:37:11.771+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:37:11.770+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:37:11.782+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:37:11.782+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:37:11.791+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-10T18:37:42.137+0000] {processor.py:157} INFO - Started process (PID=31077) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:37:42.139+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:37:42.142+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:37:42.141+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:37:42.153+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:37:42.172+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:37:42.172+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:37:42.184+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:37:42.184+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:37:42.194+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-10T18:38:12.464+0000] {processor.py:157} INFO - Started process (PID=31087) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:38:12.465+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:38:12.469+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:38:12.468+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:38:12.485+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:38:12.504+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:38:12.504+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:38:12.517+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:38:12.517+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:38:12.526+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-10T18:38:42.781+0000] {processor.py:157} INFO - Started process (PID=31097) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:38:42.785+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:38:42.787+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:38:42.787+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:38:42.796+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:38:42.811+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:38:42.810+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:38:42.822+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:38:42.822+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:38:42.832+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-10T18:39:13.142+0000] {processor.py:157} INFO - Started process (PID=31107) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:39:13.143+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:39:13.145+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:39:13.145+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:39:13.154+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:39:13.170+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:39:13.170+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:39:13.180+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:39:13.179+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:39:13.189+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-10T18:39:43.453+0000] {processor.py:157} INFO - Started process (PID=31117) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:39:43.456+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:39:43.458+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:39:43.458+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:39:43.471+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:39:43.491+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:39:43.491+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:39:43.503+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:39:43.503+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:39:43.512+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-10T18:40:13.723+0000] {processor.py:157} INFO - Started process (PID=31127) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:40:13.724+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:40:13.728+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:40:13.728+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:40:13.742+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:40:13.761+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:40:13.761+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:40:13.773+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:40:13.773+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:40:13.784+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-10T18:40:44.111+0000] {processor.py:157} INFO - Started process (PID=31137) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:40:44.111+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:40:44.113+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:40:44.112+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:40:44.126+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:40:44.140+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:40:44.140+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:40:44.151+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:40:44.151+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:40:44.162+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-10T18:41:14.504+0000] {processor.py:157} INFO - Started process (PID=31147) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:41:14.505+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:41:14.508+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:41:14.507+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:41:14.525+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:41:14.543+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:41:14.543+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:41:14.557+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:41:14.557+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:41:14.566+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-10T18:41:44.807+0000] {processor.py:157} INFO - Started process (PID=31157) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:41:44.808+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:41:44.811+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:41:44.811+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:41:44.830+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:41:44.845+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:41:44.845+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:41:44.856+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:41:44.856+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:41:44.866+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-10T18:42:15.200+0000] {processor.py:157} INFO - Started process (PID=31167) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:42:15.204+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:42:15.207+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:42:15.206+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:42:15.218+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:42:15.239+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:42:15.239+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:42:15.250+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:42:15.250+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:42:15.259+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-10T18:42:45.631+0000] {processor.py:157} INFO - Started process (PID=31177) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:42:45.633+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:42:45.635+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:42:45.635+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:42:45.648+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:42:45.664+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:42:45.664+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:42:45.674+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:42:45.674+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:42:45.683+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-10T18:43:16.009+0000] {processor.py:157} INFO - Started process (PID=31187) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:43:16.010+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:43:16.012+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:43:16.012+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:43:16.025+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:43:16.046+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:43:16.045+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:43:16.058+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:43:16.058+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:43:16.066+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-10T18:43:46.398+0000] {processor.py:157} INFO - Started process (PID=31197) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:43:46.401+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:43:46.403+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:43:46.403+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:43:46.416+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:43:46.432+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:43:46.432+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:43:46.442+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:43:46.442+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:43:46.450+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-10T18:44:16.755+0000] {processor.py:157} INFO - Started process (PID=31207) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:44:16.756+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:44:16.758+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:44:16.758+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:44:16.769+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:44:16.787+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:44:16.787+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:44:16.800+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:44:16.800+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:44:16.812+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-10T18:44:47.105+0000] {processor.py:157} INFO - Started process (PID=31217) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:44:47.106+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:44:47.108+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:44:47.108+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:44:47.124+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:44:47.139+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:44:47.139+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:44:47.152+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:44:47.152+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:44:47.160+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-10T18:45:17.485+0000] {processor.py:157} INFO - Started process (PID=31227) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:45:17.486+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:45:17.489+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:45:17.489+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:45:17.502+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:45:17.525+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:45:17.525+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:45:17.538+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:45:17.538+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:45:17.547+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-10T18:45:47.781+0000] {processor.py:157} INFO - Started process (PID=31237) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:45:47.782+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:45:47.785+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:45:47.785+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:45:47.799+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:45:47.811+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:45:47.811+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:45:47.822+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:45:47.822+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:45:47.831+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-10T18:46:18.155+0000] {processor.py:157} INFO - Started process (PID=31247) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:46:18.157+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:46:18.159+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:46:18.159+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:46:18.172+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:46:18.187+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:46:18.187+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:46:18.200+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:46:18.200+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:46:18.209+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-10T18:46:48.549+0000] {processor.py:157} INFO - Started process (PID=31257) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:46:48.551+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:46:48.553+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:46:48.553+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:46:48.565+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:46:48.583+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:46:48.583+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:46:48.594+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:46:48.594+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:46:48.603+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-10T18:47:18.949+0000] {processor.py:157} INFO - Started process (PID=31267) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:47:18.949+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:47:18.952+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:47:18.952+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:47:18.963+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:47:18.984+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:47:18.983+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:47:18.996+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:47:18.996+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:47:19.006+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-10T18:47:49.253+0000] {processor.py:157} INFO - Started process (PID=31277) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:47:49.255+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:47:49.258+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:47:49.258+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:47:49.269+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:47:49.284+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:47:49.284+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:47:49.294+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:47:49.294+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:47:49.301+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-10T18:48:19.651+0000] {processor.py:157} INFO - Started process (PID=31287) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:48:19.652+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:48:19.655+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:48:19.654+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:48:19.671+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:48:19.689+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:48:19.689+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:48:19.700+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:48:19.700+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:48:19.709+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-10T18:48:50.042+0000] {processor.py:157} INFO - Started process (PID=31297) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:48:50.043+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:48:50.045+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:48:50.045+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:48:50.057+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:48:50.078+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:48:50.078+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:48:50.091+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:48:50.091+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:48:50.101+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-10T18:49:20.370+0000] {processor.py:157} INFO - Started process (PID=31307) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:49:20.371+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:49:20.374+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:49:20.373+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:49:20.385+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:49:20.400+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:49:20.400+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:49:20.410+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:49:20.410+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:49:20.419+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-10T18:49:50.752+0000] {processor.py:157} INFO - Started process (PID=31317) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:49:50.753+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:49:50.755+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:49:50.754+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:49:50.768+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:49:50.787+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:49:50.787+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:49:50.799+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:49:50.799+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:49:50.808+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-10T18:50:21.031+0000] {processor.py:157} INFO - Started process (PID=31326) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:50:21.032+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:50:21.043+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:50:21.042+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:50:21.062+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:50:21.085+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:50:21.085+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:50:21.098+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:50:21.098+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:50:21.107+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-08-10T18:50:51.309+0000] {processor.py:157} INFO - Started process (PID=31337) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:50:51.312+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:50:51.313+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:50:51.313+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:50:51.328+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:50:51.341+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:50:51.341+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:50:51.352+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:50:51.352+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:50:51.359+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-10T18:51:21.717+0000] {processor.py:157} INFO - Started process (PID=31347) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:51:21.720+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:51:21.722+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:51:21.722+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:51:21.735+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:51:21.755+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:51:21.755+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:51:21.769+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:51:21.769+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:51:21.778+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-10T18:51:52.075+0000] {processor.py:157} INFO - Started process (PID=31357) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:51:52.077+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:51:52.079+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:51:52.079+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:51:52.092+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:51:52.111+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:51:52.111+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:51:52.126+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:51:52.126+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:51:52.134+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-10T18:52:22.444+0000] {processor.py:157} INFO - Started process (PID=31367) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:52:22.449+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:52:22.451+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:52:22.451+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:52:22.465+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:52:22.493+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:52:22.493+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:52:22.504+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:52:22.504+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:52:22.515+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-08-10T18:52:52.763+0000] {processor.py:157} INFO - Started process (PID=31377) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:52:52.765+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:52:52.767+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:52:52.767+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:52:52.781+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:52:52.798+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:52:52.798+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:52:52.809+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:52:52.809+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:52:52.820+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-10T18:53:23.179+0000] {processor.py:157} INFO - Started process (PID=31387) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:53:23.182+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:53:23.184+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:53:23.184+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:53:23.199+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:53:23.220+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:53:23.220+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:53:23.232+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:53:23.232+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:53:23.243+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-10T18:53:53.514+0000] {processor.py:157} INFO - Started process (PID=31397) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:53:53.515+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:53:53.517+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:53:53.517+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:53:53.533+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:53:53.550+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:53:53.549+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:53:53.561+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:53:53.561+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:53:53.571+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-10T18:54:23.910+0000] {processor.py:157} INFO - Started process (PID=31407) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:54:23.914+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:54:23.917+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:54:23.916+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:54:23.929+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:54:23.948+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:54:23.948+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:54:23.958+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:54:23.958+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:54:23.967+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-10T18:54:54.308+0000] {processor.py:157} INFO - Started process (PID=31417) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:54:54.310+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:54:54.319+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:54:54.318+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:54:54.343+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:54:54.381+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:54:54.381+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:54:54.397+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:54:54.397+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:54:54.407+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-08-10T18:55:24.750+0000] {processor.py:157} INFO - Started process (PID=31427) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:55:24.752+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:55:24.755+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:55:24.755+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:55:24.767+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:55:24.787+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:55:24.787+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:55:24.800+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:55:24.800+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:55:24.811+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-10T18:55:55.078+0000] {processor.py:157} INFO - Started process (PID=31437) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:55:55.080+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:55:55.084+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:55:55.084+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:55:55.099+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:55:55.121+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:55:55.120+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:55:55.135+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:55:55.135+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:55:55.146+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-10T18:56:25.345+0000] {processor.py:157} INFO - Started process (PID=31447) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:56:25.348+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:56:25.352+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:56:25.351+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:56:25.374+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:56:25.392+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:56:25.392+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:56:25.405+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:56:25.405+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:56:25.414+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-10T18:56:55.595+0000] {processor.py:157} INFO - Started process (PID=31457) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:56:55.596+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:56:55.599+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:56:55.598+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:56:55.613+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:56:55.627+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:56:55.627+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:56:55.639+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:56:55.638+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:56:55.647+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-10T18:57:25.915+0000] {processor.py:157} INFO - Started process (PID=31467) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:57:25.915+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:57:25.918+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:57:25.917+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:57:25.928+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:57:25.945+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:57:25.945+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:57:25.956+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:57:25.956+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:57:25.963+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-10T18:57:56.304+0000] {processor.py:157} INFO - Started process (PID=31477) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:57:56.306+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:57:56.307+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:57:56.307+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:57:56.316+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:57:56.333+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:57:56.333+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:57:56.344+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:57:56.344+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:57:56.353+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-10T18:58:26.676+0000] {processor.py:157} INFO - Started process (PID=31487) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:58:26.678+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:58:26.681+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:58:26.680+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:58:26.691+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:58:26.707+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:58:26.707+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:58:26.716+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:58:26.716+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:58:26.727+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-10T18:58:57.054+0000] {processor.py:157} INFO - Started process (PID=31497) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:58:57.055+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:58:57.058+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:58:57.057+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:58:57.068+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:58:57.087+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:58:57.087+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:58:57.099+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:58:57.099+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:58:57.108+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-10T18:59:27.437+0000] {processor.py:157} INFO - Started process (PID=31507) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:59:27.438+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:59:27.439+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:59:27.439+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:59:27.454+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:59:27.466+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:59:27.466+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:59:27.477+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:59:27.477+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:59:27.486+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-10T18:59:57.822+0000] {processor.py:157} INFO - Started process (PID=31517) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:59:57.823+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T18:59:57.826+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:59:57.826+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:59:57.841+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T18:59:57.861+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:59:57.861+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T18:59:57.873+0000] {logging_mixin.py:151} INFO - [2024-08-10T18:59:57.873+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T18:59:57.883+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-10T19:00:28.176+0000] {processor.py:157} INFO - Started process (PID=31527) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T19:00:28.177+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T19:00:28.179+0000] {logging_mixin.py:151} INFO - [2024-08-10T19:00:28.179+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T19:00:28.190+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T19:00:28.207+0000] {logging_mixin.py:151} INFO - [2024-08-10T19:00:28.207+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T19:00:28.220+0000] {logging_mixin.py:151} INFO - [2024-08-10T19:00:28.220+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T19:00:28.232+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-10T19:00:58.548+0000] {processor.py:157} INFO - Started process (PID=31537) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T19:00:58.549+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T19:00:58.550+0000] {logging_mixin.py:151} INFO - [2024-08-10T19:00:58.550+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T19:00:58.564+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T19:00:58.579+0000] {logging_mixin.py:151} INFO - [2024-08-10T19:00:58.579+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T19:00:58.588+0000] {logging_mixin.py:151} INFO - [2024-08-10T19:00:58.588+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T19:00:58.596+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-10T19:01:28.934+0000] {processor.py:157} INFO - Started process (PID=31547) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T19:01:28.935+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T19:01:28.936+0000] {logging_mixin.py:151} INFO - [2024-08-10T19:01:28.936+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T19:01:28.948+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T19:01:28.962+0000] {logging_mixin.py:151} INFO - [2024-08-10T19:01:28.962+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T19:01:28.971+0000] {logging_mixin.py:151} INFO - [2024-08-10T19:01:28.971+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T19:01:28.981+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-10T19:01:59.339+0000] {processor.py:157} INFO - Started process (PID=31557) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T19:01:59.339+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T19:01:59.340+0000] {logging_mixin.py:151} INFO - [2024-08-10T19:01:59.340+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T19:01:59.356+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T19:01:59.370+0000] {logging_mixin.py:151} INFO - [2024-08-10T19:01:59.370+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T19:01:59.382+0000] {logging_mixin.py:151} INFO - [2024-08-10T19:01:59.381+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T19:01:59.390+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-10T19:02:29.657+0000] {processor.py:157} INFO - Started process (PID=31567) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T19:02:29.662+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T19:02:29.665+0000] {logging_mixin.py:151} INFO - [2024-08-10T19:02:29.665+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T19:02:29.675+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T19:02:29.690+0000] {logging_mixin.py:151} INFO - [2024-08-10T19:02:29.690+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T19:02:29.699+0000] {logging_mixin.py:151} INFO - [2024-08-10T19:02:29.699+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T19:02:29.707+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-10T19:02:59.993+0000] {processor.py:157} INFO - Started process (PID=31577) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T19:02:59.993+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T19:02:59.995+0000] {logging_mixin.py:151} INFO - [2024-08-10T19:02:59.995+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T19:03:00.007+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T19:03:00.023+0000] {logging_mixin.py:151} INFO - [2024-08-10T19:03:00.023+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T19:03:00.033+0000] {logging_mixin.py:151} INFO - [2024-08-10T19:03:00.033+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T19:03:00.041+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-10T19:03:30.292+0000] {processor.py:157} INFO - Started process (PID=31587) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T19:03:30.293+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T19:03:30.296+0000] {logging_mixin.py:151} INFO - [2024-08-10T19:03:30.296+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T19:03:30.306+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T19:03:30.322+0000] {logging_mixin.py:151} INFO - [2024-08-10T19:03:30.322+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T19:03:30.333+0000] {logging_mixin.py:151} INFO - [2024-08-10T19:03:30.333+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T19:03:30.343+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-10T19:04:00.669+0000] {processor.py:157} INFO - Started process (PID=31597) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T19:04:00.670+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T19:04:00.672+0000] {logging_mixin.py:151} INFO - [2024-08-10T19:04:00.671+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T19:04:00.679+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T19:04:00.694+0000] {logging_mixin.py:151} INFO - [2024-08-10T19:04:00.693+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T19:04:00.703+0000] {logging_mixin.py:151} INFO - [2024-08-10T19:04:00.703+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T19:04:00.711+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.044 seconds
[2024-08-10T19:04:31.057+0000] {processor.py:157} INFO - Started process (PID=31607) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T19:04:31.059+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T19:04:31.062+0000] {logging_mixin.py:151} INFO - [2024-08-10T19:04:31.062+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T19:04:31.076+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T19:04:31.097+0000] {logging_mixin.py:151} INFO - [2024-08-10T19:04:31.097+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T19:04:31.110+0000] {logging_mixin.py:151} INFO - [2024-08-10T19:04:31.110+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T19:04:31.120+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-10T19:05:01.395+0000] {processor.py:157} INFO - Started process (PID=31617) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T19:05:01.397+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T19:05:01.399+0000] {logging_mixin.py:151} INFO - [2024-08-10T19:05:01.399+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T19:05:01.407+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T19:05:01.423+0000] {logging_mixin.py:151} INFO - [2024-08-10T19:05:01.423+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T19:05:01.433+0000] {logging_mixin.py:151} INFO - [2024-08-10T19:05:01.433+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T19:05:01.443+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-10T19:05:31.808+0000] {processor.py:157} INFO - Started process (PID=31627) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T19:05:31.809+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T19:05:31.812+0000] {logging_mixin.py:151} INFO - [2024-08-10T19:05:31.812+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T19:05:31.823+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T19:05:31.840+0000] {logging_mixin.py:151} INFO - [2024-08-10T19:05:31.840+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T19:05:31.851+0000] {logging_mixin.py:151} INFO - [2024-08-10T19:05:31.851+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T19:05:31.859+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-10T19:06:02.238+0000] {processor.py:157} INFO - Started process (PID=31637) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T19:06:02.241+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T19:06:02.245+0000] {logging_mixin.py:151} INFO - [2024-08-10T19:06:02.245+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T19:06:02.264+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T19:06:02.290+0000] {logging_mixin.py:151} INFO - [2024-08-10T19:06:02.290+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T19:06:02.314+0000] {logging_mixin.py:151} INFO - [2024-08-10T19:06:02.314+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T19:06:02.326+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-08-10T19:21:56.639+0000] {processor.py:157} INFO - Started process (PID=31648) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T19:21:56.640+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T19:21:56.643+0000] {logging_mixin.py:151} INFO - [2024-08-10T19:21:56.643+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T19:21:56.662+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T19:21:56.681+0000] {logging_mixin.py:151} INFO - [2024-08-10T19:21:56.681+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T19:21:56.696+0000] {logging_mixin.py:151} INFO - [2024-08-10T19:21:56.696+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T19:21:56.706+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-10T19:22:27.064+0000] {processor.py:157} INFO - Started process (PID=31659) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T19:22:27.068+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T19:22:27.071+0000] {logging_mixin.py:151} INFO - [2024-08-10T19:22:27.071+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T19:22:27.091+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T19:22:27.114+0000] {logging_mixin.py:151} INFO - [2024-08-10T19:22:27.114+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T19:22:27.135+0000] {logging_mixin.py:151} INFO - [2024-08-10T19:22:27.135+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T19:22:27.145+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-08-10T19:22:57.387+0000] {processor.py:157} INFO - Started process (PID=31669) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T19:22:57.391+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T19:22:57.394+0000] {logging_mixin.py:151} INFO - [2024-08-10T19:22:57.394+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T19:22:57.410+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T19:22:57.431+0000] {logging_mixin.py:151} INFO - [2024-08-10T19:22:57.431+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T19:22:57.446+0000] {logging_mixin.py:151} INFO - [2024-08-10T19:22:57.445+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T19:22:57.455+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-10T19:23:27.685+0000] {processor.py:157} INFO - Started process (PID=31679) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T19:23:27.687+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T19:23:27.689+0000] {logging_mixin.py:151} INFO - [2024-08-10T19:23:27.688+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T19:23:27.698+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T19:23:27.715+0000] {logging_mixin.py:151} INFO - [2024-08-10T19:23:27.715+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T19:23:27.725+0000] {logging_mixin.py:151} INFO - [2024-08-10T19:23:27.725+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T19:23:27.735+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-10T19:23:58.077+0000] {processor.py:157} INFO - Started process (PID=31689) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T19:23:58.079+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T19:23:58.081+0000] {logging_mixin.py:151} INFO - [2024-08-10T19:23:58.081+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T19:23:58.101+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T19:23:58.118+0000] {logging_mixin.py:151} INFO - [2024-08-10T19:23:58.118+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T19:23:58.133+0000] {logging_mixin.py:151} INFO - [2024-08-10T19:23:58.133+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T19:23:58.143+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-10T19:24:28.337+0000] {processor.py:157} INFO - Started process (PID=31699) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T19:24:28.338+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T19:24:28.340+0000] {logging_mixin.py:151} INFO - [2024-08-10T19:24:28.340+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T19:24:28.353+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T19:24:28.378+0000] {logging_mixin.py:151} INFO - [2024-08-10T19:24:28.378+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T19:24:28.406+0000] {logging_mixin.py:151} INFO - [2024-08-10T19:24:28.406+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T19:24:28.418+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-08-10T19:24:58.659+0000] {processor.py:157} INFO - Started process (PID=31709) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T19:24:58.661+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T19:24:58.662+0000] {logging_mixin.py:151} INFO - [2024-08-10T19:24:58.662+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T19:24:58.671+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T19:24:58.686+0000] {logging_mixin.py:151} INFO - [2024-08-10T19:24:58.686+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T19:24:58.697+0000] {logging_mixin.py:151} INFO - [2024-08-10T19:24:58.697+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T19:24:58.708+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-10T19:25:29.052+0000] {processor.py:157} INFO - Started process (PID=31719) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T19:25:29.053+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T19:25:29.054+0000] {logging_mixin.py:151} INFO - [2024-08-10T19:25:29.054+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T19:25:29.065+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T19:25:29.081+0000] {logging_mixin.py:151} INFO - [2024-08-10T19:25:29.081+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T19:25:29.091+0000] {logging_mixin.py:151} INFO - [2024-08-10T19:25:29.091+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T19:25:29.100+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-10T19:25:59.474+0000] {processor.py:157} INFO - Started process (PID=31729) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T19:25:59.476+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T19:25:59.480+0000] {logging_mixin.py:151} INFO - [2024-08-10T19:25:59.479+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T19:25:59.496+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T19:25:59.515+0000] {logging_mixin.py:151} INFO - [2024-08-10T19:25:59.515+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T19:25:59.528+0000] {logging_mixin.py:151} INFO - [2024-08-10T19:25:59.528+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T19:25:59.538+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-10T19:26:29.948+0000] {processor.py:157} INFO - Started process (PID=31739) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T19:26:29.949+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T19:26:29.950+0000] {logging_mixin.py:151} INFO - [2024-08-10T19:26:29.950+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T19:26:29.967+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T19:26:29.983+0000] {logging_mixin.py:151} INFO - [2024-08-10T19:26:29.983+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T19:26:29.999+0000] {logging_mixin.py:151} INFO - [2024-08-10T19:26:29.999+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T19:26:30.009+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-10T19:42:25.021+0000] {processor.py:157} INFO - Started process (PID=31751) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T19:42:25.026+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T19:42:25.037+0000] {logging_mixin.py:151} INFO - [2024-08-10T19:42:25.036+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T19:42:25.073+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T19:42:25.113+0000] {logging_mixin.py:151} INFO - [2024-08-10T19:42:25.113+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T19:42:25.142+0000] {logging_mixin.py:151} INFO - [2024-08-10T19:42:25.142+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T19:42:25.161+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.149 seconds
[2024-08-10T20:00:05.465+0000] {processor.py:157} INFO - Started process (PID=31761) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T20:00:05.469+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T20:00:05.472+0000] {logging_mixin.py:151} INFO - [2024-08-10T20:00:05.472+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T20:00:05.492+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T20:00:05.585+0000] {logging_mixin.py:151} INFO - [2024-08-10T20:00:05.584+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T20:00:05.608+0000] {logging_mixin.py:151} INFO - [2024-08-10T20:00:05.607+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T20:00:05.628+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.168 seconds
[2024-08-10T20:00:35.999+0000] {processor.py:157} INFO - Started process (PID=31771) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T20:00:36.000+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T20:00:36.005+0000] {logging_mixin.py:151} INFO - [2024-08-10T20:00:36.004+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T20:00:36.034+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T20:00:36.058+0000] {logging_mixin.py:151} INFO - [2024-08-10T20:00:36.058+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T20:00:36.072+0000] {logging_mixin.py:151} INFO - [2024-08-10T20:00:36.072+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T20:00:36.082+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-08-10T21:05:58.108+0000] {processor.py:157} INFO - Started process (PID=31781) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T21:05:58.109+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T21:05:58.111+0000] {logging_mixin.py:151} INFO - [2024-08-10T21:05:58.111+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T21:05:58.123+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T21:05:58.137+0000] {logging_mixin.py:151} INFO - [2024-08-10T21:05:58.137+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T21:05:58.148+0000] {logging_mixin.py:151} INFO - [2024-08-10T21:05:58.148+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T21:05:58.166+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-10T22:32:18.151+0000] {processor.py:157} INFO - Started process (PID=31791) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-10T22:32:18.156+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-10T22:32:18.161+0000] {logging_mixin.py:151} INFO - [2024-08-10T22:32:18.160+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T22:32:18.186+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-10T22:32:18.229+0000] {logging_mixin.py:151} INFO - [2024-08-10T22:32:18.229+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-10T22:32:18.251+0000] {logging_mixin.py:151} INFO - [2024-08-10T22:32:18.251+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-10T22:32:18.275+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
