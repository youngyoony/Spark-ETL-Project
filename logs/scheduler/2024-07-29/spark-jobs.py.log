[2024-07-29T00:08:06.017+0000] {processor.py:157} INFO - Started process (PID=11938) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T00:08:06.023+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T00:08:06.036+0000] {logging_mixin.py:151} INFO - [2024-07-29T00:08:06.035+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T00:08:06.057+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T00:08:06.114+0000] {logging_mixin.py:151} INFO - [2024-07-29T00:08:06.113+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T00:08:06.138+0000] {logging_mixin.py:151} INFO - [2024-07-29T00:08:06.138+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-29T00:08:06.158+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.152 seconds
[2024-07-29T00:08:36.263+0000] {processor.py:157} INFO - Started process (PID=11963) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T00:08:36.264+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T00:08:36.268+0000] {logging_mixin.py:151} INFO - [2024-07-29T00:08:36.268+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T00:08:36.282+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T00:08:36.302+0000] {logging_mixin.py:151} INFO - [2024-07-29T00:08:36.302+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T00:08:36.313+0000] {logging_mixin.py:151} INFO - [2024-07-29T00:08:36.313+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-29T00:08:36.322+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.065 seconds
[2024-07-29T00:09:06.642+0000] {processor.py:157} INFO - Started process (PID=11988) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T00:09:06.643+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T00:09:06.645+0000] {logging_mixin.py:151} INFO - [2024-07-29T00:09:06.644+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T00:09:06.656+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T00:09:06.674+0000] {logging_mixin.py:151} INFO - [2024-07-29T00:09:06.674+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T00:09:06.686+0000] {logging_mixin.py:151} INFO - [2024-07-29T00:09:06.686+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-29T00:09:06.783+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.145 seconds
[2024-07-29T00:09:37.091+0000] {processor.py:157} INFO - Started process (PID=12013) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T00:09:37.092+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T00:09:37.095+0000] {logging_mixin.py:151} INFO - [2024-07-29T00:09:37.095+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T00:09:37.105+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T00:09:37.122+0000] {logging_mixin.py:151} INFO - [2024-07-29T00:09:37.122+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T00:09:37.205+0000] {logging_mixin.py:151} INFO - [2024-07-29T00:09:37.205+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-29T00:09:37.212+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.124 seconds
[2024-07-29T00:25:45.233+0000] {processor.py:157} INFO - Started process (PID=12038) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T00:25:45.235+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T00:25:45.245+0000] {logging_mixin.py:151} INFO - [2024-07-29T00:25:45.244+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T00:25:45.266+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T00:25:45.323+0000] {logging_mixin.py:151} INFO - [2024-07-29T00:25:45.322+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T00:25:45.540+0000] {logging_mixin.py:151} INFO - [2024-07-29T00:25:45.540+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-29T00:25:45.552+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.329 seconds
[2024-07-29T00:26:16.138+0000] {processor.py:157} INFO - Started process (PID=12063) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T00:26:16.138+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T00:26:16.143+0000] {logging_mixin.py:151} INFO - [2024-07-29T00:26:16.142+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T00:26:16.153+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T00:26:16.169+0000] {logging_mixin.py:151} INFO - [2024-07-29T00:26:16.169+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T00:26:16.180+0000] {logging_mixin.py:151} INFO - [2024-07-29T00:26:16.180+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-29T00:26:16.189+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-29T00:26:46.636+0000] {processor.py:157} INFO - Started process (PID=12088) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T00:26:46.636+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T00:26:46.639+0000] {logging_mixin.py:151} INFO - [2024-07-29T00:26:46.639+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T00:26:46.651+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T00:26:46.668+0000] {logging_mixin.py:151} INFO - [2024-07-29T00:26:46.668+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T00:26:46.680+0000] {logging_mixin.py:151} INFO - [2024-07-29T00:26:46.680+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-29T00:26:46.689+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-29T00:27:17.072+0000] {processor.py:157} INFO - Started process (PID=12113) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T00:27:17.073+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T00:27:17.077+0000] {logging_mixin.py:151} INFO - [2024-07-29T00:27:17.077+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T00:27:17.090+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T00:27:17.109+0000] {logging_mixin.py:151} INFO - [2024-07-29T00:27:17.109+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T00:27:17.122+0000] {logging_mixin.py:151} INFO - [2024-07-29T00:27:17.121+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-29T00:27:17.132+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-29T00:27:47.556+0000] {processor.py:157} INFO - Started process (PID=12138) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T00:27:47.557+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T00:27:47.560+0000] {logging_mixin.py:151} INFO - [2024-07-29T00:27:47.560+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T00:27:47.574+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T00:27:47.593+0000] {logging_mixin.py:151} INFO - [2024-07-29T00:27:47.593+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T00:27:47.603+0000] {logging_mixin.py:151} INFO - [2024-07-29T00:27:47.603+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-29T00:27:47.743+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.190 seconds
[2024-07-29T00:45:33.340+0000] {processor.py:157} INFO - Started process (PID=12163) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T00:45:33.341+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T00:45:33.345+0000] {logging_mixin.py:151} INFO - [2024-07-29T00:45:33.344+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T00:45:33.358+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T00:45:33.380+0000] {logging_mixin.py:151} INFO - [2024-07-29T00:45:33.379+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T00:45:33.511+0000] {logging_mixin.py:151} INFO - [2024-07-29T00:45:33.511+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-29T00:45:33.520+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.186 seconds
[2024-07-29T00:46:03.995+0000] {processor.py:157} INFO - Started process (PID=12580) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T00:46:03.997+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T00:46:03.999+0000] {logging_mixin.py:151} INFO - [2024-07-29T00:46:03.999+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T00:46:04.010+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T00:46:04.028+0000] {logging_mixin.py:151} INFO - [2024-07-29T00:46:04.028+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T00:46:04.049+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-29T00:46:34.507+0000] {processor.py:157} INFO - Started process (PID=12605) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T00:46:34.508+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T00:46:34.513+0000] {logging_mixin.py:151} INFO - [2024-07-29T00:46:34.512+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T00:46:34.528+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T00:46:34.549+0000] {logging_mixin.py:151} INFO - [2024-07-29T00:46:34.549+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T00:46:34.571+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.070 seconds
[2024-07-29T00:47:04.947+0000] {processor.py:157} INFO - Started process (PID=12630) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T00:47:04.951+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T00:47:04.954+0000] {logging_mixin.py:151} INFO - [2024-07-29T00:47:04.953+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T00:47:04.966+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T00:47:04.981+0000] {logging_mixin.py:151} INFO - [2024-07-29T00:47:04.981+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T00:47:04.998+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-29T00:47:35.486+0000] {processor.py:157} INFO - Started process (PID=12655) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T00:47:35.487+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T00:47:35.491+0000] {logging_mixin.py:151} INFO - [2024-07-29T00:47:35.491+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T00:47:35.504+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T00:47:35.536+0000] {logging_mixin.py:151} INFO - [2024-07-29T00:47:35.536+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T00:47:35.557+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.076 seconds
[2024-07-29T01:03:14.382+0000] {processor.py:157} INFO - Started process (PID=12692) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T01:03:14.384+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T01:03:14.391+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:03:14.390+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T01:03:14.418+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T01:03:14.494+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:03:14.494+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T01:03:14.835+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:03:14.835+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T01:03:14.842+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.466 seconds
[2024-07-29T01:03:45.298+0000] {processor.py:157} INFO - Started process (PID=13100) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T01:03:45.300+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T01:03:45.305+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:03:45.304+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T01:03:45.340+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T01:03:45.391+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:03:45.391+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T01:03:45.526+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:03:45.526+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T01:03:45.534+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.243 seconds
[2024-07-29T01:04:16.137+0000] {processor.py:157} INFO - Started process (PID=13125) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T01:04:16.138+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T01:04:16.140+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:04:16.140+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T01:04:16.152+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T01:04:16.177+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:04:16.177+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T01:04:16.188+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:04:16.187+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T01:04:16.195+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-29T01:04:46.593+0000] {processor.py:157} INFO - Started process (PID=13150) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T01:04:46.595+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T01:04:46.597+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:04:46.597+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T01:04:46.617+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T01:04:46.632+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:04:46.632+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T01:04:46.644+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:04:46.644+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T01:04:46.653+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-29T01:05:17.117+0000] {processor.py:157} INFO - Started process (PID=13175) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T01:05:17.119+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T01:05:17.122+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:05:17.122+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T01:05:17.184+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T01:05:17.205+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:05:17.204+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T01:05:17.216+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:05:17.216+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T01:05:17.226+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.113 seconds
[2024-07-29T01:21:05.535+0000] {processor.py:157} INFO - Started process (PID=13202) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T01:21:05.536+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T01:21:05.540+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:21:05.539+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T01:21:05.575+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T01:21:05.612+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:21:05.612+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T01:21:05.641+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:21:05.641+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T01:21:05.756+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.228 seconds
[2024-07-29T01:21:36.229+0000] {processor.py:157} INFO - Started process (PID=13227) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T01:21:36.230+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T01:21:36.236+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:21:36.236+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T01:21:36.254+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T01:21:36.280+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:21:36.280+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T01:21:36.450+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:21:36.450+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T01:21:36.458+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.237 seconds
[2024-07-29T01:22:06.916+0000] {processor.py:157} INFO - Started process (PID=13252) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T01:22:06.917+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T01:22:06.920+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:22:06.920+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T01:22:06.936+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T01:22:06.976+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:22:06.976+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T01:22:07.067+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:22:07.067+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T01:22:07.074+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.163 seconds
[2024-07-29T01:22:37.602+0000] {processor.py:157} INFO - Started process (PID=13277) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T01:22:37.603+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T01:22:37.608+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:22:37.608+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T01:22:37.623+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T01:22:37.644+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:22:37.644+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T01:22:37.654+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:22:37.654+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T01:22:37.663+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-29T01:23:08.041+0000] {processor.py:157} INFO - Started process (PID=13302) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T01:23:08.042+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T01:23:08.045+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:23:08.045+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T01:23:08.056+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T01:23:08.080+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:23:08.080+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T01:23:08.095+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:23:08.095+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T01:23:08.104+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.068 seconds
[2024-07-29T01:31:22.474+0000] {processor.py:157} INFO - Started process (PID=13329) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T01:31:22.477+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T01:31:22.485+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:31:22.485+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T01:31:22.524+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T01:31:22.574+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:31:22.574+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T01:31:22.590+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:31:22.590+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T01:31:22.602+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.135 seconds
[2024-07-29T01:31:53.088+0000] {processor.py:157} INFO - Started process (PID=13354) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T01:31:53.090+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T01:31:53.095+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:31:53.095+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T01:31:53.109+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T01:31:53.144+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:31:53.144+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T01:31:53.160+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:31:53.160+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T01:31:53.322+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.241 seconds
[2024-07-29T01:32:23.886+0000] {processor.py:157} INFO - Started process (PID=13379) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T01:32:23.887+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T01:32:23.889+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:32:23.889+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T01:32:23.901+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T01:32:23.930+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:32:23.930+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T01:32:24.024+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:32:24.024+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T01:32:24.036+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.154 seconds
[2024-07-29T01:32:54.515+0000] {processor.py:157} INFO - Started process (PID=13404) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T01:32:54.518+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T01:32:54.522+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:32:54.522+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T01:32:54.536+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T01:32:54.653+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:32:54.653+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T01:32:54.662+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:32:54.662+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T01:32:54.670+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.161 seconds
[2024-07-29T01:33:25.171+0000] {processor.py:157} INFO - Started process (PID=13429) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T01:33:25.174+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T01:33:25.177+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:33:25.177+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T01:33:25.201+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T01:33:25.235+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:33:25.235+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T01:33:25.252+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:33:25.252+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T01:33:25.265+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.099 seconds
[2024-07-29T01:33:55.756+0000] {processor.py:157} INFO - Started process (PID=13454) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T01:33:55.757+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T01:33:55.761+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:33:55.761+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T01:33:55.781+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T01:33:55.813+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:33:55.813+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T01:33:55.827+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:33:55.827+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T01:33:55.836+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.085 seconds
[2024-07-29T01:34:26.288+0000] {processor.py:157} INFO - Started process (PID=13479) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T01:34:26.289+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T01:34:26.291+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:34:26.291+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T01:34:26.302+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T01:34:26.321+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:34:26.321+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T01:34:26.333+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:34:26.333+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T01:34:26.342+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-29T01:34:56.680+0000] {processor.py:157} INFO - Started process (PID=13504) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T01:34:56.681+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T01:34:56.683+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:34:56.683+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T01:34:56.692+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T01:34:56.711+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:34:56.710+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T01:34:56.881+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:34:56.880+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T01:34:56.891+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.214 seconds
[2024-07-29T01:51:20.270+0000] {processor.py:157} INFO - Started process (PID=13531) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T01:51:20.271+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T01:51:20.279+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:51:20.279+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T01:51:20.312+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T01:51:20.353+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:51:20.352+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T01:51:20.638+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:51:20.638+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T01:51:20.795+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.531 seconds
[2024-07-29T01:51:51.381+0000] {processor.py:157} INFO - Started process (PID=13556) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T01:51:51.382+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T01:51:51.406+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:51:51.403+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T01:51:51.430+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T01:51:51.609+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:51:51.608+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T01:51:51.619+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:51:51.619+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T01:51:51.628+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.254 seconds
[2024-07-29T01:52:22.057+0000] {processor.py:157} INFO - Started process (PID=13581) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T01:52:22.058+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T01:52:22.062+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:52:22.062+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T01:52:22.076+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T01:52:22.094+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:52:22.094+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T01:52:22.103+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:52:22.103+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T01:52:22.113+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-29T01:52:52.534+0000] {processor.py:157} INFO - Started process (PID=13606) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T01:52:52.535+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T01:52:52.539+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:52:52.539+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T01:52:52.556+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T01:52:52.581+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:52:52.581+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T01:52:52.593+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:52:52.593+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T01:52:52.602+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.075 seconds
[2024-07-29T01:53:22.927+0000] {processor.py:157} INFO - Started process (PID=13631) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T01:53:22.929+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T01:53:22.931+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:53:22.930+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T01:53:22.942+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T01:53:22.959+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:53:22.959+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T01:53:22.970+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:53:22.970+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T01:53:23.117+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.193 seconds
[2024-07-29T01:53:53.600+0000] {processor.py:157} INFO - Started process (PID=13656) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T01:53:53.600+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T01:53:53.603+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:53:53.603+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T01:53:53.613+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T01:53:53.628+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:53:53.628+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T01:53:53.709+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:53:53.709+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T01:53:53.717+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.120 seconds
[2024-07-29T02:09:34.214+0000] {processor.py:157} INFO - Started process (PID=13681) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T02:09:34.219+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T02:09:34.230+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:09:34.229+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T02:09:34.252+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T02:09:34.298+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:09:34.298+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T02:09:34.571+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:09:34.571+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T02:09:34.589+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.390 seconds
[2024-07-29T02:10:05.400+0000] {processor.py:157} INFO - Started process (PID=13706) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T02:10:05.405+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T02:10:05.412+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:10:05.411+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T02:10:05.436+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T02:10:05.649+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:10:05.649+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T02:10:05.658+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:10:05.657+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T02:10:05.666+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.288 seconds
[2024-07-29T02:10:36.236+0000] {processor.py:157} INFO - Started process (PID=13731) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T02:10:36.237+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T02:10:36.240+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:10:36.240+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T02:10:36.255+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T02:10:36.272+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:10:36.271+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T02:10:36.282+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:10:36.282+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T02:10:36.291+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-29T02:11:06.728+0000] {processor.py:157} INFO - Started process (PID=13756) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T02:11:06.732+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T02:11:06.736+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:11:06.736+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T02:11:06.751+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T02:11:06.775+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:11:06.775+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T02:11:06.787+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:11:06.787+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T02:11:06.798+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.076 seconds
[2024-07-29T02:11:37.280+0000] {processor.py:157} INFO - Started process (PID=13781) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T02:11:37.281+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T02:11:37.285+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:11:37.284+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T02:11:37.296+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T02:11:37.315+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:11:37.315+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T02:11:37.324+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:11:37.324+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T02:11:37.489+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.213 seconds
[2024-07-29T02:29:25.995+0000] {processor.py:157} INFO - Started process (PID=13807) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T02:29:25.997+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T02:29:26.002+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:29:26.002+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T02:29:26.019+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T02:29:26.059+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:29:26.059+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T02:29:26.147+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:29:26.147+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T02:29:26.154+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.163 seconds
[2024-07-29T02:29:56.795+0000] {processor.py:157} INFO - Started process (PID=13833) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T02:29:56.796+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T02:29:56.807+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:29:56.801+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T02:29:56.832+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T02:29:56.883+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:29:56.883+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T02:29:57.045+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:29:57.044+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T02:29:57.054+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.266 seconds
[2024-07-29T02:30:27.602+0000] {processor.py:157} INFO - Started process (PID=13858) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T02:30:27.603+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T02:30:27.605+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:30:27.605+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T02:30:27.615+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T02:30:27.634+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:30:27.634+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T02:30:27.643+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:30:27.643+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T02:30:27.651+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-29T02:30:58.025+0000] {processor.py:157} INFO - Started process (PID=13883) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T02:30:58.027+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T02:30:58.030+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:30:58.030+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T02:30:58.047+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T02:30:58.071+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:30:58.071+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T02:30:58.084+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:30:58.083+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T02:30:58.093+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.074 seconds
[2024-07-29T02:31:28.506+0000] {processor.py:157} INFO - Started process (PID=13908) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T02:31:28.509+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T02:31:28.512+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:31:28.512+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T02:31:28.523+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T02:31:28.539+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:31:28.539+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T02:31:28.549+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:31:28.549+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T02:31:28.559+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-29T02:31:58.955+0000] {processor.py:157} INFO - Started process (PID=13933) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T02:31:58.955+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T02:31:58.957+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:31:58.957+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T02:31:58.966+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T02:31:58.983+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:31:58.983+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T02:31:58.992+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:31:58.992+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T02:31:59.157+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.206 seconds
[2024-07-29T02:43:04.187+0000] {processor.py:157} INFO - Started process (PID=13958) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T02:43:04.188+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T02:43:04.194+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:43:04.193+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T02:43:04.223+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T02:43:04.258+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:43:04.257+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T02:43:04.440+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:43:04.440+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T02:43:04.448+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.265 seconds
[2024-07-29T02:43:34.854+0000] {processor.py:157} INFO - Started process (PID=13983) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T02:43:34.856+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T02:43:34.861+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:43:34.860+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T02:43:34.881+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T02:43:35.104+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:43:35.103+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T02:43:35.115+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:43:35.114+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T02:43:35.122+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.283 seconds
[2024-07-29T02:44:05.558+0000] {processor.py:157} INFO - Started process (PID=14008) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T02:44:05.561+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T02:44:05.564+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:44:05.564+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T02:44:05.576+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T02:44:05.594+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:44:05.594+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T02:44:05.605+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:44:05.605+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T02:44:05.614+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-29T02:44:36.021+0000] {processor.py:157} INFO - Started process (PID=14033) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T02:44:36.026+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T02:44:36.029+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:44:36.029+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T02:44:36.045+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T02:44:36.068+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:44:36.068+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T02:44:36.080+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:44:36.080+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T02:44:36.089+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.073 seconds
[2024-07-29T02:45:06.552+0000] {processor.py:157} INFO - Started process (PID=14058) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T02:45:06.553+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T02:45:06.556+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:45:06.556+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T02:45:06.572+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T02:45:06.589+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:45:06.589+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T02:45:06.601+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:45:06.601+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T02:45:06.609+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-29T02:54:29.099+0000] {processor.py:157} INFO - Started process (PID=14085) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T02:54:29.104+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T02:54:29.115+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:54:29.112+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T02:54:29.145+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T02:54:29.216+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:54:29.216+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T02:54:29.384+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:54:29.384+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T02:54:29.394+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.303 seconds
[2024-07-29T02:54:59.854+0000] {processor.py:157} INFO - Started process (PID=14110) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T02:54:59.856+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T02:54:59.860+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:54:59.859+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T02:54:59.879+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T02:54:59.913+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:54:59.912+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T02:55:00.068+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:55:00.068+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T02:55:00.078+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.230 seconds
[2024-07-29T02:55:30.468+0000] {processor.py:157} INFO - Started process (PID=14135) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T02:55:30.469+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T02:55:30.470+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:55:30.470+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T02:55:30.481+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T02:55:30.573+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:55:30.573+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T02:55:30.583+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:55:30.583+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T02:55:30.590+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.126 seconds
[2024-07-29T02:56:01.120+0000] {processor.py:157} INFO - Started process (PID=14160) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T02:56:01.121+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T02:56:01.123+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:56:01.122+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T02:56:01.134+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T02:56:01.155+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:56:01.155+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T02:56:01.166+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:56:01.166+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T02:56:01.176+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-29T02:56:31.595+0000] {processor.py:157} INFO - Started process (PID=14185) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T02:56:31.596+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T02:56:31.598+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:56:31.598+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T02:56:31.612+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T02:56:31.634+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:56:31.634+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T02:56:31.643+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:56:31.643+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T02:56:31.651+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-29T02:57:02.002+0000] {processor.py:157} INFO - Started process (PID=14210) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T02:57:02.003+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T02:57:02.005+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:57:02.005+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T02:57:02.018+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T02:57:02.037+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:57:02.037+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T02:57:02.049+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:57:02.049+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T02:57:02.123+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.125 seconds
[2024-07-29T03:02:23.928+0000] {processor.py:157} INFO - Started process (PID=14235) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T03:02:23.929+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T03:02:23.936+0000] {logging_mixin.py:151} INFO - [2024-07-29T03:02:23.935+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T03:02:23.956+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T03:02:24.008+0000] {logging_mixin.py:151} INFO - [2024-07-29T03:02:24.008+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T03:02:24.242+0000] {logging_mixin.py:151} INFO - [2024-07-29T03:02:24.242+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T03:02:24.257+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.336 seconds
[2024-07-29T03:02:54.925+0000] {processor.py:157} INFO - Started process (PID=14260) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T03:02:54.926+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T03:02:54.930+0000] {logging_mixin.py:151} INFO - [2024-07-29T03:02:54.930+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T03:02:54.950+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T03:02:54.976+0000] {logging_mixin.py:151} INFO - [2024-07-29T03:02:54.976+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T03:02:55.075+0000] {logging_mixin.py:151} INFO - [2024-07-29T03:02:55.075+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T03:02:55.085+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.164 seconds
[2024-07-29T03:15:42.785+0000] {processor.py:157} INFO - Started process (PID=14286) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T03:15:42.786+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T03:15:42.790+0000] {logging_mixin.py:151} INFO - [2024-07-29T03:15:42.789+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T03:15:42.809+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T03:15:43.055+0000] {logging_mixin.py:151} INFO - [2024-07-29T03:15:43.055+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T03:15:43.068+0000] {logging_mixin.py:151} INFO - [2024-07-29T03:15:43.068+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T03:15:43.082+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.301 seconds
[2024-07-29T03:32:14.600+0000] {processor.py:157} INFO - Started process (PID=14312) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T03:32:14.601+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T03:32:14.604+0000] {logging_mixin.py:151} INFO - [2024-07-29T03:32:14.603+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T03:32:14.621+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T03:32:14.645+0000] {logging_mixin.py:151} INFO - [2024-07-29T03:32:14.645+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T03:32:14.658+0000] {logging_mixin.py:151} INFO - [2024-07-29T03:32:14.658+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T03:32:14.669+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.073 seconds
[2024-07-29T03:32:45.087+0000] {processor.py:157} INFO - Started process (PID=14337) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T03:32:45.088+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T03:32:45.091+0000] {logging_mixin.py:151} INFO - [2024-07-29T03:32:45.091+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T03:32:45.104+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T03:32:45.123+0000] {logging_mixin.py:151} INFO - [2024-07-29T03:32:45.122+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T03:32:45.134+0000] {logging_mixin.py:151} INFO - [2024-07-29T03:32:45.134+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T03:32:45.144+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-29T03:42:55.066+0000] {processor.py:157} INFO - Started process (PID=14364) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T03:42:55.071+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T03:42:55.074+0000] {logging_mixin.py:151} INFO - [2024-07-29T03:42:55.073+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T03:42:55.096+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T03:42:55.142+0000] {logging_mixin.py:151} INFO - [2024-07-29T03:42:55.142+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T03:42:55.390+0000] {logging_mixin.py:151} INFO - [2024-07-29T03:42:55.390+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T03:42:55.404+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.355 seconds
[2024-07-29T03:43:26.156+0000] {processor.py:157} INFO - Started process (PID=14389) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T03:43:26.158+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T03:43:26.164+0000] {logging_mixin.py:151} INFO - [2024-07-29T03:43:26.164+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T03:43:26.184+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T03:43:26.206+0000] {logging_mixin.py:151} INFO - [2024-07-29T03:43:26.206+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T03:43:26.314+0000] {logging_mixin.py:151} INFO - [2024-07-29T03:43:26.314+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T03:43:26.322+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.173 seconds
[2024-07-29T04:00:14.362+0000] {processor.py:157} INFO - Started process (PID=14414) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:00:14.363+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T04:00:14.369+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:00:14.369+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:00:14.395+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:00:14.625+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:00:14.624+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:00:14.635+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:00:14.635+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T04:00:14.645+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.290 seconds
[2024-07-29T04:00:45.295+0000] {processor.py:157} INFO - Started process (PID=14439) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:00:45.297+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T04:00:45.302+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:00:45.302+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:00:45.321+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:00:45.350+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:00:45.350+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:00:45.363+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:00:45.363+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T04:00:45.373+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.087 seconds
[2024-07-29T04:01:15.777+0000] {processor.py:157} INFO - Started process (PID=14464) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:01:15.778+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T04:01:15.782+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:01:15.781+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:01:15.792+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:01:15.810+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:01:15.810+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:01:15.821+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:01:15.821+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T04:01:15.832+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-29T04:01:46.178+0000] {processor.py:157} INFO - Started process (PID=14489) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:01:46.179+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T04:01:46.181+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:01:46.181+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:01:46.194+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:01:46.219+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:01:46.219+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:01:46.231+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:01:46.231+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T04:01:46.374+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.200 seconds
[2024-07-29T04:02:16.800+0000] {processor.py:157} INFO - Started process (PID=14514) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:02:16.801+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T04:02:16.804+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:02:16.804+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:02:16.815+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:02:16.832+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:02:16.832+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:02:16.913+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:02:16.913+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T04:02:16.921+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.125 seconds
[2024-07-29T04:02:47.406+0000] {processor.py:157} INFO - Started process (PID=14539) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:02:47.407+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T04:02:47.409+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:02:47.409+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:02:47.419+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:02:47.437+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:02:47.437+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:02:47.517+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:02:47.517+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T04:02:47.525+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.122 seconds
[2024-07-29T04:03:18.080+0000] {processor.py:157} INFO - Started process (PID=14564) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:03:18.081+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T04:03:18.084+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:03:18.084+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:03:18.104+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:03:18.225+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:03:18.225+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:03:18.233+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:03:18.233+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T04:03:18.241+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.168 seconds
[2024-07-29T04:03:48.770+0000] {processor.py:157} INFO - Started process (PID=14589) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:03:48.773+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T04:03:48.775+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:03:48.774+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:03:48.787+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:03:48.804+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:03:48.804+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:03:48.813+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:03:48.813+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T04:03:48.822+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-29T04:04:19.167+0000] {processor.py:157} INFO - Started process (PID=14614) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:04:19.168+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T04:04:19.173+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:04:19.173+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:04:19.191+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:04:19.211+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:04:19.211+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:04:19.220+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:04:19.220+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T04:04:19.229+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-29T04:04:49.583+0000] {processor.py:157} INFO - Started process (PID=14639) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:04:49.584+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T04:04:49.588+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:04:49.587+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:04:49.600+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:04:49.619+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:04:49.618+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:04:49.629+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:04:49.629+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T04:04:49.705+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.126 seconds
[2024-07-29T04:05:20.160+0000] {processor.py:157} INFO - Started process (PID=14664) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:05:20.161+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T04:05:20.164+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:05:20.164+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:05:20.174+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:05:20.191+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:05:20.191+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:05:20.272+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:05:20.272+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T04:05:20.280+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.124 seconds
[2024-07-29T04:05:50.789+0000] {processor.py:157} INFO - Started process (PID=14689) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:05:50.790+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T04:05:50.793+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:05:50.793+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:05:50.804+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:05:50.821+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:05:50.820+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:05:50.928+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:05:50.928+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T04:05:50.937+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.152 seconds
[2024-07-29T04:06:21.337+0000] {processor.py:157} INFO - Started process (PID=14714) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:06:21.338+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T04:06:21.343+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:06:21.342+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:06:21.361+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:06:21.456+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:06:21.456+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:06:21.464+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:06:21.464+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T04:06:21.473+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.142 seconds
[2024-07-29T04:06:51.906+0000] {processor.py:157} INFO - Started process (PID=14739) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:06:51.907+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T04:06:51.910+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:06:51.909+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:06:51.922+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:06:51.941+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:06:51.941+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:06:51.951+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:06:51.951+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T04:06:51.961+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-29T04:07:22.313+0000] {processor.py:157} INFO - Started process (PID=14764) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:07:22.313+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T04:07:22.316+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:07:22.315+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:07:22.324+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:07:22.339+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:07:22.339+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:07:22.351+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:07:22.351+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T04:07:22.361+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-29T04:07:52.766+0000] {processor.py:157} INFO - Started process (PID=14789) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:07:52.767+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T04:07:52.770+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:07:52.770+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:07:52.782+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:07:52.801+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:07:52.801+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:07:52.913+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:07:52.912+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T04:07:52.921+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.159 seconds
[2024-07-29T04:08:23.462+0000] {processor.py:157} INFO - Started process (PID=14814) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:08:23.465+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T04:08:23.473+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:08:23.472+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:08:23.490+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:08:23.516+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:08:23.516+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:08:23.612+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:08:23.612+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T04:08:23.621+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.176 seconds
[2024-07-29T04:08:54.165+0000] {processor.py:157} INFO - Started process (PID=14839) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:08:54.166+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T04:08:54.170+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:08:54.169+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:08:54.186+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:08:54.310+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:08:54.310+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:08:54.318+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:08:54.318+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T04:08:54.326+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.165 seconds
[2024-07-29T04:09:24.856+0000] {processor.py:157} INFO - Started process (PID=14864) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:09:24.858+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T04:09:24.864+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:09:24.864+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:09:24.961+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:09:24.974+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:09:24.974+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:09:24.982+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:09:24.982+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T04:09:24.990+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.140 seconds
[2024-07-29T04:09:55.482+0000] {processor.py:157} INFO - Started process (PID=14889) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:09:55.483+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T04:09:55.485+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:09:55.484+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:09:55.495+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:09:55.524+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:09:55.524+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:09:55.536+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:09:55.536+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T04:09:55.544+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.065 seconds
[2024-07-29T04:10:25.930+0000] {processor.py:157} INFO - Started process (PID=14914) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:10:25.931+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T04:10:25.934+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:10:25.934+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:10:25.947+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:10:25.964+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:10:25.964+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:10:25.975+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:10:25.974+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T04:10:26.081+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.156 seconds
[2024-07-29T04:10:56.501+0000] {processor.py:157} INFO - Started process (PID=14939) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:10:56.502+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T04:10:56.507+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:10:56.506+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:10:56.524+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:10:56.546+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:10:56.546+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:10:56.628+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:10:56.628+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T04:10:56.637+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.143 seconds
[2024-07-29T04:11:27.071+0000] {processor.py:157} INFO - Started process (PID=14964) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:11:27.073+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T04:11:27.078+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:11:27.078+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:11:27.101+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:11:27.124+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:11:27.123+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:11:27.250+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:11:27.250+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T04:11:27.260+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.203 seconds
[2024-07-29T04:11:57.667+0000] {processor.py:157} INFO - Started process (PID=14989) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:11:57.668+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T04:11:57.673+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:11:57.673+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:11:57.686+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:11:57.801+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:11:57.801+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:11:57.809+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:11:57.809+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T04:11:57.818+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.155 seconds
[2024-07-29T04:12:28.210+0000] {processor.py:157} INFO - Started process (PID=15014) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:12:28.211+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T04:12:28.216+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:12:28.215+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:12:28.230+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:12:28.254+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:12:28.254+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:12:28.267+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:12:28.267+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T04:12:28.278+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.073 seconds
[2024-07-29T04:12:58.647+0000] {processor.py:157} INFO - Started process (PID=15039) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:12:58.647+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T04:12:58.651+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:12:58.651+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:12:58.686+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:12:58.711+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:12:58.711+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:12:58.724+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:12:58.724+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T04:12:58.734+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.091 seconds
[2024-07-29T04:13:29.150+0000] {processor.py:157} INFO - Started process (PID=15064) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:13:29.151+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T04:13:29.155+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:13:29.154+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:13:29.166+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:13:29.182+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:13:29.182+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:13:29.192+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:13:29.192+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T04:13:29.302+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.155 seconds
[2024-07-29T04:13:59.677+0000] {processor.py:157} INFO - Started process (PID=15089) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:13:59.680+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T04:13:59.682+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:13:59.682+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:13:59.698+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:13:59.717+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:13:59.717+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:13:59.803+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:13:59.803+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T04:13:59.811+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.138 seconds
[2024-07-29T04:14:30.251+0000] {processor.py:157} INFO - Started process (PID=15114) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:14:30.252+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T04:14:30.255+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:14:30.255+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:14:30.266+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:14:30.283+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:14:30.283+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:14:30.361+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:14:30.361+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T04:14:30.367+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.121 seconds
[2024-07-29T04:15:00.792+0000] {processor.py:157} INFO - Started process (PID=15139) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:15:00.792+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T04:15:00.796+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:15:00.795+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:15:00.816+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:15:00.945+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:15:00.945+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:15:00.955+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:15:00.955+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T04:15:00.963+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.177 seconds
[2024-07-29T04:15:31.442+0000] {processor.py:157} INFO - Started process (PID=15164) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:15:31.443+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T04:15:31.449+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:15:31.448+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:15:31.460+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:15:31.481+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:15:31.480+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:15:31.491+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:15:31.490+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T04:15:31.500+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-29T04:16:01.875+0000] {processor.py:157} INFO - Started process (PID=15189) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:16:01.877+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T04:16:01.887+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:16:01.885+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:16:01.907+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:16:01.942+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:16:01.942+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:16:01.955+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:16:01.955+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T04:16:01.967+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.097 seconds
[2024-07-29T04:16:32.358+0000] {processor.py:157} INFO - Started process (PID=15214) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:16:32.359+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T04:16:32.364+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:16:32.364+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:16:32.383+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:16:32.398+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:16:32.398+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:16:32.600+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:16:32.600+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T04:16:32.608+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.254 seconds
[2024-07-29T04:17:03.137+0000] {processor.py:157} INFO - Started process (PID=15239) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:17:03.138+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T04:17:03.142+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:17:03.142+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:17:03.155+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:17:03.174+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:17:03.174+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:17:03.264+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:17:03.264+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T04:17:03.273+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.139 seconds
[2024-07-29T04:17:33.710+0000] {processor.py:157} INFO - Started process (PID=15264) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:17:33.711+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T04:17:33.716+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:17:33.715+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:17:33.734+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:17:33.831+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:17:33.831+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:17:33.839+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:17:33.839+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T04:17:33.846+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.142 seconds
[2024-07-29T04:18:04.407+0000] {processor.py:157} INFO - Started process (PID=15289) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:18:04.408+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T04:18:04.411+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:18:04.411+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:18:04.503+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:18:04.515+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:18:04.515+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:18:04.522+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:18:04.522+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T04:18:04.530+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.127 seconds
[2024-07-29T04:18:34.880+0000] {processor.py:157} INFO - Started process (PID=15314) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:18:34.881+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T04:18:34.882+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:18:34.882+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:18:34.890+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:18:34.907+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:18:34.906+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:18:34.916+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:18:34.916+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T04:18:34.923+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.045 seconds
[2024-07-29T04:19:05.275+0000] {processor.py:157} INFO - Started process (PID=15339) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:19:05.276+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T04:19:05.279+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:19:05.279+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:19:05.292+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:19:05.311+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:19:05.311+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:19:05.321+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:19:05.321+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T04:19:05.442+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.173 seconds
[2024-07-29T04:19:35.905+0000] {processor.py:157} INFO - Started process (PID=15364) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:19:35.906+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T04:19:35.909+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:19:35.908+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:19:35.921+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:19:35.941+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:19:35.941+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:19:36.018+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:19:36.018+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T04:19:36.026+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.125 seconds
[2024-07-29T04:20:06.592+0000] {processor.py:157} INFO - Started process (PID=15389) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:20:06.593+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T04:20:06.599+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:20:06.599+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:20:06.615+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:20:06.637+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:20:06.637+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:20:06.717+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:20:06.717+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T04:20:06.725+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.139 seconds
[2024-07-29T04:20:37.282+0000] {processor.py:157} INFO - Started process (PID=15414) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:20:37.282+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T04:20:37.287+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:20:37.286+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:20:37.298+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:20:37.387+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:20:37.387+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:20:37.395+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:20:37.395+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T04:20:37.402+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.125 seconds
[2024-07-29T04:21:07.948+0000] {processor.py:157} INFO - Started process (PID=15439) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:21:07.949+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T04:21:07.950+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:21:07.950+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:21:08.057+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:21:08.070+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:21:08.070+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:21:08.079+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:21:08.079+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T04:21:08.086+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.140 seconds
[2024-07-29T04:21:38.633+0000] {processor.py:157} INFO - Started process (PID=15464) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:21:38.635+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T04:21:38.651+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:21:38.644+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:21:38.689+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:21:38.717+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:21:38.717+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:21:38.731+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:21:38.731+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T04:21:38.747+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.123 seconds
[2024-07-29T04:22:09.178+0000] {processor.py:157} INFO - Started process (PID=15489) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:22:09.179+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T04:22:09.184+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:22:09.183+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:22:09.202+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:22:09.228+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:22:09.228+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:22:09.241+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:22:09.241+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T04:22:09.252+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.089 seconds
[2024-07-29T04:22:39.707+0000] {processor.py:157} INFO - Started process (PID=15514) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:22:39.709+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T04:22:39.713+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:22:39.713+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:22:39.737+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:22:39.764+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:22:39.764+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:22:39.783+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:22:39.783+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T04:22:39.795+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.106 seconds
[2024-07-29T04:23:10.212+0000] {processor.py:157} INFO - Started process (PID=15539) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:23:10.212+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T04:23:10.216+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:23:10.215+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:23:10.231+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:23:10.254+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:23:10.254+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:23:10.270+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:23:10.270+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T04:23:10.284+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.078 seconds
[2024-07-29T04:23:40.769+0000] {processor.py:157} INFO - Started process (PID=15564) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:23:40.770+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T04:23:40.774+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:23:40.773+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:23:40.785+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:23:40.801+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:23:40.801+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:23:40.810+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:23:40.810+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T04:23:40.822+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-29T04:24:11.144+0000] {processor.py:157} INFO - Started process (PID=15589) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:24:11.146+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T04:24:11.150+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:24:11.149+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:24:11.166+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:24:11.198+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:24:11.198+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:24:11.212+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:24:11.212+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T04:24:11.223+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.084 seconds
[2024-07-29T04:24:41.662+0000] {processor.py:157} INFO - Started process (PID=15614) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:24:41.664+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T04:24:41.668+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:24:41.667+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:24:41.677+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:24:41.694+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:24:41.694+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:24:41.706+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:24:41.706+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T04:24:41.717+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-29T04:25:12.066+0000] {processor.py:157} INFO - Started process (PID=15639) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:25:12.067+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T04:25:12.070+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:25:12.070+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:25:12.082+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:25:12.099+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:25:12.098+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:25:12.109+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:25:12.109+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T04:25:12.119+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-29T04:25:42.502+0000] {processor.py:157} INFO - Started process (PID=15664) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:25:42.503+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T04:25:42.505+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:25:42.505+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:25:42.515+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:25:42.534+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:25:42.534+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:25:42.543+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:25:42.543+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T04:25:42.553+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-29T04:26:12.949+0000] {processor.py:157} INFO - Started process (PID=15689) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:26:12.951+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T04:26:12.955+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:26:12.955+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:26:12.970+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:26:12.992+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:26:12.992+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:26:13.005+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:26:13.004+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T04:26:13.015+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-29T04:26:43.392+0000] {processor.py:157} INFO - Started process (PID=15714) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:26:43.393+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T04:26:43.396+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:26:43.395+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:26:43.409+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:26:43.425+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:26:43.425+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:26:43.438+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:26:43.438+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T04:26:43.445+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-29T04:27:13.851+0000] {processor.py:157} INFO - Started process (PID=15739) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:27:13.852+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T04:27:13.854+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:27:13.854+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:27:13.868+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:27:13.885+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:27:13.885+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:27:13.898+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:27:13.897+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T04:27:13.907+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-29T04:27:44.213+0000] {processor.py:157} INFO - Started process (PID=15764) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:27:44.214+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T04:27:44.216+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:27:44.216+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:27:44.223+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:27:44.239+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:27:44.239+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:27:44.252+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:27:44.252+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T04:27:44.260+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-29T04:28:14.676+0000] {processor.py:157} INFO - Started process (PID=15789) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:28:14.677+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T04:28:14.681+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:28:14.681+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:28:14.697+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:28:14.718+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:28:14.718+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:28:14.732+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:28:14.732+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T04:28:14.742+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.072 seconds
[2024-07-29T04:28:45.094+0000] {processor.py:157} INFO - Started process (PID=15814) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:28:45.096+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T04:28:45.099+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:28:45.099+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:28:45.109+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:28:45.126+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:28:45.126+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:28:45.138+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:28:45.138+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T04:28:45.146+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-29T04:36:17.581+0000] {processor.py:157} INFO - Started process (PID=15839) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:36:17.582+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T04:36:17.586+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:36:17.585+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:36:17.601+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:36:17.623+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:36:17.623+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:36:17.636+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:36:17.636+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T04:36:17.646+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.072 seconds
[2024-07-29T04:52:29.723+0000] {processor.py:157} INFO - Started process (PID=15866) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:52:29.725+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T04:52:29.730+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:52:29.729+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:52:29.769+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:52:29.800+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:52:29.800+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:52:29.832+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:52:29.832+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T04:52:29.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.129 seconds
[2024-07-29T04:53:00.426+0000] {processor.py:157} INFO - Started process (PID=15891) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:53:00.429+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T04:53:00.434+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:53:00.434+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:53:00.451+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:53:00.473+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:53:00.473+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:53:00.496+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:53:00.496+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T04:53:00.507+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.087 seconds
[2024-07-29T04:53:30.833+0000] {processor.py:157} INFO - Started process (PID=15916) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:53:30.834+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T04:53:30.837+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:53:30.836+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:53:30.847+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:53:30.864+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:53:30.864+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:53:30.875+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:53:30.875+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T04:53:30.883+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-29T04:54:01.276+0000] {processor.py:157} INFO - Started process (PID=15941) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:54:01.277+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T04:54:01.280+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:54:01.279+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:54:01.290+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:54:01.306+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:54:01.306+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:54:01.320+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:54:01.320+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T04:54:01.328+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-29T04:54:31.740+0000] {processor.py:157} INFO - Started process (PID=15966) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:54:31.741+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T04:54:31.743+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:54:31.743+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:54:31.752+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T04:54:31.770+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:54:31.770+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:54:31.779+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:54:31.779+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T04:54:31.787+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-29T05:05:23.303+0000] {processor.py:157} INFO - Started process (PID=15991) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T05:05:23.304+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T05:05:23.307+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:05:23.306+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T05:05:23.321+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T05:05:23.341+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:05:23.341+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T05:05:23.370+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:05:23.370+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T05:05:23.387+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.087 seconds
[2024-07-29T05:05:53.833+0000] {processor.py:157} INFO - Started process (PID=16018) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T05:05:53.834+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T05:05:53.838+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:05:53.837+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T05:05:53.856+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T05:05:53.884+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:05:53.884+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T05:05:53.897+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:05:53.897+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T05:05:53.907+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.080 seconds
[2024-07-29T05:06:24.344+0000] {processor.py:157} INFO - Started process (PID=16043) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T05:06:24.345+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T05:06:24.349+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:06:24.349+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T05:06:24.363+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T05:06:24.380+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:06:24.380+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T05:06:24.390+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:06:24.390+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T05:06:24.399+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-29T05:06:54.811+0000] {processor.py:157} INFO - Started process (PID=16068) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T05:06:54.812+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T05:06:54.814+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:06:54.814+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T05:06:54.826+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T05:06:54.844+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:06:54.844+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T05:06:54.856+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:06:54.856+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T05:06:54.865+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-29T05:07:25.266+0000] {processor.py:157} INFO - Started process (PID=16093) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T05:07:25.267+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T05:07:25.271+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:07:25.270+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T05:07:25.283+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T05:07:25.301+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:07:25.300+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T05:07:25.311+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:07:25.311+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T05:07:25.320+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-29T05:07:55.703+0000] {processor.py:157} INFO - Started process (PID=16118) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T05:07:55.704+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T05:07:55.707+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:07:55.707+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T05:07:55.719+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T05:07:55.735+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:07:55.735+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T05:07:55.748+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:07:55.748+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T05:07:55.758+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-29T05:24:30.594+0000] {processor.py:157} INFO - Started process (PID=16143) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T05:24:30.596+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T05:24:30.601+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:24:30.601+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T05:24:30.617+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T05:24:30.641+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:24:30.641+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T05:24:30.656+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:24:30.656+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T05:24:30.666+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.075 seconds
[2024-07-29T05:25:01.105+0000] {processor.py:157} INFO - Started process (PID=16170) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T05:25:01.108+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T05:25:01.112+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:25:01.112+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T05:25:01.133+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T05:25:01.155+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:25:01.155+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T05:25:01.168+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:25:01.168+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T05:25:01.179+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.080 seconds
[2024-07-29T05:25:31.598+0000] {processor.py:157} INFO - Started process (PID=16195) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T05:25:31.599+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T05:25:31.602+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:25:31.602+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T05:25:31.615+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T05:25:31.633+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:25:31.633+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T05:25:31.644+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:25:31.644+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T05:25:31.654+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-29T05:26:02.100+0000] {processor.py:157} INFO - Started process (PID=16220) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T05:26:02.101+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T05:26:02.104+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:26:02.104+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T05:26:02.115+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T05:26:02.132+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:26:02.132+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T05:26:02.146+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:26:02.146+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T05:26:02.155+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-29T05:26:32.527+0000] {processor.py:157} INFO - Started process (PID=16245) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T05:26:32.528+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T05:26:32.531+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:26:32.530+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T05:26:32.540+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T05:26:32.559+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:26:32.559+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T05:26:32.569+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:26:32.569+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T05:26:32.577+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-29T05:27:02.923+0000] {processor.py:157} INFO - Started process (PID=16270) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T05:27:02.925+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T05:27:02.929+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:27:02.929+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T05:27:02.940+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T05:27:02.959+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:27:02.959+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T05:27:02.972+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:27:02.972+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T05:27:02.979+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-29T05:27:33.422+0000] {processor.py:157} INFO - Started process (PID=16295) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T05:27:33.423+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T05:27:33.429+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:27:33.429+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T05:27:33.443+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T05:27:33.464+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:27:33.464+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T05:27:33.479+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:27:33.479+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T05:27:33.487+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.072 seconds
[2024-07-29T05:28:03.928+0000] {processor.py:157} INFO - Started process (PID=16320) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T05:28:03.929+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T05:28:03.931+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:28:03.930+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T05:28:03.941+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T05:28:03.959+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:28:03.959+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T05:28:03.969+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:28:03.969+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T05:28:03.979+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-29T05:28:34.418+0000] {processor.py:157} INFO - Started process (PID=16345) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T05:28:34.419+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T05:28:34.422+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:28:34.422+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T05:28:34.436+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T05:28:34.459+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:28:34.459+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T05:28:34.473+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:28:34.473+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T05:28:34.482+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.070 seconds
[2024-07-29T05:44:08.935+0000] {processor.py:157} INFO - Started process (PID=16370) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T05:44:08.936+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T05:44:08.941+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:44:08.941+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T05:44:08.964+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T05:44:08.999+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:44:08.999+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T05:44:09.031+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:44:09.031+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T05:44:09.046+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.115 seconds
[2024-07-29T05:44:39.567+0000] {processor.py:157} INFO - Started process (PID=16395) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T05:44:39.568+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T05:44:39.572+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:44:39.571+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T05:44:39.590+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T05:44:39.612+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:44:39.612+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T05:44:39.624+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:44:39.624+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T05:44:39.634+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.074 seconds
[2024-07-29T05:45:10.034+0000] {processor.py:157} INFO - Started process (PID=16420) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T05:45:10.035+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T05:45:10.037+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:45:10.037+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T05:45:10.048+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T05:45:10.064+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:45:10.064+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T05:45:10.075+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:45:10.075+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T05:45:10.084+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-29T05:45:40.501+0000] {processor.py:157} INFO - Started process (PID=16445) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T05:45:40.502+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T05:45:40.504+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:45:40.504+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T05:45:40.515+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T05:45:40.531+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:45:40.531+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T05:45:40.541+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:45:40.541+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T05:45:40.550+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-29T05:46:10.924+0000] {processor.py:157} INFO - Started process (PID=16470) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T05:46:10.925+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T05:46:10.928+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:46:10.928+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T05:46:10.941+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T05:46:10.962+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:46:10.962+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T05:46:10.974+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:46:10.974+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T05:46:10.989+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-29T05:47:03.667+0000] {processor.py:157} INFO - Started process (PID=16495) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T05:47:03.668+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T05:47:03.670+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:47:03.670+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T05:47:03.682+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T05:47:03.700+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:47:03.700+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T05:47:03.710+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:47:03.710+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T05:47:03.720+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-29T05:47:34.190+0000] {processor.py:157} INFO - Started process (PID=16520) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T05:47:34.191+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T05:47:34.195+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:47:34.195+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T05:47:34.210+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T05:47:34.230+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:47:34.230+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T05:47:34.240+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:47:34.240+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T05:47:34.248+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-29T05:48:04.695+0000] {processor.py:157} INFO - Started process (PID=16545) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T05:48:04.695+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T05:48:04.698+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:48:04.698+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T05:48:04.708+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T05:48:04.727+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:48:04.727+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T05:48:04.736+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:48:04.736+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T05:48:04.745+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-29T05:48:35.183+0000] {processor.py:157} INFO - Started process (PID=16570) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T05:48:35.187+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T05:48:35.191+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:48:35.191+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T05:48:35.207+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T05:48:35.228+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:48:35.228+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T05:48:35.241+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:48:35.241+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T05:48:35.251+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.073 seconds
[2024-07-29T05:49:05.745+0000] {processor.py:157} INFO - Started process (PID=16595) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T05:49:05.746+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T05:49:05.751+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:49:05.751+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T05:49:05.763+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T05:49:05.781+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:49:05.781+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T05:49:05.791+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:49:05.791+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T05:49:05.803+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-29T06:02:46.507+0000] {processor.py:157} INFO - Started process (PID=16620) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T06:02:46.511+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T06:02:46.515+0000] {logging_mixin.py:151} INFO - [2024-07-29T06:02:46.514+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T06:02:46.552+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T06:02:46.591+0000] {logging_mixin.py:151} INFO - [2024-07-29T06:02:46.591+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T06:02:46.612+0000] {logging_mixin.py:151} INFO - [2024-07-29T06:02:46.612+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T06:02:46.634+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.133 seconds
[2024-07-29T06:03:17.164+0000] {processor.py:157} INFO - Started process (PID=16645) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T06:03:17.166+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T06:03:17.171+0000] {logging_mixin.py:151} INFO - [2024-07-29T06:03:17.171+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T06:03:17.190+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T06:03:17.212+0000] {logging_mixin.py:151} INFO - [2024-07-29T06:03:17.212+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T06:03:17.226+0000] {logging_mixin.py:151} INFO - [2024-07-29T06:03:17.226+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T06:03:17.234+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.080 seconds
[2024-07-29T06:03:47.610+0000] {processor.py:157} INFO - Started process (PID=16670) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T06:03:47.611+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T06:03:47.614+0000] {logging_mixin.py:151} INFO - [2024-07-29T06:03:47.614+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T06:03:47.625+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T06:03:47.641+0000] {logging_mixin.py:151} INFO - [2024-07-29T06:03:47.641+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T06:03:47.652+0000] {logging_mixin.py:151} INFO - [2024-07-29T06:03:47.652+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T06:03:47.669+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-29T06:04:18.057+0000] {processor.py:157} INFO - Started process (PID=16695) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T06:04:18.059+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T06:04:18.061+0000] {logging_mixin.py:151} INFO - [2024-07-29T06:04:18.060+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T06:04:18.075+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T06:04:18.087+0000] {logging_mixin.py:151} INFO - [2024-07-29T06:04:18.087+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T06:04:18.096+0000] {logging_mixin.py:151} INFO - [2024-07-29T06:04:18.096+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T06:04:18.104+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-29T06:11:18.650+0000] {processor.py:157} INFO - Started process (PID=16720) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T06:11:18.651+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T06:11:18.654+0000] {logging_mixin.py:151} INFO - [2024-07-29T06:11:18.654+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T06:11:18.670+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T06:11:18.700+0000] {logging_mixin.py:151} INFO - [2024-07-29T06:11:18.700+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T06:11:18.717+0000] {logging_mixin.py:151} INFO - [2024-07-29T06:11:18.717+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T06:11:18.733+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.086 seconds
[2024-07-29T06:11:49.283+0000] {processor.py:157} INFO - Started process (PID=16747) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T06:11:49.284+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T06:11:49.287+0000] {logging_mixin.py:151} INFO - [2024-07-29T06:11:49.287+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T06:11:49.299+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T06:11:49.315+0000] {logging_mixin.py:151} INFO - [2024-07-29T06:11:49.315+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T06:11:49.324+0000] {logging_mixin.py:151} INFO - [2024-07-29T06:11:49.324+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T06:11:49.332+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-29T06:29:04.395+0000] {processor.py:157} INFO - Started process (PID=16772) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T06:29:04.396+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T06:29:04.402+0000] {logging_mixin.py:151} INFO - [2024-07-29T06:29:04.401+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T06:29:04.424+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T06:29:04.459+0000] {logging_mixin.py:151} INFO - [2024-07-29T06:29:04.459+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T06:29:04.479+0000] {logging_mixin.py:151} INFO - [2024-07-29T06:29:04.478+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T06:29:04.494+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.104 seconds
[2024-07-29T06:44:53.818+0000] {processor.py:157} INFO - Started process (PID=16797) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T06:44:53.820+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T06:44:53.824+0000] {logging_mixin.py:151} INFO - [2024-07-29T06:44:53.823+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T06:44:53.841+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T06:44:53.865+0000] {logging_mixin.py:151} INFO - [2024-07-29T06:44:53.865+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T06:44:53.879+0000] {logging_mixin.py:151} INFO - [2024-07-29T06:44:53.879+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T06:44:53.889+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.077 seconds
[2024-07-29T06:45:24.260+0000] {processor.py:157} INFO - Started process (PID=16822) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T06:45:24.262+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T06:45:24.267+0000] {logging_mixin.py:151} INFO - [2024-07-29T06:45:24.266+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T06:45:24.287+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T06:45:24.313+0000] {logging_mixin.py:151} INFO - [2024-07-29T06:45:24.313+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T06:45:24.327+0000] {logging_mixin.py:151} INFO - [2024-07-29T06:45:24.327+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T06:45:24.337+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.082 seconds
[2024-07-29T06:45:54.799+0000] {processor.py:157} INFO - Started process (PID=16847) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T06:45:54.800+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T06:45:54.803+0000] {logging_mixin.py:151} INFO - [2024-07-29T06:45:54.803+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T06:45:54.815+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T06:45:54.831+0000] {logging_mixin.py:151} INFO - [2024-07-29T06:45:54.830+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T06:45:54.841+0000] {logging_mixin.py:151} INFO - [2024-07-29T06:45:54.841+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T06:45:54.850+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-29T06:46:25.260+0000] {processor.py:157} INFO - Started process (PID=16872) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T06:46:25.262+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T06:46:25.268+0000] {logging_mixin.py:151} INFO - [2024-07-29T06:46:25.268+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T06:46:25.283+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T06:46:25.306+0000] {logging_mixin.py:151} INFO - [2024-07-29T06:46:25.306+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T06:46:25.320+0000] {logging_mixin.py:151} INFO - [2024-07-29T06:46:25.320+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T06:46:25.330+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.076 seconds
[2024-07-29T06:46:55.744+0000] {processor.py:157} INFO - Started process (PID=16897) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T06:46:55.744+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T06:46:55.747+0000] {logging_mixin.py:151} INFO - [2024-07-29T06:46:55.747+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T06:46:55.756+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T06:46:55.772+0000] {logging_mixin.py:151} INFO - [2024-07-29T06:46:55.771+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T06:46:55.782+0000] {logging_mixin.py:151} INFO - [2024-07-29T06:46:55.782+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T06:46:55.790+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-29T07:03:27.252+0000] {processor.py:157} INFO - Started process (PID=16924) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:03:27.253+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T07:03:27.259+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:03:27.258+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:03:27.290+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:03:27.324+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:03:27.324+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T07:03:27.356+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:03:27.355+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T07:03:27.372+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.126 seconds
[2024-07-29T07:03:57.891+0000] {processor.py:157} INFO - Started process (PID=16949) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:03:57.894+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T07:03:57.896+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:03:57.896+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:03:57.908+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:03:57.924+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:03:57.924+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T07:03:57.936+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:03:57.936+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T07:03:57.946+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-29T07:04:28.342+0000] {processor.py:157} INFO - Started process (PID=16974) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:04:28.343+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T07:04:28.347+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:04:28.347+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:04:28.368+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:04:28.396+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:04:28.396+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T07:04:28.410+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:04:28.410+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T07:04:28.419+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.083 seconds
[2024-07-29T07:04:58.770+0000] {processor.py:157} INFO - Started process (PID=16999) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:04:58.771+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T07:04:58.772+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:04:58.772+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:04:58.782+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:04:58.800+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:04:58.800+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T07:04:58.810+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:04:58.810+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T07:04:58.822+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-29T07:21:01.130+0000] {processor.py:157} INFO - Started process (PID=17026) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:21:01.132+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T07:21:01.138+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:21:01.137+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:21:01.154+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:21:01.182+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:21:01.182+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T07:21:01.200+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:21:01.200+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T07:21:01.219+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.092 seconds
[2024-07-29T07:21:31.624+0000] {processor.py:157} INFO - Started process (PID=17051) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:21:31.625+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T07:21:31.629+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:21:31.629+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:21:31.639+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:21:31.658+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:21:31.658+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T07:21:31.669+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:21:31.669+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T07:21:31.679+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-29T07:22:02.071+0000] {processor.py:157} INFO - Started process (PID=17076) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:22:02.073+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T07:22:02.077+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:22:02.077+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:22:02.093+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:22:02.117+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:22:02.117+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T07:22:02.133+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:22:02.133+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T07:22:02.145+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.081 seconds
[2024-07-29T07:22:32.568+0000] {processor.py:157} INFO - Started process (PID=17101) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:22:32.569+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T07:22:32.572+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:22:32.572+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:22:32.583+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:22:32.601+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:22:32.600+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T07:22:32.613+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:22:32.613+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T07:22:32.621+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-29T07:23:02.995+0000] {processor.py:157} INFO - Started process (PID=17126) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:23:02.996+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T07:23:02.998+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:23:02.997+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:23:03.009+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:23:03.026+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:23:03.026+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T07:23:03.035+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:23:03.035+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T07:23:03.045+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-29T07:28:24.747+0000] {processor.py:157} INFO - Started process (PID=17153) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:28:24.748+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T07:28:24.752+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:28:24.751+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:28:24.766+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:28:24.788+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:28:24.788+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T07:28:24.799+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:28:24.799+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T07:28:24.810+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-29T07:28:55.176+0000] {processor.py:157} INFO - Started process (PID=17178) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:28:55.178+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T07:28:55.180+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:28:55.180+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:28:55.195+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:28:55.215+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:28:55.215+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T07:28:55.227+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:28:55.227+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T07:28:55.237+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.065 seconds
[2024-07-29T07:29:25.660+0000] {processor.py:157} INFO - Started process (PID=17203) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:29:25.662+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T07:29:25.664+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:29:25.664+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:29:25.676+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:29:25.691+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:29:25.691+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T07:29:25.703+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:29:25.703+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T07:29:25.713+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-29T07:29:56.058+0000] {processor.py:157} INFO - Started process (PID=17228) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:29:56.058+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T07:29:56.062+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:29:56.061+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:29:56.074+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:29:56.090+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:29:56.090+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T07:29:56.098+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:29:56.098+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T07:29:56.108+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-29T07:30:26.399+0000] {processor.py:157} INFO - Started process (PID=17253) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:30:26.400+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T07:30:26.403+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:30:26.402+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:30:26.412+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:30:26.428+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:30:26.428+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T07:30:26.442+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:30:26.442+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T07:30:26.451+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-29T07:30:56.839+0000] {processor.py:157} INFO - Started process (PID=17278) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:30:56.840+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T07:30:56.844+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:30:56.843+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:30:56.855+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:30:56.871+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:30:56.870+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T07:30:56.880+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:30:56.880+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T07:30:56.888+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-29T07:31:27.227+0000] {processor.py:157} INFO - Started process (PID=17303) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:31:27.228+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T07:31:27.230+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:31:27.230+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:31:27.241+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:31:27.257+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:31:27.257+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T07:31:27.267+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:31:27.267+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T07:31:27.278+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-29T07:31:57.668+0000] {processor.py:157} INFO - Started process (PID=17328) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:31:57.669+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T07:31:57.671+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:31:57.671+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:31:57.683+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:31:57.699+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:31:57.699+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T07:31:57.710+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:31:57.710+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T07:31:57.719+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-29T07:32:28.058+0000] {processor.py:157} INFO - Started process (PID=17353) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:32:28.059+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T07:32:28.061+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:32:28.060+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:32:28.069+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:32:28.085+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:32:28.085+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T07:32:28.102+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:32:28.102+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T07:32:28.109+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-29T07:32:58.458+0000] {processor.py:157} INFO - Started process (PID=17378) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:32:58.459+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T07:32:58.461+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:32:58.461+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:32:58.471+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:32:58.487+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:32:58.487+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T07:32:58.500+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:32:58.500+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T07:32:58.509+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-29T07:33:28.989+0000] {processor.py:157} INFO - Started process (PID=17403) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:33:28.990+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T07:33:28.997+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:33:28.997+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:33:29.013+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:33:29.037+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:33:29.037+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T07:33:29.050+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:33:29.050+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T07:33:29.060+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.077 seconds
[2024-07-29T07:33:59.471+0000] {processor.py:157} INFO - Started process (PID=17428) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:33:59.472+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T07:33:59.475+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:33:59.475+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:33:59.484+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:33:59.504+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:33:59.504+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T07:33:59.515+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:33:59.515+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T07:33:59.524+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-29T07:34:29.918+0000] {processor.py:157} INFO - Started process (PID=17453) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:34:29.920+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T07:34:29.922+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:34:29.921+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:34:29.932+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:34:29.948+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:34:29.948+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T07:34:29.958+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:34:29.958+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T07:34:29.966+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-29T07:35:00.347+0000] {processor.py:157} INFO - Started process (PID=17478) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:35:00.348+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T07:35:00.353+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:35:00.353+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:35:00.367+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:35:00.391+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:35:00.391+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T07:35:00.404+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:35:00.404+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T07:35:00.414+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-29T07:35:30.779+0000] {processor.py:157} INFO - Started process (PID=17503) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:35:30.779+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T07:35:30.782+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:35:30.782+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:35:30.791+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:35:30.808+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:35:30.808+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T07:35:30.818+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:35:30.818+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T07:35:30.830+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-29T07:36:01.180+0000] {processor.py:157} INFO - Started process (PID=17528) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:36:01.182+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T07:36:01.184+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:36:01.184+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:36:01.196+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:36:01.214+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:36:01.214+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T07:36:01.228+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:36:01.228+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T07:36:01.237+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-29T07:36:31.604+0000] {processor.py:157} INFO - Started process (PID=17553) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:36:31.605+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T07:36:31.607+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:36:31.607+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:36:31.619+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:36:31.636+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:36:31.636+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T07:36:31.646+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:36:31.646+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T07:36:31.654+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-29T07:37:02.025+0000] {processor.py:157} INFO - Started process (PID=17578) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:37:02.026+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T07:37:02.028+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:37:02.028+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:37:02.038+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:37:02.054+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:37:02.054+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T07:37:02.067+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:37:02.067+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T07:37:02.074+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-29T07:37:32.402+0000] {processor.py:157} INFO - Started process (PID=17603) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:37:32.403+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T07:37:32.405+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:37:32.405+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:37:32.416+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:37:32.433+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:37:32.433+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T07:37:32.443+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:37:32.443+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T07:37:32.452+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-29T07:38:02.861+0000] {processor.py:157} INFO - Started process (PID=17628) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:38:02.862+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T07:38:02.865+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:38:02.865+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:38:02.875+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:38:02.891+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:38:02.891+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T07:38:02.902+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:38:02.902+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T07:38:02.909+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-29T07:38:33.323+0000] {processor.py:157} INFO - Started process (PID=17653) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:38:33.324+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T07:38:33.328+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:38:33.327+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:38:33.344+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:38:33.368+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:38:33.368+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T07:38:33.379+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:38:33.379+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T07:38:33.389+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.072 seconds
[2024-07-29T07:39:03.827+0000] {processor.py:157} INFO - Started process (PID=17678) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:39:03.828+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T07:39:03.832+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:39:03.832+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:39:03.842+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:39:03.857+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:39:03.857+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T07:39:03.870+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:39:03.870+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T07:39:03.879+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-29T07:39:34.302+0000] {processor.py:157} INFO - Started process (PID=17703) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:39:34.303+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T07:39:34.305+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:39:34.305+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:39:34.317+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:39:34.336+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:39:34.336+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T07:39:34.349+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:39:34.349+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T07:39:34.358+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-29T07:40:04.741+0000] {processor.py:157} INFO - Started process (PID=17728) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:40:04.742+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T07:40:04.744+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:40:04.744+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:40:04.753+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:40:04.772+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:40:04.772+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T07:40:04.781+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:40:04.781+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T07:40:04.791+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-29T07:40:35.200+0000] {processor.py:157} INFO - Started process (PID=17753) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:40:35.202+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T07:40:35.203+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:40:35.203+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:40:35.214+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:40:35.231+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:40:35.230+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T07:40:35.240+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:40:35.240+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T07:40:35.250+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-29T07:41:05.614+0000] {processor.py:157} INFO - Started process (PID=17778) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:41:05.615+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T07:41:05.619+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:41:05.619+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:41:05.631+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:41:05.658+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:41:05.658+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T07:41:05.670+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:41:05.670+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T07:41:05.681+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-29T07:41:36.138+0000] {processor.py:157} INFO - Started process (PID=17803) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:41:36.139+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T07:41:36.149+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:41:36.148+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:41:36.185+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:41:36.207+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:41:36.207+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T07:41:36.219+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:41:36.219+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T07:41:36.227+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.095 seconds
[2024-07-29T07:42:06.566+0000] {processor.py:157} INFO - Started process (PID=17828) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:42:06.567+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T07:42:06.570+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:42:06.570+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:42:06.586+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:42:06.602+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:42:06.602+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T07:42:06.612+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:42:06.612+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T07:42:06.623+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-29T07:42:37.069+0000] {processor.py:157} INFO - Started process (PID=17853) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:42:37.070+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T07:42:37.072+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:42:37.072+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:42:37.083+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:42:37.099+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:42:37.099+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T07:42:37.109+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:42:37.109+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T07:42:37.117+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-29T07:43:07.524+0000] {processor.py:157} INFO - Started process (PID=17878) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:43:07.532+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T07:43:07.535+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:43:07.535+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:43:07.554+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:43:07.580+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:43:07.580+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T07:43:07.593+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:43:07.592+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T07:43:07.603+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.086 seconds
[2024-07-29T07:43:53.345+0000] {processor.py:157} INFO - Started process (PID=17905) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:43:53.346+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T07:43:53.348+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:43:53.347+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:43:53.356+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:43:53.372+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:43:53.372+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T07:43:53.386+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:43:53.385+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T07:43:53.393+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-29T07:45:51.574+0000] {processor.py:157} INFO - Started process (PID=17930) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:45:51.575+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T07:45:51.579+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:45:51.578+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:45:51.589+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:45:51.605+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:45:51.605+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T07:45:51.615+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:45:51.615+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T07:45:51.624+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-29T07:46:22.047+0000] {processor.py:157} INFO - Started process (PID=17955) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:46:22.049+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T07:46:22.053+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:46:22.053+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:46:22.069+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T07:46:22.087+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:46:22.087+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T07:46:22.098+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:46:22.098+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T07:46:22.108+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.065 seconds
[2024-07-29T08:02:09.277+0000] {processor.py:157} INFO - Started process (PID=17980) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:02:09.278+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T08:02:09.281+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:02:09.280+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:02:09.295+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:02:09.315+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:02:09.315+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:02:09.324+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:02:09.324+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T08:02:09.338+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-29T08:02:39.756+0000] {processor.py:157} INFO - Started process (PID=18005) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:02:39.757+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T08:02:39.763+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:02:39.762+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:02:39.786+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:02:39.819+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:02:39.819+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:02:39.831+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:02:39.831+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T08:02:39.840+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.088 seconds
[2024-07-29T08:18:39.687+0000] {processor.py:157} INFO - Started process (PID=18030) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:18:39.689+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T08:18:39.696+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:18:39.695+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:18:39.706+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:18:39.725+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:18:39.725+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:18:39.742+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:18:39.742+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T08:18:39.751+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-29T08:19:10.171+0000] {processor.py:157} INFO - Started process (PID=18057) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:19:10.172+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T08:19:10.176+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:19:10.176+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:19:10.193+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:19:10.227+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:19:10.227+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:19:10.256+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:19:10.255+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T08:19:10.267+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.100 seconds
[2024-07-29T08:19:40.803+0000] {processor.py:157} INFO - Started process (PID=18082) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:19:40.804+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T08:19:40.807+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:19:40.807+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:19:40.822+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:19:40.838+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:19:40.838+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:19:40.850+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:19:40.850+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T08:19:40.861+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-29T08:20:11.281+0000] {processor.py:157} INFO - Started process (PID=18107) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:20:11.282+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T08:20:11.284+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:20:11.284+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:20:11.299+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:20:11.317+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:20:11.317+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:20:11.327+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:20:11.327+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T08:20:11.334+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-29T08:26:04.095+0000] {processor.py:157} INFO - Started process (PID=18132) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:26:04.097+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T08:26:04.103+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:26:04.103+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:26:04.137+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:26:04.185+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:26:04.184+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:26:04.200+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:26:04.200+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T08:26:04.212+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.136 seconds
[2024-07-29T08:26:34.647+0000] {processor.py:157} INFO - Started process (PID=18157) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:26:34.648+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T08:26:34.653+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:26:34.652+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:26:34.671+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:26:34.697+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:26:34.697+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:26:34.711+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:26:34.711+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T08:26:34.723+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.083 seconds
[2024-07-29T08:27:05.047+0000] {processor.py:157} INFO - Started process (PID=18182) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:27:05.048+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T08:27:05.050+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:27:05.049+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:27:05.058+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:27:05.074+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:27:05.074+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:27:05.086+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:27:05.086+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T08:27:05.098+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-29T08:27:35.602+0000] {processor.py:157} INFO - Started process (PID=18207) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:27:35.603+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T08:27:35.605+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:27:35.604+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:27:35.616+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:27:35.631+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:27:35.631+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:27:35.641+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:27:35.641+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T08:27:35.651+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-29T08:28:06.123+0000] {processor.py:157} INFO - Started process (PID=18232) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:28:06.125+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T08:28:06.129+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:28:06.129+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:28:06.147+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:28:06.171+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:28:06.171+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:28:06.183+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:28:06.183+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T08:28:06.192+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.075 seconds
[2024-07-29T08:28:36.566+0000] {processor.py:157} INFO - Started process (PID=18257) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:28:36.567+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T08:28:36.570+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:28:36.570+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:28:36.582+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:28:36.598+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:28:36.598+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:28:36.612+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:28:36.612+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T08:28:36.620+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-29T08:29:07.039+0000] {processor.py:157} INFO - Started process (PID=18282) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:29:07.040+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T08:29:07.042+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:29:07.042+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:29:07.052+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:29:07.070+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:29:07.070+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:29:07.079+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:29:07.079+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T08:29:07.088+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-29T08:29:37.483+0000] {processor.py:157} INFO - Started process (PID=18307) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:29:37.485+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T08:29:37.488+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:29:37.487+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:29:37.501+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:29:37.520+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:29:37.520+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:29:37.529+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:29:37.529+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T08:29:37.538+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-29T08:30:07.904+0000] {processor.py:157} INFO - Started process (PID=18332) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:30:07.905+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T08:30:07.908+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:30:07.908+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:30:07.918+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:30:07.936+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:30:07.936+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:30:07.947+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:30:07.947+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T08:30:07.957+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-29T08:30:38.282+0000] {processor.py:157} INFO - Started process (PID=18357) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:30:38.282+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T08:30:38.284+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:30:38.284+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:30:38.291+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:30:38.304+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:30:38.304+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:30:38.315+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:30:38.315+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T08:30:38.322+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.042 seconds
[2024-07-29T08:31:08.755+0000] {processor.py:157} INFO - Started process (PID=18382) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:31:08.756+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T08:31:08.758+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:31:08.758+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:31:08.771+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:31:08.788+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:31:08.788+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:31:08.801+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:31:08.801+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T08:31:08.810+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-29T08:31:39.230+0000] {processor.py:157} INFO - Started process (PID=18407) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:31:39.231+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T08:31:39.234+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:31:39.234+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:31:39.252+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:31:39.274+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:31:39.274+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:31:39.287+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:31:39.287+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T08:31:39.298+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.074 seconds
[2024-07-29T08:32:09.736+0000] {processor.py:157} INFO - Started process (PID=18432) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:32:09.737+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T08:32:09.739+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:32:09.739+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:32:09.750+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:32:09.769+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:32:09.769+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:32:09.778+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:32:09.778+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T08:32:09.787+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-29T08:32:40.218+0000] {processor.py:157} INFO - Started process (PID=18457) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:32:40.218+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T08:32:40.221+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:32:40.220+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:32:40.234+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:32:40.252+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:32:40.252+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:32:40.262+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:32:40.262+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T08:32:40.269+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-29T08:33:10.702+0000] {processor.py:157} INFO - Started process (PID=18482) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:33:10.703+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T08:33:10.706+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:33:10.706+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:33:10.716+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:33:10.734+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:33:10.734+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:33:10.748+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:33:10.748+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T08:33:10.758+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-29T08:33:41.167+0000] {processor.py:157} INFO - Started process (PID=18507) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:33:41.168+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T08:33:41.171+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:33:41.170+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:33:41.180+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:33:41.197+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:33:41.197+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:33:41.207+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:33:41.207+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T08:33:41.215+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-29T08:34:11.617+0000] {processor.py:157} INFO - Started process (PID=18532) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:34:11.617+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T08:34:11.621+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:34:11.621+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:34:11.639+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:34:11.663+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:34:11.663+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:34:11.675+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:34:11.675+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T08:34:11.686+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.075 seconds
[2024-07-29T08:34:42.156+0000] {processor.py:157} INFO - Started process (PID=18557) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:34:42.157+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T08:34:42.160+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:34:42.159+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:34:42.172+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:34:42.190+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:34:42.190+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:34:42.203+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:34:42.203+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T08:34:42.213+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-29T08:35:12.651+0000] {processor.py:157} INFO - Started process (PID=18582) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:35:12.654+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T08:35:12.656+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:35:12.656+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:35:12.667+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:35:12.685+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:35:12.685+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:35:12.697+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:35:12.697+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T08:35:12.709+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-29T08:35:43.106+0000] {processor.py:157} INFO - Started process (PID=18607) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:35:43.108+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T08:35:43.112+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:35:43.112+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:35:43.130+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:35:43.153+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:35:43.153+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:35:43.165+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:35:43.165+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T08:35:43.176+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.075 seconds
[2024-07-29T08:36:13.589+0000] {processor.py:157} INFO - Started process (PID=18632) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:36:13.589+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T08:36:13.592+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:36:13.592+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:36:13.606+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:36:13.623+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:36:13.623+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:36:13.635+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:36:13.635+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T08:36:13.644+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-29T08:36:44.008+0000] {processor.py:157} INFO - Started process (PID=18657) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:36:44.008+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T08:36:44.011+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:36:44.011+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:36:44.028+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:36:44.044+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:36:44.044+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:36:44.055+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:36:44.055+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T08:36:44.065+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-29T08:37:14.527+0000] {processor.py:157} INFO - Started process (PID=18682) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:37:14.527+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T08:37:14.529+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:37:14.529+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:37:14.540+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:37:14.559+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:37:14.559+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:37:14.570+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:37:14.570+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T08:37:14.579+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-29T08:37:44.940+0000] {processor.py:157} INFO - Started process (PID=18707) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:37:44.943+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T08:37:44.945+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:37:44.944+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:37:44.955+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:37:44.970+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:37:44.970+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:37:44.984+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:37:44.984+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T08:37:44.994+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-29T08:38:15.426+0000] {processor.py:157} INFO - Started process (PID=18732) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:38:15.426+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T08:38:15.428+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:38:15.428+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:38:15.438+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:38:15.453+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:38:15.453+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:38:15.463+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:38:15.463+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T08:38:15.472+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-29T08:38:45.762+0000] {processor.py:157} INFO - Started process (PID=18757) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:38:45.763+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T08:38:45.766+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:38:45.766+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:38:45.779+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:38:45.798+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:38:45.798+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:38:45.809+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:38:45.808+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T08:38:45.818+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-29T08:39:16.319+0000] {processor.py:157} INFO - Started process (PID=18782) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:39:16.320+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T08:39:16.323+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:39:16.323+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:39:16.337+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:39:16.362+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:39:16.362+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:39:16.375+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:39:16.375+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T08:39:16.385+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-29T08:39:46.778+0000] {processor.py:157} INFO - Started process (PID=18807) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:39:46.779+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T08:39:46.781+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:39:46.781+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:39:46.793+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:39:46.812+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:39:46.812+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:39:46.823+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:39:46.823+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T08:39:46.831+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-29T08:40:17.256+0000] {processor.py:157} INFO - Started process (PID=18832) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:40:17.257+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T08:40:17.260+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:40:17.259+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:40:17.270+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:40:17.287+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:40:17.287+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:40:17.298+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:40:17.298+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T08:40:17.307+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-29T08:40:47.762+0000] {processor.py:157} INFO - Started process (PID=18857) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:40:47.763+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T08:40:47.764+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:40:47.764+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:40:47.770+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:40:47.784+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:40:47.784+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:40:47.792+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:40:47.792+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T08:40:47.801+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.040 seconds
[2024-07-29T08:41:18.242+0000] {processor.py:157} INFO - Started process (PID=18882) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:41:18.243+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T08:41:18.246+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:41:18.246+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:41:18.265+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:41:18.287+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:41:18.287+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:41:18.302+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:41:18.301+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T08:41:18.311+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.075 seconds
[2024-07-29T08:41:48.780+0000] {processor.py:157} INFO - Started process (PID=18907) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:41:48.781+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T08:41:48.783+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:41:48.783+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:41:48.796+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:41:48.812+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:41:48.812+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:41:48.823+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:41:48.823+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T08:41:48.833+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-29T08:42:19.265+0000] {processor.py:157} INFO - Started process (PID=18932) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:42:19.266+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T08:42:19.268+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:42:19.268+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:42:19.279+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:42:19.297+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:42:19.297+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:42:19.312+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:42:19.312+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T08:42:19.322+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-29T08:42:49.735+0000] {processor.py:157} INFO - Started process (PID=18957) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:42:49.736+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T08:42:49.738+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:42:49.738+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:42:49.750+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:42:49.769+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:42:49.769+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:42:49.779+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:42:49.779+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T08:42:49.788+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-29T08:43:20.134+0000] {processor.py:157} INFO - Started process (PID=18982) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:43:20.135+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T08:43:20.139+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:43:20.139+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:43:20.156+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:43:20.178+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:43:20.178+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:43:20.190+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:43:20.190+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T08:43:20.201+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.072 seconds
[2024-07-29T08:43:50.674+0000] {processor.py:157} INFO - Started process (PID=19007) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:43:50.675+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T08:43:50.678+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:43:50.677+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:43:50.690+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:43:50.710+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:43:50.710+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:43:50.721+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:43:50.721+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T08:43:50.731+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-29T08:44:21.079+0000] {processor.py:157} INFO - Started process (PID=19032) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:44:21.079+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T08:44:21.080+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:44:21.080+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:44:21.087+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:44:21.102+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:44:21.102+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:44:21.117+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:44:21.117+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T08:44:21.126+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-29T08:44:51.520+0000] {processor.py:157} INFO - Started process (PID=19057) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:44:51.525+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T08:44:51.527+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:44:51.527+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:44:51.539+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:44:51.556+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:44:51.556+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:44:51.568+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:44:51.567+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T08:44:51.578+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-29T08:45:21.977+0000] {processor.py:157} INFO - Started process (PID=19082) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:45:21.978+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T08:45:21.980+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:45:21.980+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:45:21.991+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:45:22.008+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:45:22.008+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:45:22.019+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:45:22.019+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T08:45:22.030+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-29T08:45:52.461+0000] {processor.py:157} INFO - Started process (PID=19107) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:45:52.462+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T08:45:52.465+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:45:52.465+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:45:52.478+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:45:52.495+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:45:52.495+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:45:52.508+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:45:52.508+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T08:45:52.518+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-29T08:46:22.973+0000] {processor.py:157} INFO - Started process (PID=19132) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:46:22.975+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T08:46:22.979+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:46:22.978+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:46:23.003+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:46:23.028+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:46:23.028+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:46:23.040+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:46:23.040+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T08:46:23.051+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.084 seconds
[2024-07-29T08:46:53.486+0000] {processor.py:157} INFO - Started process (PID=19157) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:46:53.487+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T08:46:53.489+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:46:53.489+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:46:53.500+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:46:53.518+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:46:53.518+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:46:53.529+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:46:53.529+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T08:46:53.539+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-29T08:47:23.865+0000] {processor.py:157} INFO - Started process (PID=19182) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:47:23.866+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T08:47:23.868+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:47:23.868+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:47:23.880+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:47:23.898+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:47:23.898+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:47:23.909+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:47:23.909+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T08:47:23.917+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-29T08:47:54.233+0000] {processor.py:157} INFO - Started process (PID=19207) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:47:54.234+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T08:47:54.238+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:47:54.237+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:47:54.253+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:47:54.278+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:47:54.278+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:47:54.289+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:47:54.289+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T08:47:54.299+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.070 seconds
[2024-07-29T08:48:24.775+0000] {processor.py:157} INFO - Started process (PID=19232) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:48:24.776+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T08:48:24.778+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:48:24.778+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:48:24.789+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:48:24.805+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:48:24.805+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:48:24.815+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:48:24.815+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T08:48:24.823+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-29T08:48:55.224+0000] {processor.py:157} INFO - Started process (PID=19257) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:48:55.225+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T08:48:55.227+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:48:55.227+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:48:55.238+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:48:55.256+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:48:55.256+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:48:55.268+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:48:55.267+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T08:48:55.278+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-29T08:49:25.689+0000] {processor.py:157} INFO - Started process (PID=19282) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:49:25.690+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T08:49:25.692+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:49:25.692+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:49:25.705+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:49:25.723+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:49:25.723+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:49:25.733+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:49:25.733+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T08:49:25.743+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-29T08:49:56.100+0000] {processor.py:157} INFO - Started process (PID=19307) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:49:56.102+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T08:49:56.106+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:49:56.105+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:49:56.123+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:49:56.146+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:49:56.146+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:49:56.159+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:49:56.159+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T08:49:56.169+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.074 seconds
[2024-07-29T08:50:26.605+0000] {processor.py:157} INFO - Started process (PID=19332) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:50:26.606+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T08:50:26.608+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:50:26.608+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:50:26.621+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:50:26.640+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:50:26.640+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:50:26.653+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:50:26.653+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T08:50:26.662+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-29T08:50:57.146+0000] {processor.py:157} INFO - Started process (PID=19357) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:50:57.147+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T08:50:57.148+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:50:57.148+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:50:57.156+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:50:57.172+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:50:57.172+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:50:57.183+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:50:57.183+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T08:50:57.193+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-29T08:51:27.611+0000] {processor.py:157} INFO - Started process (PID=19382) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:51:27.613+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T08:51:27.617+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:51:27.617+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:51:27.636+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:51:27.657+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:51:27.657+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:51:27.668+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:51:27.668+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T08:51:27.677+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-29T08:51:58.107+0000] {processor.py:157} INFO - Started process (PID=19407) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:51:58.108+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T08:51:58.111+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:51:58.111+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:51:58.121+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:51:58.139+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:51:58.139+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:51:58.150+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:51:58.150+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T08:51:58.162+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-29T08:52:28.597+0000] {processor.py:157} INFO - Started process (PID=19432) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:52:28.598+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T08:52:28.601+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:52:28.601+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:52:28.611+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:52:28.629+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:52:28.629+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:52:28.642+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:52:28.642+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T08:52:28.650+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-29T08:52:59.092+0000] {processor.py:157} INFO - Started process (PID=19457) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:52:59.094+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T08:52:59.097+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:52:59.097+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:52:59.108+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:52:59.124+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:52:59.124+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:52:59.137+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:52:59.137+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T08:52:59.146+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-29T08:53:29.496+0000] {processor.py:157} INFO - Started process (PID=19482) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:53:29.497+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T08:53:29.499+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:53:29.498+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:53:29.511+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:53:29.527+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:53:29.527+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:53:29.537+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:53:29.537+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T08:53:29.547+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-29T08:53:59.955+0000] {processor.py:157} INFO - Started process (PID=19507) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:53:59.956+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T08:53:59.958+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:53:59.958+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:53:59.968+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:53:59.985+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:53:59.985+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:53:59.997+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:53:59.997+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T08:54:00.005+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-29T08:54:30.445+0000] {processor.py:157} INFO - Started process (PID=19532) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:54:30.445+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T08:54:30.447+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:54:30.446+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:54:30.453+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:54:30.466+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:54:30.466+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:54:30.477+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:54:30.477+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T08:54:30.485+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.042 seconds
[2024-07-29T08:55:00.954+0000] {processor.py:157} INFO - Started process (PID=19557) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:55:00.956+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T08:55:00.960+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:55:00.959+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:55:00.975+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:55:00.998+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:55:00.998+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:55:01.014+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:55:01.014+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T08:55:01.025+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.075 seconds
[2024-07-29T08:55:31.450+0000] {processor.py:157} INFO - Started process (PID=19582) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:55:31.450+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T08:55:31.452+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:55:31.452+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:55:31.462+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:55:31.479+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:55:31.479+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:55:31.489+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:55:31.489+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T08:55:31.497+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-29T08:56:01.924+0000] {processor.py:157} INFO - Started process (PID=19607) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:56:01.925+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T08:56:01.928+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:56:01.928+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:56:01.939+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:56:01.958+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:56:01.957+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:56:01.972+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:56:01.972+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T08:56:01.981+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-29T08:56:32.320+0000] {processor.py:157} INFO - Started process (PID=19632) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:56:32.320+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T08:56:32.322+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:56:32.322+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:56:32.333+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:56:32.352+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:56:32.352+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:56:32.361+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:56:32.361+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T08:56:32.370+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-29T08:57:02.744+0000] {processor.py:157} INFO - Started process (PID=19657) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:57:02.746+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T08:57:02.748+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:57:02.748+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:57:02.757+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:57:02.774+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:57:02.774+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:57:02.787+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:57:02.787+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T08:57:02.797+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-29T08:57:33.293+0000] {processor.py:157} INFO - Started process (PID=19682) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:57:33.294+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T08:57:33.296+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:57:33.296+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:57:33.306+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:57:33.321+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:57:33.321+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:57:33.332+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:57:33.332+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T08:57:33.342+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-29T08:58:03.891+0000] {processor.py:157} INFO - Started process (PID=19707) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:58:03.894+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T08:58:03.898+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:58:03.897+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:58:03.915+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:58:03.936+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:58:03.936+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:58:03.946+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:58:03.945+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T08:58:03.954+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.068 seconds
[2024-07-29T08:58:34.444+0000] {processor.py:157} INFO - Started process (PID=19732) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:58:34.445+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T08:58:34.447+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:58:34.446+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:58:34.455+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:58:34.471+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:58:34.471+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:58:34.485+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:58:34.485+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T08:58:34.494+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-29T08:59:04.909+0000] {processor.py:157} INFO - Started process (PID=19757) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:59:04.910+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T08:59:04.912+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:59:04.911+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:59:04.924+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:59:04.946+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:59:04.946+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:59:04.958+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:59:04.958+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T08:59:04.966+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-29T08:59:35.422+0000] {processor.py:157} INFO - Started process (PID=19782) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:59:35.423+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T08:59:35.426+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:59:35.425+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:59:35.437+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T08:59:35.454+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:59:35.454+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:59:35.464+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:59:35.464+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T08:59:35.473+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-29T09:00:05.970+0000] {processor.py:157} INFO - Started process (PID=19807) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:00:05.971+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:00:05.973+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:00:05.972+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:00:05.984+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:00:06.001+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:00:06.001+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:00:06.011+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:00:06.010+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:00:06.019+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-29T09:00:36.402+0000] {processor.py:157} INFO - Started process (PID=19832) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:00:36.422+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:00:36.425+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:00:36.425+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:00:36.439+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:00:36.459+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:00:36.459+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:00:36.474+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:00:36.474+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:00:36.482+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.086 seconds
[2024-07-29T09:01:06.882+0000] {processor.py:157} INFO - Started process (PID=19857) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:01:06.883+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:01:06.885+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:01:06.885+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:01:06.893+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:01:06.909+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:01:06.909+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:01:06.924+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:01:06.924+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:01:06.936+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-29T09:01:37.367+0000] {processor.py:157} INFO - Started process (PID=19882) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:01:37.368+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:01:37.370+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:01:37.370+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:01:37.381+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:01:37.399+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:01:37.399+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:01:37.409+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:01:37.409+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:01:37.419+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-29T09:02:07.756+0000] {processor.py:157} INFO - Started process (PID=19907) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:02:07.757+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:02:07.760+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:02:07.760+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:02:07.772+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:02:07.794+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:02:07.793+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:02:07.809+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:02:07.809+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:02:07.819+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-29T09:02:38.257+0000] {processor.py:157} INFO - Started process (PID=19932) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:02:38.258+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:02:38.260+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:02:38.260+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:02:38.268+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:02:38.284+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:02:38.283+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:02:38.295+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:02:38.294+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:02:38.304+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-29T09:03:08.737+0000] {processor.py:157} INFO - Started process (PID=19957) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:03:08.740+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:03:08.743+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:03:08.743+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:03:08.761+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:03:08.777+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:03:08.777+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:03:08.786+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:03:08.786+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:03:08.794+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-29T09:03:39.248+0000] {processor.py:157} INFO - Started process (PID=19982) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:03:39.249+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:03:39.251+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:03:39.251+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:03:39.261+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:03:39.279+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:03:39.279+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:03:39.288+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:03:39.288+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:03:39.297+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-29T09:04:09.719+0000] {processor.py:157} INFO - Started process (PID=20007) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:04:09.720+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:04:09.721+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:04:09.721+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:04:09.730+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:04:09.745+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:04:09.745+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:04:09.755+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:04:09.755+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:04:09.766+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-29T09:04:40.181+0000] {processor.py:157} INFO - Started process (PID=20032) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:04:40.182+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:04:40.183+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:04:40.183+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:04:40.196+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:04:40.213+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:04:40.213+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:04:40.226+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:04:40.225+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:04:40.234+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-29T09:05:10.651+0000] {processor.py:157} INFO - Started process (PID=20057) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:05:10.652+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:05:10.655+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:05:10.654+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:05:10.664+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:05:10.681+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:05:10.681+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:05:10.692+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:05:10.692+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:05:10.701+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-29T09:05:41.059+0000] {processor.py:157} INFO - Started process (PID=20082) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:05:41.060+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:05:41.064+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:05:41.064+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:05:41.087+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:05:41.105+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:05:41.105+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:05:41.114+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:05:41.114+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:05:41.123+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-29T09:06:11.556+0000] {processor.py:157} INFO - Started process (PID=20107) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:06:11.558+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:06:11.561+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:06:11.561+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:06:11.571+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:06:11.591+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:06:11.591+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:06:11.606+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:06:11.606+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:06:11.613+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-29T09:06:41.953+0000] {processor.py:157} INFO - Started process (PID=20132) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:06:41.954+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:06:41.957+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:06:41.957+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:06:41.971+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:06:41.989+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:06:41.989+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:06:42.000+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:06:41.999+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:06:42.009+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-29T09:07:12.461+0000] {processor.py:157} INFO - Started process (PID=20157) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:07:12.462+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:07:12.466+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:07:12.465+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:07:12.480+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:07:12.497+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:07:12.496+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:07:12.507+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:07:12.507+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:07:12.517+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-29T09:07:42.977+0000] {processor.py:157} INFO - Started process (PID=20182) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:07:42.977+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:07:42.978+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:07:42.978+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:07:42.984+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:07:42.998+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:07:42.997+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:07:43.008+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:07:43.008+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:07:43.016+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.041 seconds
[2024-07-29T09:08:13.375+0000] {processor.py:157} INFO - Started process (PID=20207) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:08:13.376+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:08:13.378+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:08:13.378+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:08:13.387+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:08:13.404+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:08:13.404+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:08:13.420+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:08:13.420+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:08:13.428+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-29T09:08:43.878+0000] {processor.py:157} INFO - Started process (PID=20232) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:08:43.878+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:08:43.880+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:08:43.880+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:08:43.891+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:08:43.909+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:08:43.909+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:08:43.919+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:08:43.919+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:08:43.929+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-29T09:09:14.271+0000] {processor.py:157} INFO - Started process (PID=20257) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:09:14.272+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:09:14.276+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:09:14.276+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:09:14.297+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:09:14.320+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:09:14.320+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:09:14.332+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:09:14.332+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:09:14.340+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.074 seconds
[2024-07-29T09:09:44.817+0000] {processor.py:157} INFO - Started process (PID=20282) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:09:44.819+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:09:44.821+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:09:44.821+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:09:44.831+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:09:44.847+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:09:44.847+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:09:44.859+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:09:44.859+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:09:44.868+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-29T09:10:15.223+0000] {processor.py:157} INFO - Started process (PID=20307) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:10:15.225+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:10:15.227+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:10:15.227+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:10:15.237+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:10:15.253+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:10:15.253+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:10:15.264+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:10:15.263+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:10:15.273+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-29T09:10:45.753+0000] {processor.py:157} INFO - Started process (PID=20332) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:10:45.754+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:10:45.756+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:10:45.756+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:10:45.766+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:10:45.785+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:10:45.785+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:10:45.795+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:10:45.795+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:10:45.801+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-29T09:11:16.172+0000] {processor.py:157} INFO - Started process (PID=20357) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:11:16.173+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:11:16.174+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:11:16.174+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:11:16.181+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:11:16.196+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:11:16.196+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:11:16.204+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:11:16.203+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:11:16.211+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.040 seconds
[2024-07-29T09:11:46.600+0000] {processor.py:157} INFO - Started process (PID=20382) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:11:46.601+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:11:46.603+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:11:46.603+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:11:46.614+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:11:46.636+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:11:46.636+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:11:46.650+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:11:46.650+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:11:46.658+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-29T09:12:17.028+0000] {processor.py:157} INFO - Started process (PID=20407) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:12:17.029+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:12:17.031+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:12:17.030+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:12:17.039+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:12:17.053+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:12:17.053+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:12:17.066+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:12:17.066+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:12:17.077+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-29T09:12:47.552+0000] {processor.py:157} INFO - Started process (PID=20432) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:12:47.553+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:12:47.555+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:12:47.555+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:12:47.565+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:12:47.580+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:12:47.580+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:12:47.590+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:12:47.590+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:12:47.599+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-29T09:13:18.017+0000] {processor.py:157} INFO - Started process (PID=20457) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:13:18.018+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:13:18.020+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:13:18.020+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:13:18.031+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:13:18.048+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:13:18.048+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:13:18.060+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:13:18.060+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:13:18.069+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-29T09:13:48.421+0000] {processor.py:157} INFO - Started process (PID=20482) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:13:48.422+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:13:48.425+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:13:48.425+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:13:48.438+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:13:48.455+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:13:48.455+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:13:48.466+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:13:48.466+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:13:48.475+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-29T09:14:18.927+0000] {processor.py:157} INFO - Started process (PID=20507) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:14:18.928+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:14:18.930+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:14:18.930+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:14:18.941+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:14:18.960+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:14:18.959+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:14:18.969+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:14:18.969+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:14:18.978+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-29T09:14:49.289+0000] {processor.py:157} INFO - Started process (PID=20532) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:14:49.290+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:14:49.292+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:14:49.292+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:14:49.305+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:14:49.323+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:14:49.323+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:14:49.334+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:14:49.334+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:14:49.344+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-29T09:15:19.735+0000] {processor.py:157} INFO - Started process (PID=20557) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:15:19.735+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:15:19.737+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:15:19.737+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:15:19.745+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:15:19.760+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:15:19.760+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:15:19.772+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:15:19.771+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:15:19.781+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-29T09:15:50.216+0000] {processor.py:157} INFO - Started process (PID=20582) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:15:50.217+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:15:50.220+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:15:50.219+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:15:50.231+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:15:50.250+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:15:50.250+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:15:50.263+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:15:50.263+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:15:50.273+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-29T09:16:20.687+0000] {processor.py:157} INFO - Started process (PID=20607) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:16:20.688+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:16:20.690+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:16:20.690+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:16:20.700+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:16:20.716+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:16:20.716+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:16:20.728+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:16:20.727+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:16:20.736+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-29T09:16:51.138+0000] {processor.py:157} INFO - Started process (PID=20632) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:16:51.139+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:16:51.142+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:16:51.142+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:16:51.152+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:16:51.169+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:16:51.169+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:16:51.183+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:16:51.183+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:16:51.193+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-29T09:17:21.600+0000] {processor.py:157} INFO - Started process (PID=20657) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:17:21.601+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:17:21.605+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:17:21.604+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:17:21.620+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:17:21.643+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:17:21.643+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:17:21.653+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:17:21.652+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:17:21.663+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-29T09:17:52.204+0000] {processor.py:157} INFO - Started process (PID=20682) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:17:52.206+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:17:52.208+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:17:52.208+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:17:52.219+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:17:52.241+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:17:52.241+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:17:52.254+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:17:52.254+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:17:52.264+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-29T09:18:22.599+0000] {processor.py:157} INFO - Started process (PID=20707) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:18:22.599+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:18:22.600+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:18:22.600+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:18:22.608+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:18:22.624+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:18:22.624+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:18:22.635+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:18:22.635+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:18:22.642+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.045 seconds
[2024-07-29T09:18:53.093+0000] {processor.py:157} INFO - Started process (PID=20732) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:18:53.094+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:18:53.095+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:18:53.095+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:18:53.107+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:18:53.126+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:18:53.126+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:18:53.138+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:18:53.138+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:18:53.145+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-29T09:19:23.586+0000] {processor.py:157} INFO - Started process (PID=20757) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:19:23.587+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:19:23.590+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:19:23.589+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:19:23.605+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:19:23.630+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:19:23.630+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:19:23.643+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:19:23.643+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:19:23.653+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.070 seconds
[2024-07-29T09:19:54.099+0000] {processor.py:157} INFO - Started process (PID=20782) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:19:54.100+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:19:54.103+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:19:54.102+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:19:54.119+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:19:54.137+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:19:54.137+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:19:54.147+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:19:54.147+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:19:54.157+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-29T09:20:24.558+0000] {processor.py:157} INFO - Started process (PID=20807) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:20:24.559+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:20:24.562+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:20:24.562+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:20:24.572+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:20:24.589+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:20:24.589+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:20:24.600+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:20:24.600+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:20:24.607+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-29T09:20:54.954+0000] {processor.py:157} INFO - Started process (PID=20832) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:20:54.956+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:20:54.958+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:20:54.958+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:20:54.970+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:20:54.986+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:20:54.986+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:20:54.999+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:20:54.999+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:20:55.008+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-29T09:21:25.499+0000] {processor.py:157} INFO - Started process (PID=20857) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:21:25.500+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:21:25.504+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:21:25.503+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:21:25.522+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:21:25.544+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:21:25.543+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:21:25.554+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:21:25.553+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:21:25.562+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.068 seconds
[2024-07-29T09:21:55.859+0000] {processor.py:157} INFO - Started process (PID=20882) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:21:55.860+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:21:55.861+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:21:55.861+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:21:55.872+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:21:55.888+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:21:55.888+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:21:55.897+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:21:55.897+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:21:55.904+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-29T09:22:26.374+0000] {processor.py:157} INFO - Started process (PID=20907) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:22:26.376+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:22:26.378+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:22:26.378+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:22:26.390+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:22:26.411+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:22:26.410+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:22:26.426+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:22:26.426+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:22:26.434+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-29T09:22:56.844+0000] {processor.py:157} INFO - Started process (PID=20932) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:22:56.845+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:22:56.849+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:22:56.849+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:22:56.863+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:22:56.884+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:22:56.884+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:22:56.894+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:22:56.894+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:22:56.903+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-29T09:23:27.267+0000] {processor.py:157} INFO - Started process (PID=20957) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:23:27.269+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:23:27.271+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:23:27.271+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:23:27.280+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:23:27.296+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:23:27.296+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:23:27.308+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:23:27.308+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:23:27.316+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-29T09:23:57.770+0000] {processor.py:157} INFO - Started process (PID=20982) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:23:57.772+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:23:57.775+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:23:57.775+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:23:57.785+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:23:57.802+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:23:57.802+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:23:57.815+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:23:57.815+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:23:57.825+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-29T09:24:28.279+0000] {processor.py:157} INFO - Started process (PID=21007) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:24:28.280+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:24:28.283+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:24:28.283+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:24:28.298+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:24:28.317+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:24:28.317+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:24:28.329+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:24:28.329+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:24:28.338+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.065 seconds
[2024-07-29T09:24:58.805+0000] {processor.py:157} INFO - Started process (PID=21032) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:24:58.805+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:24:58.807+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:24:58.807+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:24:58.814+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:24:58.832+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:24:58.832+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:24:58.843+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:24:58.843+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:24:58.852+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-29T09:25:29.276+0000] {processor.py:157} INFO - Started process (PID=21057) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:25:29.279+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:25:29.281+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:25:29.281+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:25:29.294+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:25:29.311+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:25:29.311+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:25:29.324+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:25:29.323+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:25:29.333+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-29T09:25:59.769+0000] {processor.py:157} INFO - Started process (PID=21082) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:25:59.770+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:25:59.774+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:25:59.773+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:25:59.792+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:25:59.817+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:25:59.817+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:25:59.829+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:25:59.829+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:25:59.839+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.075 seconds
[2024-07-29T09:26:30.377+0000] {processor.py:157} INFO - Started process (PID=21107) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:26:30.378+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:26:30.383+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:26:30.383+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:26:30.404+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:26:30.437+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:26:30.437+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:26:30.451+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:26:30.451+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:26:30.461+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.090 seconds
[2024-07-29T09:27:00.923+0000] {processor.py:157} INFO - Started process (PID=21132) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:27:00.925+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:27:00.929+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:27:00.929+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:27:00.949+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:27:00.975+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:27:00.975+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:27:00.990+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:27:00.990+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:27:01.001+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.090 seconds
[2024-07-29T09:27:31.361+0000] {processor.py:157} INFO - Started process (PID=21157) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:27:31.362+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:27:31.364+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:27:31.364+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:27:31.376+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:27:31.393+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:27:31.393+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:27:31.405+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:27:31.405+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:27:31.416+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-29T09:28:01.837+0000] {processor.py:157} INFO - Started process (PID=21182) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:28:01.839+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:28:01.841+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:28:01.841+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:28:01.854+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:28:01.874+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:28:01.874+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:28:01.887+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:28:01.887+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:28:01.895+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-29T09:28:32.186+0000] {processor.py:157} INFO - Started process (PID=21207) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:28:32.187+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:28:32.189+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:28:32.189+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:28:32.201+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:28:32.225+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:28:32.225+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:28:32.237+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:28:32.237+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:28:32.246+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-29T09:29:02.686+0000] {processor.py:157} INFO - Started process (PID=21232) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:29:02.687+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:29:02.688+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:29:02.688+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:29:02.698+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:29:02.714+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:29:02.714+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:29:02.728+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:29:02.728+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:29:02.738+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-29T09:29:33.142+0000] {processor.py:157} INFO - Started process (PID=21257) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:29:33.143+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:29:33.145+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:29:33.145+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:29:33.158+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:29:33.174+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:29:33.174+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:29:33.186+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:29:33.186+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:29:33.196+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-29T09:30:03.614+0000] {processor.py:157} INFO - Started process (PID=21282) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:30:03.615+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:30:03.617+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:30:03.616+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:30:03.629+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:30:03.645+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:30:03.645+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:30:03.659+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:30:03.659+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:30:03.668+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-29T09:30:34.081+0000] {processor.py:157} INFO - Started process (PID=21307) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:30:34.082+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:30:34.085+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:30:34.084+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:30:34.098+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:30:34.115+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:30:34.115+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:30:34.128+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:30:34.128+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:30:34.137+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-29T09:31:04.560+0000] {processor.py:157} INFO - Started process (PID=21332) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:31:04.562+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:31:04.566+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:31:04.566+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:31:04.585+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:31:04.608+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:31:04.608+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:31:04.620+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:31:04.620+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:31:04.627+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.073 seconds
[2024-07-29T09:31:35.010+0000] {processor.py:157} INFO - Started process (PID=21357) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:31:35.010+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:31:35.012+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:31:35.012+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:31:35.022+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:31:35.038+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:31:35.038+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:31:35.049+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:31:35.049+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:31:35.057+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-29T09:32:05.373+0000] {processor.py:157} INFO - Started process (PID=21382) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:32:05.373+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:32:05.375+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:32:05.374+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:32:05.382+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:32:05.397+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:32:05.397+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:32:05.409+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:32:05.408+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:32:05.418+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-29T09:32:35.839+0000] {processor.py:157} INFO - Started process (PID=21407) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:32:35.840+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:32:35.842+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:32:35.842+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:32:35.856+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:32:35.872+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:32:35.872+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:32:35.882+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:32:35.882+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:32:35.892+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-29T09:33:06.308+0000] {processor.py:157} INFO - Started process (PID=21432) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:33:06.308+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:33:06.311+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:33:06.310+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:33:06.321+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:33:06.338+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:33:06.338+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:33:06.348+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:33:06.348+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:33:06.356+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-29T09:33:36.782+0000] {processor.py:157} INFO - Started process (PID=21457) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:33:36.783+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:33:36.787+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:33:36.786+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:33:36.806+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:33:36.828+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:33:36.828+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:33:36.841+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:33:36.841+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:33:36.851+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.075 seconds
[2024-07-29T09:34:07.301+0000] {processor.py:157} INFO - Started process (PID=21482) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:34:07.302+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:34:07.305+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:34:07.305+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:34:07.316+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:34:07.332+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:34:07.332+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:34:07.344+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:34:07.344+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:34:07.353+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-29T09:34:37.822+0000] {processor.py:157} INFO - Started process (PID=21507) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:34:37.822+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:34:37.825+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:34:37.825+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:34:37.840+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:34:37.859+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:34:37.859+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:34:37.869+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:34:37.869+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:34:37.877+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-29T09:35:08.249+0000] {processor.py:157} INFO - Started process (PID=21532) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:35:08.250+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:35:08.252+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:35:08.252+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:35:08.262+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:35:08.282+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:35:08.282+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:35:08.302+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:35:08.302+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:35:08.315+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-29T09:35:38.698+0000] {processor.py:157} INFO - Started process (PID=21557) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:35:38.699+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:35:38.702+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:35:38.701+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:35:38.713+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:35:38.732+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:35:38.732+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:35:38.743+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:35:38.743+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:35:38.753+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-29T09:36:09.297+0000] {processor.py:157} INFO - Started process (PID=21582) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:36:09.297+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:36:09.300+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:36:09.300+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:36:09.312+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:36:09.330+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:36:09.330+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:36:09.340+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:36:09.340+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:36:09.350+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-29T09:36:39.720+0000] {processor.py:157} INFO - Started process (PID=21607) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:36:39.721+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:36:39.725+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:36:39.724+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:36:39.742+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:36:39.769+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:36:39.769+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:36:39.785+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:36:39.785+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:36:39.795+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.086 seconds
[2024-07-29T09:37:10.193+0000] {processor.py:157} INFO - Started process (PID=21632) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:37:10.194+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:37:10.196+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:37:10.196+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:37:10.209+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:37:10.225+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:37:10.225+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:37:10.235+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:37:10.235+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:37:10.247+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-29T09:37:40.702+0000] {processor.py:157} INFO - Started process (PID=21657) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:37:40.702+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:37:40.705+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:37:40.705+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:37:40.717+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:37:40.734+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:37:40.734+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:37:40.744+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:37:40.744+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:37:40.756+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-29T09:38:11.221+0000] {processor.py:157} INFO - Started process (PID=21682) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:38:11.222+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:38:11.225+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:38:11.225+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:38:11.236+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:38:11.254+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:38:11.254+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:38:11.266+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:38:11.265+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:38:11.275+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-29T09:38:41.663+0000] {processor.py:157} INFO - Started process (PID=21707) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:38:41.664+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:38:41.665+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:38:41.665+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:38:41.672+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:38:41.685+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:38:41.685+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:38:41.694+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:38:41.694+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:38:41.703+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.042 seconds
[2024-07-29T09:39:12.082+0000] {processor.py:157} INFO - Started process (PID=21732) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:39:12.082+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:39:12.084+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:39:12.084+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:39:12.096+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:39:12.113+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:39:12.113+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:39:12.123+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:39:12.122+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:39:12.131+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-29T09:39:42.601+0000] {processor.py:157} INFO - Started process (PID=21757) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:39:42.603+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:39:42.607+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:39:42.606+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:39:42.625+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:39:42.648+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:39:42.648+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:39:42.661+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:39:42.661+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:39:42.670+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.075 seconds
[2024-07-29T09:40:13.086+0000] {processor.py:157} INFO - Started process (PID=21782) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:40:13.087+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:40:13.090+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:40:13.090+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:40:13.103+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:40:13.123+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:40:13.123+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:40:13.133+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:40:13.133+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:40:13.143+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-29T09:40:43.659+0000] {processor.py:157} INFO - Started process (PID=21807) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:40:43.660+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:40:43.661+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:40:43.661+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:40:43.671+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:40:43.688+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:40:43.688+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:40:43.700+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:40:43.700+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:40:43.710+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-29T09:41:14.166+0000] {processor.py:157} INFO - Started process (PID=21832) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:41:14.167+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:41:14.170+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:41:14.169+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:41:14.180+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:41:14.199+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:41:14.199+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:41:14.209+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:41:14.209+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:41:14.219+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-29T09:41:44.615+0000] {processor.py:157} INFO - Started process (PID=21857) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:41:44.616+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:41:44.621+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:41:44.620+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:41:44.638+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:41:44.660+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:41:44.660+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:41:44.671+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:41:44.671+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:41:44.680+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.072 seconds
[2024-07-29T09:42:15.090+0000] {processor.py:157} INFO - Started process (PID=21882) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:42:15.090+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:42:15.092+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:42:15.092+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:42:15.104+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:42:15.124+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:42:15.124+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:42:15.138+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:42:15.138+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:42:15.147+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-29T09:42:45.589+0000] {processor.py:157} INFO - Started process (PID=21907) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:42:45.590+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:42:45.592+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:42:45.592+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:42:45.602+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:42:45.619+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:42:45.618+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:42:45.629+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:42:45.629+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:42:45.638+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-29T09:43:15.982+0000] {processor.py:157} INFO - Started process (PID=21932) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:43:15.982+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:43:15.985+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:43:15.985+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:43:15.995+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:43:16.011+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:43:16.010+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:43:16.021+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:43:16.020+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:43:16.029+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-29T09:43:46.398+0000] {processor.py:157} INFO - Started process (PID=21957) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:43:46.398+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:43:46.401+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:43:46.401+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:43:46.411+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:43:46.427+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:43:46.427+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:43:46.436+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:43:46.436+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:43:46.445+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-29T09:44:16.953+0000] {processor.py:157} INFO - Started process (PID=21982) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:44:16.954+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:44:16.956+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:44:16.956+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:44:16.971+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:44:16.988+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:44:16.988+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:44:16.999+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:44:16.999+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:44:17.009+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-29T09:44:47.458+0000] {processor.py:157} INFO - Started process (PID=22007) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:44:47.459+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:44:47.461+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:44:47.461+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:44:47.470+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:44:47.486+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:44:47.486+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:44:47.499+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:44:47.499+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:44:47.509+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-29T09:45:17.907+0000] {processor.py:157} INFO - Started process (PID=22032) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:45:17.907+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:45:17.909+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:45:17.908+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:45:17.916+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:45:17.929+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:45:17.929+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:45:17.939+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:45:17.939+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:45:17.948+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.043 seconds
[2024-07-29T09:45:48.336+0000] {processor.py:157} INFO - Started process (PID=22057) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:45:48.337+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:45:48.339+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:45:48.339+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:45:48.350+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:45:48.367+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:45:48.367+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:45:48.377+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:45:48.377+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:45:48.387+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-29T09:46:18.773+0000] {processor.py:157} INFO - Started process (PID=22082) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:46:18.774+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:46:18.777+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:46:18.776+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:46:18.790+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:46:18.809+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:46:18.809+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:46:18.819+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:46:18.819+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:46:18.828+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-29T09:46:49.222+0000] {processor.py:157} INFO - Started process (PID=22107) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:46:49.223+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:46:49.228+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:46:49.227+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:46:49.244+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:46:49.265+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:46:49.265+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:46:49.276+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:46:49.276+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:46:49.287+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.073 seconds
[2024-07-29T09:47:19.714+0000] {processor.py:157} INFO - Started process (PID=22132) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:47:19.715+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:47:19.717+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:47:19.716+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:47:19.730+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:47:19.748+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:47:19.748+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:47:19.760+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:47:19.760+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:47:19.768+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-29T09:47:50.148+0000] {processor.py:157} INFO - Started process (PID=22157) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:47:50.149+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:47:50.151+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:47:50.151+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:47:50.161+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:47:50.177+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:47:50.177+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:47:50.189+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:47:50.189+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:47:50.199+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-29T09:48:20.641+0000] {processor.py:157} INFO - Started process (PID=22182) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:48:20.642+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:48:20.644+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:48:20.643+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:48:20.656+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:48:20.675+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:48:20.675+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:48:20.684+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:48:20.684+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:48:20.693+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-29T09:48:51.054+0000] {processor.py:157} INFO - Started process (PID=22207) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:48:51.054+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:48:51.055+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:48:51.055+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:48:51.062+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:48:51.074+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:48:51.074+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:48:51.082+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:48:51.082+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:48:51.089+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.037 seconds
[2024-07-29T09:49:21.480+0000] {processor.py:157} INFO - Started process (PID=22232) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:49:21.481+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:49:21.483+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:49:21.483+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:49:21.496+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:49:21.515+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:49:21.515+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:49:21.526+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:49:21.525+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:49:21.536+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-29T09:49:51.998+0000] {processor.py:157} INFO - Started process (PID=22257) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:49:52.000+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:49:52.003+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:49:52.003+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:49:52.012+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:49:52.029+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:49:52.029+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:49:52.040+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:49:52.040+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:49:52.050+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-29T09:50:22.533+0000] {processor.py:157} INFO - Started process (PID=22282) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:50:22.534+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:50:22.537+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:50:22.537+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:50:22.550+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:50:22.568+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:50:22.568+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:50:22.579+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:50:22.579+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:50:22.589+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-29T09:50:52.971+0000] {processor.py:157} INFO - Started process (PID=22307) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:50:52.972+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:50:52.974+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:50:52.974+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:50:52.984+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:50:53.000+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:50:53.000+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:50:53.011+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:50:53.011+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:50:53.021+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-29T09:51:23.383+0000] {processor.py:157} INFO - Started process (PID=22332) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:51:23.383+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:51:23.385+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:51:23.385+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:51:23.399+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:51:23.414+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:51:23.414+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:51:23.424+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:51:23.424+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:51:23.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-29T09:51:53.884+0000] {processor.py:157} INFO - Started process (PID=22357) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:51:53.885+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:51:53.887+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:51:53.887+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:51:53.898+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:51:53.914+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:51:53.914+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:51:53.925+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:51:53.925+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:51:53.936+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-29T09:52:24.332+0000] {processor.py:157} INFO - Started process (PID=22382) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:52:24.333+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:52:24.334+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:52:24.334+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:52:24.342+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:52:24.357+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:52:24.357+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:52:24.365+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:52:24.365+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:52:24.374+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.045 seconds
[2024-07-29T09:52:54.751+0000] {processor.py:157} INFO - Started process (PID=22407) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:52:54.752+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:52:54.756+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:52:54.755+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:52:54.772+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:52:54.796+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:52:54.796+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:52:54.808+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:52:54.808+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:52:54.816+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.070 seconds
[2024-07-29T09:53:25.280+0000] {processor.py:157} INFO - Started process (PID=22432) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:53:25.281+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:53:25.283+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:53:25.283+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:53:25.295+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:53:25.316+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:53:25.316+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:53:25.324+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:53:25.324+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:53:25.332+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-29T09:53:55.717+0000] {processor.py:157} INFO - Started process (PID=22457) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:53:55.718+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:53:55.720+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:53:55.720+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:53:55.729+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:53:55.745+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:53:55.745+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:53:55.762+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:53:55.761+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:53:55.771+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-29T09:54:26.237+0000] {processor.py:157} INFO - Started process (PID=22482) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:54:26.239+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:54:26.241+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:54:26.241+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:54:26.249+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:54:26.266+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:54:26.266+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:54:26.277+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:54:26.277+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:54:26.287+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-29T09:54:56.643+0000] {processor.py:157} INFO - Started process (PID=22507) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:54:56.644+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:54:56.646+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:54:56.646+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:54:56.656+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:54:56.674+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:54:56.674+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:54:56.686+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:54:56.686+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:54:56.695+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-29T09:55:27.123+0000] {processor.py:157} INFO - Started process (PID=22532) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:55:27.124+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:55:27.126+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:55:27.126+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:55:27.140+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:55:27.157+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:55:27.157+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:55:27.170+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:55:27.170+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:55:27.180+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-29T09:55:57.515+0000] {processor.py:157} INFO - Started process (PID=22557) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:55:57.515+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:55:57.517+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:55:57.517+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:55:57.524+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:55:57.538+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:55:57.538+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:55:57.548+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:55:57.548+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:55:57.559+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.046 seconds
[2024-07-29T09:56:27.938+0000] {processor.py:157} INFO - Started process (PID=22582) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:56:27.939+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:56:27.942+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:56:27.942+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:56:27.953+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:56:27.969+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:56:27.969+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:56:27.978+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:56:27.978+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:56:27.990+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-29T09:56:58.422+0000] {processor.py:157} INFO - Started process (PID=22607) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:56:58.423+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:56:58.425+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:56:58.425+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:56:58.434+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:56:58.450+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:56:58.450+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:56:58.462+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:56:58.462+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:56:58.470+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-29T09:57:28.836+0000] {processor.py:157} INFO - Started process (PID=22632) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:57:28.836+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:57:28.839+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:57:28.839+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:57:28.853+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:57:28.871+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:57:28.871+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:57:28.881+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:57:28.881+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:57:28.890+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-29T09:57:59.325+0000] {processor.py:157} INFO - Started process (PID=22657) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:57:59.325+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:57:59.329+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:57:59.329+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:57:59.346+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:57:59.370+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:57:59.370+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:57:59.383+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:57:59.383+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:57:59.395+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.075 seconds
[2024-07-29T09:58:29.782+0000] {processor.py:157} INFO - Started process (PID=22682) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:58:29.784+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:58:29.786+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:58:29.786+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:58:29.794+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:58:29.810+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:58:29.810+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:58:29.822+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:58:29.822+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:58:29.831+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-29T09:59:00.284+0000] {processor.py:157} INFO - Started process (PID=22707) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:59:00.285+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:59:00.287+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:59:00.287+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:59:00.297+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:59:00.313+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:59:00.313+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:59:00.323+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:59:00.323+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:59:00.333+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-29T09:59:30.761+0000] {processor.py:157} INFO - Started process (PID=22732) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:59:30.761+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T09:59:30.762+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:59:30.762+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:59:30.770+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T09:59:30.786+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:59:30.785+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:59:30.794+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:59:30.794+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T09:59:30.802+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.042 seconds
[2024-07-29T10:00:01.185+0000] {processor.py:157} INFO - Started process (PID=22757) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:00:01.186+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T10:00:01.189+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:00:01.189+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:00:01.204+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:00:01.222+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:00:01.222+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:00:01.232+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:00:01.232+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T10:00:01.241+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-29T10:00:31.709+0000] {processor.py:157} INFO - Started process (PID=22782) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:00:31.709+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T10:00:31.711+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:00:31.711+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:00:31.724+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:00:31.741+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:00:31.740+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:00:31.750+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:00:31.750+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T10:00:31.760+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-29T10:01:02.191+0000] {processor.py:157} INFO - Started process (PID=22807) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:01:02.192+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T10:01:02.194+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:01:02.194+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:01:02.207+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:01:02.225+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:01:02.225+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:01:02.237+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:01:02.237+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T10:01:02.245+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-29T10:01:32.646+0000] {processor.py:157} INFO - Started process (PID=22832) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:01:32.646+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T10:01:32.649+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:01:32.649+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:01:32.658+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:01:32.674+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:01:32.674+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:01:32.688+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:01:32.688+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T10:01:32.696+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-29T10:02:03.131+0000] {processor.py:157} INFO - Started process (PID=22857) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:02:03.132+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T10:02:03.134+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:02:03.134+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:02:03.145+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:02:03.162+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:02:03.162+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:02:03.172+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:02:03.172+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T10:02:03.179+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-29T10:02:33.534+0000] {processor.py:157} INFO - Started process (PID=22882) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:02:33.535+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T10:02:33.537+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:02:33.537+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:02:33.549+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:02:33.567+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:02:33.567+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:02:33.578+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:02:33.578+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T10:02:33.587+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-29T10:03:04.012+0000] {processor.py:157} INFO - Started process (PID=22907) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:03:04.014+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T10:03:04.018+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:03:04.017+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:03:04.035+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:03:04.058+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:03:04.058+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:03:04.069+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:03:04.069+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T10:03:04.079+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.072 seconds
[2024-07-29T10:03:34.476+0000] {processor.py:157} INFO - Started process (PID=22932) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:03:34.477+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T10:03:34.479+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:03:34.479+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:03:34.489+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:03:34.506+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:03:34.506+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:03:34.517+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:03:34.517+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T10:03:34.526+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-29T10:04:04.978+0000] {processor.py:157} INFO - Started process (PID=22957) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:04:04.979+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T10:04:04.981+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:04:04.981+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:04:04.991+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:04:05.009+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:04:05.008+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:04:05.020+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:04:05.019+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T10:04:05.029+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-29T10:04:35.437+0000] {processor.py:157} INFO - Started process (PID=22982) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:04:35.438+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T10:04:35.441+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:04:35.441+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:04:35.453+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:04:35.470+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:04:35.470+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:04:35.484+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:04:35.484+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T10:04:35.494+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-29T10:05:05.911+0000] {processor.py:157} INFO - Started process (PID=23007) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:05:05.913+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T10:05:05.915+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:05:05.914+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:05:05.923+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:05:05.939+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:05:05.939+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:05:05.950+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:05:05.950+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T10:05:05.959+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-29T10:05:36.423+0000] {processor.py:157} INFO - Started process (PID=23032) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:05:36.425+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T10:05:36.429+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:05:36.428+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:05:36.444+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:05:36.465+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:05:36.465+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:05:36.478+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:05:36.478+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T10:05:36.486+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.068 seconds
[2024-07-29T10:06:06.987+0000] {processor.py:157} INFO - Started process (PID=23057) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:06:06.988+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T10:06:06.991+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:06:06.990+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:06:07.002+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:06:07.023+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:06:07.023+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:06:07.037+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:06:07.037+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T10:06:07.047+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-29T10:06:37.517+0000] {processor.py:157} INFO - Started process (PID=23082) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:06:37.518+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T10:06:37.520+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:06:37.520+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:06:37.530+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:06:37.547+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:06:37.547+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:06:37.559+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:06:37.559+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T10:06:37.569+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-29T10:07:07.974+0000] {processor.py:157} INFO - Started process (PID=23107) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:07:07.976+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T10:07:07.979+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:07:07.979+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:07:07.998+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:07:08.020+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:07:08.020+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:07:08.033+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:07:08.033+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T10:07:08.040+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.073 seconds
[2024-07-29T10:07:38.523+0000] {processor.py:157} INFO - Started process (PID=23132) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:07:38.525+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T10:07:38.527+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:07:38.527+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:07:38.538+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:07:38.556+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:07:38.556+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:07:38.571+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:07:38.571+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T10:07:38.581+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-29T10:08:09.001+0000] {processor.py:157} INFO - Started process (PID=23157) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:08:09.002+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T10:08:09.006+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:08:09.005+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:08:09.016+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:08:09.032+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:08:09.032+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:08:09.044+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:08:09.044+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T10:08:09.053+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-29T10:08:39.383+0000] {processor.py:157} INFO - Started process (PID=23182) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:08:39.384+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T10:08:39.387+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:08:39.387+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:08:39.401+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:08:39.418+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:08:39.418+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:08:39.428+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:08:39.428+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T10:08:39.438+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-29T10:09:09.808+0000] {processor.py:157} INFO - Started process (PID=23207) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:09:09.810+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T10:09:09.812+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:09:09.811+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:09:09.821+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:09:09.837+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:09:09.837+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:09:09.853+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:09:09.853+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T10:09:09.864+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-29T10:09:40.240+0000] {processor.py:157} INFO - Started process (PID=23232) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:09:40.241+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T10:09:40.242+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:09:40.242+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:09:40.250+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:09:40.263+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:09:40.263+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:09:40.273+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:09:40.273+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T10:09:40.283+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.045 seconds
[2024-07-29T10:10:10.620+0000] {processor.py:157} INFO - Started process (PID=23257) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:10:10.621+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T10:10:10.624+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:10:10.623+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:10:10.635+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:10:10.652+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:10:10.652+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:10:10.662+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:10:10.662+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T10:10:10.672+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-29T10:10:41.090+0000] {processor.py:157} INFO - Started process (PID=23282) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:10:41.091+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T10:10:41.094+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:10:41.094+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:10:41.106+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:10:41.126+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:10:41.126+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:10:41.136+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:10:41.136+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T10:10:41.145+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-29T10:11:11.601+0000] {processor.py:157} INFO - Started process (PID=23307) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:11:11.603+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T10:11:11.605+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:11:11.604+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:11:11.615+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:11:11.631+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:11:11.631+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:11:11.642+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:11:11.642+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T10:11:11.650+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-29T10:11:42.063+0000] {processor.py:157} INFO - Started process (PID=23332) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:11:42.064+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T10:11:42.067+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:11:42.067+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:11:42.083+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:11:42.106+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:11:42.106+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:11:42.120+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:11:42.120+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T10:11:42.129+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.073 seconds
[2024-07-29T10:12:12.533+0000] {processor.py:157} INFO - Started process (PID=23357) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:12:12.534+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T10:12:12.536+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:12:12.536+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:12:12.545+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:12:12.564+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:12:12.564+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:12:12.574+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:12:12.574+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T10:12:12.585+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-29T10:12:42.939+0000] {processor.py:157} INFO - Started process (PID=23382) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:12:42.940+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T10:12:42.942+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:12:42.941+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:12:42.953+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:12:42.970+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:12:42.970+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:12:42.982+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:12:42.982+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T10:12:42.993+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-29T10:13:13.336+0000] {processor.py:157} INFO - Started process (PID=23407) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:13:13.337+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T10:13:13.339+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:13:13.339+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:13:13.351+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:13:13.367+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:13:13.367+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:13:13.378+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:13:13.377+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T10:13:13.388+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-29T10:13:43.873+0000] {processor.py:157} INFO - Started process (PID=23432) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:13:43.874+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T10:13:43.876+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:13:43.876+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:13:43.888+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:13:43.903+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:13:43.903+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:13:43.914+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:13:43.914+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T10:13:43.927+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-29T10:14:14.365+0000] {processor.py:157} INFO - Started process (PID=23457) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:14:14.366+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T10:14:14.368+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:14:14.367+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:14:14.380+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:14:14.399+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:14:14.399+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:14:14.409+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:14:14.409+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T10:14:14.417+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-29T10:14:44.817+0000] {processor.py:157} INFO - Started process (PID=23482) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:14:44.818+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T10:14:44.820+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:14:44.820+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:14:44.829+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:14:44.845+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:14:44.845+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:14:44.857+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:14:44.857+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T10:14:44.865+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-29T10:15:15.297+0000] {processor.py:157} INFO - Started process (PID=23507) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:15:15.298+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T10:15:15.301+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:15:15.301+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:15:15.310+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:15:15.327+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:15:15.326+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:15:15.338+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:15:15.337+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T10:15:15.347+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-29T10:15:45.687+0000] {processor.py:157} INFO - Started process (PID=23532) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:15:45.688+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T10:15:45.690+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:15:45.690+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:15:45.699+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:15:45.716+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:15:45.715+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:15:45.727+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:15:45.727+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T10:15:45.736+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-29T10:16:16.177+0000] {processor.py:157} INFO - Started process (PID=23557) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:16:16.180+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T10:16:16.181+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:16:16.181+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:16:16.190+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:16:16.206+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:16:16.206+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:16:16.218+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:16:16.218+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T10:16:16.227+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-29T10:16:46.590+0000] {processor.py:157} INFO - Started process (PID=23582) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:16:46.590+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T10:16:46.591+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:16:46.591+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:16:46.598+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:16:46.611+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:16:46.611+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:16:46.620+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:16:46.619+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T10:16:46.627+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.038 seconds
[2024-07-29T10:17:16.971+0000] {processor.py:157} INFO - Started process (PID=23607) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:17:16.972+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T10:17:16.974+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:17:16.973+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:17:16.987+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:17:17.004+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:17:17.004+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:17:17.015+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:17:17.014+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T10:17:17.023+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-29T10:17:47.447+0000] {processor.py:157} INFO - Started process (PID=23632) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:17:47.449+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T10:17:47.452+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:17:47.452+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:17:47.469+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:17:47.491+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:17:47.491+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:17:47.505+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:17:47.505+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T10:17:47.513+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.072 seconds
[2024-07-29T10:18:17.891+0000] {processor.py:157} INFO - Started process (PID=23657) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:18:17.892+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T10:18:17.897+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:18:17.897+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:18:17.915+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:18:17.938+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:18:17.938+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:18:17.948+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:18:17.948+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T10:18:17.959+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.074 seconds
[2024-07-29T10:18:48.396+0000] {processor.py:157} INFO - Started process (PID=23682) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:18:48.397+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T10:18:48.400+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:18:48.399+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:18:48.412+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:18:48.426+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:18:48.426+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:18:48.439+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:18:48.439+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T10:18:48.448+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-29T10:19:18.804+0000] {processor.py:157} INFO - Started process (PID=23707) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:19:18.807+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T10:19:18.809+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:19:18.809+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:19:18.820+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:19:18.837+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:19:18.837+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:19:18.849+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:19:18.849+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T10:19:18.858+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-29T10:19:49.291+0000] {processor.py:157} INFO - Started process (PID=23732) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:19:49.292+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T10:19:49.294+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:19:49.294+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:19:49.307+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:19:49.326+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:19:49.326+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:19:49.336+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:19:49.335+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T10:19:49.344+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-29T10:20:19.733+0000] {processor.py:157} INFO - Started process (PID=23757) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:20:19.734+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T10:20:19.736+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:20:19.736+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:20:19.744+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:20:19.761+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:20:19.761+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:20:19.771+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:20:19.771+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T10:20:19.781+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-29T10:20:50.223+0000] {processor.py:157} INFO - Started process (PID=23782) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:20:50.224+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T10:20:50.226+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:20:50.226+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:20:50.238+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:20:50.255+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:20:50.255+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:20:50.264+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:20:50.264+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T10:20:50.273+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-29T10:21:20.717+0000] {processor.py:157} INFO - Started process (PID=23807) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:21:20.718+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T10:21:20.720+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:21:20.719+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:21:20.731+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:21:20.750+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:21:20.750+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:21:20.764+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:21:20.763+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T10:21:20.772+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-29T10:21:51.201+0000] {processor.py:157} INFO - Started process (PID=23832) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:21:51.202+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T10:21:51.204+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:21:51.204+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:21:51.216+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:21:51.235+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:21:51.235+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:21:51.247+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:21:51.247+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T10:21:51.256+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-29T10:22:21.676+0000] {processor.py:157} INFO - Started process (PID=23857) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:22:21.677+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T10:22:21.682+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:22:21.681+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:22:21.698+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:22:21.717+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:22:21.717+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:22:21.726+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:22:21.726+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T10:22:21.734+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-29T10:22:52.032+0000] {processor.py:157} INFO - Started process (PID=23882) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:22:52.033+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T10:22:52.036+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:22:52.036+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:22:52.053+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:22:52.076+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:22:52.076+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:22:52.087+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:22:52.087+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T10:22:52.096+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-29T10:23:22.647+0000] {processor.py:157} INFO - Started process (PID=23907) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:23:22.649+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T10:23:22.653+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:23:22.653+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:23:22.676+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:23:22.702+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:23:22.702+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:23:22.715+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:23:22.715+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T10:23:22.724+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.084 seconds
[2024-07-29T10:23:53.194+0000] {processor.py:157} INFO - Started process (PID=23932) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:23:53.196+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T10:23:53.197+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:23:53.197+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:23:53.203+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:23:53.216+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:23:53.216+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:23:53.229+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:23:53.228+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T10:23:53.238+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.046 seconds
[2024-07-29T10:24:46.100+0000] {processor.py:157} INFO - Started process (PID=23959) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:24:46.101+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T10:24:46.105+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:24:46.105+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:24:46.126+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:24:46.152+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:24:46.152+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:24:46.173+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:24:46.173+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T10:24:46.183+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.104 seconds
[2024-07-29T10:25:16.548+0000] {processor.py:157} INFO - Started process (PID=23984) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:25:16.548+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T10:25:16.551+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:25:16.551+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:25:16.565+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:25:16.579+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:25:16.579+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:25:16.590+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:25:16.590+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T10:25:16.599+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-29T10:27:33.720+0000] {processor.py:157} INFO - Started process (PID=24009) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:27:33.721+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T10:27:33.727+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:27:33.727+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:27:33.749+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:27:33.805+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:27:33.804+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:27:33.833+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:27:33.833+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T10:27:33.853+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.140 seconds
[2024-07-29T10:28:04.708+0000] {processor.py:157} INFO - Started process (PID=24034) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:28:04.710+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T10:28:04.714+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:28:04.713+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:28:04.731+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:28:04.754+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:28:04.754+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:28:04.766+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:28:04.766+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T10:28:04.775+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-29T10:28:35.219+0000] {processor.py:157} INFO - Started process (PID=24059) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:28:35.221+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T10:28:35.224+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:28:35.224+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:28:35.240+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:28:35.256+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:28:35.256+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:28:35.267+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:28:35.267+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T10:28:35.277+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-29T10:29:38.967+0000] {processor.py:157} INFO - Started process (PID=24084) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:29:38.968+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T10:29:38.975+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:29:38.975+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:29:39.010+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:29:39.041+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:29:39.041+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:29:39.055+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:29:39.055+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T10:29:39.067+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.108 seconds
[2024-07-29T10:30:37.982+0000] {processor.py:157} INFO - Started process (PID=24111) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:30:37.982+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T10:30:37.985+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:30:37.984+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:30:37.995+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:30:38.016+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:30:38.016+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:30:38.026+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:30:38.025+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T10:30:38.036+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-29T10:42:49.977+0000] {processor.py:157} INFO - Started process (PID=24136) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:42:49.981+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T10:42:49.992+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:42:49.991+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:42:50.033+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:42:50.083+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:42:50.083+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:42:50.113+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:42:50.113+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T10:42:50.142+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.171 seconds
[2024-07-29T10:43:20.784+0000] {processor.py:157} INFO - Started process (PID=24161) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:43:20.786+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T10:43:20.791+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:43:20.790+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:43:20.814+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:43:20.848+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:43:20.848+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:43:20.864+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:43:20.864+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T10:43:20.874+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.097 seconds
[2024-07-29T10:43:51.243+0000] {processor.py:157} INFO - Started process (PID=24186) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:43:51.244+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T10:43:51.247+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:43:51.247+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:43:51.259+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:43:51.277+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:43:51.277+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:43:51.287+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:43:51.286+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T10:43:51.296+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-29T10:44:21.648+0000] {processor.py:157} INFO - Started process (PID=24211) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:44:21.650+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T10:44:21.655+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:44:21.655+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:44:21.675+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:44:21.701+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:44:21.701+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:44:21.714+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:44:21.713+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T10:44:21.725+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.083 seconds
[2024-07-29T10:44:52.047+0000] {processor.py:157} INFO - Started process (PID=24236) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:44:52.048+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T10:44:52.050+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:44:52.050+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:44:52.063+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:44:52.084+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:44:52.084+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:44:52.094+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:44:52.094+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T10:44:52.103+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-29T10:45:22.549+0000] {processor.py:157} INFO - Started process (PID=24261) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:45:22.550+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T10:45:22.553+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:45:22.553+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:45:22.563+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:45:22.585+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:45:22.585+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:45:22.595+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:45:22.595+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T10:45:22.607+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-29T10:45:52.914+0000] {processor.py:157} INFO - Started process (PID=24286) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:45:52.914+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T10:45:52.915+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:45:52.915+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:45:52.923+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:45:52.937+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:45:52.937+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:45:52.948+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:45:52.947+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T10:45:52.956+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.045 seconds
[2024-07-29T10:46:23.362+0000] {processor.py:157} INFO - Started process (PID=24311) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:46:23.363+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T10:46:23.369+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:46:23.368+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:46:23.387+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:46:23.410+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:46:23.410+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:46:23.422+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:46:23.422+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T10:46:23.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.078 seconds
[2024-07-29T10:46:53.875+0000] {processor.py:157} INFO - Started process (PID=24336) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:46:53.876+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T10:46:53.879+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:46:53.879+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:46:53.891+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:46:53.910+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:46:53.910+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:46:53.920+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:46:53.920+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T10:46:53.928+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-29T10:47:24.238+0000] {processor.py:157} INFO - Started process (PID=24361) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:47:24.239+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T10:47:24.241+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:47:24.240+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:47:24.253+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:47:24.272+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:47:24.272+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:47:24.283+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:47:24.283+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T10:47:24.291+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-29T10:47:54.669+0000] {processor.py:157} INFO - Started process (PID=24386) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:47:54.670+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T10:47:54.672+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:47:54.672+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:47:54.682+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:47:54.698+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:47:54.698+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:47:54.710+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:47:54.710+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T10:47:54.719+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-29T10:48:25.086+0000] {processor.py:157} INFO - Started process (PID=24411) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:48:25.087+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T10:48:25.089+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:48:25.089+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:48:25.101+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:48:25.119+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:48:25.118+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:48:25.128+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:48:25.128+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T10:48:25.137+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-29T10:48:55.568+0000] {processor.py:157} INFO - Started process (PID=24436) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:48:55.569+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T10:48:55.574+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:48:55.574+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:48:55.591+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:48:55.614+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:48:55.614+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:48:55.628+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:48:55.628+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T10:48:55.637+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.075 seconds
[2024-07-29T10:49:25.967+0000] {processor.py:157} INFO - Started process (PID=24461) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:49:25.967+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T10:49:25.970+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:49:25.970+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:49:25.978+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:49:25.994+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:49:25.994+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:49:26.003+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:49:26.003+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T10:49:26.013+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-29T10:49:56.435+0000] {processor.py:157} INFO - Started process (PID=24486) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:49:56.436+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T10:49:56.439+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:49:56.439+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:49:56.450+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:49:56.467+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:49:56.467+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:49:56.477+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:49:56.477+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T10:49:56.487+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-29T10:50:26.893+0000] {processor.py:157} INFO - Started process (PID=24511) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:50:26.894+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T10:50:26.898+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:50:26.898+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:50:26.910+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:50:26.926+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:50:26.926+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:50:26.936+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:50:26.936+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T10:50:26.947+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-29T10:50:57.361+0000] {processor.py:157} INFO - Started process (PID=24536) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:50:57.362+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T10:50:57.367+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:50:57.367+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:50:57.386+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:50:57.407+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:50:57.407+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:50:57.420+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:50:57.420+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T10:50:57.431+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.077 seconds
[2024-07-29T10:51:27.818+0000] {processor.py:157} INFO - Started process (PID=24561) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:51:27.819+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T10:51:27.821+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:51:27.821+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:51:27.835+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:51:27.855+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:51:27.855+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:51:27.865+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:51:27.865+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T10:51:27.874+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-29T10:51:58.297+0000] {processor.py:157} INFO - Started process (PID=24586) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:51:58.298+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T10:51:58.303+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:51:58.303+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:51:58.321+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:51:58.346+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:51:58.346+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:51:58.358+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:51:58.358+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T10:51:58.369+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.077 seconds
[2024-07-29T10:52:28.764+0000] {processor.py:157} INFO - Started process (PID=24611) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:52:28.768+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T10:52:28.770+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:52:28.770+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:52:28.784+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:52:28.801+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:52:28.801+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:52:28.810+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:52:28.810+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T10:52:28.818+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-29T10:52:59.148+0000] {processor.py:157} INFO - Started process (PID=24636) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:52:59.149+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T10:52:59.151+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:52:59.150+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:52:59.158+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:52:59.173+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:52:59.173+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:52:59.183+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:52:59.183+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T10:52:59.192+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.046 seconds
[2024-07-29T10:53:29.544+0000] {processor.py:157} INFO - Started process (PID=24661) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:53:29.544+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T10:53:29.547+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:53:29.547+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:53:29.557+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:53:29.576+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:53:29.576+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:53:29.589+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:53:29.589+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T10:53:29.598+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-29T10:54:00.024+0000] {processor.py:157} INFO - Started process (PID=24686) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:54:00.024+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T10:54:00.027+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:54:00.027+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:54:00.037+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:54:00.053+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:54:00.053+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:54:00.063+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:54:00.063+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T10:54:00.072+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-29T10:54:30.428+0000] {processor.py:157} INFO - Started process (PID=24711) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:54:30.429+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T10:54:30.431+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:54:30.431+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:54:30.441+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:54:30.458+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:54:30.458+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:54:30.469+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:54:30.469+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T10:54:30.478+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-29T10:55:00.839+0000] {processor.py:157} INFO - Started process (PID=24736) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:55:00.840+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T10:55:00.842+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:55:00.842+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:55:00.854+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:55:00.870+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:55:00.870+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:55:00.880+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:55:00.880+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T10:55:00.888+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-29T10:55:31.335+0000] {processor.py:157} INFO - Started process (PID=24761) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:55:31.336+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T10:55:31.338+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:55:31.338+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:55:31.349+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:55:31.365+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:55:31.365+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:55:31.375+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:55:31.375+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T10:55:31.383+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-29T10:56:01.730+0000] {processor.py:157} INFO - Started process (PID=24786) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:56:01.731+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T10:56:01.735+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:56:01.735+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:56:01.747+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:56:01.763+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:56:01.763+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:56:01.774+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:56:01.774+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T10:56:01.780+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-29T10:56:32.231+0000] {processor.py:157} INFO - Started process (PID=24811) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:56:32.233+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T10:56:32.237+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:56:32.237+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:56:32.260+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:56:32.287+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:56:32.287+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:56:32.302+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:56:32.302+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T10:56:32.312+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.086 seconds
[2024-07-29T10:57:02.664+0000] {processor.py:157} INFO - Started process (PID=24836) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:57:02.664+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T10:57:02.666+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:57:02.666+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:57:02.676+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:57:02.695+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:57:02.695+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:57:02.705+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:57:02.705+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T10:57:02.712+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-29T10:57:33.117+0000] {processor.py:157} INFO - Started process (PID=24861) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:57:33.118+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T10:57:33.121+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:57:33.121+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:57:33.135+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:57:33.154+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:57:33.154+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:57:33.165+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:57:33.165+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T10:57:33.175+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-29T10:58:03.578+0000] {processor.py:157} INFO - Started process (PID=24886) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:58:03.580+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T10:58:03.582+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:58:03.582+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:58:03.594+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:58:03.611+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:58:03.611+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:58:03.621+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:58:03.621+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T10:58:03.633+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-29T10:58:34.019+0000] {processor.py:157} INFO - Started process (PID=24911) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:58:34.020+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T10:58:34.023+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:58:34.022+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:58:34.036+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:58:34.052+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:58:34.052+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:58:34.063+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:58:34.063+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T10:58:34.074+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-29T10:59:04.538+0000] {processor.py:157} INFO - Started process (PID=24936) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:59:04.539+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T10:59:04.542+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:59:04.541+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:59:04.555+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:59:04.573+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:59:04.573+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:59:04.587+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:59:04.587+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T10:59:04.597+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-29T10:59:35.024+0000] {processor.py:157} INFO - Started process (PID=24961) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:59:35.025+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T10:59:35.029+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:59:35.029+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:59:35.043+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T10:59:35.059+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:59:35.059+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:59:35.071+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:59:35.071+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T10:59:35.080+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-29T11:00:05.477+0000] {processor.py:157} INFO - Started process (PID=24986) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:00:05.478+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:00:05.481+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:00:05.480+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:00:05.497+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:00:05.519+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:00:05.518+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:00:05.532+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:00:05.532+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:00:05.541+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.068 seconds
[2024-07-29T11:00:35.907+0000] {processor.py:157} INFO - Started process (PID=25011) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:00:35.907+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:00:35.909+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:00:35.909+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:00:35.920+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:00:35.935+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:00:35.935+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:00:35.949+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:00:35.949+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:00:35.958+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-29T11:01:06.340+0000] {processor.py:157} INFO - Started process (PID=25036) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:01:06.341+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:01:06.343+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:01:06.342+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:01:06.356+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:01:06.375+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:01:06.375+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:01:06.385+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:01:06.385+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:01:06.395+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-29T11:01:36.702+0000] {processor.py:157} INFO - Started process (PID=25061) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:01:36.703+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:01:36.706+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:01:36.706+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:01:36.714+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:01:36.728+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:01:36.728+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:01:36.738+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:01:36.738+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:01:36.749+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-29T11:02:07.129+0000] {processor.py:157} INFO - Started process (PID=25086) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:02:07.130+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:02:07.133+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:02:07.132+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:02:07.144+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:02:07.160+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:02:07.160+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:02:07.173+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:02:07.173+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:02:07.182+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-29T11:02:37.657+0000] {processor.py:157} INFO - Started process (PID=25111) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:02:37.658+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:02:37.660+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:02:37.660+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:02:37.670+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:02:37.687+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:02:37.687+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:02:37.698+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:02:37.698+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:02:37.709+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-29T11:03:08.187+0000] {processor.py:157} INFO - Started process (PID=25136) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:03:08.188+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:03:08.192+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:03:08.192+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:03:08.208+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:03:08.237+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:03:08.237+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:03:08.250+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:03:08.250+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:03:08.260+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.078 seconds
[2024-07-29T11:03:38.708+0000] {processor.py:157} INFO - Started process (PID=25161) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:03:38.709+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:03:38.710+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:03:38.710+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:03:38.720+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:03:38.736+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:03:38.736+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:03:38.747+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:03:38.747+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:03:38.758+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-29T11:04:09.238+0000] {processor.py:157} INFO - Started process (PID=25186) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:04:09.239+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:04:09.241+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:04:09.241+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:04:09.256+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:04:09.273+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:04:09.273+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:04:09.284+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:04:09.284+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:04:09.291+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-29T11:04:39.700+0000] {processor.py:157} INFO - Started process (PID=25211) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:04:39.702+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:04:39.706+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:04:39.705+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:04:39.716+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:04:39.731+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:04:39.731+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:04:39.742+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:04:39.742+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:04:39.748+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-29T11:05:10.184+0000] {processor.py:157} INFO - Started process (PID=25236) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:05:10.185+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:05:10.190+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:05:10.190+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:05:10.208+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:05:10.231+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:05:10.231+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:05:10.242+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:05:10.242+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:05:10.250+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.072 seconds
[2024-07-29T11:05:40.780+0000] {processor.py:157} INFO - Started process (PID=25261) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:05:40.782+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:05:40.784+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:05:40.784+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:05:40.798+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:05:40.815+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:05:40.815+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:05:40.827+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:05:40.827+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:05:40.837+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-29T11:06:11.270+0000] {processor.py:157} INFO - Started process (PID=25286) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:06:11.272+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:06:11.277+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:06:11.277+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:06:11.291+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:06:11.309+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:06:11.309+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:06:11.319+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:06:11.319+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:06:11.328+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-29T11:06:41.739+0000] {processor.py:157} INFO - Started process (PID=25311) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:06:41.740+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:06:41.742+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:06:41.741+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:06:41.754+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:06:41.774+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:06:41.774+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:06:41.785+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:06:41.784+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:06:41.793+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-29T11:07:12.182+0000] {processor.py:157} INFO - Started process (PID=25336) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:07:12.183+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:07:12.186+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:07:12.186+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:07:12.196+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:07:12.212+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:07:12.212+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:07:12.222+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:07:12.222+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:07:12.231+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-29T11:07:42.582+0000] {processor.py:157} INFO - Started process (PID=25361) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:07:42.583+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:07:42.586+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:07:42.586+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:07:42.597+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:07:42.614+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:07:42.614+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:07:42.625+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:07:42.625+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:07:42.635+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-29T11:08:13.053+0000] {processor.py:157} INFO - Started process (PID=25386) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:08:13.054+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:08:13.059+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:08:13.058+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:08:13.084+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:08:13.111+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:08:13.111+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:08:13.125+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:08:13.125+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:08:13.135+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.087 seconds
[2024-07-29T11:08:43.561+0000] {processor.py:157} INFO - Started process (PID=25411) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:08:43.563+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:08:43.565+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:08:43.565+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:08:43.579+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:08:43.596+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:08:43.596+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:08:43.606+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:08:43.606+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:08:43.615+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-29T11:09:13.989+0000] {processor.py:157} INFO - Started process (PID=25436) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:09:13.990+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:09:13.993+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:09:13.993+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:09:14.007+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:09:14.024+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:09:14.024+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:09:14.036+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:09:14.036+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:09:14.045+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-29T11:09:44.383+0000] {processor.py:157} INFO - Started process (PID=25461) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:09:44.384+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:09:44.387+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:09:44.387+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:09:44.397+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:09:44.414+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:09:44.414+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:09:44.425+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:09:44.425+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:09:44.435+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-29T11:10:14.846+0000] {processor.py:157} INFO - Started process (PID=25486) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:10:14.848+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:10:14.849+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:10:14.849+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:10:14.863+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:10:14.879+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:10:14.879+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:10:14.891+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:10:14.891+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:10:14.902+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-29T11:10:45.241+0000] {processor.py:157} INFO - Started process (PID=25511) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:10:45.242+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:10:45.245+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:10:45.245+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:10:45.266+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:10:45.296+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:10:45.296+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:10:45.320+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:10:45.320+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:10:45.331+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.095 seconds
[2024-07-29T11:11:15.847+0000] {processor.py:157} INFO - Started process (PID=25536) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:11:15.849+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:11:15.854+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:11:15.853+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:11:15.882+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:11:15.912+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:11:15.912+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:11:15.925+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:11:15.925+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:11:15.934+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.094 seconds
[2024-07-29T11:11:46.365+0000] {processor.py:157} INFO - Started process (PID=25561) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:11:46.367+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:11:46.374+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:11:46.373+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:11:46.405+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:11:46.475+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:11:46.475+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:11:46.491+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:11:46.491+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:11:46.505+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.152 seconds
[2024-07-29T11:12:17.000+0000] {processor.py:157} INFO - Started process (PID=25586) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:12:17.011+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:12:17.038+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:12:17.036+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:12:17.092+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:12:17.122+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:12:17.122+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:12:17.143+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:12:17.143+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:12:17.154+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.172 seconds
[2024-07-29T11:12:47.640+0000] {processor.py:157} INFO - Started process (PID=25611) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:12:47.642+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:12:47.648+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:12:47.647+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:12:47.669+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:12:47.700+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:12:47.700+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:12:47.714+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:12:47.714+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:12:47.725+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.104 seconds
[2024-07-29T11:13:18.202+0000] {processor.py:157} INFO - Started process (PID=25636) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:13:18.206+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:13:18.212+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:13:18.212+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:13:18.235+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:13:18.278+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:13:18.278+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:13:18.294+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:13:18.294+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:13:18.305+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.127 seconds
[2024-07-29T11:13:48.698+0000] {processor.py:157} INFO - Started process (PID=25661) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:13:48.702+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:13:48.728+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:13:48.727+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:13:48.755+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:13:48.819+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:13:48.819+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:13:48.838+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:13:48.838+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:13:48.850+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.161 seconds
[2024-07-29T11:14:19.273+0000] {processor.py:157} INFO - Started process (PID=25686) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:14:19.275+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:14:19.278+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:14:19.278+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:14:19.299+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:14:19.328+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:14:19.328+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:14:19.348+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:14:19.348+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:14:19.357+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.093 seconds
[2024-07-29T11:14:49.782+0000] {processor.py:157} INFO - Started process (PID=25711) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:14:49.783+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:14:49.785+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:14:49.785+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:14:49.798+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:14:49.815+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:14:49.815+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:14:49.827+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:14:49.827+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:14:49.836+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-29T11:15:20.221+0000] {processor.py:157} INFO - Started process (PID=25736) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:15:20.222+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:15:20.224+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:15:20.224+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:15:20.234+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:15:20.252+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:15:20.252+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:15:20.265+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:15:20.265+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:15:20.274+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-29T11:15:50.635+0000] {processor.py:157} INFO - Started process (PID=25761) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:15:50.635+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:15:50.638+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:15:50.637+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:15:50.650+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:15:50.667+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:15:50.666+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:15:50.676+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:15:50.676+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:15:50.685+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-29T11:16:21.137+0000] {processor.py:157} INFO - Started process (PID=25786) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:16:21.139+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:16:21.150+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:16:21.150+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:16:21.181+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:16:21.220+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:16:21.220+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:16:21.237+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:16:21.236+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:16:21.248+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.121 seconds
[2024-07-29T11:16:51.629+0000] {processor.py:157} INFO - Started process (PID=25811) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:16:51.629+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:16:51.632+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:16:51.631+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:16:51.642+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:16:51.661+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:16:51.660+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:16:51.670+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:16:51.670+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:16:51.679+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-29T11:17:22.127+0000] {processor.py:157} INFO - Started process (PID=25836) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:17:22.128+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:17:22.131+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:17:22.131+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:17:22.143+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:17:22.161+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:17:22.161+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:17:22.171+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:17:22.171+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:17:22.179+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-29T11:17:52.540+0000] {processor.py:157} INFO - Started process (PID=25861) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:17:52.542+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:17:52.548+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:17:52.547+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:17:52.570+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:17:52.619+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:17:52.619+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:17:52.632+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:17:52.632+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:17:52.641+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.120 seconds
[2024-07-29T11:18:23.081+0000] {processor.py:157} INFO - Started process (PID=25886) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:18:23.086+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:18:23.093+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:18:23.093+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:18:23.114+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:18:23.139+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:18:23.139+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:18:23.153+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:18:23.153+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:18:23.163+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.105 seconds
[2024-07-29T11:18:53.553+0000] {processor.py:157} INFO - Started process (PID=25911) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:18:53.554+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:18:53.558+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:18:53.558+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:18:53.581+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:18:53.606+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:18:53.606+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:18:53.620+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:18:53.620+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:18:53.630+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.083 seconds
[2024-07-29T11:19:24.044+0000] {processor.py:157} INFO - Started process (PID=25936) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:19:24.045+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:19:24.049+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:19:24.049+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:19:24.059+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:19:24.077+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:19:24.077+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:19:24.088+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:19:24.088+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:19:24.098+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-29T11:19:54.465+0000] {processor.py:157} INFO - Started process (PID=25961) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:19:54.466+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:19:54.469+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:19:54.469+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:19:54.484+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:19:54.503+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:19:54.503+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:19:54.515+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:19:54.515+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:19:54.526+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-29T11:20:24.940+0000] {processor.py:157} INFO - Started process (PID=25986) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:20:24.941+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:20:24.945+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:20:24.945+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:20:24.959+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:20:24.980+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:20:24.980+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:20:24.995+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:20:24.995+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:20:25.004+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-29T11:20:55.462+0000] {processor.py:157} INFO - Started process (PID=26011) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:20:55.463+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:20:55.469+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:20:55.469+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:20:55.490+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:20:55.511+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:20:55.511+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:20:55.525+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:20:55.524+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:20:55.534+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.079 seconds
[2024-07-29T11:21:26.310+0000] {processor.py:157} INFO - Started process (PID=26036) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:21:26.312+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:21:26.316+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:21:26.316+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:21:26.347+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:21:26.379+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:21:26.379+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:21:26.396+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:21:26.396+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:21:26.410+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.108 seconds
[2024-07-29T11:21:56.879+0000] {processor.py:157} INFO - Started process (PID=26061) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:21:56.886+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:21:56.890+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:21:56.890+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:21:56.909+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:21:56.936+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:21:56.936+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:21:56.950+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:21:56.950+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:21:56.961+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.101 seconds
[2024-07-29T11:22:27.385+0000] {processor.py:157} INFO - Started process (PID=26086) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:22:27.386+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:22:27.390+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:22:27.389+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:22:27.403+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:22:27.422+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:22:27.422+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:22:27.436+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:22:27.436+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:22:27.446+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.065 seconds
[2024-07-29T11:22:57.953+0000] {processor.py:157} INFO - Started process (PID=26111) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:22:57.954+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:22:57.959+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:22:57.959+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:22:57.980+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:22:58.007+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:22:58.007+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:22:58.022+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:22:58.022+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:22:58.033+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.088 seconds
[2024-07-29T11:23:28.399+0000] {processor.py:157} INFO - Started process (PID=26136) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:23:28.400+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:23:28.402+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:23:28.402+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:23:28.414+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:23:28.432+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:23:28.431+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:23:28.442+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:23:28.442+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:23:28.451+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-29T11:23:58.848+0000] {processor.py:157} INFO - Started process (PID=26161) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:23:58.849+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:23:58.854+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:23:58.853+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:23:58.875+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:23:58.901+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:23:58.901+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:23:58.914+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:23:58.914+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:23:58.924+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.083 seconds
[2024-07-29T11:24:29.489+0000] {processor.py:157} INFO - Started process (PID=26186) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:24:29.498+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:24:29.500+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:24:29.500+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:24:29.524+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:24:29.556+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:24:29.556+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:24:29.570+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:24:29.570+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:24:29.580+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.107 seconds
[2024-07-29T11:24:59.958+0000] {processor.py:157} INFO - Started process (PID=26211) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:24:59.959+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:24:59.961+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:24:59.961+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:24:59.974+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:24:59.994+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:24:59.994+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:25:00.007+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:25:00.007+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:25:00.017+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-29T11:25:30.424+0000] {processor.py:157} INFO - Started process (PID=26236) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:25:30.424+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:25:30.429+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:25:30.428+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:25:30.443+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:25:30.465+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:25:30.465+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:25:30.478+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:25:30.478+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:25:30.488+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-29T11:26:00.929+0000] {processor.py:157} INFO - Started process (PID=26261) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:26:00.931+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:26:00.936+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:26:00.936+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:26:00.956+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:26:00.979+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:26:00.979+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:26:00.992+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:26:00.992+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:26:01.002+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.079 seconds
[2024-07-29T11:26:31.552+0000] {processor.py:157} INFO - Started process (PID=26286) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:26:31.556+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:26:31.560+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:26:31.560+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:26:31.587+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:26:31.610+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:26:31.610+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:26:31.629+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:26:31.629+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:26:31.641+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.095 seconds
[2024-07-29T11:27:02.129+0000] {processor.py:157} INFO - Started process (PID=26311) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:27:02.132+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:27:02.139+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:27:02.139+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:27:02.196+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:27:02.259+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:27:02.259+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:27:02.273+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:27:02.273+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:27:02.284+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.164 seconds
[2024-07-29T11:27:32.669+0000] {processor.py:157} INFO - Started process (PID=26336) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:27:32.671+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:27:32.676+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:27:32.676+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:27:32.699+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:27:32.727+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:27:32.727+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:27:32.742+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:27:32.742+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:27:32.752+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.091 seconds
[2024-07-29T11:28:03.266+0000] {processor.py:157} INFO - Started process (PID=26361) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:28:03.268+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:28:03.273+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:28:03.272+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:28:03.298+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:28:03.340+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:28:03.340+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:28:03.359+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:28:03.359+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:28:03.369+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.110 seconds
[2024-07-29T11:28:33.792+0000] {processor.py:157} INFO - Started process (PID=26386) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:28:33.797+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:28:33.808+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:28:33.807+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:28:33.849+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:28:33.892+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:28:33.892+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:28:33.908+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:28:33.908+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:28:33.919+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.138 seconds
[2024-07-29T11:29:04.305+0000] {processor.py:157} INFO - Started process (PID=26411) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:29:04.307+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:29:04.309+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:29:04.309+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:29:04.318+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:29:04.338+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:29:04.337+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:29:04.346+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:29:04.346+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:29:04.356+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-29T11:29:34.694+0000] {processor.py:157} INFO - Started process (PID=26436) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:29:34.695+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:29:34.700+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:29:34.700+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:29:34.719+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:29:34.739+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:29:34.739+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:29:34.753+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:29:34.752+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:29:34.763+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.075 seconds
[2024-07-29T11:30:05.190+0000] {processor.py:157} INFO - Started process (PID=26461) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:30:05.192+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:30:05.194+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:30:05.194+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:30:05.216+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:30:05.245+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:30:05.245+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:30:05.259+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:30:05.259+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:30:05.273+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.088 seconds
[2024-07-29T11:30:35.643+0000] {processor.py:157} INFO - Started process (PID=26486) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:30:35.644+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:30:35.647+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:30:35.647+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:30:35.657+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:30:35.675+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:30:35.674+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:30:35.685+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:30:35.685+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:30:35.695+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-29T11:31:06.049+0000] {processor.py:157} INFO - Started process (PID=26511) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:31:06.054+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:31:06.059+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:31:06.058+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:31:06.074+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:31:06.090+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:31:06.090+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:31:06.101+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:31:06.101+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:31:06.112+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-29T11:31:36.534+0000] {processor.py:157} INFO - Started process (PID=26536) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:31:36.535+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:31:36.541+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:31:36.541+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:31:36.555+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:31:36.575+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:31:36.575+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:31:36.586+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:31:36.586+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:31:36.596+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-29T11:32:06.888+0000] {processor.py:157} INFO - Started process (PID=26561) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:32:06.891+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:32:06.893+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:32:06.893+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:32:06.907+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:32:06.930+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:32:06.930+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:32:06.943+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:32:06.943+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:32:06.955+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.070 seconds
[2024-07-29T11:32:37.386+0000] {processor.py:157} INFO - Started process (PID=26586) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:32:37.389+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:32:37.392+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:32:37.392+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:32:37.404+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:32:37.421+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:32:37.421+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:32:37.432+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:32:37.432+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:32:37.440+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-29T11:33:07.878+0000] {processor.py:157} INFO - Started process (PID=26611) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:33:07.881+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:33:07.885+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:33:07.885+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:33:07.905+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:33:07.934+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:33:07.934+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:33:07.954+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:33:07.954+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:33:07.976+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.105 seconds
[2024-07-29T11:33:38.341+0000] {processor.py:157} INFO - Started process (PID=26636) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:33:38.343+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:33:38.346+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:33:38.346+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:33:38.361+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:33:38.379+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:33:38.379+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:33:38.392+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:33:38.392+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:33:38.401+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-29T11:34:08.862+0000] {processor.py:157} INFO - Started process (PID=26661) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:34:08.863+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:34:08.867+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:34:08.867+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:34:08.890+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:34:08.915+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:34:08.915+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:34:08.939+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:34:08.938+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:34:08.951+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.112 seconds
[2024-07-29T11:34:39.389+0000] {processor.py:157} INFO - Started process (PID=26686) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:34:39.391+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:34:39.398+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:34:39.397+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:34:39.441+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:34:39.497+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:34:39.497+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:34:39.514+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:34:39.513+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:34:39.526+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.148 seconds
[2024-07-29T11:35:09.967+0000] {processor.py:157} INFO - Started process (PID=26711) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:35:09.970+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:35:09.975+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:35:09.974+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:35:09.993+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:35:10.020+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:35:10.020+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:35:10.038+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:35:10.038+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:35:10.050+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.089 seconds
[2024-07-29T11:35:40.528+0000] {processor.py:157} INFO - Started process (PID=26736) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:35:40.531+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:35:40.542+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:35:40.542+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:35:40.563+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:35:40.593+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:35:40.593+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:35:40.607+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:35:40.607+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:35:40.620+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.108 seconds
[2024-07-29T11:36:11.044+0000] {processor.py:157} INFO - Started process (PID=26761) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:36:11.046+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:36:11.051+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:36:11.050+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:36:11.070+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:36:11.096+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:36:11.096+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:36:11.109+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:36:11.109+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:36:11.119+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.082 seconds
[2024-07-29T11:36:41.626+0000] {processor.py:157} INFO - Started process (PID=26786) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:36:41.630+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:36:41.635+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:36:41.634+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:36:41.661+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:36:41.687+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:36:41.687+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:36:41.701+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:36:41.701+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:36:41.712+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.093 seconds
[2024-07-29T11:37:12.074+0000] {processor.py:157} INFO - Started process (PID=26811) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:37:12.078+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:37:12.082+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:37:12.081+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:37:12.093+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:37:12.110+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:37:12.110+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:37:12.120+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:37:12.120+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:37:12.128+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-29T11:37:42.467+0000] {processor.py:157} INFO - Started process (PID=26836) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:37:42.468+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:37:42.470+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:37:42.470+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:37:42.481+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:37:42.496+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:37:42.496+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:37:42.511+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:37:42.511+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:37:42.521+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-29T11:38:12.945+0000] {processor.py:157} INFO - Started process (PID=26861) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:38:12.947+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:38:12.952+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:38:12.951+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:38:12.969+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:38:12.993+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:38:12.993+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:38:13.008+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:38:13.008+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:38:13.020+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.080 seconds
[2024-07-29T11:38:43.465+0000] {processor.py:157} INFO - Started process (PID=26886) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:38:43.468+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:38:43.477+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:38:43.477+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:38:43.499+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:38:43.531+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:38:43.530+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:38:43.546+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:38:43.546+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:38:43.560+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.106 seconds
[2024-07-29T11:39:14.361+0000] {processor.py:157} INFO - Started process (PID=26911) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:39:14.363+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:39:14.369+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:39:14.369+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:39:14.390+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:39:14.424+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:39:14.424+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:39:14.442+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:39:14.442+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:39:14.453+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.101 seconds
[2024-07-29T11:39:44.946+0000] {processor.py:157} INFO - Started process (PID=26936) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:39:44.947+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:39:44.951+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:39:44.951+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:39:44.971+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:39:44.996+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:39:44.996+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:39:45.009+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:39:45.009+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:39:45.019+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.080 seconds
[2024-07-29T11:40:15.435+0000] {processor.py:157} INFO - Started process (PID=26961) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:40:15.435+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:40:15.438+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:40:15.438+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:40:15.450+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:40:15.468+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:40:15.468+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:40:15.479+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:40:15.479+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:40:15.490+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-29T11:40:45.873+0000] {processor.py:157} INFO - Started process (PID=26986) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:40:45.877+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:40:45.881+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:40:45.880+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:40:45.893+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:40:45.911+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:40:45.911+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:40:45.921+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:40:45.921+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:40:45.930+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-29T11:41:16.277+0000] {processor.py:157} INFO - Started process (PID=27011) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:41:16.278+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:41:16.281+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:41:16.281+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:41:16.295+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:41:16.318+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:41:16.318+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:41:16.332+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:41:16.332+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:41:16.342+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.068 seconds
[2024-07-29T11:41:46.760+0000] {processor.py:157} INFO - Started process (PID=27036) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:41:46.761+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:41:46.764+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:41:46.763+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:41:46.775+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:41:46.791+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:41:46.791+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:41:46.803+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:41:46.803+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:41:46.811+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-29T11:42:17.193+0000] {processor.py:157} INFO - Started process (PID=27061) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:42:17.194+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:42:17.197+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:42:17.197+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:42:17.206+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:42:17.220+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:42:17.220+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:42:17.230+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:42:17.230+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:42:17.239+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-29T11:42:47.670+0000] {processor.py:157} INFO - Started process (PID=27086) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:42:47.671+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:42:47.673+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:42:47.673+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:42:47.686+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:42:47.703+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:42:47.703+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:42:47.712+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:42:47.712+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:42:47.721+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-29T11:43:18.153+0000] {processor.py:157} INFO - Started process (PID=27111) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:43:18.156+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:43:18.159+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:43:18.159+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:43:18.174+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:43:18.192+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:43:18.192+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:43:18.202+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:43:18.202+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:43:18.211+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-29T11:43:48.655+0000] {processor.py:157} INFO - Started process (PID=27136) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:43:48.657+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:43:48.662+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:43:48.661+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:43:48.679+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:43:48.703+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:43:48.703+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:43:48.715+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:43:48.715+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:43:48.725+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.076 seconds
[2024-07-29T11:44:19.165+0000] {processor.py:157} INFO - Started process (PID=27161) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:44:19.165+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:44:19.166+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:44:19.166+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:44:19.175+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:44:19.188+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:44:19.188+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:44:19.198+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:44:19.198+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:44:19.207+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.044 seconds
[2024-07-29T11:44:49.625+0000] {processor.py:157} INFO - Started process (PID=27186) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:44:49.629+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:44:49.632+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:44:49.631+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:44:49.641+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:44:49.657+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:44:49.657+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:44:49.669+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:44:49.668+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:44:49.675+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-29T11:45:20.144+0000] {processor.py:157} INFO - Started process (PID=27211) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:45:20.145+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:45:20.148+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:45:20.148+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:45:20.159+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:45:20.175+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:45:20.175+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:45:20.189+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:45:20.189+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:45:20.196+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-29T11:45:50.625+0000] {processor.py:157} INFO - Started process (PID=27236) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:45:50.626+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:45:50.629+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:45:50.628+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:45:50.640+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:45:50.658+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:45:50.658+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:45:50.667+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:45:50.667+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:45:50.677+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-29T11:46:21.121+0000] {processor.py:157} INFO - Started process (PID=27261) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:46:21.122+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:46:21.126+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:46:21.126+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:46:21.140+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:46:21.157+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:46:21.157+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:46:21.167+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:46:21.167+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:46:21.175+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-29T11:46:51.555+0000] {processor.py:157} INFO - Started process (PID=27286) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:46:51.556+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:46:51.559+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:46:51.558+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:46:51.575+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:46:51.599+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:46:51.599+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:46:51.612+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:46:51.612+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:46:51.622+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.070 seconds
[2024-07-29T11:47:22.108+0000] {processor.py:157} INFO - Started process (PID=27311) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:47:22.109+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:47:22.112+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:47:22.111+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:47:22.124+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:47:22.139+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:47:22.139+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:47:22.151+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:47:22.151+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:47:22.161+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-29T11:47:52.471+0000] {processor.py:157} INFO - Started process (PID=27336) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:47:52.472+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:47:52.474+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:47:52.474+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:47:52.481+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:47:52.494+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:47:52.494+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:47:52.504+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:47:52.504+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:47:52.514+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.045 seconds
[2024-07-29T11:48:22.841+0000] {processor.py:157} INFO - Started process (PID=27361) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:48:22.841+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:48:22.843+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:48:22.843+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:48:22.856+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:48:22.872+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:48:22.872+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:48:22.882+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:48:22.882+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:48:22.890+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-29T11:48:53.315+0000] {processor.py:157} INFO - Started process (PID=27386) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:48:53.318+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:48:53.320+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:48:53.320+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:48:53.334+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:48:53.350+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:48:53.350+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:48:53.361+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:48:53.361+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:48:53.368+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-29T11:49:23.681+0000] {processor.py:157} INFO - Started process (PID=27411) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:49:23.682+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:49:23.685+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:49:23.685+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:49:23.695+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:49:23.710+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:49:23.710+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:49:23.720+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:49:23.720+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:49:23.730+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-29T11:49:54.162+0000] {processor.py:157} INFO - Started process (PID=27436) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:49:54.163+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:49:54.168+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:49:54.168+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:49:54.183+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:49:54.207+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:49:54.207+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:49:54.219+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:49:54.219+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:49:54.229+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.074 seconds
[2024-07-29T11:50:24.639+0000] {processor.py:157} INFO - Started process (PID=27461) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:50:24.640+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:50:24.642+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:50:24.641+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:50:24.655+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:50:24.674+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:50:24.674+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:50:24.686+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:50:24.686+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:50:24.695+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-29T11:50:55.172+0000] {processor.py:157} INFO - Started process (PID=27486) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:50:55.173+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:50:55.176+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:50:55.176+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:50:55.186+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:50:55.204+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:50:55.204+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:50:55.215+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:50:55.215+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:50:55.225+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-29T11:51:25.586+0000] {processor.py:157} INFO - Started process (PID=27511) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:51:25.588+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:51:25.590+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:51:25.590+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:51:25.596+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:51:25.610+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:51:25.610+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:51:25.620+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:51:25.620+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:51:25.631+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.046 seconds
[2024-07-29T11:51:56.056+0000] {processor.py:157} INFO - Started process (PID=27536) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:51:56.057+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:51:56.060+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:51:56.060+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:51:56.070+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:51:56.089+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:51:56.089+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:51:56.099+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:51:56.099+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:51:56.108+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-29T11:52:26.524+0000] {processor.py:157} INFO - Started process (PID=27561) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:52:26.525+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:52:26.528+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:52:26.528+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:52:26.543+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:52:26.562+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:52:26.562+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:52:26.571+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:52:26.571+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:52:26.579+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-29T11:52:56.980+0000] {processor.py:157} INFO - Started process (PID=27586) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:52:56.982+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:52:56.986+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:52:56.986+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:52:56.998+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:52:57.013+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:52:57.013+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:52:57.023+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:52:57.023+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:52:57.032+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-29T11:53:27.360+0000] {processor.py:157} INFO - Started process (PID=27611) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:53:27.363+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:53:27.365+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:53:27.365+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:53:27.379+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:53:27.395+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:53:27.395+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:53:27.406+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:53:27.405+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:53:27.413+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-29T11:53:57.784+0000] {processor.py:157} INFO - Started process (PID=27636) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:53:57.785+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:53:57.788+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:53:57.788+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:53:57.800+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:53:57.822+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:53:57.822+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:53:57.832+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:53:57.832+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:53:57.842+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-29T11:54:28.275+0000] {processor.py:157} INFO - Started process (PID=27661) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:54:28.279+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:54:28.283+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:54:28.283+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:54:28.302+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:54:28.323+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:54:28.323+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:54:28.339+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:54:28.339+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:54:28.349+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.080 seconds
[2024-07-29T11:54:58.726+0000] {processor.py:157} INFO - Started process (PID=27686) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:54:58.727+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:54:58.728+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:54:58.727+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:54:58.737+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:54:58.752+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:54:58.752+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:54:58.761+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:54:58.761+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:54:58.771+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-29T11:55:29.156+0000] {processor.py:157} INFO - Started process (PID=27711) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:55:29.157+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:55:29.160+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:55:29.160+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:55:29.169+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:55:29.188+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:55:29.188+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:55:29.200+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:55:29.200+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:55:29.209+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-29T11:55:59.648+0000] {processor.py:157} INFO - Started process (PID=27736) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:55:59.649+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:55:59.651+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:55:59.651+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:55:59.665+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:55:59.680+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:55:59.680+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:55:59.691+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:55:59.691+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:55:59.698+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-29T11:56:30.031+0000] {processor.py:157} INFO - Started process (PID=27761) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:56:30.034+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:56:30.035+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:56:30.035+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:56:30.045+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:56:30.061+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:56:30.061+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:56:30.073+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:56:30.073+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:56:30.083+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-29T11:57:00.443+0000] {processor.py:157} INFO - Started process (PID=27786) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:57:00.445+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:57:00.449+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:57:00.449+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:57:00.461+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:57:00.478+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:57:00.478+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:57:00.487+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:57:00.487+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:57:00.496+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-29T11:57:30.871+0000] {processor.py:157} INFO - Started process (PID=27811) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:57:30.872+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:57:30.874+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:57:30.874+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:57:30.886+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:57:30.903+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:57:30.903+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:57:30.913+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:57:30.913+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:57:30.923+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-29T11:58:01.277+0000] {processor.py:157} INFO - Started process (PID=27836) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:58:01.278+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:58:01.281+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:58:01.281+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:58:01.293+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:58:01.308+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:58:01.308+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:58:01.319+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:58:01.319+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:58:01.328+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-29T11:58:31.754+0000] {processor.py:157} INFO - Started process (PID=27861) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:58:31.757+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:58:31.759+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:58:31.758+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:58:31.771+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:58:31.789+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:58:31.789+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:58:31.799+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:58:31.799+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:58:31.809+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-29T11:59:02.127+0000] {processor.py:157} INFO - Started process (PID=27886) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:59:02.130+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:59:02.133+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:59:02.133+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:59:02.142+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:59:02.157+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:59:02.157+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:59:02.167+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:59:02.167+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:59:02.176+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-29T11:59:32.546+0000] {processor.py:157} INFO - Started process (PID=27911) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:59:32.548+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T11:59:32.552+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:59:32.551+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:59:32.566+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T11:59:32.582+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:59:32.582+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:59:32.592+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:59:32.592+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T11:59:32.601+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-29T12:00:03.065+0000] {processor.py:157} INFO - Started process (PID=27936) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:00:03.068+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:00:03.072+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:00:03.072+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:00:03.088+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:00:03.110+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:00:03.110+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:00:03.124+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:00:03.124+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:00:03.134+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.073 seconds
[2024-07-29T12:00:33.529+0000] {processor.py:157} INFO - Started process (PID=27961) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:00:33.530+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:00:33.532+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:00:33.532+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:00:33.545+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:00:33.562+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:00:33.562+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:00:33.572+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:00:33.572+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:00:33.580+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-29T12:01:04.016+0000] {processor.py:157} INFO - Started process (PID=27986) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:01:04.018+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:01:04.020+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:01:04.020+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:01:04.030+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:01:04.045+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:01:04.045+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:01:04.058+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:01:04.058+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:01:04.066+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-29T12:01:34.482+0000] {processor.py:157} INFO - Started process (PID=28011) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:01:34.484+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:01:34.486+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:01:34.486+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:01:34.498+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:01:34.514+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:01:34.514+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:01:34.525+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:01:34.525+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:01:34.533+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-29T12:02:04.974+0000] {processor.py:157} INFO - Started process (PID=28036) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:02:04.978+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:02:04.980+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:02:04.979+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:02:04.990+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:02:05.007+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:02:05.007+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:02:05.018+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:02:05.018+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:02:05.026+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-29T12:02:35.458+0000] {processor.py:157} INFO - Started process (PID=28061) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:02:35.461+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:02:35.464+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:02:35.464+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:02:35.477+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:02:35.494+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:02:35.494+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:02:35.506+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:02:35.506+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:02:35.515+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-29T12:03:06.041+0000] {processor.py:157} INFO - Started process (PID=28086) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:03:06.042+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:03:06.046+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:03:06.046+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:03:06.058+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:03:06.076+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:03:06.076+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:03:06.088+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:03:06.088+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:03:06.097+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-29T12:03:36.448+0000] {processor.py:157} INFO - Started process (PID=28111) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:03:36.451+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:03:36.457+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:03:36.456+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:03:36.475+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:03:36.494+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:03:36.493+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:03:36.507+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:03:36.507+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:03:36.517+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.075 seconds
[2024-07-29T12:04:06.907+0000] {processor.py:157} INFO - Started process (PID=28136) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:04:06.908+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:04:06.911+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:04:06.911+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:04:06.921+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:04:06.937+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:04:06.937+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:04:06.949+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:04:06.949+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:04:06.958+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-29T12:04:37.373+0000] {processor.py:157} INFO - Started process (PID=28161) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:04:37.376+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:04:37.378+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:04:37.378+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:04:37.392+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:04:37.406+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:04:37.406+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:04:37.420+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:04:37.420+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:04:37.428+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-29T12:05:07.917+0000] {processor.py:157} INFO - Started process (PID=28186) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:05:07.919+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:05:07.921+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:05:07.921+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:05:07.934+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:05:07.950+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:05:07.950+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:05:07.960+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:05:07.960+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:05:07.970+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-29T12:05:38.397+0000] {processor.py:157} INFO - Started process (PID=28211) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:05:38.397+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:05:38.399+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:05:38.399+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:05:38.408+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:05:38.422+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:05:38.422+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:05:38.431+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:05:38.431+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:05:38.440+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.045 seconds
[2024-07-29T12:06:08.779+0000] {processor.py:157} INFO - Started process (PID=28236) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:06:08.784+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:06:08.786+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:06:08.786+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:06:08.801+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:06:08.816+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:06:08.816+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:06:08.826+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:06:08.826+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:06:08.836+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-29T12:06:39.195+0000] {processor.py:157} INFO - Started process (PID=28261) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:06:39.198+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:06:39.199+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:06:39.199+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:06:39.210+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:06:39.226+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:06:39.226+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:06:39.236+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:06:39.236+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:06:39.243+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-29T12:07:09.657+0000] {processor.py:157} INFO - Started process (PID=28286) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:07:09.658+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:07:09.662+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:07:09.662+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:07:09.676+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:07:09.693+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:07:09.692+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:07:09.703+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:07:09.702+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:07:09.711+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-29T12:07:40.090+0000] {processor.py:157} INFO - Started process (PID=28311) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:07:40.091+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:07:40.093+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:07:40.093+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:07:40.107+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:07:40.123+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:07:40.122+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:07:40.133+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:07:40.133+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:07:40.141+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-29T12:08:10.570+0000] {processor.py:157} INFO - Started process (PID=28336) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:08:10.573+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:08:10.578+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:08:10.578+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:08:10.595+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:08:10.619+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:08:10.618+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:08:10.631+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:08:10.631+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:08:10.641+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.077 seconds
[2024-07-29T12:08:41.067+0000] {processor.py:157} INFO - Started process (PID=28361) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:08:41.068+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:08:41.070+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:08:41.069+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:08:41.080+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:08:41.099+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:08:41.098+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:08:41.110+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:08:41.110+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:08:41.124+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-29T12:09:11.472+0000] {processor.py:157} INFO - Started process (PID=28386) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:09:11.474+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:09:11.475+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:09:11.475+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:09:11.482+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:09:11.494+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:09:11.494+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:09:11.504+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:09:11.504+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:09:11.514+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.043 seconds
[2024-07-29T12:09:41.970+0000] {processor.py:157} INFO - Started process (PID=28411) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:09:41.970+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:09:41.972+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:09:41.972+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:09:41.987+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:09:42.004+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:09:42.004+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:09:42.015+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:09:42.015+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:09:42.024+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-29T12:10:12.410+0000] {processor.py:157} INFO - Started process (PID=28436) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:10:12.413+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:10:12.415+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:10:12.415+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:10:12.425+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:10:12.442+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:10:12.442+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:10:12.453+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:10:12.453+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:10:12.463+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-29T12:10:42.837+0000] {processor.py:157} INFO - Started process (PID=28461) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:10:42.837+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:10:42.839+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:10:42.839+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:10:42.853+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:10:42.870+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:10:42.870+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:10:42.883+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:10:42.883+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:10:42.892+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-29T12:11:13.379+0000] {processor.py:157} INFO - Started process (PID=28486) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:11:13.379+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:11:13.382+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:11:13.382+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:11:13.396+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:11:13.413+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:11:13.413+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:11:13.424+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:11:13.424+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:11:13.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-29T12:11:43.816+0000] {processor.py:157} INFO - Started process (PID=28511) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:11:43.817+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:11:43.819+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:11:43.819+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:11:43.831+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:11:43.847+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:11:43.847+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:11:43.857+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:11:43.857+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:11:43.865+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-29T12:12:14.257+0000] {processor.py:157} INFO - Started process (PID=28536) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:12:14.258+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:12:14.263+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:12:14.262+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:12:14.281+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:12:14.304+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:12:14.304+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:12:14.317+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:12:14.317+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:12:14.327+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.077 seconds
[2024-07-29T12:12:44.754+0000] {processor.py:157} INFO - Started process (PID=28561) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:12:44.755+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:12:44.757+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:12:44.757+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:12:44.764+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:12:44.776+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:12:44.776+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:12:44.787+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:12:44.787+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:12:44.798+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.045 seconds
[2024-07-29T12:13:15.237+0000] {processor.py:157} INFO - Started process (PID=28586) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:13:15.239+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:13:15.242+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:13:15.242+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:13:15.251+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:13:15.267+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:13:15.267+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:13:15.279+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:13:15.279+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:13:15.287+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-29T12:13:45.691+0000] {processor.py:157} INFO - Started process (PID=28611) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:13:45.695+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:13:45.697+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:13:45.697+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:13:45.708+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:13:45.727+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:13:45.726+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:13:45.737+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:13:45.736+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:13:45.744+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-29T12:14:16.086+0000] {processor.py:157} INFO - Started process (PID=28636) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:14:16.088+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:14:16.090+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:14:16.090+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:14:16.101+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:14:16.116+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:14:16.116+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:14:16.131+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:14:16.131+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:14:16.140+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-29T12:14:46.625+0000] {processor.py:157} INFO - Started process (PID=28661) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:14:46.628+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:14:46.630+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:14:46.630+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:14:46.642+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:14:46.658+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:14:46.658+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:14:46.675+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:14:46.674+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:14:46.684+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-29T12:15:17.073+0000] {processor.py:157} INFO - Started process (PID=28686) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:15:17.074+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:15:17.077+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:15:17.076+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:15:17.089+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:15:17.106+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:15:17.106+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:15:17.116+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:15:17.116+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:15:17.124+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-29T12:15:47.539+0000] {processor.py:157} INFO - Started process (PID=28711) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:15:47.542+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:15:47.544+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:15:47.544+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:15:47.555+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:15:47.573+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:15:47.573+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:15:47.583+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:15:47.583+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:15:47.592+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-29T12:16:18.014+0000] {processor.py:157} INFO - Started process (PID=28736) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:16:18.017+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:16:18.019+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:16:18.019+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:16:18.029+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:16:18.046+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:16:18.046+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:16:18.057+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:16:18.057+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:16:18.066+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-29T12:16:48.907+0000] {processor.py:157} INFO - Started process (PID=28761) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:16:48.910+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:16:48.922+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:16:48.920+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:16:48.953+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:16:48.992+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:16:48.992+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:16:49.019+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:16:49.019+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:16:49.039+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.141 seconds
[2024-07-29T12:17:19.494+0000] {processor.py:157} INFO - Started process (PID=28786) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:17:19.496+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:17:19.501+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:17:19.501+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:17:19.540+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:17:19.575+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:17:19.575+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:17:19.593+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:17:19.593+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:17:19.608+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.122 seconds
[2024-07-29T12:17:49.981+0000] {processor.py:157} INFO - Started process (PID=28811) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:17:49.982+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:17:49.985+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:17:49.984+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:17:50.001+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:17:50.024+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:17:50.024+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:17:50.037+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:17:50.037+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:17:50.050+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.072 seconds
[2024-07-29T12:18:20.480+0000] {processor.py:157} INFO - Started process (PID=28836) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:18:20.482+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:18:20.488+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:18:20.487+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:18:20.516+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:18:20.541+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:18:20.541+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:18:20.556+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:18:20.556+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:18:20.570+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.097 seconds
[2024-07-29T12:18:50.918+0000] {processor.py:157} INFO - Started process (PID=28861) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:18:50.919+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:18:50.921+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:18:50.921+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:18:50.932+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:18:50.945+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:18:50.945+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:18:50.955+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:18:50.955+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:18:50.963+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.046 seconds
[2024-07-29T12:19:21.426+0000] {processor.py:157} INFO - Started process (PID=28886) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:19:21.428+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:19:21.432+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:19:21.431+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:19:21.450+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:19:21.472+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:19:21.471+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:19:21.486+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:19:21.485+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:19:21.497+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.076 seconds
[2024-07-29T12:19:51.988+0000] {processor.py:157} INFO - Started process (PID=28911) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:19:51.993+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:19:52.003+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:19:52.003+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:19:52.027+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:19:52.056+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:19:52.055+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:19:52.076+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:19:52.076+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:19:52.089+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.110 seconds
[2024-07-29T12:20:22.883+0000] {processor.py:157} INFO - Started process (PID=28936) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:20:22.885+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:20:22.891+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:20:22.890+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:20:22.921+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:20:22.959+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:20:22.959+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:20:22.987+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:20:22.987+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:20:23.000+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.153 seconds
[2024-07-29T12:20:53.425+0000] {processor.py:157} INFO - Started process (PID=28961) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:20:53.428+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:20:53.431+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:20:53.431+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:20:53.452+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:20:53.476+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:20:53.476+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:20:53.493+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:20:53.493+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:20:53.503+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.085 seconds
[2024-07-29T12:21:24.021+0000] {processor.py:157} INFO - Started process (PID=28986) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:21:24.023+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:21:24.032+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:21:24.031+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:21:24.083+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:21:24.152+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:21:24.152+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:21:24.173+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:21:24.173+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:21:24.190+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.181 seconds
[2024-07-29T12:21:54.601+0000] {processor.py:157} INFO - Started process (PID=29011) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:21:54.606+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:21:54.612+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:21:54.612+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:21:54.644+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:21:54.675+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:21:54.674+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:21:54.697+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:21:54.697+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:21:54.710+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.117 seconds
[2024-07-29T12:22:25.162+0000] {processor.py:157} INFO - Started process (PID=29036) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:22:25.165+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:22:25.172+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:22:25.172+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:22:25.204+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:22:25.245+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:22:25.245+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:22:25.260+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:22:25.260+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:22:25.273+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.120 seconds
[2024-07-29T12:22:55.728+0000] {processor.py:157} INFO - Started process (PID=29061) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:22:55.732+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:22:55.736+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:22:55.735+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:22:55.755+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:22:55.780+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:22:55.780+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:22:55.793+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:22:55.793+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:22:55.804+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.081 seconds
[2024-07-29T12:23:26.272+0000] {processor.py:157} INFO - Started process (PID=29086) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:23:26.274+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:23:26.279+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:23:26.278+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:23:26.317+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:23:26.361+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:23:26.361+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:23:26.382+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:23:26.382+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:23:26.397+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.136 seconds
[2024-07-29T12:23:56.899+0000] {processor.py:157} INFO - Started process (PID=29111) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:23:56.902+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:23:56.908+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:23:56.908+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:23:56.929+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:23:56.956+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:23:56.956+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:23:56.969+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:23:56.969+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:23:56.982+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.091 seconds
[2024-07-29T12:24:27.471+0000] {processor.py:157} INFO - Started process (PID=29136) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:24:27.474+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:24:27.478+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:24:27.477+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:24:27.502+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:24:27.551+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:24:27.551+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:24:27.566+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:24:27.566+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:24:27.578+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.134 seconds
[2024-07-29T12:24:58.071+0000] {processor.py:157} INFO - Started process (PID=29161) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:24:58.073+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:24:58.080+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:24:58.079+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:24:58.105+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:24:58.139+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:24:58.139+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:24:58.165+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:24:58.165+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:24:58.178+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.115 seconds
[2024-07-29T12:25:28.701+0000] {processor.py:157} INFO - Started process (PID=29186) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:25:28.705+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:25:28.723+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:25:28.723+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:25:28.752+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:25:28.813+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:25:28.813+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:25:28.898+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:25:28.897+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:25:28.958+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.266 seconds
[2024-07-29T12:25:59.365+0000] {processor.py:157} INFO - Started process (PID=29211) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:25:59.366+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:25:59.371+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:25:59.371+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:25:59.394+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:25:59.422+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:25:59.422+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:25:59.441+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:25:59.440+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:25:59.451+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.093 seconds
[2024-07-29T12:26:29.869+0000] {processor.py:157} INFO - Started process (PID=29236) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:26:29.870+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:26:29.876+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:26:29.876+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:26:29.889+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:26:29.913+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:26:29.913+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:26:29.925+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:26:29.925+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:26:29.935+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.072 seconds
[2024-07-29T12:27:00.374+0000] {processor.py:157} INFO - Started process (PID=29261) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:27:00.377+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:27:00.383+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:27:00.382+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:27:00.405+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:27:00.453+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:27:00.453+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:27:00.468+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:27:00.468+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:27:00.479+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.122 seconds
[2024-07-29T12:27:31.039+0000] {processor.py:157} INFO - Started process (PID=29286) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:27:31.042+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:27:31.049+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:27:31.048+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:27:31.092+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:27:31.122+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:27:31.122+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:27:31.137+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:27:31.137+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:27:31.147+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.117 seconds
[2024-07-29T12:28:01.605+0000] {processor.py:157} INFO - Started process (PID=29311) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:28:01.606+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:28:01.610+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:28:01.610+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:28:01.630+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:28:01.671+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:28:01.671+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:28:01.694+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:28:01.694+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:28:01.704+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.111 seconds
[2024-07-29T12:28:32.211+0000] {processor.py:157} INFO - Started process (PID=29336) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:28:32.213+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:28:32.218+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:28:32.218+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:28:32.239+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:28:32.275+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:28:32.275+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:28:32.295+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:28:32.295+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:28:32.306+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.103 seconds
[2024-07-29T12:29:02.790+0000] {processor.py:157} INFO - Started process (PID=29361) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:29:02.793+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:29:02.798+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:29:02.798+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:29:02.822+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:29:02.855+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:29:02.855+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:29:02.869+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:29:02.869+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:29:02.879+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.094 seconds
[2024-07-29T12:29:33.314+0000] {processor.py:157} INFO - Started process (PID=29386) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:29:33.315+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:29:33.320+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:29:33.319+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:29:33.339+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:29:33.367+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:29:33.367+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:29:33.389+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:29:33.389+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:29:33.399+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.104 seconds
[2024-07-29T12:30:03.858+0000] {processor.py:157} INFO - Started process (PID=29411) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:30:03.862+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:30:03.880+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:30:03.880+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:30:03.900+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:30:03.926+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:30:03.926+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:30:03.940+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:30:03.940+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:30:03.950+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.097 seconds
[2024-07-29T12:30:34.415+0000] {processor.py:157} INFO - Started process (PID=29436) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:30:34.418+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:30:34.428+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:30:34.427+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:30:34.458+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:30:34.491+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:30:34.491+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:30:34.505+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:30:34.505+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:30:34.515+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.114 seconds
[2024-07-29T12:31:05.082+0000] {processor.py:157} INFO - Started process (PID=29461) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:31:05.084+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:31:05.088+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:31:05.088+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:31:05.111+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:31:05.135+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:31:05.135+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:31:05.149+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:31:05.149+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:31:05.159+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.084 seconds
[2024-07-29T12:31:35.504+0000] {processor.py:157} INFO - Started process (PID=29486) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:31:35.507+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:31:35.510+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:31:35.510+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:31:35.528+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:31:35.547+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:31:35.547+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:31:35.556+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:31:35.556+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:31:35.564+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-29T12:32:05.956+0000] {processor.py:157} INFO - Started process (PID=29511) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:32:05.957+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:32:05.958+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:32:05.958+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:32:05.973+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:32:05.990+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:32:05.990+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:32:05.999+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:32:05.999+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:32:06.007+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-29T12:32:36.539+0000] {processor.py:157} INFO - Started process (PID=29536) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:32:36.544+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:32:36.548+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:32:36.548+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:32:36.567+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:32:36.595+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:32:36.595+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:32:36.609+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:32:36.609+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:32:36.622+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.088 seconds
[2024-07-29T12:33:07.100+0000] {processor.py:157} INFO - Started process (PID=29561) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:33:07.103+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:33:07.110+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:33:07.110+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:33:07.139+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:33:07.194+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:33:07.194+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:33:07.217+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:33:07.217+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:33:07.232+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.164 seconds
[2024-07-29T12:33:37.744+0000] {processor.py:157} INFO - Started process (PID=29586) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:33:37.745+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:33:37.751+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:33:37.750+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:33:37.768+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:33:37.799+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:33:37.799+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:33:37.816+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:33:37.816+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:33:37.827+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.103 seconds
[2024-07-29T12:34:08.320+0000] {processor.py:157} INFO - Started process (PID=29611) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:34:08.322+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:34:08.328+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:34:08.328+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:34:08.363+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:34:08.420+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:34:08.420+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:34:08.437+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:34:08.437+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:34:08.447+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.136 seconds
[2024-07-29T12:34:38.830+0000] {processor.py:157} INFO - Started process (PID=29636) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:34:38.832+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:34:38.838+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:34:38.837+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:34:38.860+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:34:38.889+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:34:38.889+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:34:38.907+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:34:38.907+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:34:38.920+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.099 seconds
[2024-07-29T12:35:09.377+0000] {processor.py:157} INFO - Started process (PID=29661) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:35:09.378+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:35:09.381+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:35:09.381+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:35:09.392+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:35:09.410+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:35:09.410+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:35:09.420+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:35:09.420+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:35:09.430+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-29T12:35:39.799+0000] {processor.py:157} INFO - Started process (PID=29686) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:35:39.800+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:35:39.801+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:35:39.801+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:35:39.811+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:35:39.826+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:35:39.826+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:35:39.836+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:35:39.836+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:35:39.845+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-29T12:36:10.204+0000] {processor.py:157} INFO - Started process (PID=29711) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:36:10.205+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:36:10.207+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:36:10.206+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:36:10.217+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:36:10.234+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:36:10.234+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:36:10.245+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:36:10.244+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:36:10.254+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-29T12:36:40.664+0000] {processor.py:157} INFO - Started process (PID=29736) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:36:40.672+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:36:40.685+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:36:40.685+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:36:40.708+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:36:40.752+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:36:40.752+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:36:40.766+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:36:40.766+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:36:40.776+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.129 seconds
[2024-07-29T12:37:11.264+0000] {processor.py:157} INFO - Started process (PID=29761) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:37:11.267+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:37:11.270+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:37:11.270+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:37:11.293+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:37:11.320+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:37:11.320+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:37:11.332+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:37:11.332+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:37:11.344+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.091 seconds
[2024-07-29T12:37:41.885+0000] {processor.py:157} INFO - Started process (PID=29786) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:37:41.887+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:37:41.892+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:37:41.892+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:37:41.913+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:37:41.942+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:37:41.942+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:37:41.963+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:37:41.962+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:37:41.974+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.105 seconds
[2024-07-29T12:38:12.478+0000] {processor.py:157} INFO - Started process (PID=29811) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:38:12.483+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:38:12.494+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:38:12.492+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:38:12.523+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:38:12.562+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:38:12.562+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:38:12.582+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:38:12.582+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:38:12.594+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.125 seconds
[2024-07-29T12:38:43.015+0000] {processor.py:157} INFO - Started process (PID=29836) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:38:43.019+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:38:43.023+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:38:43.023+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:38:43.056+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:38:43.095+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:38:43.095+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:38:43.111+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:38:43.111+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:38:43.123+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.114 seconds
[2024-07-29T12:39:13.588+0000] {processor.py:157} INFO - Started process (PID=29861) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:39:13.589+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:39:13.593+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:39:13.593+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:39:13.613+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:39:13.641+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:39:13.640+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:39:13.664+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:39:13.664+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:39:13.675+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.092 seconds
[2024-07-29T12:39:44.081+0000] {processor.py:157} INFO - Started process (PID=29886) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:39:44.082+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:39:44.085+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:39:44.085+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:39:44.094+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:39:44.113+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:39:44.113+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:39:44.123+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:39:44.122+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:39:44.134+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-29T12:40:14.581+0000] {processor.py:157} INFO - Started process (PID=29911) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:40:14.584+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:40:14.588+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:40:14.587+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:40:14.607+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:40:14.635+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:40:14.635+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:40:14.651+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:40:14.651+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:40:14.661+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.086 seconds
[2024-07-29T12:40:45.100+0000] {processor.py:157} INFO - Started process (PID=29936) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:40:45.102+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:40:45.107+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:40:45.106+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:40:45.125+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:40:45.149+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:40:45.149+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:40:45.163+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:40:45.163+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:40:45.173+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.079 seconds
[2024-07-29T12:41:15.622+0000] {processor.py:157} INFO - Started process (PID=29961) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:41:15.623+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:41:15.626+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:41:15.626+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:41:15.636+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:41:15.655+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:41:15.654+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:41:15.666+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:41:15.666+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:41:15.675+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-29T12:41:46.295+0000] {processor.py:157} INFO - Started process (PID=29986) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:41:46.296+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:41:46.301+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:41:46.301+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:41:46.323+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:41:46.356+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:41:46.356+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:41:46.370+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:41:46.370+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:41:46.386+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.097 seconds
[2024-07-29T12:42:16.832+0000] {processor.py:157} INFO - Started process (PID=30011) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:42:16.836+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:42:16.839+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:42:16.839+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:42:16.851+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:42:16.871+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:42:16.871+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:42:16.883+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:42:16.883+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:42:16.892+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-29T12:42:47.344+0000] {processor.py:157} INFO - Started process (PID=30036) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:42:47.345+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:42:47.349+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:42:47.349+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:42:47.371+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:42:47.409+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:42:47.409+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:42:47.422+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:42:47.422+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:42:47.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.095 seconds
[2024-07-29T12:43:17.929+0000] {processor.py:157} INFO - Started process (PID=30061) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:43:17.932+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:43:17.935+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:43:17.935+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:43:17.956+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:43:17.987+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:43:17.987+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:43:18.001+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:43:18.001+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:43:18.011+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.101 seconds
[2024-07-29T12:43:48.469+0000] {processor.py:157} INFO - Started process (PID=30086) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:43:48.472+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:43:48.476+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:43:48.475+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:43:48.502+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:43:48.532+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:43:48.532+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:43:48.546+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:43:48.546+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:43:48.555+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.092 seconds
[2024-07-29T12:44:18.947+0000] {processor.py:157} INFO - Started process (PID=30111) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:44:18.948+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:44:18.950+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:44:18.950+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:44:18.957+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:44:18.973+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:44:18.972+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:44:18.983+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:44:18.983+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:44:18.993+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-29T12:44:49.506+0000] {processor.py:157} INFO - Started process (PID=30136) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:44:49.508+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:44:49.514+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:44:49.514+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:44:49.561+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:44:49.591+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:44:49.591+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:44:49.616+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:44:49.616+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:44:49.628+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.130 seconds
[2024-07-29T12:45:20.037+0000] {processor.py:157} INFO - Started process (PID=30161) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:45:20.039+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:45:20.044+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:45:20.043+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:45:20.066+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:45:20.094+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:45:20.094+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:45:20.107+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:45:20.107+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:45:20.119+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.090 seconds
[2024-07-29T12:45:50.657+0000] {processor.py:157} INFO - Started process (PID=30186) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:45:50.660+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:45:50.664+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:45:50.663+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:45:50.680+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:45:50.706+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:45:50.706+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:45:50.726+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:45:50.725+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:45:50.738+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.090 seconds
[2024-07-29T12:46:21.097+0000] {processor.py:157} INFO - Started process (PID=30211) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:46:21.101+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:46:21.103+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:46:21.103+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:46:21.115+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:46:21.132+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:46:21.132+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:46:21.143+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:46:21.143+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:46:21.153+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-29T12:46:51.617+0000] {processor.py:157} INFO - Started process (PID=30236) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:46:51.621+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:46:51.628+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:46:51.627+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:46:51.649+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:46:51.684+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:46:51.684+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:46:51.701+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:46:51.701+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:46:51.711+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.101 seconds
[2024-07-29T12:47:22.106+0000] {processor.py:157} INFO - Started process (PID=30261) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:47:22.108+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:47:22.116+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:47:22.115+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:47:22.152+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:47:22.206+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:47:22.206+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:47:22.222+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:47:22.222+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:47:22.233+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.135 seconds
[2024-07-29T12:47:52.750+0000] {processor.py:157} INFO - Started process (PID=30286) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:47:52.754+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:47:52.760+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:47:52.759+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:47:52.795+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:47:52.850+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:47:52.850+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:47:52.867+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:47:52.867+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:47:52.879+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.138 seconds
[2024-07-29T12:48:23.342+0000] {processor.py:157} INFO - Started process (PID=30311) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:48:23.344+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:48:23.349+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:48:23.349+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:48:23.379+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:48:23.410+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:48:23.410+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:48:23.429+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:48:23.429+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:48:23.438+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.104 seconds
[2024-07-29T12:48:53.865+0000] {processor.py:157} INFO - Started process (PID=30336) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:48:53.869+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:48:53.874+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:48:53.874+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:48:53.900+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:48:53.939+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:48:53.939+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:48:53.957+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:48:53.957+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:48:53.966+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.108 seconds
[2024-07-29T12:49:24.379+0000] {processor.py:157} INFO - Started process (PID=30361) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:49:24.380+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:49:24.385+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:49:24.384+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:49:24.405+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:49:24.435+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:49:24.434+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:49:24.448+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:49:24.448+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:49:24.459+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.085 seconds
[2024-07-29T12:49:54.873+0000] {processor.py:157} INFO - Started process (PID=30386) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:49:54.875+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:49:54.877+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:49:54.877+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:49:54.889+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:49:54.907+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:49:54.907+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:49:54.923+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:49:54.922+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:49:54.932+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-29T12:50:25.660+0000] {processor.py:157} INFO - Started process (PID=30411) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:50:25.662+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:50:25.667+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:50:25.666+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:50:25.704+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:50:25.733+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:50:25.732+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:50:25.757+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:50:25.757+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:50:25.771+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.118 seconds
[2024-07-29T12:50:56.527+0000] {processor.py:157} INFO - Started process (PID=30436) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:50:56.529+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:50:56.549+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:50:56.548+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:50:56.569+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:50:56.597+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:50:56.597+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:50:56.612+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:50:56.611+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:50:56.622+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.101 seconds
[2024-07-29T12:51:27.053+0000] {processor.py:157} INFO - Started process (PID=30461) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:51:27.055+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:51:27.060+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:51:27.059+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:51:27.080+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:51:27.105+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:51:27.104+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:51:27.120+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:51:27.119+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:51:27.133+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.086 seconds
[2024-07-29T12:51:58.006+0000] {processor.py:157} INFO - Started process (PID=30486) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:51:58.007+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:51:58.012+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:51:58.011+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:51:58.031+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:51:58.067+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:51:58.067+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:51:58.083+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:51:58.083+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:51:58.094+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.094 seconds
[2024-07-29T12:52:28.529+0000] {processor.py:157} INFO - Started process (PID=30511) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:52:28.530+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:52:28.536+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:52:28.535+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:52:28.557+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:52:28.590+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:52:28.590+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:52:28.605+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:52:28.605+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:52:28.615+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.095 seconds
[2024-07-29T12:52:59.043+0000] {processor.py:157} INFO - Started process (PID=30536) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:52:59.045+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:52:59.052+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:52:59.051+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:52:59.069+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:52:59.095+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:52:59.094+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:52:59.109+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:52:59.109+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:52:59.121+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.085 seconds
[2024-07-29T12:53:29.798+0000] {processor.py:157} INFO - Started process (PID=30561) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:53:29.812+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:53:29.821+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:53:29.821+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:53:29.851+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:53:29.893+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:53:29.893+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:53:29.914+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:53:29.914+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:53:29.937+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.181 seconds
[2024-07-29T12:54:22.290+0000] {processor.py:157} INFO - Started process (PID=30586) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:54:22.291+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:54:22.295+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:54:22.295+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:54:22.310+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:54:22.334+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:54:22.334+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:54:22.347+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:54:22.347+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:54:22.357+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-29T12:56:02.222+0000] {processor.py:157} INFO - Started process (PID=30613) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:56:02.225+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:56:02.238+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:56:02.238+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:56:02.260+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:56:02.292+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:56:02.292+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:56:02.314+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:56:02.313+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:56:02.326+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.111 seconds
[2024-07-29T12:56:32.813+0000] {processor.py:157} INFO - Started process (PID=30638) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:56:32.814+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:56:32.819+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:56:32.819+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:56:32.838+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:56:32.862+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:56:32.862+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:56:32.876+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:56:32.876+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:56:32.889+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.080 seconds
[2024-07-29T12:57:03.348+0000] {processor.py:157} INFO - Started process (PID=30663) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:57:03.350+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:57:03.355+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:57:03.355+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:57:03.375+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:57:03.415+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:57:03.415+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:57:03.429+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:57:03.429+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:57:03.447+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.104 seconds
[2024-07-29T12:57:33.907+0000] {processor.py:157} INFO - Started process (PID=30688) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:57:33.909+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:57:33.913+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:57:33.913+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:57:33.934+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:57:33.969+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:57:33.969+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:57:33.983+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:57:33.983+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:57:33.995+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.095 seconds
[2024-07-29T12:58:04.349+0000] {processor.py:157} INFO - Started process (PID=30713) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:58:04.350+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:58:04.352+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:58:04.352+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:58:04.362+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:58:04.377+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:58:04.377+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:58:04.389+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:58:04.389+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:58:04.399+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-29T12:58:34.833+0000] {processor.py:157} INFO - Started process (PID=30738) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:58:34.834+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:58:34.838+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:58:34.837+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:58:34.855+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:58:34.892+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:58:34.892+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:58:34.914+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:58:34.914+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:58:34.925+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.097 seconds
[2024-07-29T12:59:05.556+0000] {processor.py:157} INFO - Started process (PID=30763) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:59:05.558+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:59:05.564+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:59:05.563+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:59:05.587+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:59:05.618+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:59:05.618+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:59:05.635+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:59:05.635+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:59:05.647+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.100 seconds
[2024-07-29T12:59:36.123+0000] {processor.py:157} INFO - Started process (PID=30788) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:59:36.125+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T12:59:36.130+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:59:36.130+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:59:36.151+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T12:59:36.199+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:59:36.199+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:59:36.216+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:59:36.216+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T12:59:36.226+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.110 seconds
[2024-07-29T13:00:06.648+0000] {processor.py:157} INFO - Started process (PID=30813) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:00:06.650+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:00:06.655+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:00:06.654+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:00:06.676+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:00:06.701+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:00:06.701+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:00:06.720+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:00:06.720+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:00:06.731+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.090 seconds
[2024-07-29T13:00:37.100+0000] {processor.py:157} INFO - Started process (PID=30838) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:00:37.103+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:00:37.110+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:00:37.109+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:00:37.161+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:00:37.212+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:00:37.212+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:00:37.235+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:00:37.235+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:00:37.251+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.161 seconds
[2024-07-29T13:01:07.643+0000] {processor.py:157} INFO - Started process (PID=30863) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:01:07.646+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:01:07.649+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:01:07.649+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:01:07.662+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:01:07.682+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:01:07.682+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:01:07.696+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:01:07.696+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:01:07.708+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.070 seconds
[2024-07-29T13:01:38.167+0000] {processor.py:157} INFO - Started process (PID=30888) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:01:38.169+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:01:38.175+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:01:38.174+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:01:38.206+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:01:38.246+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:01:38.246+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:01:38.279+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:01:38.279+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:01:38.304+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.148 seconds
[2024-07-29T13:02:08.626+0000] {processor.py:157} INFO - Started process (PID=30913) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:02:08.627+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:02:08.631+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:02:08.631+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:02:08.653+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:02:08.678+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:02:08.678+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:02:08.695+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:02:08.695+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:02:08.709+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.090 seconds
[2024-07-29T13:02:39.192+0000] {processor.py:157} INFO - Started process (PID=30938) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:02:39.195+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:02:39.213+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:02:39.212+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:02:39.235+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:02:39.270+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:02:39.269+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:02:39.286+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:02:39.286+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:02:39.310+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.127 seconds
[2024-07-29T13:03:09.764+0000] {processor.py:157} INFO - Started process (PID=30963) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:03:09.766+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:03:09.771+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:03:09.771+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:03:09.797+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:03:09.827+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:03:09.827+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:03:09.842+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:03:09.842+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:03:09.853+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.099 seconds
[2024-07-29T13:03:40.262+0000] {processor.py:157} INFO - Started process (PID=30988) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:03:40.264+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:03:40.291+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:03:40.288+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:03:40.332+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:03:40.397+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:03:40.397+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:03:40.419+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:03:40.419+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:03:40.439+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.207 seconds
[2024-07-29T13:04:10.994+0000] {processor.py:157} INFO - Started process (PID=31013) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:04:10.995+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:04:11.003+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:04:11.002+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:04:11.034+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:04:11.066+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:04:11.066+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:04:11.082+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:04:11.082+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:04:11.093+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.137 seconds
[2024-07-29T13:04:41.494+0000] {processor.py:157} INFO - Started process (PID=31038) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:04:41.496+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:04:41.504+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:04:41.503+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:04:41.566+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:04:41.606+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:04:41.606+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:04:41.625+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:04:41.625+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:04:41.652+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.167 seconds
[2024-07-29T13:05:12.177+0000] {processor.py:157} INFO - Started process (PID=31063) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:05:12.179+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:05:12.188+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:05:12.187+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:05:12.225+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:05:12.290+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:05:12.290+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:05:12.308+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:05:12.307+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:05:12.323+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.180 seconds
[2024-07-29T13:05:42.764+0000] {processor.py:157} INFO - Started process (PID=31088) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:05:42.766+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:05:42.771+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:05:42.771+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:05:42.795+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:05:42.826+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:05:42.825+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:05:42.841+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:05:42.841+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:05:42.854+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.097 seconds
[2024-07-29T13:06:13.323+0000] {processor.py:157} INFO - Started process (PID=31113) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:06:13.325+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:06:13.331+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:06:13.331+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:06:13.363+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:06:13.428+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:06:13.428+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:06:13.457+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:06:13.456+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:06:13.479+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.166 seconds
[2024-07-29T13:06:43.935+0000] {processor.py:157} INFO - Started process (PID=31138) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:06:43.936+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:06:43.941+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:06:43.941+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:06:43.962+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:06:43.992+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:06:43.992+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:06:44.007+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:06:44.007+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:06:44.017+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.089 seconds
[2024-07-29T13:07:14.444+0000] {processor.py:157} INFO - Started process (PID=31163) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:07:14.445+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:07:14.449+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:07:14.448+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:07:14.468+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:07:14.492+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:07:14.492+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:07:14.507+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:07:14.507+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:07:14.518+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.079 seconds
[2024-07-29T13:07:44.948+0000] {processor.py:157} INFO - Started process (PID=31188) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:07:44.952+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:07:44.960+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:07:44.959+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:07:45.011+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:07:45.088+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:07:45.088+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:07:45.144+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:07:45.144+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:07:45.169+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.233 seconds
[2024-07-29T13:08:15.700+0000] {processor.py:157} INFO - Started process (PID=31213) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:08:15.703+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:08:15.711+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:08:15.710+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:08:15.739+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:08:15.773+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:08:15.773+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:08:15.794+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:08:15.794+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:08:15.811+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.121 seconds
[2024-07-29T13:08:46.249+0000] {processor.py:157} INFO - Started process (PID=31238) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:08:46.256+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:08:46.262+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:08:46.261+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:08:46.297+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:08:46.343+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:08:46.343+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:08:46.367+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:08:46.367+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:08:46.393+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.157 seconds
[2024-07-29T13:09:16.824+0000] {processor.py:157} INFO - Started process (PID=31263) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:09:16.826+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:09:16.830+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:09:16.830+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:09:16.860+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:09:16.889+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:09:16.889+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:09:16.905+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:09:16.905+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:09:16.916+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.108 seconds
[2024-07-29T13:09:47.367+0000] {processor.py:157} INFO - Started process (PID=31288) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:09:47.369+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:09:47.375+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:09:47.375+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:09:47.425+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:09:47.467+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:09:47.467+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:09:47.488+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:09:47.488+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:09:47.547+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.190 seconds
[2024-07-29T13:10:18.097+0000] {processor.py:157} INFO - Started process (PID=31313) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:10:18.099+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:10:18.104+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:10:18.103+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:10:18.124+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:10:18.159+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:10:18.159+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:10:18.174+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:10:18.174+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:10:18.187+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.097 seconds
[2024-07-29T13:10:48.605+0000] {processor.py:157} INFO - Started process (PID=31338) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:10:48.606+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:10:48.610+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:10:48.610+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:10:48.628+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:10:48.649+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:10:48.649+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:10:48.665+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:10:48.664+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:10:48.676+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.076 seconds
[2024-07-29T13:11:19.091+0000] {processor.py:157} INFO - Started process (PID=31363) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:11:19.094+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:11:19.099+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:11:19.099+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:11:19.144+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:11:19.174+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:11:19.174+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:11:19.191+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:11:19.191+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:11:19.202+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.119 seconds
[2024-07-29T13:11:49.662+0000] {processor.py:157} INFO - Started process (PID=31388) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:11:49.664+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:11:49.670+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:11:49.669+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:11:49.692+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:11:49.728+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:11:49.728+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:11:49.742+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:11:49.742+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:11:49.753+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.102 seconds
[2024-07-29T13:12:20.215+0000] {processor.py:157} INFO - Started process (PID=31413) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:12:20.217+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:12:20.222+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:12:20.222+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:12:20.243+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:12:20.270+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:12:20.270+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:12:20.290+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:12:20.290+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:12:20.300+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.091 seconds
[2024-07-29T13:12:50.769+0000] {processor.py:157} INFO - Started process (PID=31438) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:12:50.771+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:12:50.775+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:12:50.775+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:12:50.793+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:12:50.815+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:12:50.815+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:12:50.828+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:12:50.828+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:12:50.838+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.076 seconds
[2024-07-29T13:13:21.303+0000] {processor.py:157} INFO - Started process (PID=31463) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:13:21.304+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:13:21.309+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:13:21.308+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:13:21.334+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:13:21.380+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:13:21.380+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:13:21.395+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:13:21.395+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:13:21.406+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.116 seconds
[2024-07-29T13:13:51.834+0000] {processor.py:157} INFO - Started process (PID=31488) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:13:51.835+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:13:51.839+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:13:51.839+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:13:51.859+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:13:51.885+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:13:51.885+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:13:51.899+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:13:51.899+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:13:51.913+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.086 seconds
[2024-07-29T13:14:22.375+0000] {processor.py:157} INFO - Started process (PID=31513) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:14:22.378+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:14:22.387+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:14:22.387+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:14:22.445+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:14:22.493+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:14:22.493+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:14:22.516+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:14:22.516+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:14:22.530+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.165 seconds
[2024-07-29T13:14:52.920+0000] {processor.py:157} INFO - Started process (PID=31538) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:14:52.922+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:14:52.927+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:14:52.926+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:14:52.947+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:14:52.981+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:14:52.981+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:14:52.996+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:14:52.996+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:14:53.008+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.094 seconds
[2024-07-29T13:15:23.570+0000] {processor.py:157} INFO - Started process (PID=31563) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:15:23.573+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:15:23.579+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:15:23.578+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:15:23.629+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:15:23.681+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:15:23.681+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:15:23.704+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:15:23.704+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:15:23.718+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.158 seconds
[2024-07-29T13:15:54.123+0000] {processor.py:157} INFO - Started process (PID=31588) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:15:54.131+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:15:54.160+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:15:54.154+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:15:54.281+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:15:54.359+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:15:54.359+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:15:54.379+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:15:54.378+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:15:54.401+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.292 seconds
[2024-07-29T13:16:24.895+0000] {processor.py:157} INFO - Started process (PID=31613) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:16:24.896+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:16:24.902+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:16:24.901+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:16:24.930+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:16:24.959+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:16:24.959+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:16:24.976+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:16:24.975+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:16:24.988+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.110 seconds
[2024-07-29T13:16:55.363+0000] {processor.py:157} INFO - Started process (PID=31638) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:16:55.364+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:16:55.369+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:16:55.368+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:16:55.388+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:16:55.410+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:16:55.410+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:16:55.423+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:16:55.423+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:16:55.434+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.077 seconds
[2024-07-29T13:17:25.920+0000] {processor.py:157} INFO - Started process (PID=31663) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:17:25.923+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:17:25.927+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:17:25.926+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:17:25.958+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:17:26.003+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:17:26.003+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:17:26.020+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:17:26.020+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:17:26.034+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.131 seconds
[2024-07-29T13:17:56.554+0000] {processor.py:157} INFO - Started process (PID=31688) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:17:56.556+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:17:56.560+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:17:56.560+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:17:56.584+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:17:56.622+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:17:56.622+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:17:56.640+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:17:56.640+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:17:56.650+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.110 seconds
[2024-07-29T13:18:27.156+0000] {processor.py:157} INFO - Started process (PID=31713) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:18:27.157+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:18:27.162+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:18:27.161+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:18:27.197+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:18:27.225+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:18:27.225+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:18:27.240+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:18:27.240+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:18:27.250+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.101 seconds
[2024-07-29T13:18:57.794+0000] {processor.py:157} INFO - Started process (PID=31738) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:18:57.797+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:18:57.819+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:18:57.819+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:18:57.841+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:18:57.867+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:18:57.867+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:18:57.883+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:18:57.883+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:18:57.894+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.106 seconds
[2024-07-29T13:19:28.356+0000] {processor.py:157} INFO - Started process (PID=31763) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:19:28.368+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:19:28.394+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:19:28.393+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:19:28.425+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:19:28.475+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:19:28.475+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:19:28.492+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:19:28.491+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:19:28.504+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.158 seconds
[2024-07-29T13:19:59.042+0000] {processor.py:157} INFO - Started process (PID=31788) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:19:59.043+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:19:59.047+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:19:59.047+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:19:59.090+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:19:59.133+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:19:59.133+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:19:59.147+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:19:59.147+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:19:59.158+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.121 seconds
[2024-07-29T13:20:29.639+0000] {processor.py:157} INFO - Started process (PID=31813) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:20:29.641+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:20:29.647+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:20:29.647+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:20:29.668+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:20:29.699+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:20:29.699+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:20:29.713+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:20:29.713+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:20:29.724+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.099 seconds
[2024-07-29T13:21:00.098+0000] {processor.py:157} INFO - Started process (PID=31838) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:21:00.100+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:21:00.103+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:21:00.102+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:21:00.115+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:21:00.137+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:21:00.137+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:21:00.151+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:21:00.151+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:21:00.163+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-29T13:21:30.554+0000] {processor.py:157} INFO - Started process (PID=31863) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:21:30.555+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:21:30.559+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:21:30.559+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:21:30.585+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:21:30.613+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:21:30.613+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:21:30.627+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:21:30.627+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:21:30.638+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.093 seconds
[2024-07-29T13:22:01.120+0000] {processor.py:157} INFO - Started process (PID=31888) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:22:01.122+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:22:01.128+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:22:01.127+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:22:01.162+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:22:01.198+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:22:01.198+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:22:01.227+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:22:01.226+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:22:01.240+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.128 seconds
[2024-07-29T13:22:31.672+0000] {processor.py:157} INFO - Started process (PID=31913) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:22:31.674+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:22:31.684+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:22:31.683+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:22:31.726+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:22:31.780+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:22:31.780+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:22:31.805+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:22:31.804+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:22:31.819+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.159 seconds
[2024-07-29T13:23:02.228+0000] {processor.py:157} INFO - Started process (PID=31938) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:23:02.230+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:23:02.235+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:23:02.235+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:23:02.255+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:23:02.291+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:23:02.291+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:23:02.305+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:23:02.305+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:23:02.318+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.095 seconds
[2024-07-29T13:23:32.722+0000] {processor.py:157} INFO - Started process (PID=31963) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:23:32.729+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:23:32.743+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:23:32.741+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:23:32.785+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:23:32.848+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:23:32.848+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:23:32.868+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:23:32.868+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:23:32.885+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.187 seconds
[2024-07-29T13:24:03.357+0000] {processor.py:157} INFO - Started process (PID=31988) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:24:03.367+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:24:03.386+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:24:03.385+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:24:03.415+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:24:03.458+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:24:03.458+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:24:03.480+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:24:03.480+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:24:03.494+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.149 seconds
[2024-07-29T13:24:33.929+0000] {processor.py:157} INFO - Started process (PID=32013) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:24:33.932+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:24:33.960+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:24:33.959+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:24:33.992+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:24:34.034+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:24:34.034+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:24:34.055+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:24:34.055+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:24:34.070+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.152 seconds
[2024-07-29T13:25:04.550+0000] {processor.py:157} INFO - Started process (PID=32038) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:25:04.552+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:25:04.559+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:25:04.559+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:25:04.607+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:25:04.653+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:25:04.653+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:25:04.672+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:25:04.672+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:25:04.687+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.147 seconds
[2024-07-29T13:25:35.059+0000] {processor.py:157} INFO - Started process (PID=32063) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:25:35.061+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:25:35.066+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:25:35.066+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:25:35.088+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:25:35.115+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:25:35.115+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:25:35.132+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:25:35.132+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:25:35.144+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.094 seconds
[2024-07-29T13:26:05.585+0000] {processor.py:157} INFO - Started process (PID=32088) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:26:05.589+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:26:05.597+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:26:05.596+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:26:05.627+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:26:05.682+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:26:05.682+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:26:05.714+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:26:05.714+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:26:05.727+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.153 seconds
[2024-07-29T13:26:36.134+0000] {processor.py:157} INFO - Started process (PID=32113) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:26:36.136+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:26:36.143+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:26:36.143+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:26:36.175+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:26:36.230+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:26:36.230+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:26:36.251+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:26:36.251+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:26:36.264+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.139 seconds
[2024-07-29T13:27:06.675+0000] {processor.py:157} INFO - Started process (PID=32138) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:27:06.676+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:27:06.681+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:27:06.681+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:27:06.701+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:27:06.728+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:27:06.728+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:27:06.744+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:27:06.743+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:27:06.756+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.087 seconds
[2024-07-29T13:27:37.176+0000] {processor.py:157} INFO - Started process (PID=32163) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:27:37.179+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:27:37.188+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:27:37.187+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:27:37.221+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:27:37.259+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:27:37.259+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:27:37.276+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:27:37.275+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:27:37.290+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.122 seconds
[2024-07-29T13:28:07.763+0000] {processor.py:157} INFO - Started process (PID=32188) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:28:07.764+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:28:07.769+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:28:07.769+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:28:07.790+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:28:07.818+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:28:07.818+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:28:07.837+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:28:07.837+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:28:07.849+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.093 seconds
[2024-07-29T13:28:38.244+0000] {processor.py:157} INFO - Started process (PID=32213) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:28:38.246+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:28:38.251+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:28:38.251+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:28:38.279+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:28:38.314+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:28:38.313+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:28:38.348+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:28:38.348+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:28:38.361+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.125 seconds
[2024-07-29T13:29:08.828+0000] {processor.py:157} INFO - Started process (PID=32238) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:29:08.832+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:29:08.839+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:29:08.838+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:29:08.894+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:29:08.935+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:29:08.935+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:29:08.964+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:29:08.964+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:29:08.981+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.164 seconds
[2024-07-29T13:29:39.446+0000] {processor.py:157} INFO - Started process (PID=32263) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:29:39.451+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:29:39.459+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:29:39.458+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:29:39.483+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:29:39.513+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:29:39.513+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:29:39.532+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:29:39.532+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:29:39.548+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.110 seconds
[2024-07-29T13:30:09.981+0000] {processor.py:157} INFO - Started process (PID=32288) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:30:09.982+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:30:09.987+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:30:09.987+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:30:10.007+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:30:10.030+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:30:10.030+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:30:10.044+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:30:10.044+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:30:10.054+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.080 seconds
[2024-07-29T13:30:40.478+0000] {processor.py:157} INFO - Started process (PID=32313) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:30:40.479+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:30:40.485+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:30:40.484+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:30:40.506+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:30:40.534+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:30:40.534+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:30:40.552+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:30:40.552+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:30:40.564+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.094 seconds
[2024-07-29T13:31:10.929+0000] {processor.py:157} INFO - Started process (PID=32338) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:31:10.931+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:31:10.935+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:31:10.934+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:31:10.949+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:31:10.974+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:31:10.974+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:31:10.994+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:31:10.994+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:31:11.009+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.086 seconds
[2024-07-29T13:31:41.443+0000] {processor.py:157} INFO - Started process (PID=32363) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:31:41.445+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:31:41.451+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:31:41.451+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:31:41.481+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:31:41.534+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:31:41.534+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:31:41.556+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:31:41.556+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:31:41.569+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.149 seconds
[2024-07-29T13:32:12.008+0000] {processor.py:157} INFO - Started process (PID=32388) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:32:12.011+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:32:12.018+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:32:12.018+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:32:12.051+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:32:12.116+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:32:12.116+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:32:12.138+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:32:12.138+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:32:12.151+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.153 seconds
[2024-07-29T13:32:42.556+0000] {processor.py:157} INFO - Started process (PID=32413) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:32:42.560+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:32:42.567+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:32:42.566+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:32:42.596+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:32:42.635+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:32:42.635+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:32:42.656+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:32:42.656+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:32:42.670+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.123 seconds
[2024-07-29T13:33:13.178+0000] {processor.py:157} INFO - Started process (PID=32438) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:33:13.179+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:33:13.185+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:33:13.184+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:33:13.206+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:33:13.236+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:33:13.236+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:33:13.259+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:33:13.259+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:33:13.272+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.100 seconds
[2024-07-29T13:33:43.752+0000] {processor.py:157} INFO - Started process (PID=32463) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:33:43.754+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:33:43.760+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:33:43.759+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:33:43.784+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:33:43.818+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:33:43.818+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:33:43.841+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:33:43.841+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:33:43.855+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.111 seconds
[2024-07-29T13:34:14.287+0000] {processor.py:157} INFO - Started process (PID=32488) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:34:14.289+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:34:14.296+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:34:14.295+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:34:14.332+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:34:14.417+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:34:14.417+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:34:14.461+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:34:14.461+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:34:14.476+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.212 seconds
[2024-07-29T13:34:44.929+0000] {processor.py:157} INFO - Started process (PID=32513) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:34:44.932+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:34:44.940+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:34:44.939+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:34:44.977+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:34:45.022+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:34:45.022+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:34:45.051+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:34:45.051+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:34:45.068+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.151 seconds
[2024-07-29T13:35:15.547+0000] {processor.py:157} INFO - Started process (PID=32538) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:35:15.551+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:35:15.577+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:35:15.571+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:35:15.608+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:35:15.656+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:35:15.655+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:35:15.683+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:35:15.682+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:35:15.702+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.163 seconds
[2024-07-29T13:35:46.288+0000] {processor.py:157} INFO - Started process (PID=32563) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:35:46.290+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:35:46.295+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:35:46.294+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:35:46.319+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:35:46.352+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:35:46.351+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:35:46.369+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:35:46.369+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:35:46.384+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.103 seconds
[2024-07-29T13:36:16.847+0000] {processor.py:157} INFO - Started process (PID=32588) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:36:16.849+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:36:16.855+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:36:16.855+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:36:16.887+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:36:16.927+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:36:16.926+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:36:16.947+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:36:16.947+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:36:16.961+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.121 seconds
[2024-07-29T13:36:47.420+0000] {processor.py:157} INFO - Started process (PID=32613) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:36:47.430+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:36:47.441+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:36:47.440+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:36:47.474+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:36:47.544+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:36:47.543+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:36:47.588+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:36:47.588+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:36:47.603+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.210 seconds
[2024-07-29T13:37:18.127+0000] {processor.py:157} INFO - Started process (PID=32638) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:37:18.130+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:37:18.140+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:37:18.139+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:37:18.171+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:37:18.232+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:37:18.231+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:37:18.256+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:37:18.256+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:37:18.271+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.158 seconds
[2024-07-29T13:37:48.622+0000] {processor.py:157} INFO - Started process (PID=32663) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:37:48.625+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:37:48.629+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:37:48.629+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:37:48.647+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:37:48.663+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:37:48.663+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:37:48.676+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:37:48.676+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:37:48.685+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.068 seconds
[2024-07-29T13:38:19.119+0000] {processor.py:157} INFO - Started process (PID=32688) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:38:19.122+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:38:19.127+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:38:19.126+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:38:19.146+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:38:19.184+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:38:19.184+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:38:19.202+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:38:19.202+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:38:19.216+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.105 seconds
[2024-07-29T13:38:49.621+0000] {processor.py:157} INFO - Started process (PID=32713) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:38:49.624+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:38:49.629+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:38:49.629+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:38:49.654+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:38:49.693+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:38:49.693+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:38:49.711+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:38:49.711+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:38:49.726+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.111 seconds
[2024-07-29T13:39:20.224+0000] {processor.py:157} INFO - Started process (PID=32738) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:39:20.227+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:39:20.234+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:39:20.233+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:39:20.268+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:39:20.306+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:39:20.306+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:39:20.328+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:39:20.328+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:39:20.344+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.132 seconds
[2024-07-29T13:39:50.818+0000] {processor.py:157} INFO - Started process (PID=32763) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:39:50.820+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:39:50.825+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:39:50.825+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:39:50.849+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:39:50.881+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:39:50.881+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:39:50.899+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:39:50.899+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:39:50.912+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.102 seconds
[2024-07-29T13:40:21.362+0000] {processor.py:157} INFO - Started process (PID=32788) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:40:21.365+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:40:21.371+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:40:21.371+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:40:21.397+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:40:21.430+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:40:21.430+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:40:21.448+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:40:21.447+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:40:21.461+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.109 seconds
[2024-07-29T13:40:51.876+0000] {processor.py:157} INFO - Started process (PID=32813) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:40:51.879+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:40:51.886+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:40:51.885+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:40:51.934+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:40:51.978+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:40:51.977+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:40:52.021+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:40:52.021+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:40:52.032+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.166 seconds
[2024-07-29T13:41:22.557+0000] {processor.py:157} INFO - Started process (PID=32838) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:41:22.560+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:41:22.570+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:41:22.569+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:41:22.601+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:41:22.643+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:41:22.643+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:41:22.680+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:41:22.680+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:41:22.697+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.154 seconds
[2024-07-29T13:41:53.088+0000] {processor.py:157} INFO - Started process (PID=32863) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:41:53.089+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:41:53.095+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:41:53.094+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:41:53.145+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:41:53.174+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:41:53.174+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:41:53.189+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:41:53.189+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:41:53.198+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.118 seconds
[2024-07-29T13:42:23.672+0000] {processor.py:157} INFO - Started process (PID=32888) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:42:23.673+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:42:23.680+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:42:23.679+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:42:23.704+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:42:23.775+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:42:23.775+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:42:23.801+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:42:23.801+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:42:23.811+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.147 seconds
[2024-07-29T13:42:54.311+0000] {processor.py:157} INFO - Started process (PID=32913) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:42:54.315+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:42:54.321+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:42:54.321+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:42:54.348+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:42:54.378+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:42:54.378+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:42:54.395+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:42:54.395+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:42:54.407+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.103 seconds
[2024-07-29T13:43:24.956+0000] {processor.py:157} INFO - Started process (PID=32938) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:43:24.959+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:43:24.967+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:43:24.966+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:43:25.001+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:43:25.054+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:43:25.053+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:43:25.073+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:43:25.073+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:43:25.087+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.143 seconds
[2024-07-29T13:43:55.512+0000] {processor.py:157} INFO - Started process (PID=32963) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:43:55.513+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:43:55.516+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:43:55.516+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:43:55.536+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:43:55.560+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:43:55.560+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:43:55.574+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:43:55.574+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:43:55.586+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.081 seconds
[2024-07-29T13:44:25.942+0000] {processor.py:157} INFO - Started process (PID=32988) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:44:25.944+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:44:25.946+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:44:25.946+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:44:25.954+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:44:25.970+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:44:25.970+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:44:25.983+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:44:25.983+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:44:25.994+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-29T13:44:56.505+0000] {processor.py:157} INFO - Started process (PID=33013) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:44:56.510+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:44:56.518+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:44:56.517+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:44:56.553+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:44:56.600+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:44:56.600+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:44:56.614+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:44:56.614+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:44:56.623+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.134 seconds
[2024-07-29T13:45:27.091+0000] {processor.py:157} INFO - Started process (PID=33038) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:45:27.097+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:45:27.103+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:45:27.102+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:45:27.121+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:45:27.153+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:45:27.153+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:45:27.167+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:45:27.167+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:45:27.176+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.092 seconds
[2024-07-29T13:45:57.961+0000] {processor.py:157} INFO - Started process (PID=33063) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:45:57.966+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:45:57.975+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:45:57.974+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:45:58.013+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:45:58.053+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:45:58.052+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:45:58.072+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:45:58.072+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:45:58.084+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.134 seconds
[2024-07-29T13:46:28.502+0000] {processor.py:157} INFO - Started process (PID=33088) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:46:28.505+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:46:28.514+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:46:28.513+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:46:28.541+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:46:28.577+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:46:28.577+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:46:28.596+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:46:28.596+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:46:28.609+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.117 seconds
[2024-07-29T13:46:59.042+0000] {processor.py:157} INFO - Started process (PID=33113) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:46:59.043+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:46:59.047+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:46:59.047+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:46:59.067+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:46:59.103+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:46:59.103+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:46:59.119+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:46:59.119+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:46:59.129+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.099 seconds
[2024-07-29T13:47:29.560+0000] {processor.py:157} INFO - Started process (PID=33138) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:47:29.561+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:47:29.565+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:47:29.565+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:47:29.585+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:47:29.603+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:47:29.603+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:47:29.613+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:47:29.613+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:47:29.621+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.068 seconds
[2024-07-29T13:47:59.983+0000] {processor.py:157} INFO - Started process (PID=33163) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:47:59.985+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:47:59.987+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:47:59.987+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:47:59.999+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:48:00.029+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:48:00.029+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:48:00.044+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:48:00.044+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:48:00.054+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.079 seconds
[2024-07-29T13:48:30.445+0000] {processor.py:157} INFO - Started process (PID=33188) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:48:30.447+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:48:30.452+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:48:30.451+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:48:30.472+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:48:30.498+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:48:30.498+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:48:30.517+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:48:30.517+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:48:30.532+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.095 seconds
[2024-07-29T13:49:01.026+0000] {processor.py:157} INFO - Started process (PID=33213) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:49:01.027+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:49:01.032+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:49:01.031+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:49:01.048+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:49:01.072+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:49:01.071+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:49:01.086+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:49:01.086+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:49:01.099+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.079 seconds
[2024-07-29T13:49:31.527+0000] {processor.py:157} INFO - Started process (PID=33238) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:49:31.528+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:49:31.530+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:49:31.530+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:49:31.540+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:49:31.557+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:49:31.557+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:49:31.567+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:49:31.567+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:49:31.575+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-29T13:50:02.025+0000] {processor.py:157} INFO - Started process (PID=33263) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:50:02.026+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:50:02.031+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:50:02.030+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:50:02.052+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:50:02.093+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:50:02.093+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:50:02.108+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:50:02.108+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:50:02.117+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.111 seconds
[2024-07-29T13:50:32.641+0000] {processor.py:157} INFO - Started process (PID=33288) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:50:32.643+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:50:32.648+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:50:32.647+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:50:32.669+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:50:32.704+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:50:32.703+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:50:32.718+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:50:32.718+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:50:32.728+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.094 seconds
[2024-07-29T13:51:03.184+0000] {processor.py:157} INFO - Started process (PID=33313) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:51:03.189+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:51:03.199+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:51:03.197+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:51:03.223+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:51:03.266+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:51:03.266+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:51:03.280+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:51:03.279+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:51:03.290+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.132 seconds
[2024-07-29T13:51:33.775+0000] {processor.py:157} INFO - Started process (PID=33338) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:51:33.776+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:51:33.780+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:51:33.779+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:51:33.800+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:51:33.823+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:51:33.823+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:51:33.837+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:51:33.837+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:51:33.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.078 seconds
[2024-07-29T13:52:04.234+0000] {processor.py:157} INFO - Started process (PID=33363) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:52:04.235+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:52:04.239+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:52:04.239+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:52:04.260+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:52:04.284+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:52:04.284+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:52:04.297+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:52:04.297+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:52:04.306+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.077 seconds
[2024-07-29T13:52:34.734+0000] {processor.py:157} INFO - Started process (PID=33388) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:52:34.738+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:52:34.743+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:52:34.742+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:52:34.759+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:52:34.784+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:52:34.784+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:52:34.799+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:52:34.798+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:52:34.808+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.084 seconds
[2024-07-29T13:53:05.141+0000] {processor.py:157} INFO - Started process (PID=33413) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:53:05.142+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:53:05.145+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:53:05.144+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:53:05.153+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:53:05.168+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:53:05.168+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:53:05.180+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:53:05.180+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:53:05.191+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-29T13:53:35.570+0000] {processor.py:157} INFO - Started process (PID=33438) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:53:35.572+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:53:35.576+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:53:35.575+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:53:35.598+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:53:35.622+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:53:35.622+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:53:35.634+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:53:35.634+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:53:35.645+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.082 seconds
[2024-07-29T13:54:06.096+0000] {processor.py:157} INFO - Started process (PID=33463) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:54:06.097+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:54:06.101+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:54:06.101+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:54:06.126+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:54:06.152+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:54:06.152+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:54:06.167+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:54:06.167+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:54:06.179+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.090 seconds
[2024-07-29T13:54:36.571+0000] {processor.py:157} INFO - Started process (PID=33488) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:54:36.573+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:54:36.575+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:54:36.575+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:54:36.588+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:54:36.610+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:54:36.610+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:54:36.626+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:54:36.626+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:54:36.639+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.073 seconds
[2024-07-29T13:55:07.045+0000] {processor.py:157} INFO - Started process (PID=33513) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:55:07.046+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:55:07.051+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:55:07.050+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:55:07.070+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:55:07.113+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:55:07.112+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:55:07.129+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:55:07.129+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:55:07.138+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.101 seconds
[2024-07-29T13:55:37.551+0000] {processor.py:157} INFO - Started process (PID=33538) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:55:37.553+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:55:37.555+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:55:37.555+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:55:37.564+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:55:37.580+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:55:37.580+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:55:37.596+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:55:37.596+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:55:37.603+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-29T13:56:07.955+0000] {processor.py:157} INFO - Started process (PID=33563) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:56:07.956+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:56:07.958+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:56:07.958+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:56:07.967+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:56:07.984+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:56:07.984+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:56:07.994+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:56:07.994+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:56:08.004+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-29T13:56:38.296+0000] {processor.py:157} INFO - Started process (PID=33588) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:56:38.296+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:56:38.298+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:56:38.297+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:56:38.306+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:56:38.317+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:56:38.317+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:56:38.328+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:56:38.328+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:56:38.336+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.042 seconds
[2024-07-29T13:57:08.723+0000] {processor.py:157} INFO - Started process (PID=33613) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:57:08.724+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:57:08.726+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:57:08.726+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:57:08.737+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:57:08.754+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:57:08.754+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:57:08.767+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:57:08.767+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:57:08.778+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-29T13:57:39.151+0000] {processor.py:157} INFO - Started process (PID=33638) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:57:39.153+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:57:39.156+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:57:39.156+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:57:39.174+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:57:39.197+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:57:39.197+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:57:39.210+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:57:39.210+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:57:39.220+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.074 seconds
[2024-07-29T13:58:09.554+0000] {processor.py:157} INFO - Started process (PID=33663) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:58:09.555+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:58:09.557+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:58:09.557+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:58:09.568+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:58:09.584+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:58:09.584+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:58:09.594+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:58:09.593+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:58:09.604+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-29T13:58:40.028+0000] {processor.py:157} INFO - Started process (PID=33688) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:58:40.030+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:58:40.032+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:58:40.032+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:58:40.043+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:58:40.059+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:58:40.059+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:58:40.074+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:58:40.073+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:58:40.082+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-29T13:59:10.477+0000] {processor.py:157} INFO - Started process (PID=33713) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:59:10.478+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:59:10.480+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:59:10.480+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:59:10.490+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:59:10.507+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:59:10.507+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:59:10.518+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:59:10.518+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:59:10.529+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-29T13:59:40.882+0000] {processor.py:157} INFO - Started process (PID=33738) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:59:40.884+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T13:59:40.887+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:59:40.887+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:59:40.896+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T13:59:40.912+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:59:40.911+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:59:40.923+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:59:40.923+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T13:59:40.931+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-29T14:00:11.292+0000] {processor.py:157} INFO - Started process (PID=33763) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:00:11.293+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:00:11.298+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:00:11.297+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:00:11.316+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:00:11.341+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:00:11.341+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:00:11.353+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:00:11.353+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:00:11.363+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.078 seconds
[2024-07-29T14:00:41.772+0000] {processor.py:157} INFO - Started process (PID=33788) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:00:41.776+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:00:41.778+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:00:41.778+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:00:41.791+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:00:41.807+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:00:41.807+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:00:41.818+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:00:41.818+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:00:41.828+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-29T14:01:12.303+0000] {processor.py:157} INFO - Started process (PID=33813) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:01:12.304+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:01:12.307+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:01:12.307+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:01:12.325+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:01:12.349+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:01:12.349+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:01:12.360+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:01:12.360+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:01:12.367+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.068 seconds
[2024-07-29T14:01:42.741+0000] {processor.py:157} INFO - Started process (PID=33838) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:01:42.742+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:01:42.745+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:01:42.744+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:01:42.753+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:01:42.769+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:01:42.769+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:01:42.781+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:01:42.781+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:01:42.792+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-29T14:02:13.123+0000] {processor.py:157} INFO - Started process (PID=33863) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:02:13.124+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:02:13.127+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:02:13.127+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:02:13.141+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:02:13.161+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:02:13.161+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:02:13.174+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:02:13.174+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:02:13.183+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-29T14:02:43.581+0000] {processor.py:157} INFO - Started process (PID=33888) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:02:43.581+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:02:43.583+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:02:43.583+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:02:43.596+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:02:43.612+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:02:43.612+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:02:43.621+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:02:43.621+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:02:43.630+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-29T14:03:14.014+0000] {processor.py:157} INFO - Started process (PID=33913) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:03:14.016+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:03:14.019+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:03:14.019+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:03:14.032+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:03:14.048+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:03:14.048+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:03:14.057+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:03:14.057+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:03:14.067+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-29T14:03:44.515+0000] {processor.py:157} INFO - Started process (PID=33938) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:03:44.516+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:03:44.519+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:03:44.519+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:03:44.529+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:03:44.545+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:03:44.545+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:03:44.556+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:03:44.556+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:03:44.568+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-29T14:04:15.085+0000] {processor.py:157} INFO - Started process (PID=33963) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:04:15.086+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:04:15.088+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:04:15.088+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:04:15.102+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:04:15.121+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:04:15.121+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:04:15.134+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:04:15.134+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:04:15.140+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-29T14:04:45.499+0000] {processor.py:157} INFO - Started process (PID=33988) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:04:45.500+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:04:45.501+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:04:45.501+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:04:45.514+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:04:45.529+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:04:45.529+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:04:45.539+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:04:45.539+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:04:45.546+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-29T14:05:15.989+0000] {processor.py:157} INFO - Started process (PID=34013) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:05:15.990+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:05:15.992+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:05:15.992+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:05:16.029+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:05:16.052+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:05:16.052+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:05:16.063+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:05:16.063+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:05:16.072+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.086 seconds
[2024-07-29T14:05:46.431+0000] {processor.py:157} INFO - Started process (PID=34038) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:05:46.432+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:05:46.435+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:05:46.435+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:05:46.450+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:05:46.471+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:05:46.471+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:05:46.484+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:05:46.484+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:05:46.495+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-29T14:06:16.924+0000] {processor.py:157} INFO - Started process (PID=34063) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:06:16.926+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:06:16.928+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:06:16.928+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:06:16.940+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:06:16.956+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:06:16.956+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:06:16.971+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:06:16.970+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:06:16.979+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-29T14:06:47.411+0000] {processor.py:157} INFO - Started process (PID=34088) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:06:47.412+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:06:47.414+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:06:47.413+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:06:47.426+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:06:47.442+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:06:47.442+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:06:47.452+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:06:47.452+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:06:47.462+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-29T14:07:17.813+0000] {processor.py:157} INFO - Started process (PID=34113) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:07:17.813+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:07:17.815+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:07:17.815+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:07:17.822+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:07:17.835+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:07:17.835+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:07:17.843+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:07:17.843+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:07:17.851+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.040 seconds
[2024-07-29T14:07:48.341+0000] {processor.py:157} INFO - Started process (PID=34138) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:07:48.342+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:07:48.344+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:07:48.344+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:07:48.355+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:07:48.372+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:07:48.372+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:07:48.385+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:07:48.385+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:07:48.394+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-29T14:08:18.819+0000] {processor.py:157} INFO - Started process (PID=34163) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:08:18.821+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:08:18.822+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:08:18.822+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:08:18.831+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:08:18.847+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:08:18.847+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:08:18.858+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:08:18.858+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:08:18.867+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-29T14:08:49.296+0000] {processor.py:157} INFO - Started process (PID=34188) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:08:49.297+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:08:49.300+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:08:49.299+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:08:49.317+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:08:49.337+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:08:49.337+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:08:49.347+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:08:49.347+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:08:49.357+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-29T14:09:19.737+0000] {processor.py:157} INFO - Started process (PID=34213) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:09:19.738+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:09:19.742+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:09:19.742+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:09:19.760+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:09:19.780+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:09:19.780+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:09:19.795+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:09:19.794+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:09:19.805+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.074 seconds
[2024-07-29T14:09:50.112+0000] {processor.py:157} INFO - Started process (PID=34238) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:09:50.112+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:09:50.114+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:09:50.114+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:09:50.126+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:09:50.142+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:09:50.142+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:09:50.152+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:09:50.152+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:09:50.160+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-29T14:10:20.662+0000] {processor.py:157} INFO - Started process (PID=34263) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:10:20.663+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:10:20.668+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:10:20.667+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:10:20.690+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:10:20.722+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:10:20.722+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:10:20.737+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:10:20.737+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:10:20.748+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.093 seconds
[2024-07-29T14:10:51.137+0000] {processor.py:157} INFO - Started process (PID=34288) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:10:51.138+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:10:51.140+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:10:51.140+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:10:51.153+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:10:51.170+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:10:51.170+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:10:51.182+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:10:51.182+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:10:51.191+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-29T14:11:21.558+0000] {processor.py:157} INFO - Started process (PID=34313) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:11:21.560+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:11:21.564+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:11:21.564+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:11:21.584+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:11:21.610+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:11:21.609+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:11:21.627+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:11:21.627+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:11:21.638+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.085 seconds
[2024-07-29T14:11:51.978+0000] {processor.py:157} INFO - Started process (PID=34338) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:11:51.978+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:11:51.981+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:11:51.981+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:11:51.994+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:11:52.010+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:11:52.010+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:11:52.019+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:11:52.019+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:11:52.028+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-29T14:12:22.468+0000] {processor.py:157} INFO - Started process (PID=34363) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:12:22.470+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:12:22.475+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:12:22.475+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:12:22.491+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:12:22.513+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:12:22.512+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:12:22.526+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:12:22.526+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:12:22.536+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.074 seconds
[2024-07-29T14:12:52.886+0000] {processor.py:157} INFO - Started process (PID=34388) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:12:52.887+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:12:52.888+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:12:52.888+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:12:52.897+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:12:52.913+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:12:52.913+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:12:52.923+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:12:52.922+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:12:52.934+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-29T14:13:23.260+0000] {processor.py:157} INFO - Started process (PID=34413) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:13:23.260+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:13:23.262+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:13:23.262+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:13:23.273+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:13:23.290+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:13:23.290+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:13:23.300+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:13:23.300+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:13:23.309+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-29T14:13:53.691+0000] {processor.py:157} INFO - Started process (PID=34438) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:13:53.692+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:13:53.695+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:13:53.695+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:13:53.705+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:13:53.721+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:13:53.721+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:13:53.736+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:13:53.736+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:13:53.743+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-29T14:14:24.096+0000] {processor.py:157} INFO - Started process (PID=34463) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:14:24.097+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:14:24.100+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:14:24.100+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:14:24.115+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:14:24.136+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:14:24.136+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:14:24.149+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:14:24.149+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:14:24.158+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-29T14:14:54.573+0000] {processor.py:157} INFO - Started process (PID=34488) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:14:54.575+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:14:54.579+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:14:54.578+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:14:54.593+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:14:54.607+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:14:54.607+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:14:54.619+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:14:54.619+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:14:54.629+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-29T14:15:25.001+0000] {processor.py:157} INFO - Started process (PID=34513) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:15:25.002+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:15:25.004+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:15:25.004+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:15:25.016+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:15:25.032+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:15:25.032+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:15:25.046+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:15:25.046+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:15:25.055+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-29T14:15:55.385+0000] {processor.py:157} INFO - Started process (PID=34538) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:15:55.386+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:15:55.389+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:15:55.389+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:15:55.398+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:15:55.414+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:15:55.414+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:15:55.423+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:15:55.423+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:15:55.432+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-29T14:16:25.777+0000] {processor.py:157} INFO - Started process (PID=34563) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:16:25.778+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:16:25.779+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:16:25.779+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:16:25.789+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:16:25.806+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:16:25.805+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:16:25.818+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:16:25.818+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:16:25.828+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-29T14:16:56.164+0000] {processor.py:157} INFO - Started process (PID=34588) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:16:56.165+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:16:56.167+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:16:56.167+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:16:56.181+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:16:56.196+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:16:56.196+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:16:56.206+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:16:56.206+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:16:56.215+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-29T14:17:26.628+0000] {processor.py:157} INFO - Started process (PID=34613) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:17:26.629+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:17:26.632+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:17:26.631+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:17:26.644+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:17:26.660+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:17:26.660+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:17:26.671+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:17:26.671+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:17:26.680+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-29T14:17:57.059+0000] {processor.py:157} INFO - Started process (PID=34638) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:17:57.061+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:17:57.062+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:17:57.062+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:17:57.071+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:17:57.085+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:17:57.085+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:17:57.098+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:17:57.098+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:17:57.107+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-29T14:18:27.531+0000] {processor.py:157} INFO - Started process (PID=34663) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:18:27.532+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:18:27.537+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:18:27.536+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:18:27.552+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:18:27.579+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:18:27.579+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:18:27.592+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:18:27.592+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:18:27.601+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.077 seconds
[2024-07-29T14:18:57.995+0000] {processor.py:157} INFO - Started process (PID=34688) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:18:57.996+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:18:57.998+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:18:57.998+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:18:58.007+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:18:58.023+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:18:58.023+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:18:58.035+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:18:58.035+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:18:58.046+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-29T14:19:28.372+0000] {processor.py:157} INFO - Started process (PID=34713) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:19:28.373+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:19:28.375+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:19:28.375+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:19:28.383+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:19:28.398+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:19:28.398+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:19:28.409+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:19:28.409+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:19:28.419+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-29T14:19:58.898+0000] {processor.py:157} INFO - Started process (PID=34738) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:19:58.899+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:19:58.901+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:19:58.901+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:19:58.911+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:19:58.927+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:19:58.927+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:19:58.936+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:19:58.936+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:19:58.946+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-29T14:20:29.279+0000] {processor.py:157} INFO - Started process (PID=34763) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:20:29.280+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:20:29.284+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:20:29.283+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:20:29.302+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:20:29.323+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:20:29.323+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:20:29.336+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:20:29.336+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:20:29.346+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.075 seconds
[2024-07-29T14:20:59.799+0000] {processor.py:157} INFO - Started process (PID=34788) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:20:59.799+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:20:59.801+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:20:59.801+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:20:59.812+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:20:59.828+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:20:59.828+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:20:59.841+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:20:59.841+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:20:59.852+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-29T14:21:30.247+0000] {processor.py:157} INFO - Started process (PID=34813) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:21:30.247+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:21:30.248+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:21:30.248+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:21:30.255+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:21:30.269+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:21:30.269+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:21:30.278+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:21:30.278+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:21:30.286+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.042 seconds
[2024-07-29T14:22:00.719+0000] {processor.py:157} INFO - Started process (PID=34838) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:22:00.720+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:22:00.722+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:22:00.722+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:22:00.761+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:22:00.779+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:22:00.778+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:22:00.787+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:22:00.787+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:22:00.796+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.079 seconds
[2024-07-29T14:22:31.188+0000] {processor.py:157} INFO - Started process (PID=34863) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:22:31.189+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:22:31.192+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:22:31.192+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:22:31.205+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:22:31.220+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:22:31.220+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:22:31.232+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:22:31.232+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:22:31.240+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-29T14:23:01.576+0000] {processor.py:157} INFO - Started process (PID=34888) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:23:01.577+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:23:01.579+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:23:01.578+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:23:01.587+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:23:01.602+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:23:01.602+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:23:01.615+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:23:01.615+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:23:01.626+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-29T14:23:32.057+0000] {processor.py:157} INFO - Started process (PID=34913) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:23:32.057+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:23:32.059+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:23:32.059+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:23:32.072+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:23:32.088+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:23:32.088+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:23:32.098+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:23:32.098+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:23:32.107+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-29T14:24:02.448+0000] {processor.py:157} INFO - Started process (PID=34938) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:24:02.449+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:24:02.453+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:24:02.452+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:24:02.470+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:24:02.494+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:24:02.494+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:24:02.508+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:24:02.508+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:24:02.519+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.077 seconds
[2024-07-29T14:24:32.999+0000] {processor.py:157} INFO - Started process (PID=34963) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:24:33.000+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:24:33.008+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:24:33.006+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:24:33.035+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:24:33.052+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:24:33.052+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:24:33.061+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:24:33.061+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:24:33.069+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.074 seconds
[2024-07-29T14:25:03.460+0000] {processor.py:157} INFO - Started process (PID=34988) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:25:03.462+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:25:03.464+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:25:03.464+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:25:03.473+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:25:03.489+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:25:03.489+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:25:03.499+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:25:03.499+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:25:03.507+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-29T14:25:33.918+0000] {processor.py:157} INFO - Started process (PID=35013) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:25:33.919+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:25:33.922+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:25:33.922+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:25:33.932+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:25:33.949+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:25:33.949+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:25:33.959+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:25:33.959+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:25:33.968+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-29T14:26:04.329+0000] {processor.py:157} INFO - Started process (PID=35038) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:26:04.331+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:26:04.333+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:26:04.333+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:26:04.342+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:26:04.357+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:26:04.357+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:26:04.367+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:26:04.367+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:26:04.376+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-29T14:26:34.681+0000] {processor.py:157} INFO - Started process (PID=35063) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:26:34.682+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:26:34.684+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:26:34.684+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:26:34.696+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:26:34.719+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:26:34.719+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:26:34.733+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:26:34.733+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:26:34.743+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.065 seconds
[2024-07-29T14:27:05.169+0000] {processor.py:157} INFO - Started process (PID=35088) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:27:05.170+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:27:05.172+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:27:05.172+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:27:05.181+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:27:05.196+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:27:05.196+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:27:05.208+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:27:05.207+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:27:05.216+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-29T14:27:35.613+0000] {processor.py:157} INFO - Started process (PID=35113) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:27:35.614+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:27:35.618+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:27:35.617+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:27:35.633+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:27:35.649+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:27:35.649+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:27:35.663+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:27:35.663+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:27:35.672+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.065 seconds
[2024-07-29T14:28:06.074+0000] {processor.py:157} INFO - Started process (PID=35138) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:28:06.075+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:28:06.077+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:28:06.077+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:28:06.088+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:28:06.104+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:28:06.104+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:28:06.114+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:28:06.114+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:28:06.122+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-29T14:28:36.482+0000] {processor.py:157} INFO - Started process (PID=35163) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:28:36.483+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:28:36.484+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:28:36.484+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:28:36.490+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:28:36.503+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:28:36.503+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:28:36.514+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:28:36.514+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:28:36.522+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.041 seconds
[2024-07-29T14:29:06.900+0000] {processor.py:157} INFO - Started process (PID=35188) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:29:06.901+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:29:06.904+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:29:06.904+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:29:06.916+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:29:06.934+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:29:06.934+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:29:06.945+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:29:06.945+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:29:06.953+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-29T14:29:37.365+0000] {processor.py:157} INFO - Started process (PID=35213) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:29:37.366+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:29:37.369+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:29:37.369+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:29:37.379+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:29:37.399+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:29:37.399+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:29:37.409+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:29:37.408+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:29:37.418+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-29T14:30:07.813+0000] {processor.py:157} INFO - Started process (PID=35238) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:30:07.815+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:30:07.818+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:30:07.818+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:30:07.829+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:30:07.845+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:30:07.845+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:30:07.855+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:30:07.855+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:30:07.864+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-29T14:30:38.262+0000] {processor.py:157} INFO - Started process (PID=35263) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:30:38.266+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:30:38.268+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:30:38.268+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:30:38.277+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:30:38.293+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:30:38.293+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:30:38.306+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:30:38.306+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:30:38.315+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-29T14:31:09.055+0000] {processor.py:157} INFO - Started process (PID=35288) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:31:09.056+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:31:09.060+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:31:09.060+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:31:09.081+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:31:09.112+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:31:09.112+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:31:09.127+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:31:09.126+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:31:09.138+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.090 seconds
[2024-07-29T14:31:39.589+0000] {processor.py:157} INFO - Started process (PID=35313) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:31:39.590+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:31:39.592+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:31:39.592+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:31:39.601+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:31:39.616+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:31:39.616+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:31:39.628+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:31:39.628+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:31:39.637+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-29T14:32:10.046+0000] {processor.py:157} INFO - Started process (PID=35338) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:32:10.048+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:32:10.053+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:32:10.052+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:32:10.070+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:32:10.090+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:32:10.090+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:32:10.101+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:32:10.101+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:32:10.109+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.070 seconds
[2024-07-29T14:32:40.477+0000] {processor.py:157} INFO - Started process (PID=35363) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:32:40.478+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:32:40.480+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:32:40.480+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:32:40.492+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:32:40.510+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:32:40.510+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:32:40.524+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:32:40.524+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:32:40.534+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-29T14:33:10.839+0000] {processor.py:157} INFO - Started process (PID=35388) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:33:10.840+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:33:10.842+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:33:10.842+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:33:10.851+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:33:10.868+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:33:10.868+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:33:10.880+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:33:10.880+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:33:10.890+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-29T14:33:41.344+0000] {processor.py:157} INFO - Started process (PID=35413) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:33:41.345+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:33:41.347+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:33:41.347+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:33:41.358+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:33:41.375+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:33:41.374+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:33:41.384+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:33:41.384+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:33:41.394+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-29T14:34:11.803+0000] {processor.py:157} INFO - Started process (PID=35438) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:34:11.806+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:34:11.810+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:34:11.810+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:34:11.836+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:34:11.856+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:34:11.856+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:34:11.872+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:34:11.871+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:34:11.883+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.087 seconds
[2024-07-29T14:34:42.332+0000] {processor.py:157} INFO - Started process (PID=35463) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:34:42.333+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:34:42.335+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:34:42.335+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:34:42.345+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:34:42.361+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:34:42.361+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:34:42.373+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:34:42.373+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:34:42.384+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-29T14:35:12.736+0000] {processor.py:157} INFO - Started process (PID=35488) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:35:12.737+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:35:12.740+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:35:12.739+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:35:12.755+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:35:12.777+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:35:12.777+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:35:12.792+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:35:12.792+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:35:12.802+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.070 seconds
[2024-07-29T14:35:43.203+0000] {processor.py:157} INFO - Started process (PID=35513) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:35:43.203+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:35:43.205+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:35:43.205+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:35:43.216+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:35:43.234+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:35:43.234+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:35:43.244+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:35:43.244+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:35:43.251+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-29T14:36:13.592+0000] {processor.py:157} INFO - Started process (PID=35538) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:36:13.593+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:36:13.595+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:36:13.595+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:36:13.604+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:36:13.621+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:36:13.621+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:36:13.634+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:36:13.634+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:36:13.644+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-29T14:36:43.937+0000] {processor.py:157} INFO - Started process (PID=35563) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:36:43.938+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:36:43.940+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:36:43.940+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:36:43.949+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:36:43.966+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:36:43.965+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:36:43.978+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:36:43.978+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:36:43.986+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-29T14:37:14.403+0000] {processor.py:157} INFO - Started process (PID=35588) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:37:14.404+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:37:14.407+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:37:14.407+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:37:14.425+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:37:14.448+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:37:14.447+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:37:14.460+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:37:14.460+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:37:14.470+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.074 seconds
[2024-07-29T14:37:44.906+0000] {processor.py:157} INFO - Started process (PID=35613) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:37:44.908+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:37:44.914+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:37:44.913+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:37:44.942+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:37:44.967+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:37:44.967+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:37:44.981+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:37:44.981+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:37:44.992+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.090 seconds
[2024-07-29T14:38:15.456+0000] {processor.py:157} INFO - Started process (PID=35638) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:38:15.461+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:38:15.467+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:38:15.466+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:38:15.497+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:38:15.530+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:38:15.530+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:38:15.548+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:38:15.548+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:38:15.559+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.115 seconds
[2024-07-29T14:38:45.907+0000] {processor.py:157} INFO - Started process (PID=35663) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:38:45.908+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:38:45.911+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:38:45.911+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:38:45.926+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:38:45.951+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:38:45.951+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:38:45.964+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:38:45.964+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:38:45.975+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.073 seconds
[2024-07-29T14:39:16.420+0000] {processor.py:157} INFO - Started process (PID=35688) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:39:16.422+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:39:16.427+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:39:16.427+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:39:16.450+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:39:16.475+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:39:16.475+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:39:16.489+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:39:16.489+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:39:16.499+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.087 seconds
[2024-07-29T14:39:46.917+0000] {processor.py:157} INFO - Started process (PID=35713) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:39:46.918+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:39:46.923+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:39:46.923+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:39:46.940+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:39:46.963+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:39:46.963+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:39:46.976+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:39:46.976+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:39:46.986+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.076 seconds
[2024-07-29T14:40:17.375+0000] {processor.py:157} INFO - Started process (PID=35738) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:40:17.376+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:40:17.379+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:40:17.379+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:40:17.393+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:40:17.412+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:40:17.412+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:40:17.423+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:40:17.423+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:40:17.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-29T14:40:47.818+0000] {processor.py:157} INFO - Started process (PID=35763) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:40:47.829+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:40:47.835+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:40:47.835+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:40:47.864+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:40:47.921+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:40:47.921+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:40:47.968+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:40:47.968+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:40:47.983+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.184 seconds
[2024-07-29T14:41:18.438+0000] {processor.py:157} INFO - Started process (PID=35788) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:41:18.441+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:41:18.448+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:41:18.447+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:41:18.469+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:41:18.498+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:41:18.498+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:41:18.517+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:41:18.517+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:41:18.530+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.099 seconds
[2024-07-29T14:41:48.941+0000] {processor.py:157} INFO - Started process (PID=35813) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:41:48.942+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:41:48.943+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:41:48.943+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:41:48.951+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:41:48.966+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:41:48.966+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:41:48.978+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:41:48.978+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:41:48.988+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-29T14:42:19.415+0000] {processor.py:157} INFO - Started process (PID=35838) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:42:19.417+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:42:19.424+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:42:19.423+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:42:19.449+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:42:19.479+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:42:19.479+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:42:19.495+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:42:19.495+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:42:19.514+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.107 seconds
[2024-07-29T14:42:49.873+0000] {processor.py:157} INFO - Started process (PID=35863) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:42:49.877+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:42:49.880+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:42:49.880+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:42:49.897+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:42:49.919+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:42:49.919+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:42:49.931+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:42:49.931+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:42:49.941+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.074 seconds
[2024-07-29T14:43:20.384+0000] {processor.py:157} INFO - Started process (PID=35888) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:43:20.385+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:43:20.391+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:43:20.390+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:43:20.414+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:43:20.444+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:43:20.444+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:43:20.462+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:43:20.462+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:43:20.473+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.097 seconds
[2024-07-29T14:43:50.865+0000] {processor.py:157} INFO - Started process (PID=35913) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:43:50.867+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:43:50.870+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:43:50.870+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:43:50.882+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:43:50.904+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:43:50.904+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:43:50.921+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:43:50.921+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:43:50.937+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.076 seconds
[2024-07-29T14:44:21.436+0000] {processor.py:157} INFO - Started process (PID=35938) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:44:21.437+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:44:21.443+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:44:21.443+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:44:21.463+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:44:21.488+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:44:21.488+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:44:21.502+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:44:21.502+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:44:21.515+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.086 seconds
[2024-07-29T14:44:51.965+0000] {processor.py:157} INFO - Started process (PID=35963) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:44:51.969+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:44:51.981+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:44:51.980+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:44:52.000+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:44:52.026+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:44:52.026+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:44:52.040+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:44:52.040+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:44:52.051+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.093 seconds
[2024-07-29T14:45:22.471+0000] {processor.py:157} INFO - Started process (PID=35988) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:45:22.474+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:45:22.480+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:45:22.479+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:45:22.502+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:45:22.529+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:45:22.529+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:45:22.546+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:45:22.546+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:45:22.560+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.098 seconds
[2024-07-29T14:45:52.953+0000] {processor.py:157} INFO - Started process (PID=36013) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:45:52.954+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:45:52.959+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:45:52.958+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:45:52.977+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:45:53.001+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:45:53.001+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:45:53.014+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:45:53.014+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:45:53.024+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.078 seconds
[2024-07-29T14:46:23.397+0000] {processor.py:157} INFO - Started process (PID=36038) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:46:23.400+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:46:23.406+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:46:23.405+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:46:23.436+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:46:23.474+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:46:23.474+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:46:23.496+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:46:23.495+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:46:23.510+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.123 seconds
[2024-07-29T14:46:53.929+0000] {processor.py:157} INFO - Started process (PID=36063) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:46:53.932+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:46:53.936+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:46:53.935+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:46:53.955+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:46:53.990+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:46:53.990+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:46:54.016+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:46:54.016+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:46:54.051+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.128 seconds
[2024-07-29T14:47:24.549+0000] {processor.py:157} INFO - Started process (PID=36088) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:47:24.553+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:47:24.558+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:47:24.557+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:47:24.579+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:47:24.608+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:47:24.608+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:47:24.625+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:47:24.625+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:47:24.639+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.097 seconds
[2024-07-29T14:47:55.062+0000] {processor.py:157} INFO - Started process (PID=36113) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:47:55.064+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:47:55.070+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:47:55.069+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:47:55.092+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:47:55.119+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:47:55.119+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:47:55.135+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:47:55.135+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:47:55.147+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.092 seconds
[2024-07-29T14:48:25.507+0000] {processor.py:157} INFO - Started process (PID=36138) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:48:25.509+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:48:25.517+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:48:25.516+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:48:25.544+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:48:25.577+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:48:25.577+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:48:25.595+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:48:25.595+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:48:25.612+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.114 seconds
[2024-07-29T14:48:55.984+0000] {processor.py:157} INFO - Started process (PID=36163) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:48:55.986+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:48:55.990+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:48:55.990+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:48:56.015+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:48:56.046+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:48:56.046+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:48:56.062+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:48:56.062+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:48:56.075+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.098 seconds
[2024-07-29T14:49:26.554+0000] {processor.py:157} INFO - Started process (PID=36188) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:49:26.556+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:49:26.562+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:49:26.561+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:49:26.591+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:49:26.629+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:49:26.629+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:49:26.652+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:49:26.652+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:49:26.664+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.121 seconds
[2024-07-29T14:49:57.150+0000] {processor.py:157} INFO - Started process (PID=36213) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:49:57.154+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:49:57.156+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:49:57.156+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:49:57.176+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:49:57.196+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:49:57.196+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:49:57.210+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:49:57.210+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:49:57.220+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.075 seconds
[2024-07-29T14:50:27.620+0000] {processor.py:157} INFO - Started process (PID=36238) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:50:27.625+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:50:27.629+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:50:27.629+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:50:27.649+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:50:27.668+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:50:27.668+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:50:27.681+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:50:27.681+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:50:27.692+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.078 seconds
[2024-07-29T14:50:58.113+0000] {processor.py:157} INFO - Started process (PID=36263) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:50:58.114+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:50:58.119+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:50:58.118+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:50:58.137+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:50:58.163+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:50:58.163+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:50:58.178+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:50:58.178+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:50:58.190+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.082 seconds
[2024-07-29T14:51:28.648+0000] {processor.py:157} INFO - Started process (PID=36288) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:51:28.650+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:51:28.654+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:51:28.654+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:51:28.671+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:51:28.697+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:51:28.697+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:51:28.712+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:51:28.712+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:51:28.723+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.081 seconds
[2024-07-29T14:51:59.190+0000] {processor.py:157} INFO - Started process (PID=36313) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:51:59.193+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:51:59.196+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:51:59.196+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:51:59.210+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:51:59.228+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:51:59.228+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:51:59.238+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:51:59.238+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:51:59.246+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-29T14:52:29.553+0000] {processor.py:157} INFO - Started process (PID=36338) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:52:29.555+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:52:29.560+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:52:29.559+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:52:29.577+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:52:29.600+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:52:29.600+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:52:29.614+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:52:29.614+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:52:29.624+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.076 seconds
[2024-07-29T14:52:59.965+0000] {processor.py:157} INFO - Started process (PID=36363) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:52:59.969+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:52:59.974+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:52:59.973+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:52:59.994+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:53:00.029+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:53:00.029+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:53:00.048+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:53:00.048+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:53:00.061+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.105 seconds
[2024-07-29T14:53:30.456+0000] {processor.py:157} INFO - Started process (PID=36388) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:53:30.457+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:53:30.460+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:53:30.459+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:53:30.472+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:53:30.490+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:53:30.489+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:53:30.504+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:53:30.504+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:53:30.513+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-29T14:54:00.868+0000] {processor.py:157} INFO - Started process (PID=36413) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:54:00.869+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:54:00.873+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:54:00.872+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:54:00.889+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:54:00.913+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:54:00.913+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:54:00.929+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:54:00.929+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:54:00.943+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.081 seconds
[2024-07-29T14:54:31.362+0000] {processor.py:157} INFO - Started process (PID=36438) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:54:31.364+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:54:31.368+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:54:31.367+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:54:31.393+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:54:31.422+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:54:31.422+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:54:31.444+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:54:31.443+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:54:31.457+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.102 seconds
[2024-07-29T14:55:01.841+0000] {processor.py:157} INFO - Started process (PID=36463) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:55:01.844+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:55:01.848+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:55:01.848+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:55:01.867+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:55:01.894+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:55:01.894+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:55:01.907+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:55:01.907+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:55:01.917+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.080 seconds
[2024-07-29T14:55:32.356+0000] {processor.py:157} INFO - Started process (PID=36488) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:55:32.358+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:55:32.365+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:55:32.364+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:55:32.389+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:55:32.425+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:55:32.425+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:55:32.449+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:55:32.449+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:55:32.465+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.118 seconds
[2024-07-29T14:56:02.853+0000] {processor.py:157} INFO - Started process (PID=36513) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:56:02.859+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:56:02.869+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:56:02.869+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:56:02.903+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:56:02.941+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:56:02.941+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:56:02.961+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:56:02.961+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:56:02.977+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.131 seconds
[2024-07-29T14:56:33.408+0000] {processor.py:157} INFO - Started process (PID=36538) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:56:33.410+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:56:33.415+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:56:33.413+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:56:33.434+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:56:33.458+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:56:33.458+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:56:33.472+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:56:33.472+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:56:33.485+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.084 seconds
[2024-07-29T14:57:03.914+0000] {processor.py:157} INFO - Started process (PID=36563) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:57:03.916+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:57:03.922+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:57:03.921+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:57:03.953+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:57:03.997+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:57:03.997+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:57:04.018+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:57:04.018+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:57:04.032+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.127 seconds
[2024-07-29T14:57:34.499+0000] {processor.py:157} INFO - Started process (PID=36588) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:57:34.500+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:57:34.502+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:57:34.502+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:57:34.511+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:57:34.526+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:57:34.526+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:57:34.537+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:57:34.536+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:57:34.547+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-29T14:58:04.920+0000] {processor.py:157} INFO - Started process (PID=36613) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:58:04.925+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:58:04.928+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:58:04.927+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:58:04.946+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:58:04.974+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:58:04.974+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:58:04.989+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:58:04.988+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:58:04.998+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.082 seconds
[2024-07-29T14:58:35.422+0000] {processor.py:157} INFO - Started process (PID=36638) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:58:35.423+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:58:35.426+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:58:35.426+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:58:35.436+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:58:35.451+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:58:35.451+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:58:35.465+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:58:35.465+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:58:35.473+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-29T14:59:05.866+0000] {processor.py:157} INFO - Started process (PID=36663) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:59:05.868+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:59:05.870+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:59:05.870+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:59:05.879+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:59:05.894+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:59:05.894+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:59:05.906+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:59:05.906+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:59:05.914+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-29T14:59:36.361+0000] {processor.py:157} INFO - Started process (PID=36688) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:59:36.362+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T14:59:36.366+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:59:36.365+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:59:36.384+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T14:59:36.407+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:59:36.407+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:59:36.420+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:59:36.419+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T14:59:36.428+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.073 seconds
[2024-07-29T15:00:06.847+0000] {processor.py:157} INFO - Started process (PID=36713) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:00:06.849+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:00:06.855+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:00:06.854+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:00:06.890+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:00:06.931+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:00:06.931+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:00:06.950+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:00:06.950+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:00:06.968+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.130 seconds
[2024-07-29T15:00:37.512+0000] {processor.py:157} INFO - Started process (PID=36738) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:00:37.514+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:00:37.519+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:00:37.518+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:00:37.550+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:00:37.597+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:00:37.596+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:00:37.617+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:00:37.617+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:00:37.636+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.154 seconds
[2024-07-29T15:01:08.068+0000] {processor.py:157} INFO - Started process (PID=36763) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:01:08.077+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:01:08.097+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:01:08.097+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:01:08.123+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:01:08.152+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:01:08.152+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:01:08.166+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:01:08.165+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:01:08.177+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.116 seconds
[2024-07-29T15:01:38.603+0000] {processor.py:157} INFO - Started process (PID=36788) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:01:38.606+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:01:38.612+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:01:38.611+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:01:38.633+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:01:38.661+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:01:38.661+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:01:38.676+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:01:38.676+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:01:38.687+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.090 seconds
[2024-07-29T15:02:09.131+0000] {processor.py:157} INFO - Started process (PID=36813) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:02:09.133+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:02:09.138+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:02:09.138+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:02:09.163+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:02:09.203+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:02:09.203+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:02:09.223+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:02:09.222+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:02:09.233+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.116 seconds
[2024-07-29T15:02:39.643+0000] {processor.py:157} INFO - Started process (PID=36838) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:02:39.644+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:02:39.647+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:02:39.647+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:02:39.658+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:02:39.677+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:02:39.677+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:02:39.692+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:02:39.692+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:02:39.704+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-29T15:03:10.094+0000] {processor.py:157} INFO - Started process (PID=36863) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:03:10.099+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:03:10.110+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:03:10.110+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:03:10.129+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:03:10.155+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:03:10.155+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:03:10.168+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:03:10.168+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:03:10.179+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.099 seconds
[2024-07-29T15:03:40.615+0000] {processor.py:157} INFO - Started process (PID=36888) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:03:40.618+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:03:40.622+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:03:40.622+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:03:40.644+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:03:40.678+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:03:40.678+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:03:40.718+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:03:40.718+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:03:40.751+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.142 seconds
[2024-07-29T15:04:11.238+0000] {processor.py:157} INFO - Started process (PID=36913) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:04:11.241+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:04:11.247+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:04:11.246+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:04:11.269+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:04:11.296+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:04:11.296+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:04:11.311+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:04:11.311+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:04:11.323+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.093 seconds
[2024-07-29T15:04:41.753+0000] {processor.py:157} INFO - Started process (PID=36938) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:04:41.756+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:04:41.762+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:04:41.761+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:04:41.820+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:04:41.854+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:04:41.854+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:04:41.869+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:04:41.869+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:04:41.881+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.135 seconds
[2024-07-29T15:05:12.335+0000] {processor.py:157} INFO - Started process (PID=36963) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:05:12.336+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:05:12.341+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:05:12.340+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:05:12.384+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:05:12.411+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:05:12.411+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:05:12.424+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:05:12.424+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:05:12.435+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.107 seconds
[2024-07-29T15:05:42.910+0000] {processor.py:157} INFO - Started process (PID=36988) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:05:42.914+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:05:42.921+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:05:42.921+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:05:42.945+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:05:42.981+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:05:42.981+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:05:43.007+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:05:43.007+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:05:43.023+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.139 seconds
[2024-07-29T15:06:13.530+0000] {processor.py:157} INFO - Started process (PID=37013) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:06:13.534+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:06:13.549+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:06:13.548+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:06:13.605+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:06:13.659+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:06:13.659+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:06:13.684+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:06:13.684+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:06:13.700+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.178 seconds
[2024-07-29T15:06:44.071+0000] {processor.py:157} INFO - Started process (PID=37038) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:06:44.084+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:06:44.105+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:06:44.104+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:06:44.136+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:06:44.207+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:06:44.207+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:06:44.226+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:06:44.226+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:06:44.243+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.183 seconds
[2024-07-29T15:07:14.735+0000] {processor.py:157} INFO - Started process (PID=37063) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:07:14.738+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:07:14.745+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:07:14.745+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:07:14.778+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:07:14.814+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:07:14.814+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:07:14.841+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:07:14.841+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:07:14.853+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.125 seconds
[2024-07-29T15:07:45.268+0000] {processor.py:157} INFO - Started process (PID=37088) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:07:45.270+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:07:45.272+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:07:45.272+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:07:45.287+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:07:45.319+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:07:45.318+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:07:45.337+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:07:45.337+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:07:45.353+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.089 seconds
[2024-07-29T15:08:15.830+0000] {processor.py:157} INFO - Started process (PID=37113) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:08:15.831+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:08:15.838+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:08:15.837+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:08:15.864+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:08:15.889+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:08:15.889+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:08:15.902+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:08:15.902+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:08:15.919+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.093 seconds
[2024-07-29T15:08:46.392+0000] {processor.py:157} INFO - Started process (PID=37138) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:08:46.394+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:08:46.403+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:08:46.402+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:08:46.427+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:08:46.458+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:08:46.458+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:08:46.476+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:08:46.476+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:08:46.489+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.104 seconds
[2024-07-29T15:09:16.944+0000] {processor.py:157} INFO - Started process (PID=37163) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:09:16.945+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:09:16.951+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:09:16.951+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:09:16.967+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:09:16.991+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:09:16.991+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:09:17.010+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:09:17.010+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:09:17.020+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.081 seconds
[2024-07-29T15:09:47.483+0000] {processor.py:157} INFO - Started process (PID=37188) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:09:47.486+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:09:47.495+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:09:47.494+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:09:47.524+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:09:47.576+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:09:47.576+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:09:47.594+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:09:47.594+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:09:47.607+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.134 seconds
[2024-07-29T15:10:18.031+0000] {processor.py:157} INFO - Started process (PID=37213) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:10:18.033+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:10:18.037+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:10:18.037+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:10:18.062+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:10:18.103+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:10:18.103+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:10:18.119+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:10:18.119+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:10:18.127+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.102 seconds
[2024-07-29T15:10:48.621+0000] {processor.py:157} INFO - Started process (PID=37238) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:10:48.622+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:10:48.627+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:10:48.627+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:10:48.650+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:10:48.677+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:10:48.677+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:10:48.693+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:10:48.693+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:10:48.703+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.087 seconds
[2024-07-29T15:11:19.043+0000] {processor.py:157} INFO - Started process (PID=37263) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:11:19.044+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:11:19.046+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:11:19.046+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:11:19.058+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:11:19.074+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:11:19.074+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:11:19.088+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:11:19.088+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:11:19.098+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-29T15:11:49.569+0000] {processor.py:157} INFO - Started process (PID=37288) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:11:49.572+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:11:49.580+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:11:49.579+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:11:49.600+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:11:49.625+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:11:49.625+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:11:49.640+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:11:49.640+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:11:49.650+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.097 seconds
[2024-07-29T15:12:20.133+0000] {processor.py:157} INFO - Started process (PID=37313) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:12:20.135+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:12:20.139+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:12:20.138+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:12:20.190+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:12:20.291+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:12:20.291+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:12:20.369+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:12:20.369+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:12:20.390+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.262 seconds
[2024-07-29T15:12:50.824+0000] {processor.py:157} INFO - Started process (PID=37338) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:12:50.826+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:12:50.833+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:12:50.832+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:12:50.859+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:12:50.920+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:12:50.920+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:12:50.945+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:12:50.945+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:12:50.960+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.162 seconds
[2024-07-29T15:13:21.419+0000] {processor.py:157} INFO - Started process (PID=37363) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:13:21.422+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:13:21.427+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:13:21.426+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:13:21.446+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:13:21.478+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:13:21.478+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:13:21.491+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:13:21.491+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:13:21.501+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.088 seconds
[2024-07-29T15:13:51.964+0000] {processor.py:157} INFO - Started process (PID=37388) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:13:51.965+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:13:51.969+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:13:51.969+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:13:51.991+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:13:52.036+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:13:52.036+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:13:52.056+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:13:52.056+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:13:52.070+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.113 seconds
[2024-07-29T15:14:22.546+0000] {processor.py:157} INFO - Started process (PID=37413) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:14:22.550+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:14:22.555+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:14:22.554+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:14:22.580+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:14:22.605+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:14:22.605+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:14:22.620+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:14:22.620+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:14:22.632+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.092 seconds
[2024-07-29T15:14:53.052+0000] {processor.py:157} INFO - Started process (PID=37438) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:14:53.054+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:14:53.058+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:14:53.058+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:14:53.077+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:14:53.101+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:14:53.101+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:14:53.115+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:14:53.115+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:14:53.125+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.077 seconds
[2024-07-29T15:15:23.593+0000] {processor.py:157} INFO - Started process (PID=37463) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:15:23.595+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:15:23.598+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:15:23.598+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:15:23.616+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:15:23.638+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:15:23.638+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:15:23.651+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:15:23.651+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:15:23.660+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.073 seconds
[2024-07-29T15:15:54.067+0000] {processor.py:157} INFO - Started process (PID=37488) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:15:54.068+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:15:54.070+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:15:54.070+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:15:54.080+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:15:54.094+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:15:54.094+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:15:54.104+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:15:54.104+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:15:54.111+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-29T15:16:24.422+0000] {processor.py:157} INFO - Started process (PID=37513) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:16:24.422+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:16:24.425+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:16:24.425+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:16:24.438+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:16:24.456+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:16:24.456+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:16:24.467+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:16:24.467+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:16:24.477+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-29T15:16:54.910+0000] {processor.py:157} INFO - Started process (PID=37538) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:16:54.912+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:16:54.919+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:16:54.918+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:16:54.966+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:16:55.005+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:16:55.005+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:16:55.022+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:16:55.021+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:16:55.041+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.137 seconds
[2024-07-29T15:17:25.510+0000] {processor.py:157} INFO - Started process (PID=37563) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:17:25.511+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:17:25.516+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:17:25.515+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:17:25.529+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:17:25.546+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:17:25.546+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:17:25.556+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:17:25.556+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:17:25.567+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-29T15:17:55.988+0000] {processor.py:157} INFO - Started process (PID=37588) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:17:55.989+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:17:55.993+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:17:55.993+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:17:56.015+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:17:56.041+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:17:56.041+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:17:56.056+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:17:56.056+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:17:56.068+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.085 seconds
[2024-07-29T15:18:26.430+0000] {processor.py:157} INFO - Started process (PID=37613) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:18:26.431+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:18:26.435+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:18:26.435+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:18:26.458+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:18:26.485+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:18:26.485+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:18:26.499+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:18:26.498+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:18:26.509+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.086 seconds
[2024-07-29T15:18:56.928+0000] {processor.py:157} INFO - Started process (PID=37638) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:18:56.929+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:18:56.932+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:18:56.932+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:18:56.949+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:18:56.974+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:18:56.974+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:18:56.991+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:18:56.990+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:18:57.007+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.083 seconds
[2024-07-29T15:19:27.475+0000] {processor.py:157} INFO - Started process (PID=37663) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:19:27.480+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:19:27.495+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:19:27.495+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:19:27.520+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:19:27.550+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:19:27.550+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:19:27.563+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:19:27.563+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:19:27.572+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.113 seconds
[2024-07-29T15:19:57.952+0000] {processor.py:157} INFO - Started process (PID=37688) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:19:57.953+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:19:57.958+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:19:57.957+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:19:57.978+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:19:58.000+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:19:57.999+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:19:58.015+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:19:58.014+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:19:58.026+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.079 seconds
[2024-07-29T15:20:28.370+0000] {processor.py:157} INFO - Started process (PID=37713) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:20:28.372+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:20:28.377+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:20:28.377+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:20:28.397+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:20:28.420+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:20:28.420+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:20:28.434+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:20:28.434+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:20:28.443+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.079 seconds
[2024-07-29T15:20:58.899+0000] {processor.py:157} INFO - Started process (PID=37738) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:20:58.899+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:20:58.902+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:20:58.901+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:20:58.912+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:20:58.929+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:20:58.929+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:20:58.940+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:20:58.940+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:20:58.950+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-29T15:21:29.312+0000] {processor.py:157} INFO - Started process (PID=37763) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:21:29.315+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:21:29.319+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:21:29.319+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:21:29.335+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:21:29.359+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:21:29.359+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:21:29.372+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:21:29.372+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:21:29.381+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.076 seconds
[2024-07-29T15:21:59.882+0000] {processor.py:157} INFO - Started process (PID=37788) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:21:59.883+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:21:59.884+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:21:59.884+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:21:59.893+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:21:59.908+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:21:59.908+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:21:59.922+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:21:59.922+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:21:59.931+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-29T15:22:30.352+0000] {processor.py:157} INFO - Started process (PID=37813) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:22:30.354+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:22:30.357+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:22:30.356+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:22:30.368+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:22:30.389+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:22:30.389+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:22:30.401+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:22:30.401+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:22:30.411+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-29T15:23:00.812+0000] {processor.py:157} INFO - Started process (PID=37838) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:23:00.813+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:23:00.817+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:23:00.817+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:23:00.832+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:23:00.854+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:23:00.853+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:23:00.866+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:23:00.866+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:23:00.877+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.070 seconds
[2024-07-29T15:23:31.346+0000] {processor.py:157} INFO - Started process (PID=37863) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:23:31.347+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:23:31.352+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:23:31.351+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:23:31.371+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:23:31.395+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:23:31.395+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:23:31.409+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:23:31.409+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:23:31.420+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.080 seconds
[2024-07-29T15:24:01.907+0000] {processor.py:157} INFO - Started process (PID=37888) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:24:01.911+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:24:01.917+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:24:01.916+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:24:01.944+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:24:01.982+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:24:01.982+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:24:01.997+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:24:01.997+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:24:02.011+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.140 seconds
[2024-07-29T15:24:32.520+0000] {processor.py:157} INFO - Started process (PID=37913) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:24:32.522+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:24:32.530+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:24:32.529+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:24:32.564+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:24:32.605+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:24:32.605+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:24:32.624+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:24:32.624+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:24:32.648+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.163 seconds
[2024-07-29T15:25:03.132+0000] {processor.py:157} INFO - Started process (PID=37938) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:25:03.134+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:25:03.140+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:25:03.139+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:25:03.159+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:25:03.186+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:25:03.186+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:25:03.202+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:25:03.202+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:25:03.215+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.090 seconds
[2024-07-29T15:25:33.629+0000] {processor.py:157} INFO - Started process (PID=37963) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:25:33.631+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:25:33.638+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:25:33.638+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:25:33.669+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:25:33.708+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:25:33.707+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:25:33.728+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:25:33.728+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:25:33.742+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.124 seconds
[2024-07-29T15:26:04.189+0000] {processor.py:157} INFO - Started process (PID=37988) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:26:04.190+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:26:04.194+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:26:04.193+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:26:04.211+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:26:04.234+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:26:04.234+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:26:04.247+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:26:04.247+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:26:04.258+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.074 seconds
[2024-07-29T15:26:34.608+0000] {processor.py:157} INFO - Started process (PID=38013) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:26:34.608+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:26:34.610+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:26:34.610+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:26:34.621+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:26:34.641+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:26:34.641+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:26:34.654+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:26:34.654+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:26:34.664+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-29T15:27:05.074+0000] {processor.py:157} INFO - Started process (PID=38038) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:27:05.075+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:27:05.077+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:27:05.077+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:27:05.088+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:27:05.105+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:27:05.105+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:27:05.116+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:27:05.116+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:27:05.125+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-29T15:27:35.510+0000] {processor.py:157} INFO - Started process (PID=38063) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:27:35.511+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:27:35.514+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:27:35.514+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:27:35.529+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:27:35.548+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:27:35.548+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:27:35.558+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:27:35.558+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:27:35.567+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-29T15:28:05.989+0000] {processor.py:157} INFO - Started process (PID=38088) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:28:05.990+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:28:05.993+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:28:05.993+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:28:06.001+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:28:06.023+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:28:06.023+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:28:06.037+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:28:06.036+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:28:06.050+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.065 seconds
[2024-07-29T15:28:36.469+0000] {processor.py:157} INFO - Started process (PID=38113) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:28:36.470+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:28:36.475+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:28:36.475+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:28:36.493+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:28:36.512+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:28:36.512+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:28:36.525+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:28:36.525+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:28:36.533+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.070 seconds
[2024-07-29T15:29:06.958+0000] {processor.py:157} INFO - Started process (PID=38138) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:29:06.960+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:29:06.963+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:29:06.962+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:29:06.978+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:29:06.997+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:29:06.997+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:29:07.010+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:29:07.010+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:29:07.020+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-29T15:29:37.414+0000] {processor.py:157} INFO - Started process (PID=38163) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:29:37.419+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:29:37.423+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:29:37.422+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:29:37.442+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:29:37.462+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:29:37.462+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:29:37.473+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:29:37.473+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:29:37.482+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.075 seconds
[2024-07-29T15:30:07.852+0000] {processor.py:157} INFO - Started process (PID=38188) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:30:07.853+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:30:07.855+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:30:07.855+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:30:07.866+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:30:07.888+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:30:07.888+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:30:07.903+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:30:07.903+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:30:07.911+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-29T15:30:38.378+0000] {processor.py:157} INFO - Started process (PID=38213) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:30:38.380+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:30:38.385+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:30:38.384+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:30:38.412+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:30:38.435+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:30:38.435+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:30:38.446+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:30:38.446+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:30:38.456+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.084 seconds
[2024-07-29T15:31:08.885+0000] {processor.py:157} INFO - Started process (PID=38238) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:31:08.887+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:31:08.893+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:31:08.893+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:31:08.916+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:31:08.956+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:31:08.956+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:31:08.972+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:31:08.972+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:31:08.990+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.131 seconds
[2024-07-29T15:31:39.394+0000] {processor.py:157} INFO - Started process (PID=38263) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:31:39.395+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:31:39.402+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:31:39.401+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:31:39.424+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:31:39.456+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:31:39.456+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:31:39.473+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:31:39.473+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:31:39.486+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.098 seconds
[2024-07-29T15:32:09.902+0000] {processor.py:157} INFO - Started process (PID=38288) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:32:09.903+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:32:09.907+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:32:09.907+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:32:09.926+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:32:09.952+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:32:09.952+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:32:09.966+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:32:09.966+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:32:09.977+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.082 seconds
[2024-07-29T15:32:40.445+0000] {processor.py:157} INFO - Started process (PID=38313) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:32:40.447+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:32:40.454+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:32:40.453+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:32:40.484+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:32:40.520+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:32:40.520+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:32:40.538+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:32:40.538+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:32:40.562+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.125 seconds
[2024-07-29T15:33:11.029+0000] {processor.py:157} INFO - Started process (PID=38338) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:33:11.033+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:33:11.054+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:33:11.053+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:33:11.104+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:33:11.138+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:33:11.138+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:33:11.156+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:33:11.156+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:33:11.171+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.162 seconds
[2024-07-29T15:33:41.663+0000] {processor.py:157} INFO - Started process (PID=38363) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:33:41.669+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:33:41.676+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:33:41.674+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:33:41.752+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:33:41.800+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:33:41.800+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:33:41.821+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:33:41.821+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:33:41.835+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.186 seconds
[2024-07-29T15:34:12.298+0000] {processor.py:157} INFO - Started process (PID=38388) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:34:12.303+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:34:12.311+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:34:12.310+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:34:12.343+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:34:12.387+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:34:12.387+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:34:12.407+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:34:12.407+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:34:12.422+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.133 seconds
[2024-07-29T15:34:42.900+0000] {processor.py:157} INFO - Started process (PID=38413) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:34:42.902+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:34:42.907+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:34:42.906+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:34:42.935+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:34:42.971+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:34:42.971+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:34:42.991+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:34:42.991+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:34:43.005+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.111 seconds
[2024-07-29T15:35:13.453+0000] {processor.py:157} INFO - Started process (PID=38438) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:35:13.455+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:35:13.461+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:35:13.460+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:35:13.491+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:35:13.523+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:35:13.523+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:35:13.561+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:35:13.561+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:35:13.574+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.144 seconds
[2024-07-29T15:35:43.985+0000] {processor.py:157} INFO - Started process (PID=38463) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:35:43.987+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:35:43.992+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:35:43.992+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:35:44.010+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:35:44.034+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:35:44.034+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:35:44.050+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:35:44.050+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:35:44.064+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.090 seconds
[2024-07-29T15:36:14.474+0000] {processor.py:157} INFO - Started process (PID=38488) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:36:14.475+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:36:14.477+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:36:14.477+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:36:14.489+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:36:14.507+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:36:14.507+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:36:14.518+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:36:14.518+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:36:14.526+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-29T15:36:44.914+0000] {processor.py:157} INFO - Started process (PID=38513) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:36:44.915+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:36:44.917+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:36:44.916+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:36:44.932+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:36:44.949+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:36:44.949+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:36:44.961+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:36:44.961+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:36:44.970+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-29T15:37:15.381+0000] {processor.py:157} INFO - Started process (PID=38538) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:37:15.381+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:37:15.384+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:37:15.383+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:37:15.393+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:37:15.409+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:37:15.409+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:37:15.421+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:37:15.421+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:37:15.430+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-29T15:37:45.762+0000] {processor.py:157} INFO - Started process (PID=38563) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:37:45.763+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:37:45.765+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:37:45.765+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:37:45.775+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:37:45.792+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:37:45.791+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:37:45.802+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:37:45.802+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:37:45.812+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-29T15:38:16.161+0000] {processor.py:157} INFO - Started process (PID=38588) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:38:16.163+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:38:16.172+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:38:16.171+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:38:16.191+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:38:16.214+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:38:16.214+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:38:16.228+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:38:16.228+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:38:16.244+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.090 seconds
[2024-07-29T15:38:46.677+0000] {processor.py:157} INFO - Started process (PID=38613) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:38:46.679+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:38:46.682+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:38:46.682+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:38:46.694+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:38:46.710+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:38:46.710+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:38:46.722+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:38:46.722+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:38:46.730+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-29T15:39:17.152+0000] {processor.py:157} INFO - Started process (PID=38638) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:39:17.153+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:39:17.157+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:39:17.157+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:39:17.177+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:39:17.200+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:39:17.200+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:39:17.213+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:39:17.213+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:39:17.222+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.076 seconds
[2024-07-29T15:39:47.707+0000] {processor.py:157} INFO - Started process (PID=38663) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:39:47.708+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:39:47.711+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:39:47.710+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:39:47.752+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:39:47.779+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:39:47.779+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:39:47.791+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:39:47.791+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:39:47.801+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.102 seconds
[2024-07-29T15:40:18.192+0000] {processor.py:157} INFO - Started process (PID=38688) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:40:18.194+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:40:18.199+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:40:18.199+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:40:18.218+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:40:18.239+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:40:18.239+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:40:18.252+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:40:18.252+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:40:18.263+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.076 seconds
[2024-07-29T15:40:48.729+0000] {processor.py:157} INFO - Started process (PID=38713) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:40:48.730+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:40:48.732+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:40:48.732+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:40:48.741+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:40:48.757+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:40:48.757+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:40:48.771+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:40:48.771+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:40:48.779+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-29T15:41:19.162+0000] {processor.py:157} INFO - Started process (PID=38738) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:41:19.163+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:41:19.164+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:41:19.164+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:41:19.175+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:41:19.193+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:41:19.193+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:41:19.203+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:41:19.203+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:41:19.213+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-29T15:41:49.602+0000] {processor.py:157} INFO - Started process (PID=38763) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:41:49.603+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:41:49.610+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:41:49.609+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:41:49.629+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:41:49.656+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:41:49.656+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:41:49.669+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:41:49.669+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:41:49.680+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.087 seconds
[2024-07-29T15:42:20.062+0000] {processor.py:157} INFO - Started process (PID=38788) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:42:20.064+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:42:20.066+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:42:20.066+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:42:20.076+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:42:20.091+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:42:20.091+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:42:20.105+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:42:20.105+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:42:20.116+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-29T15:42:50.511+0000] {processor.py:157} INFO - Started process (PID=38813) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:42:50.512+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:42:50.515+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:42:50.515+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:42:50.532+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:42:50.553+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:42:50.553+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:42:50.564+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:42:50.564+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:42:50.573+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-29T15:43:21.026+0000] {processor.py:157} INFO - Started process (PID=38838) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:43:21.028+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:43:21.031+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:43:21.030+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:43:21.040+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:43:21.058+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:43:21.058+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:43:21.068+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:43:21.068+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:43:21.079+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-29T15:43:51.468+0000] {processor.py:157} INFO - Started process (PID=38863) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:43:51.472+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:43:51.474+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:43:51.474+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:43:51.484+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:43:51.502+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:43:51.502+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:43:51.514+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:43:51.514+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:43:51.522+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-29T15:44:21.874+0000] {processor.py:157} INFO - Started process (PID=38888) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:44:21.875+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:44:21.879+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:44:21.878+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:44:21.897+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:44:21.920+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:44:21.920+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:44:21.933+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:44:21.933+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:44:21.941+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.073 seconds
[2024-07-29T15:44:52.322+0000] {processor.py:157} INFO - Started process (PID=38913) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:44:52.323+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:44:52.327+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:44:52.327+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:44:52.357+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:44:52.403+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:44:52.403+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:44:52.426+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:44:52.426+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:44:52.438+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.122 seconds
[2024-07-29T15:45:22.898+0000] {processor.py:157} INFO - Started process (PID=38938) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:45:22.899+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:45:22.901+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:45:22.901+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:45:22.915+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:45:22.940+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:45:22.940+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:45:22.954+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:45:22.954+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:45:22.964+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.072 seconds
[2024-07-29T15:45:53.340+0000] {processor.py:157} INFO - Started process (PID=38963) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:45:53.341+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:45:53.343+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:45:53.343+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:45:53.354+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:45:53.370+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:45:53.370+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:45:53.380+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:45:53.380+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:45:53.388+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-29T15:46:23.891+0000] {processor.py:157} INFO - Started process (PID=38988) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:46:23.891+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:46:23.895+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:46:23.894+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:46:23.913+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:46:23.929+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:46:23.929+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:46:23.939+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:46:23.939+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:46:23.948+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-29T15:46:54.343+0000] {processor.py:157} INFO - Started process (PID=39013) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:46:54.343+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:46:54.346+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:46:54.345+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:46:54.366+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:46:54.387+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:46:54.387+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:46:54.400+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:46:54.400+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:46:54.410+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-29T15:47:24.782+0000] {processor.py:157} INFO - Started process (PID=39038) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:47:24.786+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:47:24.789+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:47:24.789+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:47:24.803+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:47:24.818+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:47:24.818+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:47:24.828+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:47:24.828+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:47:24.836+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-29T15:47:55.269+0000] {processor.py:157} INFO - Started process (PID=39063) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:47:55.270+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:47:55.275+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:47:55.274+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:47:55.289+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:47:55.312+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:47:55.312+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:47:55.325+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:47:55.325+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:47:55.335+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.073 seconds
[2024-07-29T15:48:25.776+0000] {processor.py:157} INFO - Started process (PID=39088) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:48:25.777+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:48:25.780+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:48:25.780+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:48:25.796+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:48:25.812+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:48:25.812+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:48:25.824+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:48:25.824+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:48:25.832+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-29T15:48:56.180+0000] {processor.py:157} INFO - Started process (PID=39113) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:48:56.182+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:48:56.186+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:48:56.185+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:48:56.207+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:48:56.231+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:48:56.231+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:48:56.245+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:48:56.245+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:48:56.255+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.081 seconds
[2024-07-29T15:49:26.758+0000] {processor.py:157} INFO - Started process (PID=39138) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:49:26.759+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:49:26.761+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:49:26.761+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:49:26.774+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:49:26.789+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:49:26.789+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:49:26.800+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:49:26.800+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:49:26.808+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-29T15:49:57.254+0000] {processor.py:157} INFO - Started process (PID=39163) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:49:57.255+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:49:57.259+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:49:57.258+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:49:57.273+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:49:57.297+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:49:57.297+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:49:57.307+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:49:57.307+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:49:57.317+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-29T15:50:27.852+0000] {processor.py:157} INFO - Started process (PID=39188) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:50:27.853+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:50:27.855+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:50:27.855+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:50:27.867+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:50:27.888+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:50:27.887+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:50:27.900+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:50:27.900+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:50:27.910+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-29T15:50:58.327+0000] {processor.py:157} INFO - Started process (PID=39213) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:50:58.328+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:50:58.331+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:50:58.331+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:50:58.341+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:50:58.356+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:50:58.356+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:50:58.367+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:50:58.367+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:50:58.376+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-29T15:51:28.874+0000] {processor.py:157} INFO - Started process (PID=39238) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:51:28.875+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:51:28.878+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:51:28.878+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:51:28.888+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:51:28.905+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:51:28.905+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:51:28.915+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:51:28.915+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:51:28.923+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-29T15:51:59.415+0000] {processor.py:157} INFO - Started process (PID=39263) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:51:59.416+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:51:59.420+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:51:59.420+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:51:59.438+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:51:59.461+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:51:59.461+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:51:59.473+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:51:59.473+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:51:59.484+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.075 seconds
[2024-07-29T15:52:29.960+0000] {processor.py:157} INFO - Started process (PID=39288) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:52:29.962+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:52:29.965+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:52:29.964+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:52:29.974+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:52:29.989+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:52:29.989+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:52:30.002+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:52:30.002+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:52:30.013+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-29T15:53:00.459+0000] {processor.py:157} INFO - Started process (PID=39313) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:53:00.460+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:53:00.462+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:53:00.462+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:53:00.477+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:53:00.493+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:53:00.493+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:53:00.504+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:53:00.504+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:53:00.514+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-29T15:53:30.978+0000] {processor.py:157} INFO - Started process (PID=39338) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:53:30.980+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:53:30.983+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:53:30.983+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:53:31.001+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:53:31.023+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:53:31.023+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:53:31.036+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:53:31.036+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:53:31.045+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.072 seconds
[2024-07-29T15:54:01.493+0000] {processor.py:157} INFO - Started process (PID=39363) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:54:01.494+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:54:01.497+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:54:01.496+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:54:01.507+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:54:01.523+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:54:01.522+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:54:01.534+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:54:01.534+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:54:01.541+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-29T15:54:31.986+0000] {processor.py:157} INFO - Started process (PID=39388) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:54:31.988+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:54:31.992+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:54:31.992+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:54:32.012+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:54:32.038+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:54:32.038+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:54:32.055+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:54:32.055+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:54:32.063+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.086 seconds
[2024-07-29T15:55:02.474+0000] {processor.py:157} INFO - Started process (PID=39413) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:55:02.475+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:55:02.478+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:55:02.478+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:55:02.491+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:55:02.508+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:55:02.508+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:55:02.519+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:55:02.519+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:55:02.527+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-29T15:55:32.967+0000] {processor.py:157} INFO - Started process (PID=39438) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:55:32.968+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:55:32.973+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:55:32.973+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:55:32.991+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:55:33.014+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:55:33.014+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:55:33.030+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:55:33.030+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:55:33.039+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.078 seconds
[2024-07-29T15:56:03.474+0000] {processor.py:157} INFO - Started process (PID=39463) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:56:03.475+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:56:03.478+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:56:03.477+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:56:03.486+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:56:03.508+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:56:03.508+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:56:03.519+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:56:03.519+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:56:03.527+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-29T15:56:33.938+0000] {processor.py:157} INFO - Started process (PID=39488) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:56:33.938+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:56:33.940+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:56:33.940+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:56:33.949+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:56:33.966+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:56:33.966+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:56:33.976+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:56:33.976+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:56:33.984+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-29T15:57:04.435+0000] {processor.py:157} INFO - Started process (PID=39513) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:57:04.436+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:57:04.440+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:57:04.439+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:57:04.463+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:57:04.491+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:57:04.491+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:57:04.504+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:57:04.504+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:57:04.515+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.086 seconds
[2024-07-29T15:57:34.927+0000] {processor.py:157} INFO - Started process (PID=39538) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:57:34.928+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:57:34.930+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:57:34.930+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:57:34.943+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:57:34.962+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:57:34.962+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:57:34.973+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:57:34.973+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:57:34.981+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-29T15:58:05.509+0000] {processor.py:157} INFO - Started process (PID=39563) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:58:05.514+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:58:05.519+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:58:05.518+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:58:05.537+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:58:05.564+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:58:05.564+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:58:05.577+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:58:05.577+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:58:05.587+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.084 seconds
[2024-07-29T15:58:36.055+0000] {processor.py:157} INFO - Started process (PID=39588) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:58:36.056+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:58:36.059+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:58:36.059+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:58:36.072+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:58:36.089+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:58:36.089+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:58:36.099+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:58:36.099+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:58:36.107+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-29T15:59:06.503+0000] {processor.py:157} INFO - Started process (PID=39613) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:59:06.506+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:59:06.508+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:59:06.508+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:59:06.525+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:59:06.547+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:59:06.547+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:59:06.560+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:59:06.560+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:59:06.570+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.074 seconds
[2024-07-29T15:59:36.981+0000] {processor.py:157} INFO - Started process (PID=39638) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:59:36.982+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T15:59:36.984+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:59:36.984+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:59:36.996+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T15:59:37.018+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:59:37.018+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:59:37.030+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:59:37.030+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T15:59:37.038+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-29T16:00:07.510+0000] {processor.py:157} INFO - Started process (PID=39663) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:00:07.511+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:00:07.515+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:00:07.514+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:00:07.555+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:00:07.585+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:00:07.585+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:00:07.598+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:00:07.598+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:00:07.609+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.106 seconds
[2024-07-29T16:00:38.082+0000] {processor.py:157} INFO - Started process (PID=39688) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:00:38.083+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:00:38.086+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:00:38.085+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:00:38.099+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:00:38.117+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:00:38.117+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:00:38.127+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:00:38.127+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:00:38.138+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-29T16:01:08.508+0000] {processor.py:157} INFO - Started process (PID=39713) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:01:08.509+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:01:08.513+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:01:08.513+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:01:08.529+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:01:08.552+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:01:08.552+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:01:08.568+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:01:08.568+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:01:08.579+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.076 seconds
[2024-07-29T16:01:38.966+0000] {processor.py:157} INFO - Started process (PID=39738) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:01:38.967+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:01:38.970+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:01:38.969+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:01:38.984+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:01:39.004+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:01:39.004+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:01:39.016+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:01:39.016+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:01:39.025+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-29T16:02:09.543+0000] {processor.py:157} INFO - Started process (PID=39763) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:02:09.544+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:02:09.548+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:02:09.548+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:02:09.568+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:02:09.596+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:02:09.596+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:02:09.608+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:02:09.608+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:02:09.618+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.082 seconds
[2024-07-29T16:02:40.117+0000] {processor.py:157} INFO - Started process (PID=39788) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:02:40.118+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:02:40.121+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:02:40.121+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:02:40.132+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:02:40.151+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:02:40.151+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:02:40.163+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:02:40.162+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:02:40.172+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-29T16:03:10.589+0000] {processor.py:157} INFO - Started process (PID=39813) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:03:10.590+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:03:10.593+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:03:10.593+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:03:10.611+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:03:10.638+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:03:10.638+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:03:10.651+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:03:10.651+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:03:10.664+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.081 seconds
[2024-07-29T16:03:41.126+0000] {processor.py:157} INFO - Started process (PID=39838) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:03:41.127+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:03:41.130+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:03:41.130+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:03:41.143+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:03:41.166+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:03:41.166+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:03:41.177+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:03:41.177+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:03:41.189+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.068 seconds
[2024-07-29T16:04:11.550+0000] {processor.py:157} INFO - Started process (PID=39863) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:04:11.552+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:04:11.556+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:04:11.555+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:04:11.573+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:04:11.601+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:04:11.601+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:04:11.613+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:04:11.613+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:04:11.623+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.079 seconds
[2024-07-29T16:04:42.094+0000] {processor.py:157} INFO - Started process (PID=39888) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:04:42.094+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:04:42.097+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:04:42.097+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:04:42.117+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:04:42.134+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:04:42.134+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:04:42.143+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:04:42.143+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:04:42.153+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-29T16:05:12.545+0000] {processor.py:157} INFO - Started process (PID=39913) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:05:12.548+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:05:12.563+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:05:12.562+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:05:12.587+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:05:12.614+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:05:12.614+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:05:12.625+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:05:12.625+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:05:12.635+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.096 seconds
[2024-07-29T16:05:43.135+0000] {processor.py:157} INFO - Started process (PID=39938) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:05:43.145+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:05:43.149+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:05:43.149+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:05:43.166+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:05:43.193+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:05:43.193+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:05:43.205+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:05:43.205+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:05:43.214+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.098 seconds
[2024-07-29T16:06:13.661+0000] {processor.py:157} INFO - Started process (PID=39963) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:06:13.662+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:06:13.666+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:06:13.666+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:06:13.681+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:06:13.703+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:06:13.703+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:06:13.716+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:06:13.716+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:06:13.725+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.068 seconds
[2024-07-29T16:06:44.043+0000] {processor.py:157} INFO - Started process (PID=39988) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:06:44.046+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:06:44.051+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:06:44.050+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:06:44.073+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:06:44.099+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:06:44.099+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:06:44.114+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:06:44.114+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:06:44.123+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.087 seconds
[2024-07-29T16:07:14.497+0000] {processor.py:157} INFO - Started process (PID=40013) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:07:14.498+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:07:14.500+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:07:14.500+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:07:14.510+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:07:14.526+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:07:14.526+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:07:14.537+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:07:14.537+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:07:14.546+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-29T16:07:44.981+0000] {processor.py:157} INFO - Started process (PID=40038) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:07:44.982+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:07:44.986+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:07:44.985+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:07:45.005+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:07:45.032+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:07:45.032+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:07:45.044+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:07:45.044+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:07:45.054+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.078 seconds
[2024-07-29T16:08:15.404+0000] {processor.py:157} INFO - Started process (PID=40063) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:08:15.406+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:08:15.408+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:08:15.408+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:08:15.421+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:08:15.441+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:08:15.441+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:08:15.450+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:08:15.450+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:08:15.458+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-29T16:08:45.874+0000] {processor.py:157} INFO - Started process (PID=40088) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:08:45.875+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:08:45.880+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:08:45.880+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:08:45.905+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:08:45.933+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:08:45.933+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:08:45.951+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:08:45.951+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:08:45.962+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.098 seconds
[2024-07-29T16:09:16.450+0000] {processor.py:157} INFO - Started process (PID=40113) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:09:16.451+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:09:16.455+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:09:16.454+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:09:16.475+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:09:16.503+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:09:16.503+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:09:16.516+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:09:16.516+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:09:16.538+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.093 seconds
[2024-07-29T16:09:47.059+0000] {processor.py:157} INFO - Started process (PID=40138) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:09:47.061+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:09:47.067+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:09:47.066+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:09:47.097+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:09:47.137+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:09:47.136+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:09:47.151+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:09:47.151+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:09:47.161+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.120 seconds
[2024-07-29T16:10:17.645+0000] {processor.py:157} INFO - Started process (PID=40163) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:10:17.646+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:10:17.651+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:10:17.650+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:10:17.668+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:10:17.693+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:10:17.693+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:10:17.705+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:10:17.705+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:10:17.716+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.077 seconds
[2024-07-29T16:10:48.144+0000] {processor.py:157} INFO - Started process (PID=40188) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:10:48.145+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:10:48.147+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:10:48.146+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:10:48.159+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:10:48.182+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:10:48.181+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:10:48.193+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:10:48.193+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:10:48.203+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-29T16:11:18.568+0000] {processor.py:157} INFO - Started process (PID=40213) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:11:18.570+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:11:18.573+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:11:18.573+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:11:18.591+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:11:18.615+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:11:18.615+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:11:18.627+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:11:18.627+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:11:18.637+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.075 seconds
[2024-07-29T16:11:49.094+0000] {processor.py:157} INFO - Started process (PID=40238) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:11:49.095+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:11:49.097+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:11:49.096+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:11:49.107+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:11:49.132+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:11:49.132+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:11:49.155+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:11:49.155+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:11:49.167+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.077 seconds
[2024-07-29T16:12:19.566+0000] {processor.py:157} INFO - Started process (PID=40263) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:12:19.567+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:12:19.570+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:12:19.569+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:12:19.586+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:12:19.603+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:12:19.603+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:12:19.613+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:12:19.613+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:12:19.621+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-29T16:12:50.120+0000] {processor.py:157} INFO - Started process (PID=40288) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:12:50.121+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:12:50.123+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:12:50.122+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:12:50.135+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:12:50.159+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:12:50.159+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:12:50.174+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:12:50.174+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:12:50.185+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-29T16:13:20.564+0000] {processor.py:157} INFO - Started process (PID=40313) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:13:20.565+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:13:20.569+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:13:20.569+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:13:20.585+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:13:20.603+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:13:20.603+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:13:20.612+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:13:20.612+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:13:20.620+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-29T16:13:51.064+0000] {processor.py:157} INFO - Started process (PID=40338) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:13:51.066+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:13:51.068+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:13:51.068+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:13:51.081+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:13:51.107+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:13:51.107+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:13:51.121+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:13:51.121+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:13:51.132+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.073 seconds
[2024-07-29T16:14:21.625+0000] {processor.py:157} INFO - Started process (PID=40363) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:14:21.626+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:14:21.630+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:14:21.630+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:14:21.650+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:14:21.691+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:14:21.691+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:14:21.701+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:14:21.701+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:14:21.710+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.090 seconds
[2024-07-29T16:14:52.220+0000] {processor.py:157} INFO - Started process (PID=40388) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:14:52.222+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:14:52.225+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:14:52.224+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:14:52.248+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:14:52.313+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:14:52.313+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:14:52.346+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:14:52.346+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:14:52.382+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.164 seconds
[2024-07-29T16:15:22.742+0000] {processor.py:157} INFO - Started process (PID=40413) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:15:22.743+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:15:22.745+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:15:22.745+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:15:22.756+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:15:22.775+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:15:22.775+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:15:22.786+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:15:22.786+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:15:22.795+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-29T16:15:53.274+0000] {processor.py:157} INFO - Started process (PID=40438) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:15:53.276+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:15:53.280+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:15:53.279+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:15:53.298+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:15:53.323+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:15:53.323+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:15:53.336+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:15:53.336+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:15:53.361+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.093 seconds
[2024-07-29T16:16:23.829+0000] {processor.py:157} INFO - Started process (PID=40463) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:16:23.831+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:16:23.833+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:16:23.832+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:16:23.844+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:16:23.865+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:16:23.865+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:16:23.876+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:16:23.876+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:16:23.886+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-29T16:16:54.421+0000] {processor.py:157} INFO - Started process (PID=40488) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:16:54.422+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:16:54.427+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:16:54.426+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:16:54.448+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:16:54.476+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:16:54.476+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:16:54.488+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:16:54.488+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:16:54.497+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.082 seconds
[2024-07-29T16:17:24.906+0000] {processor.py:157} INFO - Started process (PID=40513) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:17:24.907+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:17:24.910+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:17:24.909+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:17:24.920+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:17:24.939+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:17:24.939+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:17:24.950+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:17:24.950+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:17:24.959+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-29T16:17:55.336+0000] {processor.py:157} INFO - Started process (PID=40538) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:17:55.337+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:17:55.341+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:17:55.341+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:17:55.359+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:17:55.391+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:17:55.391+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:17:55.403+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:17:55.403+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:17:55.412+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.082 seconds
[2024-07-29T16:18:25.806+0000] {processor.py:157} INFO - Started process (PID=40563) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:18:25.806+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:18:25.808+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:18:25.808+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:18:25.820+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:18:25.844+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:18:25.844+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:18:25.858+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:18:25.858+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:18:25.868+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-29T16:18:56.329+0000] {processor.py:157} INFO - Started process (PID=40588) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:18:56.330+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:18:56.334+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:18:56.334+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:18:56.351+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:18:56.370+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:18:56.370+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:18:56.383+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:18:56.383+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:18:56.393+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.070 seconds
[2024-07-29T16:19:26.726+0000] {processor.py:157} INFO - Started process (PID=40613) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:19:26.727+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:19:26.731+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:19:26.730+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:19:26.751+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:19:26.777+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:19:26.777+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:19:26.790+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:19:26.790+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:19:26.800+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.080 seconds
[2024-07-29T16:19:57.220+0000] {processor.py:157} INFO - Started process (PID=40638) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:19:57.224+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:19:57.227+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:19:57.227+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:19:57.241+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:19:57.260+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:19:57.260+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:19:57.270+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:19:57.270+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:19:57.281+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-29T16:20:27.809+0000] {processor.py:157} INFO - Started process (PID=40663) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:20:27.810+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:20:27.815+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:20:27.814+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:20:27.834+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:20:27.859+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:20:27.859+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:20:27.871+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:20:27.871+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:20:27.881+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.079 seconds
[2024-07-29T16:20:58.409+0000] {processor.py:157} INFO - Started process (PID=40688) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:20:58.410+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:20:58.414+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:20:58.414+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:20:58.428+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:20:58.446+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:20:58.446+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:20:58.458+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:20:58.457+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:20:58.465+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-29T16:21:28.954+0000] {processor.py:157} INFO - Started process (PID=40713) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:21:28.955+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:21:28.958+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:21:28.958+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:21:28.979+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:21:29.006+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:21:29.006+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:21:29.019+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:21:29.019+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:21:29.026+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.076 seconds
[2024-07-29T16:21:59.524+0000] {processor.py:157} INFO - Started process (PID=40738) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:21:59.525+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:21:59.528+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:21:59.528+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:21:59.542+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:21:59.563+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:21:59.563+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:21:59.573+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:21:59.573+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:21:59.582+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-29T16:22:29.964+0000] {processor.py:157} INFO - Started process (PID=40763) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:22:29.965+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:22:29.970+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:22:29.969+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:22:29.991+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:22:30.016+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:22:30.016+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:22:30.028+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:22:30.028+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:22:30.038+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.080 seconds
[2024-07-29T16:23:00.505+0000] {processor.py:157} INFO - Started process (PID=40788) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:23:00.506+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:23:00.510+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:23:00.509+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:23:00.530+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:23:00.547+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:23:00.547+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:23:00.559+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:23:00.559+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:23:00.569+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.093 seconds
[2024-07-29T16:23:31.090+0000] {processor.py:157} INFO - Started process (PID=40813) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:23:31.091+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:23:31.096+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:23:31.094+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:23:31.126+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:23:31.153+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:23:31.153+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:23:31.165+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:23:31.165+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:23:31.175+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.090 seconds
[2024-07-29T16:24:01.621+0000] {processor.py:157} INFO - Started process (PID=40838) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:24:01.622+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:24:01.626+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:24:01.626+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:24:01.639+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:24:01.662+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:24:01.662+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:24:01.689+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:24:01.689+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:24:01.699+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.084 seconds
[2024-07-29T16:24:32.068+0000] {processor.py:157} INFO - Started process (PID=40863) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:24:32.071+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:24:32.086+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:24:32.085+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:24:32.103+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:24:32.141+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:24:32.141+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:24:32.154+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:24:32.154+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:24:32.163+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.109 seconds
[2024-07-29T16:25:02.602+0000] {processor.py:157} INFO - Started process (PID=40888) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:25:02.604+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:25:02.607+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:25:02.607+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:25:02.620+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:25:02.640+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:25:02.640+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:25:02.652+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:25:02.652+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:25:02.661+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.068 seconds
[2024-07-29T16:25:33.086+0000] {processor.py:157} INFO - Started process (PID=40913) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:25:33.090+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:25:33.093+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:25:33.093+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:25:33.111+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:25:33.166+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:25:33.166+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:25:33.179+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:25:33.179+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:25:33.190+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.110 seconds
[2024-07-29T16:26:03.669+0000] {processor.py:157} INFO - Started process (PID=40938) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:26:03.670+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:26:03.673+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:26:03.673+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:26:03.688+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:26:03.725+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:26:03.725+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:26:03.737+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:26:03.737+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:26:03.747+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.083 seconds
[2024-07-29T16:26:34.183+0000] {processor.py:157} INFO - Started process (PID=40963) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:26:34.185+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:26:34.188+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:26:34.187+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:26:34.207+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:26:34.240+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:26:34.240+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:26:34.256+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:26:34.256+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:26:34.267+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.089 seconds
[2024-07-29T16:27:04.708+0000] {processor.py:157} INFO - Started process (PID=40988) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:27:04.711+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:27:04.713+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:27:04.713+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:27:04.726+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:27:04.746+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:27:04.745+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:27:04.755+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:27:04.755+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:27:04.763+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-29T16:27:35.213+0000] {processor.py:157} INFO - Started process (PID=41013) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:27:35.219+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:27:35.225+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:27:35.225+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:27:35.241+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:27:35.268+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:27:35.267+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:27:35.281+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:27:35.281+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:27:35.291+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.097 seconds
[2024-07-29T16:28:05.696+0000] {processor.py:157} INFO - Started process (PID=41038) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:28:05.697+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:28:05.701+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:28:05.700+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:28:05.712+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:28:05.730+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:28:05.730+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:28:05.742+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:28:05.741+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:28:05.752+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-29T16:28:36.151+0000] {processor.py:157} INFO - Started process (PID=41063) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:28:36.152+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:28:36.156+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:28:36.155+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:28:36.172+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:28:36.195+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:28:36.195+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:28:36.208+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:28:36.208+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:28:36.220+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.075 seconds
[2024-07-29T16:29:06.583+0000] {processor.py:157} INFO - Started process (PID=41088) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:29:06.584+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:29:06.586+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:29:06.586+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:29:06.597+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:29:06.615+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:29:06.615+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:29:06.625+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:29:06.625+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:29:06.634+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-29T16:29:37.156+0000] {processor.py:157} INFO - Started process (PID=41113) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:29:37.157+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:29:37.170+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:29:37.169+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:29:37.191+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:29:37.221+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:29:37.221+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:29:37.243+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:29:37.243+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:29:37.254+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.105 seconds
[2024-07-29T16:30:07.702+0000] {processor.py:157} INFO - Started process (PID=41138) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:30:07.703+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:30:07.706+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:30:07.706+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:30:07.719+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:30:07.739+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:30:07.738+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:30:07.749+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:30:07.749+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:30:07.759+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-29T16:30:38.171+0000] {processor.py:157} INFO - Started process (PID=41163) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:30:38.172+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:30:38.177+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:30:38.176+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:30:38.199+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:30:38.226+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:30:38.226+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:30:38.239+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:30:38.239+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:30:38.250+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.086 seconds
[2024-07-29T16:31:08.733+0000] {processor.py:157} INFO - Started process (PID=41188) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:31:08.735+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:31:08.739+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:31:08.739+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:31:08.753+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:31:08.772+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:31:08.772+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:31:08.782+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:31:08.782+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:31:08.791+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-29T16:31:39.232+0000] {processor.py:157} INFO - Started process (PID=41213) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:31:39.233+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:31:39.237+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:31:39.237+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:31:39.257+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:31:39.284+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:31:39.284+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:31:39.301+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:31:39.301+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:31:39.311+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.085 seconds
[2024-07-29T16:32:09.701+0000] {processor.py:157} INFO - Started process (PID=41238) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:32:09.707+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:32:09.719+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:32:09.717+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:32:09.731+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:32:09.752+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:32:09.752+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:32:09.763+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:32:09.763+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:32:09.772+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.076 seconds
[2024-07-29T16:32:40.225+0000] {processor.py:157} INFO - Started process (PID=41263) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:32:40.228+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:32:40.234+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:32:40.234+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:32:40.252+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:32:40.278+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:32:40.278+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:32:40.290+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:32:40.290+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:32:40.299+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.088 seconds
[2024-07-29T16:33:10.761+0000] {processor.py:157} INFO - Started process (PID=41288) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:33:10.763+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:33:10.766+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:33:10.766+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:33:10.777+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:33:10.809+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:33:10.809+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:33:10.820+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:33:10.819+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:33:10.829+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.072 seconds
[2024-07-29T16:33:41.316+0000] {processor.py:157} INFO - Started process (PID=41313) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:33:41.317+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:33:41.321+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:33:41.320+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:33:41.365+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:33:41.391+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:33:41.391+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:33:41.403+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:33:41.402+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:33:41.412+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.101 seconds
[2024-07-29T16:34:11.936+0000] {processor.py:157} INFO - Started process (PID=41338) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:34:11.937+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:34:11.941+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:34:11.941+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:34:11.969+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:34:12.010+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:34:12.010+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:34:12.023+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:34:12.023+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:34:12.033+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.102 seconds
[2024-07-29T16:34:42.519+0000] {processor.py:157} INFO - Started process (PID=41363) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:34:42.520+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:34:42.526+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:34:42.525+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:34:42.550+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:34:42.588+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:34:42.588+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:34:42.602+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:34:42.602+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:34:42.613+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.124 seconds
[2024-07-29T16:35:13.084+0000] {processor.py:157} INFO - Started process (PID=41388) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:35:13.085+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:35:13.087+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:35:13.087+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:35:13.098+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:35:13.115+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:35:13.115+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:35:13.127+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:35:13.127+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:35:13.138+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-29T16:35:43.648+0000] {processor.py:157} INFO - Started process (PID=41413) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:35:43.649+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:35:43.656+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:35:43.655+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:35:43.676+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:35:43.703+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:35:43.703+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:35:43.718+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:35:43.718+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:35:43.730+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.089 seconds
[2024-07-29T16:36:14.157+0000] {processor.py:157} INFO - Started process (PID=41438) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:36:14.158+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:36:14.160+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:36:14.160+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:36:14.172+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:36:14.189+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:36:14.189+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:36:14.201+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:36:14.200+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:36:14.209+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-29T16:36:44.771+0000] {processor.py:157} INFO - Started process (PID=41463) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:36:44.774+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:36:44.783+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:36:44.783+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:36:44.804+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:36:44.830+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:36:44.830+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:36:44.851+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:36:44.851+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:36:44.863+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.109 seconds
[2024-07-29T16:37:15.334+0000] {processor.py:157} INFO - Started process (PID=41488) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:37:15.335+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:37:15.337+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:37:15.336+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:37:15.347+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:37:15.363+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:37:15.363+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:37:15.374+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:37:15.374+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:37:15.384+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-29T16:37:45.783+0000] {processor.py:157} INFO - Started process (PID=41513) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:37:45.784+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:37:45.788+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:37:45.787+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:37:45.825+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:37:45.851+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:37:45.851+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:37:45.866+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:37:45.866+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:37:45.876+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.100 seconds
[2024-07-29T16:38:16.242+0000] {processor.py:157} INFO - Started process (PID=41538) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:38:16.244+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:38:16.246+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:38:16.246+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:38:16.255+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:38:16.277+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:38:16.277+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:38:16.286+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:38:16.286+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:38:16.296+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-29T16:38:46.753+0000] {processor.py:157} INFO - Started process (PID=41563) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:38:46.755+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:38:46.759+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:38:46.759+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:38:46.777+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:38:46.809+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:38:46.809+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:38:46.824+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:38:46.824+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:38:46.834+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.086 seconds
[2024-07-29T16:39:17.229+0000] {processor.py:157} INFO - Started process (PID=41588) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:39:17.231+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:39:17.235+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:39:17.234+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:39:17.267+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:39:17.296+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:39:17.296+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:39:17.311+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:39:17.311+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:39:17.321+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.099 seconds
[2024-07-29T16:39:47.811+0000] {processor.py:157} INFO - Started process (PID=41613) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:39:47.816+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:39:47.821+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:39:47.821+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:39:47.839+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:39:47.868+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:39:47.868+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:39:47.881+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:39:47.881+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:39:47.890+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.104 seconds
[2024-07-29T16:40:18.245+0000] {processor.py:157} INFO - Started process (PID=41638) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:40:18.247+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:40:18.250+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:40:18.249+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:40:18.266+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:40:18.285+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:40:18.285+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:40:18.296+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:40:18.296+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:40:18.306+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-29T16:40:48.732+0000] {processor.py:157} INFO - Started process (PID=41663) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:40:48.733+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:40:48.736+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:40:48.735+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:40:48.755+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:40:48.782+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:40:48.782+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:40:48.794+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:40:48.794+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:40:48.804+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.079 seconds
[2024-07-29T16:41:19.281+0000] {processor.py:157} INFO - Started process (PID=41688) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:41:19.283+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:41:19.288+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:41:19.287+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:41:19.309+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:41:19.351+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:41:19.351+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:41:19.364+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:41:19.364+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:41:19.374+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.100 seconds
[2024-07-29T16:41:49.803+0000] {processor.py:157} INFO - Started process (PID=41713) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:41:49.806+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:41:49.820+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:41:49.818+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:41:49.877+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:41:49.917+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:41:49.917+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:41:49.937+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:41:49.937+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:41:49.957+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.165 seconds
[2024-07-29T16:42:20.343+0000] {processor.py:157} INFO - Started process (PID=41738) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:42:20.344+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:42:20.347+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:42:20.346+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:42:20.356+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:42:20.373+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:42:20.373+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:42:20.387+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:42:20.387+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:42:20.396+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-29T16:42:50.761+0000] {processor.py:157} INFO - Started process (PID=41763) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:42:50.772+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:42:50.786+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:42:50.785+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:42:50.817+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:42:50.866+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:42:50.866+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:42:50.882+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:42:50.882+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:42:50.894+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.140 seconds
[2024-07-29T16:43:21.311+0000] {processor.py:157} INFO - Started process (PID=41788) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:43:21.316+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:43:21.327+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:43:21.327+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:43:21.358+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:43:21.396+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:43:21.396+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:43:21.430+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:43:21.429+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:43:21.443+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.162 seconds
[2024-07-29T16:43:51.851+0000] {processor.py:157} INFO - Started process (PID=41813) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:43:51.852+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:43:51.854+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:43:51.854+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:43:51.869+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:43:51.888+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:43:51.888+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:43:51.899+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:43:51.899+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:43:51.907+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-29T16:44:22.322+0000] {processor.py:157} INFO - Started process (PID=41838) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:44:22.326+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:44:22.332+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:44:22.332+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:44:22.388+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:44:22.421+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:44:22.421+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:44:22.437+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:44:22.437+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:44:22.450+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.159 seconds
[2024-07-29T16:44:52.920+0000] {processor.py:157} INFO - Started process (PID=41863) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:44:52.923+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:44:52.932+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:44:52.931+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:44:52.967+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:44:53.038+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:44:53.037+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:44:53.058+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:44:53.058+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:44:53.072+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.162 seconds
[2024-07-29T16:45:23.539+0000] {processor.py:157} INFO - Started process (PID=41888) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:45:23.544+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:45:23.549+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:45:23.549+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:45:23.570+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:45:23.611+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:45:23.611+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:45:23.624+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:45:23.624+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:45:23.635+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.114 seconds
[2024-07-29T16:45:54.033+0000] {processor.py:157} INFO - Started process (PID=41913) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:45:54.036+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:45:54.042+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:45:54.041+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:45:54.063+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:45:54.096+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:45:54.096+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:45:54.112+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:45:54.112+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:45:54.122+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.097 seconds
[2024-07-29T16:46:24.457+0000] {processor.py:157} INFO - Started process (PID=41938) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:46:24.461+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:46:24.467+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:46:24.466+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:46:24.507+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:46:24.536+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:46:24.536+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:46:24.552+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:46:24.552+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:46:24.568+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.118 seconds
[2024-07-29T16:46:54.995+0000] {processor.py:157} INFO - Started process (PID=41963) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:46:54.999+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:46:55.010+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:46:55.009+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:46:55.044+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:46:55.097+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:46:55.097+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:46:55.122+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:46:55.121+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:46:55.139+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.156 seconds
[2024-07-29T16:47:25.630+0000] {processor.py:157} INFO - Started process (PID=41988) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:47:25.635+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:47:25.656+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:47:25.655+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:47:25.690+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:47:25.742+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:47:25.742+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:47:25.761+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:47:25.761+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:47:25.776+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.163 seconds
[2024-07-29T16:47:56.249+0000] {processor.py:157} INFO - Started process (PID=42013) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:47:56.251+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:47:56.258+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:47:56.258+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:47:56.302+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:47:56.348+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:47:56.348+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:47:56.393+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:47:56.393+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:47:56.406+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.167 seconds
[2024-07-29T16:48:26.869+0000] {processor.py:157} INFO - Started process (PID=42038) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:48:26.872+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:48:26.876+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:48:26.875+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:48:26.896+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:48:26.930+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:48:26.930+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:48:26.942+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:48:26.942+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:48:26.953+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.094 seconds
[2024-07-29T16:48:57.421+0000] {processor.py:157} INFO - Started process (PID=42063) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:48:57.424+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:48:57.430+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:48:57.430+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:48:57.450+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:48:57.497+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:48:57.497+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:48:57.512+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:48:57.512+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:48:57.521+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.106 seconds
[2024-07-29T16:49:27.979+0000] {processor.py:157} INFO - Started process (PID=42088) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:49:27.980+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:49:27.985+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:49:27.985+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:49:28.017+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:49:28.047+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:49:28.047+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:49:28.064+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:49:28.064+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:49:28.075+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.102 seconds
[2024-07-29T16:49:58.509+0000] {processor.py:157} INFO - Started process (PID=42113) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:49:58.513+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:49:58.520+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:49:58.519+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:49:58.550+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:49:58.623+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:49:58.622+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:49:58.644+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:49:58.644+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:49:58.658+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.158 seconds
[2024-07-29T16:50:29.113+0000] {processor.py:157} INFO - Started process (PID=42138) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:50:29.114+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:50:29.117+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:50:29.116+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:50:29.128+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:50:29.145+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:50:29.145+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:50:29.157+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:50:29.157+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:50:29.166+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-29T16:50:59.540+0000] {processor.py:157} INFO - Started process (PID=42163) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:50:59.544+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:50:59.550+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:50:59.549+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:50:59.581+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:50:59.636+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:50:59.635+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:50:59.653+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:50:59.653+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:50:59.667+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.152 seconds
[2024-07-29T16:51:30.098+0000] {processor.py:157} INFO - Started process (PID=42188) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:51:30.101+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:51:30.106+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:51:30.105+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:51:30.129+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:51:30.183+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:51:30.183+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:51:30.199+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:51:30.199+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:51:30.212+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.133 seconds
[2024-07-29T16:52:00.650+0000] {processor.py:157} INFO - Started process (PID=42213) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:52:00.653+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:52:00.670+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:52:00.669+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:52:00.695+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:52:00.737+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:52:00.737+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:52:00.751+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:52:00.751+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:52:00.760+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.118 seconds
[2024-07-29T16:52:31.207+0000] {processor.py:157} INFO - Started process (PID=42238) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:52:31.208+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:52:31.234+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:52:31.230+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:52:31.257+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:52:31.290+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:52:31.290+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:52:31.307+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:52:31.307+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:52:31.318+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.119 seconds
[2024-07-29T16:53:01.755+0000] {processor.py:157} INFO - Started process (PID=42263) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:53:01.757+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:53:01.763+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:53:01.762+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:53:01.792+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:53:01.830+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:53:01.830+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:53:01.858+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:53:01.858+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:53:01.870+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.123 seconds
[2024-07-29T16:53:32.361+0000] {processor.py:157} INFO - Started process (PID=42288) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:53:32.363+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:53:32.385+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:53:32.383+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:53:32.409+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:53:32.441+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:53:32.441+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:53:32.457+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:53:32.457+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:53:32.470+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.118 seconds
[2024-07-29T16:54:02.809+0000] {processor.py:157} INFO - Started process (PID=42313) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:54:02.811+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:54:02.816+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:54:02.816+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:54:02.834+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:54:02.859+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:54:02.859+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:54:02.873+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:54:02.873+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:54:02.885+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.082 seconds
[2024-07-29T16:54:33.304+0000] {processor.py:157} INFO - Started process (PID=42338) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:54:33.307+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:54:33.313+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:54:33.312+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:54:33.345+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:54:33.384+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:54:33.384+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:54:33.400+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:54:33.400+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:54:33.411+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.117 seconds
[2024-07-29T16:55:03.750+0000] {processor.py:157} INFO - Started process (PID=42363) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:55:03.752+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:55:03.756+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:55:03.756+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:55:03.777+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:55:03.810+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:55:03.810+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:55:03.829+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:55:03.829+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:55:03.841+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.096 seconds
[2024-07-29T16:55:34.313+0000] {processor.py:157} INFO - Started process (PID=42388) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:55:34.315+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:55:34.322+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:55:34.321+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:55:34.356+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:55:34.407+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:55:34.407+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:55:34.423+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:55:34.423+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:55:34.434+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.129 seconds
[2024-07-29T16:56:04.837+0000] {processor.py:157} INFO - Started process (PID=42413) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:56:04.839+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:56:04.844+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:56:04.843+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:56:04.867+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:56:04.911+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:56:04.911+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:56:04.924+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:56:04.924+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:56:04.934+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.104 seconds
[2024-07-29T16:56:35.403+0000] {processor.py:157} INFO - Started process (PID=42438) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:56:35.407+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:56:35.415+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:56:35.414+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:56:35.457+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:56:35.529+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:56:35.529+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:56:35.551+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:56:35.551+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:56:35.567+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.175 seconds
[2024-07-29T16:57:06.089+0000] {processor.py:157} INFO - Started process (PID=42463) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:57:06.092+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:57:06.103+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:57:06.101+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:57:06.122+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:57:06.150+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:57:06.150+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:57:06.164+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:57:06.164+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:57:06.177+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.101 seconds
[2024-07-29T16:57:36.591+0000] {processor.py:157} INFO - Started process (PID=42488) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:57:36.592+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:57:36.597+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:57:36.597+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:57:36.616+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:57:36.641+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:57:36.641+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:57:36.656+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:57:36.656+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:57:36.669+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.085 seconds
[2024-07-29T16:58:07.114+0000] {processor.py:157} INFO - Started process (PID=42513) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:58:07.118+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:58:07.124+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:58:07.124+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:58:07.149+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:58:07.202+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:58:07.202+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:58:07.218+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:58:07.218+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:58:07.229+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.135 seconds
[2024-07-29T16:58:37.732+0000] {processor.py:157} INFO - Started process (PID=42538) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:58:37.734+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:58:37.743+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:58:37.742+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:58:37.774+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:58:37.817+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:58:37.817+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:58:37.838+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:58:37.837+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:58:37.853+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.130 seconds
[2024-07-29T16:59:08.379+0000] {processor.py:157} INFO - Started process (PID=42563) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:59:08.383+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:59:08.399+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:59:08.398+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:59:08.440+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:59:08.498+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:59:08.498+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:59:08.516+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:59:08.516+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:59:08.530+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.169 seconds
[2024-07-29T16:59:38.945+0000] {processor.py:157} INFO - Started process (PID=42588) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:59:38.949+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T16:59:38.953+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:59:38.952+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:59:38.973+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T16:59:39.015+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:59:39.015+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:59:39.028+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:59:39.028+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T16:59:39.039+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.101 seconds
[2024-07-29T17:00:09.526+0000] {processor.py:157} INFO - Started process (PID=42613) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:00:09.528+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:00:09.533+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:00:09.533+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:00:09.553+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:00:09.585+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:00:09.584+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:00:09.597+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:00:09.597+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:00:09.610+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.090 seconds
[2024-07-29T17:00:40.029+0000] {processor.py:157} INFO - Started process (PID=42638) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:00:40.029+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:00:40.034+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:00:40.033+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:00:40.049+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:00:40.069+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:00:40.069+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:00:40.079+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:00:40.079+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:00:40.087+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-29T17:01:10.576+0000] {processor.py:157} INFO - Started process (PID=42663) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:01:10.582+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:01:10.591+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:01:10.590+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:01:10.635+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:01:10.672+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:01:10.672+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:01:10.696+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:01:10.696+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:01:10.710+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.143 seconds
[2024-07-29T17:01:41.061+0000] {processor.py:157} INFO - Started process (PID=42688) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:01:41.064+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:01:41.079+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:01:41.075+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:01:41.113+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:01:41.157+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:01:41.157+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:01:41.172+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:01:41.172+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:01:41.182+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.129 seconds
[2024-07-29T17:02:11.641+0000] {processor.py:157} INFO - Started process (PID=42713) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:02:11.642+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:02:11.646+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:02:11.646+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:02:11.665+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:02:11.700+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:02:11.700+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:02:11.712+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:02:11.712+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:02:11.723+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.087 seconds
[2024-07-29T17:02:42.079+0000] {processor.py:157} INFO - Started process (PID=42738) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:02:42.080+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:02:42.082+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:02:42.082+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:02:42.094+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:02:42.111+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:02:42.110+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:02:42.122+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:02:42.122+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:02:42.132+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-29T17:03:12.538+0000] {processor.py:157} INFO - Started process (PID=42763) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:03:12.539+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:03:12.541+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:03:12.541+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:03:12.550+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:03:12.566+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:03:12.566+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:03:12.577+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:03:12.577+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:03:12.588+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-29T17:03:42.987+0000] {processor.py:157} INFO - Started process (PID=42788) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:03:42.988+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:03:42.999+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:03:42.998+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:03:43.019+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:03:43.045+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:03:43.045+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:03:43.068+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:03:43.068+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:03:43.079+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.100 seconds
[2024-07-29T17:04:13.479+0000] {processor.py:157} INFO - Started process (PID=42813) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:04:13.480+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:04:13.483+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:04:13.483+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:04:13.495+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:04:13.514+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:04:13.514+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:04:13.523+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:04:13.523+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:04:13.531+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-29T17:04:44.002+0000] {processor.py:157} INFO - Started process (PID=42838) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:04:44.006+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:04:44.013+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:04:44.013+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:04:44.041+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:04:44.092+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:04:44.092+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:04:44.110+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:04:44.110+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:04:44.123+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.127 seconds
[2024-07-29T17:05:14.637+0000] {processor.py:157} INFO - Started process (PID=42863) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:05:14.647+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:05:14.656+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:05:14.656+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:05:14.677+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:05:14.712+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:05:14.712+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:05:14.732+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:05:14.732+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:05:14.744+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.126 seconds
[2024-07-29T17:05:45.178+0000] {processor.py:157} INFO - Started process (PID=42888) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:05:45.181+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:05:45.189+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:05:45.189+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:05:45.220+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:05:45.372+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:05:45.372+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:05:45.401+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:05:45.401+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:05:45.421+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.255 seconds
[2024-07-29T17:06:15.931+0000] {processor.py:157} INFO - Started process (PID=42913) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:06:15.933+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:06:15.938+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:06:15.938+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:06:15.959+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:06:15.994+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:06:15.994+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:06:16.013+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:06:16.013+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:06:16.025+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.105 seconds
[2024-07-29T17:06:46.384+0000] {processor.py:157} INFO - Started process (PID=42938) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:06:46.387+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:06:46.392+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:06:46.391+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:06:46.414+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:06:46.460+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:06:46.459+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:06:46.477+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:06:46.476+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:06:46.488+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.111 seconds
[2024-07-29T17:07:16.972+0000] {processor.py:157} INFO - Started process (PID=42963) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:07:16.975+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:07:16.989+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:07:16.986+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:07:17.018+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:07:17.046+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:07:17.046+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:07:17.059+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:07:17.059+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:07:17.070+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.106 seconds
[2024-07-29T17:07:47.551+0000] {processor.py:157} INFO - Started process (PID=42988) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:07:47.554+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:07:47.560+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:07:47.559+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:07:47.578+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:07:47.605+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:07:47.605+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:07:47.640+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:07:47.640+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:07:47.655+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.110 seconds
[2024-07-29T17:08:18.132+0000] {processor.py:157} INFO - Started process (PID=43013) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:08:18.134+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:08:18.139+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:08:18.139+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:08:18.157+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:08:18.181+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:08:18.181+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:08:18.194+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:08:18.194+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:08:18.203+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.078 seconds
[2024-07-29T17:08:48.621+0000] {processor.py:157} INFO - Started process (PID=43038) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:08:48.623+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:08:48.626+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:08:48.626+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:08:48.639+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:08:48.663+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:08:48.662+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:08:48.674+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:08:48.673+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:08:48.684+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-29T17:09:19.105+0000] {processor.py:157} INFO - Started process (PID=43063) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:09:19.106+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:09:19.110+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:09:19.110+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:09:19.141+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:09:19.164+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:09:19.163+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:09:19.180+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:09:19.179+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:09:19.194+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.095 seconds
[2024-07-29T17:09:49.638+0000] {processor.py:157} INFO - Started process (PID=43088) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:09:49.639+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:09:49.642+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:09:49.642+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:09:49.664+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:09:49.719+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:09:49.719+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:09:49.729+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:09:49.729+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:09:49.738+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.104 seconds
[2024-07-29T17:10:20.140+0000] {processor.py:157} INFO - Started process (PID=43113) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:10:20.143+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:10:20.148+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:10:20.148+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:10:20.171+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:10:20.214+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:10:20.214+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:10:20.228+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:10:20.228+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:10:20.238+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.105 seconds
[2024-07-29T17:10:50.630+0000] {processor.py:157} INFO - Started process (PID=43138) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:10:50.632+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:10:50.640+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:10:50.639+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:10:50.687+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:10:50.731+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:10:50.731+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:10:50.748+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:10:50.748+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:10:50.760+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.140 seconds
[2024-07-29T17:11:21.158+0000] {processor.py:157} INFO - Started process (PID=43163) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:11:21.160+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:11:21.165+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:11:21.165+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:11:21.182+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:11:21.206+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:11:21.206+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:11:21.215+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:11:21.215+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:11:21.225+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.073 seconds
[2024-07-29T17:11:51.658+0000] {processor.py:157} INFO - Started process (PID=43188) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:11:51.660+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:11:51.662+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:11:51.662+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:11:51.672+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:11:51.690+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:11:51.690+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:11:51.706+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:11:51.706+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:11:51.716+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-29T17:12:22.090+0000] {processor.py:157} INFO - Started process (PID=43213) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:12:22.091+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:12:22.096+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:12:22.095+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:12:22.114+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:12:22.137+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:12:22.137+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:12:22.148+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:12:22.148+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:12:22.158+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.074 seconds
[2024-07-29T17:12:52.577+0000] {processor.py:157} INFO - Started process (PID=43238) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:12:52.579+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:12:52.582+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:12:52.582+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:12:52.593+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:12:52.614+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:12:52.614+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:12:52.628+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:12:52.628+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:12:52.638+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-29T17:13:23.102+0000] {processor.py:157} INFO - Started process (PID=43263) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:13:23.104+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:13:23.108+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:13:23.108+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:13:23.129+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:13:23.175+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:13:23.174+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:13:23.189+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:13:23.189+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:13:23.198+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.103 seconds
[2024-07-29T17:13:53.586+0000] {processor.py:157} INFO - Started process (PID=43288) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:13:53.587+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:13:53.589+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:13:53.589+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:13:53.600+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:13:53.617+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:13:53.617+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:13:53.629+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:13:53.629+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:13:53.640+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-29T17:14:24.126+0000] {processor.py:157} INFO - Started process (PID=43313) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:14:24.127+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:14:24.131+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:14:24.131+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:14:24.155+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:14:24.190+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:14:24.190+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:14:24.203+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:14:24.203+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:14:24.214+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.093 seconds
[2024-07-29T17:14:54.565+0000] {processor.py:157} INFO - Started process (PID=43338) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:14:54.568+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:14:54.574+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:14:54.574+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:14:54.592+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:14:54.622+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:14:54.621+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:14:54.636+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:14:54.636+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:14:54.645+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.088 seconds
[2024-07-29T17:15:25.094+0000] {processor.py:157} INFO - Started process (PID=43363) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:15:25.099+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:15:25.127+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:15:25.127+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:15:25.155+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:15:25.210+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:15:25.209+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:15:25.233+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:15:25.233+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:15:25.250+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.167 seconds
[2024-07-29T17:15:55.630+0000] {processor.py:157} INFO - Started process (PID=43388) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:15:55.632+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:15:55.636+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:15:55.636+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:15:55.654+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:15:55.683+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:15:55.683+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:15:55.694+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:15:55.694+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:15:55.704+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.079 seconds
[2024-07-29T17:16:26.153+0000] {processor.py:157} INFO - Started process (PID=43413) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:16:26.156+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:16:26.163+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:16:26.163+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:16:26.184+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:16:26.216+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:16:26.216+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:16:26.234+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:16:26.234+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:16:26.248+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.104 seconds
[2024-07-29T17:16:56.577+0000] {processor.py:157} INFO - Started process (PID=43438) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:16:56.578+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:16:56.581+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:16:56.581+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:16:56.593+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:16:56.618+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:16:56.618+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:16:56.630+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:16:56.630+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:16:56.642+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-29T17:17:27.019+0000] {processor.py:157} INFO - Started process (PID=43463) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:17:27.022+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:17:27.026+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:17:27.026+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:17:27.046+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:17:27.070+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:17:27.070+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:17:27.084+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:17:27.084+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:17:27.095+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.083 seconds
[2024-07-29T17:17:57.469+0000] {processor.py:157} INFO - Started process (PID=43488) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:17:57.470+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:17:57.472+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:17:57.472+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:17:57.481+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:17:57.497+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:17:57.497+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:17:57.508+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:17:57.508+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:17:57.518+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-29T17:18:27.936+0000] {processor.py:157} INFO - Started process (PID=43513) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:18:27.937+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:18:27.940+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:18:27.939+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:18:27.950+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:18:27.971+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:18:27.971+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:18:27.987+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:18:27.987+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:18:27.996+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.065 seconds
[2024-07-29T17:18:58.446+0000] {processor.py:157} INFO - Started process (PID=43538) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:18:58.446+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:18:58.450+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:18:58.449+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:18:58.462+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:18:58.481+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:18:58.481+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:18:58.493+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:18:58.493+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:18:58.503+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-29T17:19:28.866+0000] {processor.py:157} INFO - Started process (PID=43563) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:19:28.867+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:19:28.870+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:19:28.870+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:19:28.879+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:19:28.894+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:19:28.894+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:19:28.905+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:19:28.905+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:19:28.917+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-29T17:19:59.300+0000] {processor.py:157} INFO - Started process (PID=43588) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:19:59.302+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:19:59.306+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:19:59.306+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:19:59.318+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:19:59.340+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:19:59.340+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:19:59.353+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:19:59.352+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:19:59.362+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-29T17:20:29.702+0000] {processor.py:157} INFO - Started process (PID=43613) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:20:29.704+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:20:29.707+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:20:29.707+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:20:29.720+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:20:29.743+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:20:29.743+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:20:29.757+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:20:29.757+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:20:29.768+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.070 seconds
[2024-07-29T17:21:00.180+0000] {processor.py:157} INFO - Started process (PID=43638) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:21:00.181+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:21:00.183+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:21:00.182+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:21:00.192+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:21:00.209+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:21:00.209+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:21:00.221+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:21:00.221+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:21:00.229+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-29T17:21:30.536+0000] {processor.py:157} INFO - Started process (PID=43663) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:21:30.540+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:21:30.543+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:21:30.543+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:21:30.559+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:21:30.580+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:21:30.580+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:21:30.593+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:21:30.593+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:21:30.604+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.073 seconds
[2024-07-29T17:22:01.097+0000] {processor.py:157} INFO - Started process (PID=43688) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:22:01.102+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:22:01.107+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:22:01.106+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:22:01.137+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:22:01.188+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:22:01.188+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:22:01.213+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:22:01.213+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:22:01.229+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.143 seconds
[2024-07-29T17:22:31.668+0000] {processor.py:157} INFO - Started process (PID=43713) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:22:31.670+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:22:31.675+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:22:31.675+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:22:31.700+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:22:31.739+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:22:31.739+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:22:31.753+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:22:31.753+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:22:31.769+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.107 seconds
[2024-07-29T17:23:02.199+0000] {processor.py:157} INFO - Started process (PID=43738) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:23:02.200+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:23:02.203+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:23:02.203+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:23:02.214+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:23:02.231+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:23:02.231+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:23:02.240+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:23:02.240+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:23:02.247+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-29T17:23:32.664+0000] {processor.py:157} INFO - Started process (PID=43763) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:23:32.665+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:23:32.669+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:23:32.668+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:23:32.686+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:23:32.717+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:23:32.717+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:23:32.732+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:23:32.731+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:23:32.741+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.084 seconds
[2024-07-29T17:24:03.214+0000] {processor.py:157} INFO - Started process (PID=43788) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:24:03.215+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:24:03.220+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:24:03.219+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:24:03.243+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:24:03.288+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:24:03.288+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:24:03.308+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:24:03.308+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:24:03.321+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.115 seconds
[2024-07-29T17:24:33.816+0000] {processor.py:157} INFO - Started process (PID=43813) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:24:33.818+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:24:33.823+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:24:33.822+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:24:33.843+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:24:33.873+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:24:33.873+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:24:33.886+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:24:33.886+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:24:33.895+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.086 seconds
[2024-07-29T17:25:04.301+0000] {processor.py:157} INFO - Started process (PID=43838) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:25:04.302+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:25:04.304+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:25:04.303+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:25:04.318+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:25:04.335+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:25:04.335+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:25:04.347+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:25:04.347+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:25:04.356+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-29T17:25:34.769+0000] {processor.py:157} INFO - Started process (PID=43863) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:25:34.771+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:25:34.775+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:25:34.775+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:25:34.795+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:25:34.830+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:25:34.830+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:25:34.842+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:25:34.842+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:25:34.853+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.089 seconds
[2024-07-29T17:26:05.233+0000] {processor.py:157} INFO - Started process (PID=43888) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:26:05.237+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:26:05.242+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:26:05.241+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:26:05.262+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:26:05.286+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:26:05.286+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:26:05.299+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:26:05.299+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:26:05.310+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.083 seconds
[2024-07-29T17:26:35.646+0000] {processor.py:157} INFO - Started process (PID=43913) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:26:35.647+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:26:35.650+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:26:35.650+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:26:35.666+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:26:35.678+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:26:35.678+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:26:35.687+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:26:35.687+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:26:35.696+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-29T17:27:06.081+0000] {processor.py:157} INFO - Started process (PID=43938) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:27:06.083+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:27:06.088+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:27:06.088+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:27:06.105+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:27:06.129+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:27:06.129+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:27:06.142+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:27:06.142+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:27:06.154+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.079 seconds
[2024-07-29T17:27:36.597+0000] {processor.py:157} INFO - Started process (PID=43963) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:27:36.600+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:27:36.604+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:27:36.603+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:27:36.615+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:27:36.632+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:27:36.632+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:27:36.642+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:27:36.641+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:27:36.650+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-29T17:28:07.083+0000] {processor.py:157} INFO - Started process (PID=43988) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:28:07.084+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:28:07.092+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:28:07.092+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:28:07.113+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:28:07.142+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:28:07.142+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:28:07.157+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:28:07.157+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:28:07.167+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.090 seconds
[2024-07-29T17:28:37.578+0000] {processor.py:157} INFO - Started process (PID=44013) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:28:37.579+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:28:37.581+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:28:37.581+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:28:37.594+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:28:37.613+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:28:37.613+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:28:37.623+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:28:37.623+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:28:37.633+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-29T17:29:08.080+0000] {processor.py:157} INFO - Started process (PID=44038) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:29:08.082+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:29:08.098+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:29:08.095+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:29:08.130+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:29:08.156+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:29:08.156+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:29:08.174+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:29:08.174+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:29:08.194+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.120 seconds
[2024-07-29T17:29:38.665+0000] {processor.py:157} INFO - Started process (PID=44063) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:29:38.667+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:29:38.670+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:29:38.669+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:29:38.682+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:29:38.701+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:29:38.701+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:29:38.712+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:29:38.712+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:29:38.722+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-29T17:30:09.299+0000] {processor.py:157} INFO - Started process (PID=44088) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:30:09.300+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:30:09.305+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:30:09.304+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:30:09.324+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:30:09.355+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:30:09.355+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:30:09.371+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:30:09.371+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:30:09.381+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.088 seconds
[2024-07-29T17:30:39.805+0000] {processor.py:157} INFO - Started process (PID=44113) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:30:39.806+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:30:39.809+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:30:39.809+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:30:39.819+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:30:39.835+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:30:39.834+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:30:39.846+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:30:39.846+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:30:39.855+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-29T17:31:10.253+0000] {processor.py:157} INFO - Started process (PID=44138) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:31:10.254+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:31:10.259+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:31:10.258+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:31:10.282+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:31:10.310+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:31:10.310+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:31:10.323+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:31:10.323+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:31:10.334+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.087 seconds
[2024-07-29T17:31:40.768+0000] {processor.py:157} INFO - Started process (PID=44163) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:31:40.770+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:31:40.772+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:31:40.772+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:31:40.783+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:31:40.801+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:31:40.801+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:31:40.813+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:31:40.813+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:31:40.823+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-29T17:32:11.200+0000] {processor.py:157} INFO - Started process (PID=44188) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:32:11.202+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:32:11.208+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:32:11.208+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:32:11.233+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:32:11.258+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:32:11.258+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:32:11.280+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:32:11.280+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:32:11.291+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.100 seconds
[2024-07-29T17:32:41.785+0000] {processor.py:157} INFO - Started process (PID=44213) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:32:41.786+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:32:41.789+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:32:41.789+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:32:41.805+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:32:41.823+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:32:41.823+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:32:41.836+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:32:41.836+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:32:41.845+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-29T17:33:12.209+0000] {processor.py:157} INFO - Started process (PID=44238) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:33:12.210+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:33:12.216+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:33:12.216+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:33:12.233+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:33:12.258+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:33:12.258+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:33:12.283+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:33:12.283+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:33:12.291+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.087 seconds
[2024-07-29T17:33:42.773+0000] {processor.py:157} INFO - Started process (PID=44263) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:33:42.774+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:33:42.778+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:33:42.778+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:33:42.789+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:33:42.808+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:33:42.808+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:33:42.820+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:33:42.819+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:33:42.830+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-29T17:34:13.190+0000] {processor.py:157} INFO - Started process (PID=44288) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:34:13.192+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:34:13.208+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:34:13.208+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:34:13.225+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:34:13.250+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:34:13.250+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:34:13.265+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:34:13.265+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:34:13.279+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.096 seconds
[2024-07-29T17:34:43.751+0000] {processor.py:157} INFO - Started process (PID=44313) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:34:43.755+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:34:43.759+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:34:43.759+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:34:43.776+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:34:43.799+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:34:43.799+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:34:43.813+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:34:43.813+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:34:43.823+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.078 seconds
[2024-07-29T17:35:14.162+0000] {processor.py:157} INFO - Started process (PID=44338) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:35:14.163+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:35:14.165+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:35:14.165+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:35:14.176+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:35:14.194+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:35:14.194+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:35:14.205+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:35:14.205+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:35:14.217+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-29T17:35:44.605+0000] {processor.py:157} INFO - Started process (PID=44363) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:35:44.606+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:35:44.613+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:35:44.613+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:35:44.636+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:35:44.663+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:35:44.663+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:35:44.679+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:35:44.679+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:35:44.690+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.091 seconds
[2024-07-29T17:36:15.105+0000] {processor.py:157} INFO - Started process (PID=44388) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:36:15.106+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:36:15.110+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:36:15.110+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:36:15.126+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:36:15.157+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:36:15.157+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:36:15.171+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:36:15.171+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:36:15.179+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.080 seconds
[2024-07-29T17:36:45.719+0000] {processor.py:157} INFO - Started process (PID=44413) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:36:45.721+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:36:45.722+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:36:45.722+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:36:45.735+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:36:45.761+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:36:45.760+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:36:45.774+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:36:45.774+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:36:45.782+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-29T17:37:16.228+0000] {processor.py:157} INFO - Started process (PID=44438) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:37:16.229+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:37:16.233+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:37:16.232+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:37:16.251+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:37:16.271+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:37:16.271+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:37:16.281+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:37:16.281+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:37:16.291+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-29T17:37:46.746+0000] {processor.py:157} INFO - Started process (PID=44463) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:37:46.748+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:37:46.750+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:37:46.750+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:37:46.761+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:37:46.863+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:37:46.862+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:37:46.885+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:37:46.884+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:37:46.897+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.155 seconds
[2024-07-29T17:38:17.282+0000] {processor.py:157} INFO - Started process (PID=44488) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:38:17.283+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:38:17.288+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:38:17.288+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:38:17.299+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:38:17.313+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:38:17.313+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:38:17.323+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:38:17.323+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:38:17.332+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-29T17:38:47.733+0000] {processor.py:157} INFO - Started process (PID=44513) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:38:47.735+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:38:47.742+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:38:47.740+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:38:47.763+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:38:47.793+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:38:47.793+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:38:47.820+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:38:47.820+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:38:47.829+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.102 seconds
[2024-07-29T17:39:18.236+0000] {processor.py:157} INFO - Started process (PID=44538) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:39:18.237+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:39:18.241+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:39:18.241+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:39:18.276+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:39:18.294+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:39:18.294+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:39:18.305+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:39:18.305+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:39:18.313+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.083 seconds
[2024-07-29T17:39:48.833+0000] {processor.py:157} INFO - Started process (PID=44563) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:39:48.834+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:39:48.839+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:39:48.838+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:39:48.862+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:39:48.897+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:39:48.897+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:39:48.914+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:39:48.914+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:39:48.929+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.103 seconds
[2024-07-29T17:40:19.298+0000] {processor.py:157} INFO - Started process (PID=44588) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:40:19.300+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:40:19.304+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:40:19.303+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:40:19.321+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:40:19.345+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:40:19.345+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:40:19.358+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:40:19.358+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:40:19.369+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.077 seconds
[2024-07-29T17:40:49.819+0000] {processor.py:157} INFO - Started process (PID=44613) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:40:49.820+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:40:49.823+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:40:49.823+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:40:49.836+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:40:49.855+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:40:49.855+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:40:49.867+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:40:49.867+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:40:49.877+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-29T17:41:20.285+0000] {processor.py:157} INFO - Started process (PID=44638) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:41:20.285+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:41:20.288+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:41:20.288+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:41:20.298+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:41:20.316+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:41:20.316+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:41:20.327+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:41:20.327+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:41:20.336+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-29T17:41:50.766+0000] {processor.py:157} INFO - Started process (PID=44663) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:41:50.767+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:41:50.772+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:41:50.772+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:41:50.789+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:41:50.813+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:41:50.813+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:41:50.827+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:41:50.827+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:41:50.835+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.076 seconds
[2024-07-29T17:42:21.322+0000] {processor.py:157} INFO - Started process (PID=44688) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:42:21.325+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:42:21.328+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:42:21.328+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:42:21.338+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:42:21.356+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:42:21.355+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:42:21.367+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:42:21.367+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:42:21.378+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-29T17:42:51.739+0000] {processor.py:157} INFO - Started process (PID=44713) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:42:51.741+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:42:51.746+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:42:51.745+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:42:51.763+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:42:51.785+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:42:51.785+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:42:51.796+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:42:51.796+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:42:51.804+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.072 seconds
[2024-07-29T17:43:22.280+0000] {processor.py:157} INFO - Started process (PID=44738) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:43:22.281+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:43:22.285+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:43:22.284+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:43:22.297+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:43:22.318+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:43:22.318+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:43:22.334+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:43:22.334+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:43:22.344+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.070 seconds
[2024-07-29T17:43:52.742+0000] {processor.py:157} INFO - Started process (PID=44763) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:43:52.744+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:43:52.746+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:43:52.746+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:43:52.757+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:43:52.774+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:43:52.774+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:43:52.788+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:43:52.788+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:43:52.798+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-29T17:44:23.206+0000] {processor.py:157} INFO - Started process (PID=44788) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:44:23.208+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:44:23.212+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:44:23.212+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:44:23.230+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:44:23.251+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:44:23.251+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:44:23.264+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:44:23.264+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:44:23.273+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.073 seconds
[2024-07-29T17:44:53.817+0000] {processor.py:157} INFO - Started process (PID=44813) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:44:53.818+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:44:53.821+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:44:53.820+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:44:53.830+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:44:53.847+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:44:53.847+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:44:53.860+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:44:53.860+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:44:53.870+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-29T17:45:24.363+0000] {processor.py:157} INFO - Started process (PID=44838) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:45:24.365+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:45:24.368+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:45:24.367+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:45:24.380+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:45:24.395+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:45:24.395+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:45:24.405+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:45:24.405+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:45:24.413+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-29T17:45:54.762+0000] {processor.py:157} INFO - Started process (PID=44863) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:45:54.764+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:45:54.768+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:45:54.768+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:45:54.786+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:45:54.808+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:45:54.808+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:45:54.820+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:45:54.820+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:45:54.834+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.077 seconds
[2024-07-29T17:46:25.298+0000] {processor.py:157} INFO - Started process (PID=44888) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:46:25.300+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:46:25.302+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:46:25.302+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:46:25.317+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:46:25.336+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:46:25.336+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:46:25.348+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:46:25.348+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:46:25.358+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-29T17:46:55.773+0000] {processor.py:157} INFO - Started process (PID=44913) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:46:55.774+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:46:55.777+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:46:55.776+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:46:55.792+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:46:55.810+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:46:55.810+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:46:55.821+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:46:55.820+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:46:55.828+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-29T17:47:26.263+0000] {processor.py:157} INFO - Started process (PID=44938) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:47:26.267+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:47:26.270+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:47:26.269+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:47:26.288+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:47:26.305+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:47:26.305+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:47:26.315+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:47:26.315+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:47:26.326+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.068 seconds
[2024-07-29T17:47:56.690+0000] {processor.py:157} INFO - Started process (PID=44963) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:47:56.691+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:47:56.694+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:47:56.694+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:47:56.704+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:47:56.722+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:47:56.722+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:47:56.734+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:47:56.734+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:47:56.744+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-29T17:48:27.195+0000] {processor.py:157} INFO - Started process (PID=44988) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:48:27.199+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:48:27.203+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:48:27.203+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:48:27.221+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:48:27.247+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:48:27.247+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:48:27.260+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:48:27.260+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:48:27.269+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.081 seconds
[2024-07-29T17:48:57.690+0000] {processor.py:157} INFO - Started process (PID=45013) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:48:57.692+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:48:57.695+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:48:57.694+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:48:57.707+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:48:57.725+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:48:57.725+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:48:57.736+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:48:57.736+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:48:57.745+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-29T17:49:28.205+0000] {processor.py:157} INFO - Started process (PID=45038) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:49:28.206+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:49:28.209+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:49:28.208+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:49:28.219+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:49:28.241+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:49:28.240+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:49:28.255+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:49:28.255+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:49:28.266+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-29T17:49:58.687+0000] {processor.py:157} INFO - Started process (PID=45063) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:49:58.688+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:49:58.693+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:49:58.692+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:49:58.711+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:49:58.732+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:49:58.732+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:49:58.745+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:49:58.745+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:49:58.754+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.074 seconds
[2024-07-29T17:50:29.184+0000] {processor.py:157} INFO - Started process (PID=45088) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:50:29.187+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:50:29.189+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:50:29.188+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:50:29.207+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:50:29.225+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:50:29.225+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:50:29.239+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:50:29.239+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:50:29.250+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-29T17:50:59.646+0000] {processor.py:157} INFO - Started process (PID=45113) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:50:59.646+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:50:59.650+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:50:59.649+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:50:59.668+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:50:59.690+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:50:59.690+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:50:59.703+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:50:59.703+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:50:59.713+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.072 seconds
[2024-07-29T17:51:30.074+0000] {processor.py:157} INFO - Started process (PID=45138) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:51:30.074+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:51:30.075+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:51:30.075+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:51:30.086+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:51:30.102+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:51:30.102+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:51:30.112+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:51:30.112+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:51:30.121+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-29T17:52:00.546+0000] {processor.py:157} INFO - Started process (PID=45163) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:52:00.547+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:52:00.551+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:52:00.550+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:52:00.561+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:52:00.581+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:52:00.581+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:52:00.596+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:52:00.596+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:52:00.606+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-29T17:52:30.972+0000] {processor.py:157} INFO - Started process (PID=45188) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:52:30.973+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:52:30.975+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:52:30.974+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:52:30.985+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:52:31.002+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:52:31.002+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:52:31.013+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:52:31.013+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:52:31.023+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-29T17:53:01.411+0000] {processor.py:157} INFO - Started process (PID=45213) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:53:01.412+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:53:01.416+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:53:01.416+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:53:01.433+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:53:01.452+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:53:01.452+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:53:01.463+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:53:01.463+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:53:01.474+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-29T17:53:31.963+0000] {processor.py:157} INFO - Started process (PID=45238) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:53:31.964+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:53:31.966+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:53:31.966+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:53:31.978+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:53:31.999+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:53:31.999+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:53:32.009+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:53:32.009+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:53:32.018+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-29T17:54:02.391+0000] {processor.py:157} INFO - Started process (PID=45263) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:54:02.392+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:54:02.394+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:54:02.393+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:54:02.405+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:54:02.422+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:54:02.422+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:54:02.432+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:54:02.432+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:54:02.440+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-29T17:54:32.839+0000] {processor.py:157} INFO - Started process (PID=45288) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:54:32.841+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:54:32.843+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:54:32.842+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:54:32.859+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:54:32.877+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:54:32.876+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:54:32.891+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:54:32.891+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:54:32.901+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-29T17:55:03.320+0000] {processor.py:157} INFO - Started process (PID=45313) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:55:03.321+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:55:03.324+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:55:03.324+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:55:03.340+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:55:03.359+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:55:03.359+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:55:03.369+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:55:03.369+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:55:03.377+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-29T17:55:33.858+0000] {processor.py:157} INFO - Started process (PID=45338) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:55:33.859+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:55:33.863+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:55:33.862+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:55:33.879+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:55:33.901+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:55:33.901+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:55:33.913+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:55:33.913+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:55:33.923+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.070 seconds
[2024-07-29T17:56:04.336+0000] {processor.py:157} INFO - Started process (PID=45363) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:56:04.338+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:56:04.342+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:56:04.341+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:56:04.356+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:56:04.374+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:56:04.373+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:56:04.386+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:56:04.386+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:56:04.395+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.065 seconds
[2024-07-29T17:56:34.813+0000] {processor.py:157} INFO - Started process (PID=45388) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:56:34.815+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:56:34.818+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:56:34.818+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:56:34.834+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:56:34.856+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:56:34.856+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:56:34.866+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:56:34.866+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:56:34.875+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-29T17:57:05.296+0000] {processor.py:157} INFO - Started process (PID=45413) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:57:05.297+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:57:05.300+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:57:05.300+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:57:05.312+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:57:05.331+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:57:05.331+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:57:05.347+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:57:05.347+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:57:05.356+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.065 seconds
[2024-07-29T17:57:35.719+0000] {processor.py:157} INFO - Started process (PID=45438) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:57:35.721+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:57:35.725+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:57:35.725+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:57:35.737+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:57:35.754+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:57:35.754+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:57:35.765+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:57:35.765+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:57:35.774+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-29T17:58:06.178+0000] {processor.py:157} INFO - Started process (PID=45463) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:58:06.181+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:58:06.184+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:58:06.183+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:58:06.199+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:58:06.218+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:58:06.218+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:58:06.229+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:58:06.229+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:58:06.240+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-29T17:58:36.702+0000] {processor.py:157} INFO - Started process (PID=45488) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:58:36.703+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:58:36.706+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:58:36.706+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:58:36.720+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:58:36.737+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:58:36.737+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:58:36.749+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:58:36.749+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:58:36.758+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-29T17:59:07.287+0000] {processor.py:157} INFO - Started process (PID=45513) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:59:07.289+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:59:07.294+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:59:07.294+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:59:07.306+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:59:07.325+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:59:07.325+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:59:07.335+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:59:07.335+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:59:07.345+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-29T17:59:37.767+0000] {processor.py:157} INFO - Started process (PID=45538) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:59:37.769+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T17:59:37.772+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:59:37.772+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:59:37.790+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T17:59:37.816+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:59:37.816+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:59:37.827+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:59:37.827+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T17:59:37.837+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.074 seconds
[2024-07-29T18:00:08.294+0000] {processor.py:157} INFO - Started process (PID=45563) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:00:08.295+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:00:08.298+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:00:08.298+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:00:08.310+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:00:08.331+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:00:08.331+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:00:08.343+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:00:08.343+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:00:08.354+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-29T18:00:38.879+0000] {processor.py:157} INFO - Started process (PID=45588) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:00:38.880+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:00:38.885+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:00:38.885+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:00:38.904+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:00:38.931+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:00:38.931+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:00:38.943+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:00:38.943+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:00:38.953+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.081 seconds
[2024-07-29T18:01:09.361+0000] {processor.py:157} INFO - Started process (PID=45613) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:01:09.361+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:01:09.363+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:01:09.363+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:01:09.370+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:01:09.386+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:01:09.386+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:01:09.400+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:01:09.400+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:01:09.410+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-29T18:01:39.881+0000] {processor.py:157} INFO - Started process (PID=45638) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:01:39.882+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:01:39.887+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:01:39.886+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:01:39.905+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:01:39.928+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:01:39.928+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:01:39.938+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:01:39.938+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:01:39.949+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.075 seconds
[2024-07-29T18:02:10.390+0000] {processor.py:157} INFO - Started process (PID=45663) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:02:10.391+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:02:10.395+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:02:10.394+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:02:10.413+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:02:10.433+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:02:10.433+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:02:10.446+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:02:10.446+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:02:10.455+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.070 seconds
[2024-07-29T18:02:40.952+0000] {processor.py:157} INFO - Started process (PID=45688) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:02:40.954+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:02:40.957+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:02:40.956+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:02:40.973+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:02:40.993+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:02:40.993+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:02:41.006+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:02:41.006+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:02:41.016+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-29T18:03:11.474+0000] {processor.py:157} INFO - Started process (PID=45713) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:03:11.475+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:03:11.477+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:03:11.477+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:03:11.488+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:03:11.512+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:03:11.512+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:03:11.524+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:03:11.524+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:03:11.534+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-29T18:03:41.997+0000] {processor.py:157} INFO - Started process (PID=45738) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:03:41.998+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:03:42.001+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:03:42.001+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:03:42.011+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:03:42.031+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:03:42.031+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:03:42.044+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:03:42.044+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:03:42.054+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-29T18:04:12.525+0000] {processor.py:157} INFO - Started process (PID=45763) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:04:12.527+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:04:12.530+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:04:12.530+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:04:12.541+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:04:12.559+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:04:12.559+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:04:12.569+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:04:12.569+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:04:12.578+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-29T18:04:43.073+0000] {processor.py:157} INFO - Started process (PID=45788) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:04:43.074+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:04:43.076+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:04:43.076+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:04:43.087+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:04:43.106+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:04:43.105+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:04:43.116+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:04:43.116+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:04:43.124+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-29T18:05:13.538+0000] {processor.py:157} INFO - Started process (PID=45813) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:05:13.539+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:05:13.543+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:05:13.543+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:05:13.562+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:05:13.585+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:05:13.585+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:05:13.598+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:05:13.598+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:05:13.608+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.077 seconds
[2024-07-29T18:05:44.037+0000] {processor.py:157} INFO - Started process (PID=45838) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:05:44.037+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:05:44.040+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:05:44.040+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:05:44.052+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:05:44.071+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:05:44.071+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:05:44.081+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:05:44.081+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:05:44.090+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-29T18:06:14.540+0000] {processor.py:157} INFO - Started process (PID=45863) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:06:14.541+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:06:14.545+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:06:14.545+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:06:14.564+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:06:14.587+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:06:14.587+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:06:14.600+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:06:14.600+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:06:14.611+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.078 seconds
[2024-07-29T18:06:45.051+0000] {processor.py:157} INFO - Started process (PID=45888) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:06:45.053+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:06:45.055+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:06:45.055+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:06:45.066+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:06:45.099+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:06:45.099+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:06:45.113+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:06:45.113+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:06:45.123+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.076 seconds
[2024-07-29T18:07:15.582+0000] {processor.py:157} INFO - Started process (PID=45913) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:07:15.585+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:07:15.588+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:07:15.588+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:07:15.604+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:07:15.626+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:07:15.626+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:07:15.643+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:07:15.642+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:07:15.653+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.075 seconds
[2024-07-29T18:07:46.133+0000] {processor.py:157} INFO - Started process (PID=45938) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:07:46.136+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:07:46.140+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:07:46.140+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:07:46.157+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:07:46.185+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:07:46.185+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:07:46.197+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:07:46.197+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:07:46.206+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.080 seconds
[2024-07-29T18:08:16.736+0000] {processor.py:157} INFO - Started process (PID=45963) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:08:16.739+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:08:16.742+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:08:16.742+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:08:16.753+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:08:16.771+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:08:16.770+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:08:16.780+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:08:16.780+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:08:16.791+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-29T18:08:47.207+0000] {processor.py:157} INFO - Started process (PID=45988) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:08:47.208+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:08:47.211+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:08:47.211+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:08:47.241+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:08:47.267+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:08:47.267+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:08:47.280+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:08:47.280+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:08:47.292+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.091 seconds
[2024-07-29T18:09:17.741+0000] {processor.py:157} INFO - Started process (PID=46013) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:09:17.745+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:09:17.750+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:09:17.749+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:09:17.768+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:09:17.799+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:09:17.799+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:09:17.812+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:09:17.812+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:09:17.823+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.088 seconds
[2024-07-29T18:09:48.295+0000] {processor.py:157} INFO - Started process (PID=46038) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:09:48.298+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:09:48.302+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:09:48.302+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:09:48.318+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:09:48.346+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:09:48.345+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:09:48.358+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:09:48.358+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:09:48.369+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.088 seconds
[2024-07-29T18:10:18.881+0000] {processor.py:157} INFO - Started process (PID=46063) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:10:18.882+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:10:18.884+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:10:18.884+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:10:18.897+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:10:18.917+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:10:18.917+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:10:18.926+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:10:18.926+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:10:18.933+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-29T18:10:49.227+0000] {processor.py:157} INFO - Started process (PID=46088) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:10:49.228+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:10:49.233+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:10:49.232+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:10:49.248+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:10:49.285+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:10:49.285+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:10:49.298+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:10:49.298+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:10:49.308+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.087 seconds
[2024-07-29T18:11:19.725+0000] {processor.py:157} INFO - Started process (PID=46113) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:11:19.728+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:11:19.742+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:11:19.741+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:11:19.758+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:11:19.779+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:11:19.779+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:11:19.790+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:11:19.790+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:11:19.798+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.078 seconds
[2024-07-29T18:11:50.309+0000] {processor.py:157} INFO - Started process (PID=46138) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:11:50.310+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:11:50.314+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:11:50.313+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:11:50.329+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:11:50.351+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:11:50.350+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:11:50.369+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:11:50.369+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:11:50.378+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.074 seconds
[2024-07-29T18:12:20.854+0000] {processor.py:157} INFO - Started process (PID=46163) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:12:20.856+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:12:20.860+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:12:20.860+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:12:20.873+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:12:20.892+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:12:20.892+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:12:20.906+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:12:20.905+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:12:20.915+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-29T18:12:51.281+0000] {processor.py:157} INFO - Started process (PID=46188) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:12:51.282+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:12:51.286+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:12:51.285+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:12:51.302+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:12:51.323+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:12:51.323+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:12:51.335+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:12:51.335+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:12:51.346+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-29T18:13:21.812+0000] {processor.py:157} INFO - Started process (PID=46213) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:13:21.812+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:13:21.815+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:13:21.815+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:13:21.837+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:13:21.859+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:13:21.859+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:13:21.873+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:13:21.873+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:13:21.885+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.078 seconds
[2024-07-29T18:13:52.189+0000] {processor.py:157} INFO - Started process (PID=46238) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:13:52.189+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:13:52.193+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:13:52.193+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:13:52.209+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:13:52.226+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:13:52.226+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:13:52.238+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:13:52.238+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:13:52.247+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-29T18:14:22.781+0000] {processor.py:157} INFO - Started process (PID=46263) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:14:22.782+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:14:22.786+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:14:22.786+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:14:22.802+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:14:22.852+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:14:22.852+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:14:22.864+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:14:22.864+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:14:22.873+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.096 seconds
[2024-07-29T18:14:53.317+0000] {processor.py:157} INFO - Started process (PID=46288) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:14:53.318+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:14:53.323+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:14:53.322+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:14:53.342+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:14:53.367+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:14:53.367+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:14:53.380+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:14:53.380+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:14:53.389+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.079 seconds
[2024-07-29T18:15:23.827+0000] {processor.py:157} INFO - Started process (PID=46313) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:15:23.829+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:15:23.833+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:15:23.832+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:15:23.848+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:15:23.868+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:15:23.868+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:15:23.879+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:15:23.878+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:15:23.887+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-29T18:15:54.366+0000] {processor.py:157} INFO - Started process (PID=46338) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:15:54.367+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:15:54.370+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:15:54.370+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:15:54.390+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:15:54.411+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:15:54.411+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:15:54.423+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:15:54.423+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:15:54.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.081 seconds
[2024-07-29T18:16:24.851+0000] {processor.py:157} INFO - Started process (PID=46363) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:16:24.852+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:16:24.855+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:16:24.855+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:16:24.871+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:16:24.897+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:16:24.897+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:16:24.907+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:16:24.907+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:16:24.915+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-29T18:16:55.303+0000] {processor.py:157} INFO - Started process (PID=46388) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:16:55.304+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:16:55.307+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:16:55.306+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:16:55.322+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:16:55.339+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:16:55.339+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:16:55.350+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:16:55.350+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:16:55.361+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-29T18:17:25.738+0000] {processor.py:157} INFO - Started process (PID=46413) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:17:25.739+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:17:25.742+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:17:25.742+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:17:25.755+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:17:25.778+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:17:25.778+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:17:25.791+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:17:25.791+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:17:25.802+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.068 seconds
[2024-07-29T18:17:56.208+0000] {processor.py:157} INFO - Started process (PID=46438) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:17:56.209+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:17:56.213+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:17:56.212+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:17:56.224+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:17:56.242+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:17:56.241+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:17:56.256+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:17:56.255+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:17:56.266+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-29T18:18:26.809+0000] {processor.py:157} INFO - Started process (PID=46463) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:18:26.813+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:18:26.818+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:18:26.818+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:18:26.835+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:18:26.861+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:18:26.861+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:18:26.875+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:18:26.875+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:18:26.885+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.082 seconds
[2024-07-29T18:18:57.276+0000] {processor.py:157} INFO - Started process (PID=46488) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:18:57.279+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:18:57.282+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:18:57.281+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:18:57.291+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:18:57.308+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:18:57.307+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:18:57.317+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:18:57.317+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:18:57.327+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-29T18:19:27.809+0000] {processor.py:157} INFO - Started process (PID=46513) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:19:27.810+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:19:27.814+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:19:27.813+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:19:27.829+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:19:27.851+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:19:27.851+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:19:27.863+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:19:27.863+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:19:27.872+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-29T18:19:58.250+0000] {processor.py:157} INFO - Started process (PID=46538) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:19:58.252+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:19:58.255+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:19:58.255+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:19:58.271+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:19:58.293+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:19:58.293+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:19:58.306+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:19:58.306+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:19:58.316+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-29T18:20:28.720+0000] {processor.py:157} INFO - Started process (PID=46563) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:20:28.722+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:20:28.725+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:20:28.724+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:20:28.738+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:20:28.761+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:20:28.761+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:20:28.775+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:20:28.775+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:20:28.782+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.068 seconds
[2024-07-29T18:20:59.271+0000] {processor.py:157} INFO - Started process (PID=46588) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:20:59.272+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:20:59.276+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:20:59.276+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:20:59.296+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:20:59.318+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:20:59.318+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:20:59.332+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:20:59.332+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:20:59.342+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.074 seconds
[2024-07-29T18:21:29.803+0000] {processor.py:157} INFO - Started process (PID=46613) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:21:29.804+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:21:29.808+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:21:29.807+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:21:29.823+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:21:29.871+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:21:29.871+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:21:29.884+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:21:29.884+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:21:29.895+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.119 seconds
[2024-07-29T18:22:00.384+0000] {processor.py:157} INFO - Started process (PID=46638) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:22:00.385+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:22:00.389+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:22:00.389+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:22:00.410+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:22:00.434+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:22:00.434+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:22:00.446+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:22:00.446+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:22:00.455+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.076 seconds
[2024-07-29T18:22:30.929+0000] {processor.py:157} INFO - Started process (PID=46663) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:22:30.930+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:22:30.933+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:22:30.933+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:22:30.944+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:22:30.961+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:22:30.961+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:22:30.972+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:22:30.972+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:22:30.981+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-29T18:23:01.336+0000] {processor.py:157} INFO - Started process (PID=46688) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:23:01.339+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:23:01.343+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:23:01.343+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:23:01.360+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:23:01.382+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:23:01.382+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:23:01.392+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:23:01.392+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:23:01.403+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.073 seconds
[2024-07-29T18:23:31.869+0000] {processor.py:157} INFO - Started process (PID=46713) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:23:31.872+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:23:31.876+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:23:31.875+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:23:31.892+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:23:31.912+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:23:31.912+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:23:31.926+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:23:31.926+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:23:31.936+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-29T18:24:02.430+0000] {processor.py:157} INFO - Started process (PID=46738) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:24:02.431+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:24:02.434+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:24:02.434+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:24:02.449+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:24:02.476+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:24:02.476+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:24:02.486+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:24:02.486+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:24:02.495+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-29T18:24:32.947+0000] {processor.py:157} INFO - Started process (PID=46763) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:24:32.949+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:24:32.953+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:24:32.952+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:24:32.970+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:24:32.997+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:24:32.997+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:24:33.012+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:24:33.012+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:24:33.020+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.078 seconds
[2024-07-29T18:25:03.484+0000] {processor.py:157} INFO - Started process (PID=46788) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:25:03.485+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:25:03.489+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:25:03.488+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:25:03.502+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:25:03.522+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:25:03.522+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:25:03.532+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:25:03.532+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:25:03.538+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-29T18:25:33.854+0000] {processor.py:157} INFO - Started process (PID=46813) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:25:33.857+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:25:33.861+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:25:33.861+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:25:33.876+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:25:33.898+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:25:33.898+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:25:33.913+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:25:33.913+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:25:33.924+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.073 seconds
[2024-07-29T18:26:04.399+0000] {processor.py:157} INFO - Started process (PID=46838) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:26:04.400+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:26:04.403+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:26:04.403+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:26:04.417+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:26:04.442+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:26:04.442+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:26:04.453+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:26:04.453+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:26:04.463+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-29T18:26:34.863+0000] {processor.py:157} INFO - Started process (PID=46863) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:26:34.864+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:26:34.868+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:26:34.867+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:26:34.881+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:26:34.900+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:26:34.900+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:26:34.916+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:26:34.916+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:26:34.926+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.068 seconds
[2024-07-29T18:27:05.463+0000] {processor.py:157} INFO - Started process (PID=46888) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:27:05.464+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:27:05.467+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:27:05.467+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:27:05.483+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:27:05.506+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:27:05.505+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:27:05.516+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:27:05.516+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:27:05.525+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-29T18:27:35.916+0000] {processor.py:157} INFO - Started process (PID=46913) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:27:35.918+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:27:35.921+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:27:35.921+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:27:35.937+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:27:35.960+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:27:35.960+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:27:35.971+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:27:35.971+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:27:35.982+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.070 seconds
[2024-07-29T18:28:06.540+0000] {processor.py:157} INFO - Started process (PID=46938) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:28:06.541+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:28:06.544+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:28:06.544+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:28:06.558+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:28:06.579+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:28:06.579+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:28:06.591+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:28:06.591+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:28:06.599+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.065 seconds
[2024-07-29T18:28:37.098+0000] {processor.py:157} INFO - Started process (PID=46963) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:28:37.100+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:28:37.104+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:28:37.103+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:28:37.119+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:28:37.140+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:28:37.140+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:28:37.152+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:28:37.152+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:28:37.162+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-29T18:29:07.639+0000] {processor.py:157} INFO - Started process (PID=46988) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:29:07.640+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:29:07.643+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:29:07.643+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:29:07.653+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:29:07.670+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:29:07.670+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:29:07.682+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:29:07.682+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:29:07.690+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-29T18:29:38.109+0000] {processor.py:157} INFO - Started process (PID=47013) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:29:38.111+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:29:38.116+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:29:38.116+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:29:38.135+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:29:38.171+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:29:38.171+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:29:38.185+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:29:38.185+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:29:38.196+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.094 seconds
[2024-07-29T18:30:08.690+0000] {processor.py:157} INFO - Started process (PID=47038) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:30:08.691+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:30:08.694+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:30:08.694+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:30:08.705+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:30:08.733+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:30:08.733+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:30:08.742+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:30:08.742+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:30:08.752+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-29T18:30:39.242+0000] {processor.py:157} INFO - Started process (PID=47063) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:30:39.246+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:30:39.250+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:30:39.250+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:30:39.271+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:30:39.297+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:30:39.297+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:30:39.309+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:30:39.309+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:30:39.320+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.088 seconds
[2024-07-29T18:31:09.783+0000] {processor.py:157} INFO - Started process (PID=47088) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:31:09.784+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:31:09.786+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:31:09.786+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:31:09.801+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:31:09.818+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:31:09.818+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:31:09.828+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:31:09.828+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:31:09.836+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-29T18:31:40.279+0000] {processor.py:157} INFO - Started process (PID=47113) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:31:40.281+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:31:40.286+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:31:40.286+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:31:40.305+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:31:40.328+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:31:40.328+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:31:40.343+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:31:40.343+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:31:40.353+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.081 seconds
[2024-07-29T18:32:10.784+0000] {processor.py:157} INFO - Started process (PID=47138) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:32:10.787+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:32:10.790+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:32:10.790+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:32:10.800+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:32:10.817+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:32:10.817+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:32:10.829+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:32:10.829+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:32:10.838+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-29T18:32:41.297+0000] {processor.py:157} INFO - Started process (PID=47163) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:32:41.298+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:32:41.303+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:32:41.303+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:32:41.324+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:32:41.352+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:32:41.352+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:32:41.364+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:32:41.364+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:32:41.376+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.086 seconds
[2024-07-29T18:33:11.835+0000] {processor.py:157} INFO - Started process (PID=47188) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:33:11.835+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:33:11.838+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:33:11.837+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:33:11.850+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:33:11.867+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:33:11.866+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:33:11.875+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:33:11.875+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:33:11.885+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-29T18:33:42.344+0000] {processor.py:157} INFO - Started process (PID=47213) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:33:42.350+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:33:42.363+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:33:42.363+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:33:42.388+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:33:42.407+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:33:42.407+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:33:42.420+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:33:42.420+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:33:42.430+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.092 seconds
[2024-07-29T18:34:12.906+0000] {processor.py:157} INFO - Started process (PID=47238) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:34:12.909+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:34:12.916+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:34:12.915+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:34:12.945+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:34:12.987+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:34:12.987+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:34:13.008+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:34:13.008+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:34:13.021+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.140 seconds
[2024-07-29T18:34:43.550+0000] {processor.py:157} INFO - Started process (PID=47263) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:34:43.552+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:34:43.556+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:34:43.555+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:34:43.574+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:34:43.598+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:34:43.598+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:34:43.611+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:34:43.611+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:34:43.623+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.079 seconds
[2024-07-29T18:35:14.123+0000] {processor.py:157} INFO - Started process (PID=47288) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:35:14.124+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:35:14.126+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:35:14.126+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:35:14.144+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:35:14.169+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:35:14.169+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:35:14.185+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:35:14.185+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:35:14.195+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.077 seconds
[2024-07-29T18:35:44.608+0000] {processor.py:157} INFO - Started process (PID=47313) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:35:44.608+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:35:44.610+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:35:44.610+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:35:44.622+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:35:44.637+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:35:44.637+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:35:44.647+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:35:44.647+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:35:44.655+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-29T18:36:15.155+0000] {processor.py:157} INFO - Started process (PID=47338) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:36:15.160+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:36:15.174+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:36:15.173+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:36:15.191+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:36:15.212+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:36:15.212+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:36:15.225+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:36:15.224+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:36:15.233+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.084 seconds
[2024-07-29T18:36:45.693+0000] {processor.py:157} INFO - Started process (PID=47363) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:36:45.696+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:36:45.701+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:36:45.700+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:36:45.717+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:36:45.740+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:36:45.740+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:36:45.754+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:36:45.754+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:36:45.763+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.074 seconds
[2024-07-29T18:37:16.215+0000] {processor.py:157} INFO - Started process (PID=47388) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:37:16.216+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:37:16.219+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:37:16.219+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:37:16.230+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:37:16.247+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:37:16.247+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:37:16.257+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:37:16.256+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:37:16.265+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-29T18:37:46.801+0000] {processor.py:157} INFO - Started process (PID=47413) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:37:46.802+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:37:46.808+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:37:46.808+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:37:46.830+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:37:46.855+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:37:46.855+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:37:46.868+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:37:46.868+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:37:46.877+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.083 seconds
[2024-07-29T18:38:17.307+0000] {processor.py:157} INFO - Started process (PID=47438) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:38:17.308+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:38:17.312+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:38:17.311+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:38:17.326+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:38:17.347+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:38:17.347+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:38:17.358+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:38:17.358+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:38:17.366+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-29T18:38:47.820+0000] {processor.py:157} INFO - Started process (PID=47463) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:38:47.823+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:38:47.828+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:38:47.827+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:38:47.846+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:38:47.867+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:38:47.867+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:38:47.879+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:38:47.879+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:38:47.889+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.077 seconds
[2024-07-29T18:39:18.412+0000] {processor.py:157} INFO - Started process (PID=47488) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:39:18.414+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:39:18.418+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:39:18.418+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:39:18.438+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:39:18.475+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:39:18.475+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:39:18.489+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:39:18.489+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:39:18.501+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.095 seconds
[2024-07-29T18:39:48.998+0000] {processor.py:157} INFO - Started process (PID=47513) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:39:49.000+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:39:49.005+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:39:49.004+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:39:49.024+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:39:49.047+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:39:49.047+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:39:49.059+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:39:49.059+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:39:49.070+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.078 seconds
[2024-07-29T18:40:19.520+0000] {processor.py:157} INFO - Started process (PID=47538) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:40:19.522+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:40:19.529+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:40:19.529+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:40:19.548+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:40:19.591+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:40:19.591+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:40:19.604+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:40:19.604+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:40:19.614+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.101 seconds
[2024-07-29T18:40:50.065+0000] {processor.py:157} INFO - Started process (PID=47563) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:40:50.067+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:40:50.070+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:40:50.070+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:40:50.084+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:40:50.101+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:40:50.101+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:40:50.111+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:40:50.111+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:40:50.119+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-29T18:41:20.553+0000] {processor.py:157} INFO - Started process (PID=47588) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:41:20.556+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:41:20.562+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:41:20.562+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:41:20.580+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:41:20.608+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:41:20.607+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:41:20.621+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:41:20.620+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:41:20.630+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.084 seconds
[2024-07-29T18:41:51.025+0000] {processor.py:157} INFO - Started process (PID=47613) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:41:51.026+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:41:51.028+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:41:51.028+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:41:51.037+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:41:51.054+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:41:51.054+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:41:51.065+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:41:51.065+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:41:51.076+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-29T18:42:21.537+0000] {processor.py:157} INFO - Started process (PID=47638) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:42:21.538+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:42:21.542+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:42:21.542+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:42:21.560+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:42:21.585+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:42:21.585+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:42:21.598+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:42:21.598+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:42:21.607+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.077 seconds
[2024-07-29T18:42:52.063+0000] {processor.py:157} INFO - Started process (PID=47663) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:42:52.064+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:42:52.066+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:42:52.066+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:42:52.076+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:42:52.093+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:42:52.093+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:42:52.104+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:42:52.104+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:42:52.113+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-29T18:43:22.561+0000] {processor.py:157} INFO - Started process (PID=47688) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:43:22.564+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:43:22.568+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:43:22.568+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:43:22.587+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:43:22.609+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:43:22.609+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:43:22.621+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:43:22.621+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:43:22.631+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.074 seconds
[2024-07-29T18:43:53.058+0000] {processor.py:157} INFO - Started process (PID=47713) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:43:53.059+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:43:53.062+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:43:53.062+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:43:53.071+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:43:53.088+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:43:53.088+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:43:53.102+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:43:53.102+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:43:53.117+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-29T18:44:23.529+0000] {processor.py:157} INFO - Started process (PID=47738) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:44:23.530+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:44:23.534+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:44:23.534+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:44:23.551+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:44:23.576+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:44:23.576+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:44:23.588+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:44:23.588+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:44:23.599+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.078 seconds
[2024-07-29T18:44:54.153+0000] {processor.py:157} INFO - Started process (PID=47763) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:44:54.156+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:44:54.159+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:44:54.159+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:44:54.172+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:44:54.189+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:44:54.189+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:44:54.198+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:44:54.198+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:44:54.206+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-29T18:45:24.592+0000] {processor.py:157} INFO - Started process (PID=47788) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:45:24.594+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:45:24.599+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:45:24.598+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:45:24.616+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:45:24.640+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:45:24.640+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:45:24.652+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:45:24.652+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:45:24.662+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.075 seconds
[2024-07-29T18:45:55.114+0000] {processor.py:157} INFO - Started process (PID=47813) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:45:55.115+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:45:55.118+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:45:55.118+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:45:55.130+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:45:55.149+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:45:55.149+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:45:55.163+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:45:55.163+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:45:55.173+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.065 seconds
[2024-07-29T18:46:25.665+0000] {processor.py:157} INFO - Started process (PID=47838) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:46:25.667+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:46:25.671+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:46:25.670+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:46:25.688+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:46:25.710+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:46:25.710+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:46:25.722+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:46:25.722+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:46:25.734+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.073 seconds
[2024-07-29T18:46:56.235+0000] {processor.py:157} INFO - Started process (PID=47863) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:46:56.236+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:46:56.240+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:46:56.240+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:46:56.253+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:46:56.271+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:46:56.271+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:46:56.284+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:46:56.283+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:46:56.294+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.065 seconds
[2024-07-29T18:47:26.746+0000] {processor.py:157} INFO - Started process (PID=47888) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:47:26.748+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:47:26.752+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:47:26.752+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:47:26.773+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:47:26.799+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:47:26.799+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:47:26.813+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:47:26.813+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:47:26.826+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.085 seconds
[2024-07-29T18:47:57.262+0000] {processor.py:157} INFO - Started process (PID=47913) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:47:57.263+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:47:57.267+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:47:57.267+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:47:57.277+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:47:57.294+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:47:57.294+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:47:57.305+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:47:57.305+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:47:57.316+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-29T18:48:27.738+0000] {processor.py:157} INFO - Started process (PID=47938) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:48:27.739+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:48:27.743+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:48:27.743+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:48:27.763+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:48:27.788+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:48:27.788+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:48:27.800+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:48:27.800+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:48:27.809+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.077 seconds
[2024-07-29T18:48:58.190+0000] {processor.py:157} INFO - Started process (PID=47963) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:48:58.191+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:48:58.194+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:48:58.193+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:48:58.207+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:48:58.228+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:48:58.228+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:48:58.238+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:48:58.238+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:48:58.247+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-29T18:49:28.730+0000] {processor.py:157} INFO - Started process (PID=47988) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:49:28.732+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:49:28.736+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:49:28.735+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:49:28.754+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:49:28.781+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:49:28.781+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:49:28.795+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:49:28.795+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:49:28.806+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.082 seconds
[2024-07-29T18:49:59.296+0000] {processor.py:157} INFO - Started process (PID=48013) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:49:59.297+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:49:59.303+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:49:59.301+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:49:59.324+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:49:59.350+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:49:59.350+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:49:59.365+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:49:59.365+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:49:59.375+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.085 seconds
[2024-07-29T18:50:29.813+0000] {processor.py:157} INFO - Started process (PID=48038) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:50:29.815+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:50:29.818+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:50:29.818+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:50:29.840+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:50:29.888+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:50:29.888+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:50:29.905+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:50:29.904+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:50:29.917+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.120 seconds
[2024-07-29T18:51:00.363+0000] {processor.py:157} INFO - Started process (PID=48063) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:51:00.366+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:51:00.373+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:51:00.372+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:51:00.429+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:51:00.471+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:51:00.470+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:51:00.488+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:51:00.488+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:51:00.502+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.147 seconds
[2024-07-29T18:51:30.945+0000] {processor.py:157} INFO - Started process (PID=48088) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:51:30.948+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:51:30.956+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:51:30.955+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:51:30.985+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:51:31.040+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:51:31.040+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:51:31.063+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:51:31.063+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:51:31.091+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.174 seconds
[2024-07-29T18:52:01.502+0000] {processor.py:157} INFO - Started process (PID=48113) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:52:01.505+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:52:01.516+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:52:01.515+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:52:01.544+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:52:01.583+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:52:01.583+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:52:01.605+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:52:01.605+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:52:01.619+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.129 seconds
[2024-07-29T18:52:32.051+0000] {processor.py:157} INFO - Started process (PID=48138) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:52:32.054+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:52:32.060+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:52:32.060+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:52:32.083+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:52:32.117+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:52:32.116+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:52:32.135+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:52:32.134+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:52:32.148+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.106 seconds
[2024-07-29T18:53:02.635+0000] {processor.py:157} INFO - Started process (PID=48163) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:53:02.638+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:53:02.650+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:53:02.649+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:53:02.683+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:53:02.738+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:53:02.738+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:53:02.756+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:53:02.755+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:53:02.772+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.146 seconds
[2024-07-29T18:53:33.148+0000] {processor.py:157} INFO - Started process (PID=48188) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:53:33.150+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:53:33.154+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:53:33.154+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:53:33.171+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:53:33.195+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:53:33.195+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:53:33.211+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:53:33.211+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:53:33.229+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.104 seconds
[2024-07-29T18:54:03.698+0000] {processor.py:157} INFO - Started process (PID=48213) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:54:03.701+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:54:03.703+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:54:03.703+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:54:03.716+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:54:03.731+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:54:03.731+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:54:03.743+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:54:03.743+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:54:03.752+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-29T18:54:34.158+0000] {processor.py:157} INFO - Started process (PID=48238) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:54:34.166+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:54:34.177+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:54:34.176+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:54:34.202+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:54:34.228+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:54:34.228+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:54:34.253+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:54:34.253+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:54:34.265+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.125 seconds
[2024-07-29T18:55:04.749+0000] {processor.py:157} INFO - Started process (PID=48263) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:55:04.751+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:55:04.757+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:55:04.756+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:55:04.777+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:55:04.808+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:55:04.808+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:55:04.822+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:55:04.822+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:55:04.834+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.092 seconds
[2024-07-29T18:55:35.219+0000] {processor.py:157} INFO - Started process (PID=48288) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:55:35.221+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:55:35.227+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:55:35.226+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:55:35.257+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:55:35.296+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:55:35.296+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:55:35.310+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:55:35.310+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:55:35.322+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.110 seconds
[2024-07-29T18:56:05.795+0000] {processor.py:157} INFO - Started process (PID=48313) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:56:05.797+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:56:05.802+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:56:05.802+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:56:05.819+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:56:05.842+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:56:05.842+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:56:05.855+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:56:05.854+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:56:05.862+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.073 seconds
[2024-07-29T18:56:36.204+0000] {processor.py:157} INFO - Started process (PID=48338) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:56:36.204+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:56:36.206+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:56:36.206+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:56:36.212+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:56:36.226+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:56:36.226+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:56:36.235+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:56:36.234+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:56:36.247+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.046 seconds
[2024-07-29T18:57:06.690+0000] {processor.py:157} INFO - Started process (PID=48363) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:57:06.692+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:57:06.699+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:57:06.698+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:57:06.728+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:57:06.802+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:57:06.802+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:57:06.821+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:57:06.821+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:57:06.835+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.155 seconds
[2024-07-29T18:57:37.284+0000] {processor.py:157} INFO - Started process (PID=48388) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:57:37.288+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:57:37.294+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:57:37.293+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:57:37.327+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:57:37.391+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:57:37.390+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:57:37.411+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:57:37.411+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:57:37.424+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.151 seconds
[2024-07-29T18:58:07.814+0000] {processor.py:157} INFO - Started process (PID=48413) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:58:07.817+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:58:07.822+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:58:07.821+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:58:07.858+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:58:07.894+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:58:07.894+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:58:07.912+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:58:07.912+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:58:07.926+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.120 seconds
[2024-07-29T18:58:38.306+0000] {processor.py:157} INFO - Started process (PID=48438) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:58:38.309+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:58:38.314+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:58:38.313+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:58:38.340+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:58:38.374+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:58:38.374+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:58:38.393+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:58:38.393+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:58:38.410+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.113 seconds
[2024-07-29T18:59:08.844+0000] {processor.py:157} INFO - Started process (PID=48463) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:59:08.847+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:59:08.852+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:59:08.852+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:59:08.874+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:59:08.905+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:59:08.905+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:59:08.922+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:59:08.922+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:59:08.938+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.102 seconds
[2024-07-29T18:59:39.334+0000] {processor.py:157} INFO - Started process (PID=48488) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:59:39.337+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T18:59:39.353+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:59:39.353+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:59:39.373+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T18:59:39.401+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:59:39.401+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:59:39.418+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:59:39.418+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T18:59:39.430+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.104 seconds
[2024-07-29T19:00:09.839+0000] {processor.py:157} INFO - Started process (PID=48513) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:00:09.841+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T19:00:09.848+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:00:09.847+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:00:09.876+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:00:09.916+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:00:09.915+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T19:00:09.936+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:00:09.936+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T19:00:09.954+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.123 seconds
[2024-07-29T19:00:40.310+0000] {processor.py:157} INFO - Started process (PID=48538) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:00:40.313+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T19:00:40.320+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:00:40.320+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:00:40.350+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:00:40.393+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:00:40.393+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T19:00:40.416+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:00:40.416+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T19:00:40.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.128 seconds
[2024-07-29T19:01:10.977+0000] {processor.py:157} INFO - Started process (PID=48563) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:01:10.979+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T19:01:10.983+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:01:10.983+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:01:11.005+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:01:11.058+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:01:11.058+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T19:01:11.076+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:01:11.076+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T19:01:11.090+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.129 seconds
[2024-07-29T19:01:41.786+0000] {processor.py:157} INFO - Started process (PID=48588) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:01:41.787+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T19:01:41.791+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:01:41.790+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:01:41.812+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:01:41.851+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:01:41.851+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T19:01:41.866+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:01:41.865+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T19:01:41.882+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.104 seconds
[2024-07-29T19:13:56.365+0000] {processor.py:157} INFO - Started process (PID=48615) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:13:56.374+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T19:13:56.385+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:13:56.382+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:13:56.428+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:13:56.485+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:13:56.485+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T19:13:56.520+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:13:56.520+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T19:13:56.539+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.201 seconds
[2024-07-29T19:14:26.955+0000] {processor.py:157} INFO - Started process (PID=48640) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:14:26.956+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T19:14:26.958+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:14:26.958+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:14:26.965+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:14:26.979+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:14:26.978+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T19:14:26.987+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:14:26.987+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T19:14:26.997+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.044 seconds
[2024-07-29T19:14:57.419+0000] {processor.py:157} INFO - Started process (PID=48665) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:14:57.420+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T19:14:57.423+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:14:57.423+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:14:57.436+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:14:57.453+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:14:57.453+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T19:14:57.464+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:14:57.464+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T19:14:57.473+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-29T19:15:27.921+0000] {processor.py:157} INFO - Started process (PID=48690) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:15:27.922+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T19:15:27.924+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:15:27.924+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:15:27.941+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:15:27.963+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:15:27.963+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T19:15:27.973+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:15:27.973+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T19:15:27.983+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-29T19:15:58.362+0000] {processor.py:157} INFO - Started process (PID=48715) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:15:58.363+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T19:15:58.368+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:15:58.368+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:15:58.384+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:15:58.407+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:15:58.407+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T19:15:58.419+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:15:58.419+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T19:15:58.430+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.074 seconds
[2024-07-29T19:16:28.812+0000] {processor.py:157} INFO - Started process (PID=48740) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:16:28.813+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T19:16:28.817+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:16:28.816+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:16:28.827+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:16:28.847+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:16:28.847+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T19:16:28.858+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:16:28.858+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T19:16:28.867+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-29T19:32:05.460+0000] {processor.py:157} INFO - Started process (PID=48765) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:32:05.462+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T19:32:05.473+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:32:05.472+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:32:05.496+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:32:05.537+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:32:05.536+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T19:32:05.558+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:32:05.558+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T19:32:05.575+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.122 seconds
[2024-07-29T19:32:36.174+0000] {processor.py:157} INFO - Started process (PID=48790) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:32:36.174+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T19:32:36.178+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:32:36.178+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:32:36.195+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:32:36.224+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:32:36.224+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T19:32:36.251+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:32:36.250+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T19:32:36.264+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.110 seconds
[2024-07-29T19:33:06.609+0000] {processor.py:157} INFO - Started process (PID=48815) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:33:06.610+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T19:33:06.616+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:33:06.616+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:33:06.634+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:33:06.658+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:33:06.658+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T19:33:06.673+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:33:06.673+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T19:33:06.683+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.080 seconds
[2024-07-29T19:33:37.151+0000] {processor.py:157} INFO - Started process (PID=48840) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:33:37.152+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T19:33:37.155+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:33:37.154+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:33:37.168+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:33:37.187+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:33:37.187+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T19:33:37.197+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:33:37.197+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T19:33:37.205+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-29T19:34:07.617+0000] {processor.py:157} INFO - Started process (PID=48865) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:34:07.618+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T19:34:07.620+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:34:07.619+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:34:07.631+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:34:07.650+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:34:07.650+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T19:34:07.660+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:34:07.660+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T19:34:07.669+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-29T19:34:38.076+0000] {processor.py:157} INFO - Started process (PID=48890) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:34:38.078+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T19:34:38.082+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:34:38.082+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:34:38.102+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:34:38.135+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:34:38.135+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T19:34:38.151+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:34:38.151+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T19:34:38.160+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.090 seconds
[2024-07-29T19:35:08.540+0000] {processor.py:157} INFO - Started process (PID=48915) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:35:08.541+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T19:35:08.544+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:35:08.544+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:35:08.557+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:35:08.574+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:35:08.574+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T19:35:08.585+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:35:08.585+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T19:35:08.594+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-29T19:35:39.024+0000] {processor.py:157} INFO - Started process (PID=48940) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:35:39.027+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T19:35:39.029+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:35:39.029+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:35:39.040+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:35:39.057+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:35:39.057+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T19:35:39.069+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:35:39.068+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T19:35:39.077+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-29T19:36:09.503+0000] {processor.py:157} INFO - Started process (PID=48965) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:36:09.506+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T19:36:09.508+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:36:09.508+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:36:09.528+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:36:09.544+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:36:09.544+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T19:36:09.559+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:36:09.559+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T19:36:09.567+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.068 seconds
[2024-07-29T19:36:39.934+0000] {processor.py:157} INFO - Started process (PID=48990) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:36:39.935+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T19:36:39.939+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:36:39.939+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:36:39.956+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:36:39.978+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:36:39.978+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T19:36:39.991+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:36:39.991+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T19:36:40.002+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-29T19:37:10.456+0000] {processor.py:157} INFO - Started process (PID=49015) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:37:10.458+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T19:37:10.462+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:37:10.461+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:37:10.502+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:37:10.530+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:37:10.530+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T19:37:10.550+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:37:10.550+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T19:37:10.560+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.108 seconds
[2024-07-29T19:37:40.990+0000] {processor.py:157} INFO - Started process (PID=49040) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:37:40.991+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T19:37:40.994+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:37:40.993+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:37:41.010+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:37:41.027+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:37:41.027+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T19:37:41.037+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:37:41.037+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T19:37:41.047+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-29T19:38:11.478+0000] {processor.py:157} INFO - Started process (PID=49065) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:38:11.480+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T19:38:11.481+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:38:11.481+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:38:11.493+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:38:11.508+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:38:11.508+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T19:38:11.521+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:38:11.520+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T19:38:11.528+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-29T19:38:41.911+0000] {processor.py:157} INFO - Started process (PID=49090) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:38:41.912+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T19:38:41.914+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:38:41.914+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:38:41.925+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:38:41.943+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:38:41.943+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T19:38:41.958+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:38:41.958+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T19:38:41.966+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-29T19:39:12.407+0000] {processor.py:157} INFO - Started process (PID=49115) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:39:12.408+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T19:39:12.411+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:39:12.411+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:39:12.423+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:39:12.440+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:39:12.440+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T19:39:12.450+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:39:12.450+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T19:39:12.458+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-29T19:39:42.819+0000] {processor.py:157} INFO - Started process (PID=49140) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:39:42.821+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T19:39:42.824+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:39:42.823+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:39:42.843+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:39:42.860+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:39:42.860+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T19:39:42.872+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:39:42.872+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T19:39:42.883+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.068 seconds
[2024-07-29T19:40:13.281+0000] {processor.py:157} INFO - Started process (PID=49165) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:40:13.284+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T19:40:13.287+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:40:13.287+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:40:13.299+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:40:13.317+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:40:13.317+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T19:40:13.328+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:40:13.328+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T19:40:13.336+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-29T19:40:43.747+0000] {processor.py:157} INFO - Started process (PID=49190) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:40:43.748+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T19:40:43.750+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:40:43.750+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:40:43.765+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:40:43.782+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:40:43.782+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T19:40:43.795+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:40:43.795+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T19:40:43.804+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-29T19:41:14.193+0000] {processor.py:157} INFO - Started process (PID=49215) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:41:14.196+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T19:41:14.199+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:41:14.198+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:41:14.210+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:41:14.226+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:41:14.226+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T19:41:14.235+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:41:14.235+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T19:41:14.244+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-29T19:41:44.668+0000] {processor.py:157} INFO - Started process (PID=49240) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:41:44.669+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T19:41:44.671+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:41:44.671+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:41:44.682+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:41:44.703+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:41:44.703+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T19:41:44.716+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:41:44.716+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T19:41:44.725+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-29T19:42:15.136+0000] {processor.py:157} INFO - Started process (PID=49265) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:42:15.137+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T19:42:15.139+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:42:15.139+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:42:15.154+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:42:15.171+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:42:15.171+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T19:42:15.182+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:42:15.182+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T19:42:15.192+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-29T19:42:45.613+0000] {processor.py:157} INFO - Started process (PID=49290) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:42:45.615+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T19:42:45.618+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:42:45.617+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:42:45.630+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:42:45.647+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:42:45.647+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T19:42:45.657+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:42:45.657+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T19:42:45.667+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-29T19:43:16.028+0000] {processor.py:157} INFO - Started process (PID=49315) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:43:16.029+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T19:43:16.035+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:43:16.034+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:43:16.050+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:43:16.073+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:43:16.073+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T19:43:16.082+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:43:16.082+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T19:43:16.091+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-29T19:43:46.524+0000] {processor.py:157} INFO - Started process (PID=49340) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:43:46.525+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T19:43:46.527+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:43:46.527+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:43:46.538+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:43:46.556+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:43:46.556+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T19:43:46.569+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:43:46.569+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T19:43:46.579+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-29T19:44:16.992+0000] {processor.py:157} INFO - Started process (PID=49365) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:44:16.993+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T19:44:16.996+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:44:16.996+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:44:17.006+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:44:17.022+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:44:17.022+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T19:44:17.032+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:44:17.032+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T19:44:17.041+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-29T19:44:47.422+0000] {processor.py:157} INFO - Started process (PID=49390) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:44:47.423+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T19:44:47.425+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:44:47.425+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:44:47.437+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:44:47.453+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:44:47.453+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T19:44:47.465+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:44:47.465+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T19:44:47.474+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-29T19:45:17.885+0000] {processor.py:157} INFO - Started process (PID=49415) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:45:17.886+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T19:45:17.889+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:45:17.889+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:45:17.901+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:45:17.918+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:45:17.918+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T19:45:17.929+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:45:17.929+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T19:45:17.937+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-29T19:45:48.419+0000] {processor.py:157} INFO - Started process (PID=49440) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:45:48.420+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T19:45:48.423+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:45:48.423+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:45:48.436+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T19:45:48.455+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:45:48.454+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T19:45:48.472+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:45:48.472+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T19:45:48.483+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-29T20:03:42.563+0000] {processor.py:157} INFO - Started process (PID=49467) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T20:03:42.568+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T20:03:42.570+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:03:42.569+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T20:03:42.588+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T20:03:42.627+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:03:42.627+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T20:03:42.648+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:03:42.648+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T20:03:42.666+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.107 seconds
[2024-07-29T20:04:13.071+0000] {processor.py:157} INFO - Started process (PID=49492) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T20:04:13.072+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T20:04:13.075+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:04:13.075+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T20:04:13.090+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T20:04:13.109+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:04:13.108+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T20:04:13.123+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:04:13.123+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T20:04:13.133+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-29T20:04:43.523+0000] {processor.py:157} INFO - Started process (PID=49517) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T20:04:43.524+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T20:04:43.526+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:04:43.526+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T20:04:43.541+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T20:04:43.560+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:04:43.560+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T20:04:43.570+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:04:43.569+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T20:04:43.580+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-29T20:05:13.889+0000] {processor.py:157} INFO - Started process (PID=49542) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T20:05:13.890+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T20:05:13.892+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:05:13.892+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T20:05:13.908+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T20:05:13.927+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:05:13.927+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T20:05:13.938+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:05:13.938+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T20:05:13.948+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-29T20:05:44.375+0000] {processor.py:157} INFO - Started process (PID=49567) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T20:05:44.375+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T20:05:44.377+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:05:44.377+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T20:05:44.386+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T20:05:44.401+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:05:44.401+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T20:05:44.411+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:05:44.411+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T20:05:44.419+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-29T20:22:05.073+0000] {processor.py:157} INFO - Started process (PID=49592) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T20:22:05.073+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T20:22:05.078+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:22:05.078+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T20:22:05.092+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T20:22:05.112+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:22:05.112+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T20:22:05.127+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:22:05.127+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T20:22:05.140+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-29T20:22:35.696+0000] {processor.py:157} INFO - Started process (PID=49619) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T20:22:35.697+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T20:22:35.702+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:22:35.702+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T20:22:35.719+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T20:22:35.743+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:22:35.743+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T20:22:35.755+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:22:35.755+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T20:22:35.766+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.075 seconds
[2024-07-29T20:23:06.243+0000] {processor.py:157} INFO - Started process (PID=49644) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T20:23:06.244+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T20:23:06.247+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:23:06.246+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T20:23:06.256+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T20:23:06.273+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:23:06.273+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T20:23:06.285+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:23:06.285+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T20:23:06.296+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-29T20:23:36.829+0000] {processor.py:157} INFO - Started process (PID=49669) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T20:23:36.830+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T20:23:36.833+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:23:36.832+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T20:23:36.845+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T20:23:36.862+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:23:36.862+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T20:23:36.875+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:23:36.875+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T20:23:36.883+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-29T20:24:07.271+0000] {processor.py:157} INFO - Started process (PID=49694) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T20:24:07.271+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T20:24:07.273+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:24:07.273+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T20:24:07.280+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T20:24:07.293+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:24:07.293+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T20:24:07.305+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:24:07.305+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T20:24:07.314+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.044 seconds
[2024-07-29T20:24:37.620+0000] {processor.py:157} INFO - Started process (PID=49719) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T20:24:37.622+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T20:24:37.625+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:24:37.625+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T20:24:37.634+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T20:24:37.651+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:24:37.651+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T20:24:37.662+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:24:37.661+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T20:24:37.671+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-29T20:25:08.091+0000] {processor.py:157} INFO - Started process (PID=49744) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T20:25:08.092+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T20:25:08.095+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:25:08.095+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T20:25:08.106+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T20:25:08.125+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:25:08.125+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T20:25:08.134+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:25:08.134+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T20:25:08.143+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-29T20:25:38.544+0000] {processor.py:157} INFO - Started process (PID=49769) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T20:25:38.546+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T20:25:38.550+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:25:38.550+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T20:25:38.561+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T20:25:38.582+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:25:38.582+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T20:25:38.593+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:25:38.593+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T20:25:38.603+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-29T20:26:09.033+0000] {processor.py:157} INFO - Started process (PID=49794) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T20:26:09.034+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T20:26:09.041+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:26:09.040+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T20:26:09.058+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T20:26:09.081+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:26:09.080+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T20:26:09.092+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:26:09.092+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T20:26:09.103+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.075 seconds
[2024-07-29T20:26:39.474+0000] {processor.py:157} INFO - Started process (PID=49819) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T20:26:39.475+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T20:26:39.479+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:26:39.478+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T20:26:39.491+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T20:26:39.508+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:26:39.508+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T20:26:39.519+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:26:39.519+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T20:26:39.528+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-29T20:43:17.287+0000] {processor.py:157} INFO - Started process (PID=49844) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T20:43:17.288+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T20:43:17.291+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:43:17.291+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T20:43:17.304+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T20:43:17.326+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:43:17.326+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T20:43:17.342+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:43:17.342+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T20:43:17.350+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-29T20:43:47.718+0000] {processor.py:157} INFO - Started process (PID=49871) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T20:43:47.719+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T20:43:47.724+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:43:47.723+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T20:43:47.741+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T20:43:47.768+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:43:47.768+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T20:43:47.782+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:43:47.782+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T20:43:47.792+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.081 seconds
[2024-07-29T20:44:18.251+0000] {processor.py:157} INFO - Started process (PID=49896) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T20:44:18.253+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T20:44:18.254+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:44:18.254+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T20:44:18.267+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T20:44:18.284+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:44:18.284+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T20:44:18.296+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:44:18.296+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T20:44:18.305+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-29T20:44:48.670+0000] {processor.py:157} INFO - Started process (PID=49921) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T20:44:48.672+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T20:44:48.674+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:44:48.674+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T20:44:48.686+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T20:44:48.703+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:44:48.703+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T20:44:48.712+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:44:48.712+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T20:44:48.720+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-29T20:45:19.049+0000] {processor.py:157} INFO - Started process (PID=49946) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T20:45:19.050+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T20:45:19.052+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:45:19.052+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T20:45:19.067+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T20:45:19.086+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:45:19.086+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T20:45:19.099+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:45:19.099+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T20:45:19.112+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-29T21:02:55.646+0000] {processor.py:157} INFO - Started process (PID=49971) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T21:02:55.647+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T21:02:55.651+0000] {logging_mixin.py:151} INFO - [2024-07-29T21:02:55.651+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T21:02:55.668+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T21:02:55.695+0000] {logging_mixin.py:151} INFO - [2024-07-29T21:02:55.695+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T21:02:55.710+0000] {logging_mixin.py:151} INFO - [2024-07-29T21:02:55.710+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T21:02:55.724+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.083 seconds
[2024-07-29T21:03:26.114+0000] {processor.py:157} INFO - Started process (PID=49998) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T21:03:26.115+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T21:03:26.120+0000] {logging_mixin.py:151} INFO - [2024-07-29T21:03:26.119+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T21:03:26.137+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T21:03:26.160+0000] {logging_mixin.py:151} INFO - [2024-07-29T21:03:26.160+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T21:03:26.173+0000] {logging_mixin.py:151} INFO - [2024-07-29T21:03:26.172+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T21:03:26.183+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.074 seconds
[2024-07-29T21:03:56.605+0000] {processor.py:157} INFO - Started process (PID=50023) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T21:03:56.606+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T21:03:56.608+0000] {logging_mixin.py:151} INFO - [2024-07-29T21:03:56.608+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T21:03:56.623+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T21:03:56.642+0000] {logging_mixin.py:151} INFO - [2024-07-29T21:03:56.641+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T21:03:56.650+0000] {logging_mixin.py:151} INFO - [2024-07-29T21:03:56.650+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T21:03:56.662+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-29T21:04:27.013+0000] {processor.py:157} INFO - Started process (PID=50048) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T21:04:27.017+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T21:04:27.020+0000] {logging_mixin.py:151} INFO - [2024-07-29T21:04:27.019+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T21:04:27.033+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T21:04:27.050+0000] {logging_mixin.py:151} INFO - [2024-07-29T21:04:27.050+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T21:04:27.059+0000] {logging_mixin.py:151} INFO - [2024-07-29T21:04:27.059+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T21:04:27.067+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-29T21:04:57.343+0000] {processor.py:157} INFO - Started process (PID=50073) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T21:04:57.345+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T21:04:57.346+0000] {logging_mixin.py:151} INFO - [2024-07-29T21:04:57.346+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T21:04:57.355+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T21:04:57.372+0000] {logging_mixin.py:151} INFO - [2024-07-29T21:04:57.371+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T21:04:57.381+0000] {logging_mixin.py:151} INFO - [2024-07-29T21:04:57.381+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T21:04:57.391+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-29T21:05:27.811+0000] {processor.py:157} INFO - Started process (PID=50098) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T21:05:27.814+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T21:05:27.815+0000] {logging_mixin.py:151} INFO - [2024-07-29T21:05:27.815+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T21:05:27.826+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T21:05:27.844+0000] {logging_mixin.py:151} INFO - [2024-07-29T21:05:27.843+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T21:05:27.857+0000] {logging_mixin.py:151} INFO - [2024-07-29T21:05:27.857+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T21:05:27.866+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-29T21:21:17.344+0000] {processor.py:157} INFO - Started process (PID=50123) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T21:21:17.346+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T21:21:17.350+0000] {logging_mixin.py:151} INFO - [2024-07-29T21:21:17.350+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T21:21:17.388+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T21:21:17.431+0000] {logging_mixin.py:151} INFO - [2024-07-29T21:21:17.431+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T21:21:17.463+0000] {logging_mixin.py:151} INFO - [2024-07-29T21:21:17.463+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T21:21:17.486+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.146 seconds
[2024-07-29T21:37:14.091+0000] {processor.py:157} INFO - Started process (PID=50150) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T21:37:14.092+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T21:37:14.097+0000] {logging_mixin.py:151} INFO - [2024-07-29T21:37:14.097+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T21:37:14.116+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T21:37:14.158+0000] {logging_mixin.py:151} INFO - [2024-07-29T21:37:14.158+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T21:37:14.180+0000] {logging_mixin.py:151} INFO - [2024-07-29T21:37:14.180+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T21:37:14.203+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.115 seconds
[2024-07-29T21:37:44.620+0000] {processor.py:157} INFO - Started process (PID=50175) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T21:37:44.624+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T21:37:44.627+0000] {logging_mixin.py:151} INFO - [2024-07-29T21:37:44.626+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T21:37:44.647+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T21:37:44.673+0000] {logging_mixin.py:151} INFO - [2024-07-29T21:37:44.673+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T21:37:44.691+0000] {logging_mixin.py:151} INFO - [2024-07-29T21:37:44.690+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T21:37:44.701+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.087 seconds
[2024-07-29T21:38:15.092+0000] {processor.py:157} INFO - Started process (PID=50200) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T21:38:15.095+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T21:38:15.098+0000] {logging_mixin.py:151} INFO - [2024-07-29T21:38:15.097+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T21:38:15.108+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T21:38:15.127+0000] {logging_mixin.py:151} INFO - [2024-07-29T21:38:15.127+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T21:38:15.141+0000] {logging_mixin.py:151} INFO - [2024-07-29T21:38:15.141+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T21:38:15.156+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.068 seconds
[2024-07-29T21:38:45.545+0000] {processor.py:157} INFO - Started process (PID=50225) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T21:38:45.546+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T21:38:45.549+0000] {logging_mixin.py:151} INFO - [2024-07-29T21:38:45.548+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T21:38:45.560+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T21:38:45.580+0000] {logging_mixin.py:151} INFO - [2024-07-29T21:38:45.580+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T21:38:45.592+0000] {logging_mixin.py:151} INFO - [2024-07-29T21:38:45.592+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T21:38:45.603+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-29T21:39:15.991+0000] {processor.py:157} INFO - Started process (PID=50250) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T21:39:15.992+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T21:39:15.993+0000] {logging_mixin.py:151} INFO - [2024-07-29T21:39:15.993+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T21:39:16.002+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T21:39:16.018+0000] {logging_mixin.py:151} INFO - [2024-07-29T21:39:16.018+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T21:39:16.026+0000] {logging_mixin.py:151} INFO - [2024-07-29T21:39:16.026+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T21:39:16.036+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.046 seconds
[2024-07-29T21:55:51.160+0000] {processor.py:157} INFO - Started process (PID=50277) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T21:55:51.161+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T21:55:51.165+0000] {logging_mixin.py:151} INFO - [2024-07-29T21:55:51.165+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T21:55:51.180+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T21:55:51.201+0000] {logging_mixin.py:151} INFO - [2024-07-29T21:55:51.201+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T21:55:51.214+0000] {logging_mixin.py:151} INFO - [2024-07-29T21:55:51.214+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T21:55:51.224+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.068 seconds
[2024-07-29T21:56:21.701+0000] {processor.py:157} INFO - Started process (PID=50302) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T21:56:21.702+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T21:56:21.706+0000] {logging_mixin.py:151} INFO - [2024-07-29T21:56:21.705+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T21:56:21.740+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T21:56:21.767+0000] {logging_mixin.py:151} INFO - [2024-07-29T21:56:21.767+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T21:56:21.792+0000] {logging_mixin.py:151} INFO - [2024-07-29T21:56:21.792+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T21:56:21.803+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.109 seconds
[2024-07-29T22:03:44.357+0000] {processor.py:157} INFO - Started process (PID=50327) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T22:03:44.359+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T22:03:44.364+0000] {logging_mixin.py:151} INFO - [2024-07-29T22:03:44.364+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T22:03:44.386+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T22:03:44.435+0000] {logging_mixin.py:151} INFO - [2024-07-29T22:03:44.435+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T22:03:44.454+0000] {logging_mixin.py:151} INFO - [2024-07-29T22:03:44.454+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T22:03:44.471+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.119 seconds
[2024-07-29T22:04:15.020+0000] {processor.py:157} INFO - Started process (PID=50352) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T22:04:15.022+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T22:04:15.027+0000] {logging_mixin.py:151} INFO - [2024-07-29T22:04:15.026+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T22:04:15.039+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T22:04:15.068+0000] {logging_mixin.py:151} INFO - [2024-07-29T22:04:15.068+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T22:04:15.078+0000] {logging_mixin.py:151} INFO - [2024-07-29T22:04:15.078+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T22:04:15.087+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.072 seconds
[2024-07-29T22:21:37.430+0000] {processor.py:157} INFO - Started process (PID=50379) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T22:21:37.435+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T22:21:37.438+0000] {logging_mixin.py:151} INFO - [2024-07-29T22:21:37.438+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T22:21:37.456+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T22:21:37.496+0000] {logging_mixin.py:151} INFO - [2024-07-29T22:21:37.496+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T22:21:37.519+0000] {logging_mixin.py:151} INFO - [2024-07-29T22:21:37.519+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T22:21:37.536+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.110 seconds
[2024-07-29T22:22:08.015+0000] {processor.py:157} INFO - Started process (PID=50404) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T22:22:08.017+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T22:22:08.020+0000] {logging_mixin.py:151} INFO - [2024-07-29T22:22:08.020+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T22:22:08.034+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T22:22:08.054+0000] {logging_mixin.py:151} INFO - [2024-07-29T22:22:08.054+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T22:22:08.067+0000] {logging_mixin.py:151} INFO - [2024-07-29T22:22:08.067+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T22:22:08.075+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.068 seconds
[2024-07-29T22:22:38.455+0000] {processor.py:157} INFO - Started process (PID=50429) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T22:22:38.455+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T22:22:38.460+0000] {logging_mixin.py:151} INFO - [2024-07-29T22:22:38.459+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T22:22:38.474+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T22:22:38.494+0000] {logging_mixin.py:151} INFO - [2024-07-29T22:22:38.494+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T22:22:38.506+0000] {logging_mixin.py:151} INFO - [2024-07-29T22:22:38.506+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T22:22:38.514+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-29T22:23:08.937+0000] {processor.py:157} INFO - Started process (PID=50454) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T22:23:08.940+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T22:23:08.943+0000] {logging_mixin.py:151} INFO - [2024-07-29T22:23:08.943+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T22:23:08.955+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T22:23:08.971+0000] {logging_mixin.py:151} INFO - [2024-07-29T22:23:08.971+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T22:23:08.981+0000] {logging_mixin.py:151} INFO - [2024-07-29T22:23:08.980+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T22:23:08.988+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-29T22:23:39.333+0000] {processor.py:157} INFO - Started process (PID=50479) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T22:23:39.336+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T22:23:39.339+0000] {logging_mixin.py:151} INFO - [2024-07-29T22:23:39.338+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T22:23:39.352+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T22:23:39.376+0000] {logging_mixin.py:151} INFO - [2024-07-29T22:23:39.376+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T22:23:39.387+0000] {logging_mixin.py:151} INFO - [2024-07-29T22:23:39.387+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T22:23:39.397+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-29T22:39:34.542+0000] {processor.py:157} INFO - Started process (PID=50505) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T22:39:34.543+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T22:39:34.551+0000] {logging_mixin.py:151} INFO - [2024-07-29T22:39:34.550+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T22:39:34.568+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T22:39:34.602+0000] {logging_mixin.py:151} INFO - [2024-07-29T22:39:34.602+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T22:39:34.632+0000] {logging_mixin.py:151} INFO - [2024-07-29T22:39:34.632+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T22:39:34.647+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.110 seconds
[2024-07-29T22:57:13.139+0000] {processor.py:157} INFO - Started process (PID=50530) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T22:57:13.142+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T22:57:13.148+0000] {logging_mixin.py:151} INFO - [2024-07-29T22:57:13.148+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T22:57:13.175+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T22:57:13.219+0000] {logging_mixin.py:151} INFO - [2024-07-29T22:57:13.219+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T22:57:13.236+0000] {logging_mixin.py:151} INFO - [2024-07-29T22:57:13.236+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T22:57:13.246+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.124 seconds
[2024-07-29T22:57:43.700+0000] {processor.py:157} INFO - Started process (PID=50555) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T22:57:43.703+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T22:57:43.708+0000] {logging_mixin.py:151} INFO - [2024-07-29T22:57:43.708+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T22:57:43.748+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T22:57:43.775+0000] {logging_mixin.py:151} INFO - [2024-07-29T22:57:43.775+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T22:57:43.788+0000] {logging_mixin.py:151} INFO - [2024-07-29T22:57:43.788+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T22:57:43.798+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.107 seconds
[2024-07-29T22:58:14.262+0000] {processor.py:157} INFO - Started process (PID=50580) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T22:58:14.263+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T22:58:14.270+0000] {logging_mixin.py:151} INFO - [2024-07-29T22:58:14.269+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T22:58:14.287+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T22:58:14.308+0000] {logging_mixin.py:151} INFO - [2024-07-29T22:58:14.308+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T22:58:14.330+0000] {logging_mixin.py:151} INFO - [2024-07-29T22:58:14.330+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T22:58:14.345+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.090 seconds
[2024-07-29T22:58:44.792+0000] {processor.py:157} INFO - Started process (PID=50605) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T22:58:44.793+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T22:58:44.795+0000] {logging_mixin.py:151} INFO - [2024-07-29T22:58:44.795+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T22:58:44.808+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T22:58:44.830+0000] {logging_mixin.py:151} INFO - [2024-07-29T22:58:44.830+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T22:58:44.838+0000] {logging_mixin.py:151} INFO - [2024-07-29T22:58:44.838+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T22:58:44.847+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-29T22:59:15.190+0000] {processor.py:157} INFO - Started process (PID=50630) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T22:59:15.191+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T22:59:15.194+0000] {logging_mixin.py:151} INFO - [2024-07-29T22:59:15.194+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T22:59:15.205+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T22:59:15.220+0000] {logging_mixin.py:151} INFO - [2024-07-29T22:59:15.220+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T22:59:15.232+0000] {logging_mixin.py:151} INFO - [2024-07-29T22:59:15.232+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T22:59:15.241+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-29T23:04:52.255+0000] {processor.py:157} INFO - Started process (PID=50657) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T23:04:52.257+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T23:04:52.265+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:04:52.264+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T23:04:52.298+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T23:04:52.353+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:04:52.353+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T23:04:52.388+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:04:52.388+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T23:04:52.413+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.163 seconds
[2024-07-29T23:05:22.996+0000] {processor.py:157} INFO - Started process (PID=50682) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T23:05:22.997+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T23:05:23.001+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:05:23.000+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T23:05:23.021+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T23:05:23.062+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:05:23.062+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T23:05:23.077+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:05:23.076+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T23:05:23.088+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.097 seconds
[2024-07-29T23:05:53.497+0000] {processor.py:157} INFO - Started process (PID=50707) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T23:05:53.499+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T23:05:53.503+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:05:53.503+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T23:05:53.515+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T23:05:53.533+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:05:53.533+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T23:05:53.544+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:05:53.544+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T23:05:53.552+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-29T23:06:23.947+0000] {processor.py:157} INFO - Started process (PID=50732) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T23:06:23.950+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T23:06:23.953+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:06:23.953+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T23:06:23.965+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T23:06:23.982+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:06:23.982+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T23:06:23.994+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:06:23.994+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T23:06:24.002+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-29T23:06:54.415+0000] {processor.py:157} INFO - Started process (PID=50757) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T23:06:54.416+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T23:06:54.423+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:06:54.423+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T23:06:54.442+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T23:06:54.465+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:06:54.465+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T23:06:54.479+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:06:54.479+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T23:06:54.771+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.362 seconds
[2024-07-29T23:22:54.578+0000] {processor.py:157} INFO - Started process (PID=50782) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T23:22:54.579+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T23:22:54.584+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:22:54.583+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T23:22:54.608+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T23:22:54.641+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:22:54.641+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T23:22:54.667+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:22:54.667+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T23:22:54.689+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.115 seconds
[2024-07-29T23:23:25.172+0000] {processor.py:157} INFO - Started process (PID=50807) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T23:23:25.173+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T23:23:25.177+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:23:25.177+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T23:23:25.198+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T23:23:25.220+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:23:25.220+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T23:23:25.233+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:23:25.233+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T23:23:25.242+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.077 seconds
[2024-07-29T23:23:55.685+0000] {processor.py:157} INFO - Started process (PID=50832) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T23:23:55.688+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T23:23:55.690+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:23:55.689+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T23:23:55.702+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T23:23:55.722+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:23:55.722+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T23:23:55.734+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:23:55.734+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T23:23:55.743+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-29T23:24:26.198+0000] {processor.py:157} INFO - Started process (PID=50857) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T23:24:26.201+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T23:24:26.203+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:24:26.203+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T23:24:26.213+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T23:24:26.231+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:24:26.231+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T23:24:26.241+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:24:26.241+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T23:24:26.250+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-29T23:41:16.193+0000] {processor.py:157} INFO - Started process (PID=50884) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T23:41:16.194+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T23:41:16.204+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:41:16.204+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T23:41:16.225+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T23:41:16.255+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:41:16.255+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T23:41:16.284+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:41:16.284+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T23:41:16.298+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.109 seconds
[2024-07-29T23:41:46.720+0000] {processor.py:157} INFO - Started process (PID=50909) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T23:41:46.722+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T23:41:46.727+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:41:46.726+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T23:41:46.746+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T23:41:46.771+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:41:46.771+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T23:41:46.783+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:41:46.783+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T23:41:46.793+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.079 seconds
[2024-07-29T23:57:49.298+0000] {processor.py:157} INFO - Started process (PID=50934) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T23:57:49.300+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T23:57:49.318+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:57:49.316+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T23:57:49.345+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T23:57:49.385+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:57:49.385+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T23:57:49.416+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:57:49.415+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T23:57:49.445+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.152 seconds
[2024-07-29T23:58:19.845+0000] {processor.py:157} INFO - Started process (PID=50959) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T23:58:19.846+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T23:58:19.849+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:58:19.849+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T23:58:19.865+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T23:58:19.887+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:58:19.887+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T23:58:19.899+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:58:19.899+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T23:58:19.909+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.068 seconds
[2024-07-29T23:58:50.353+0000] {processor.py:157} INFO - Started process (PID=50984) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T23:58:50.354+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T23:58:50.358+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:58:50.358+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T23:58:50.369+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T23:58:50.386+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:58:50.386+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T23:58:50.396+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:58:50.395+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T23:58:50.405+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-29T23:59:20.853+0000] {processor.py:157} INFO - Started process (PID=51009) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T23:59:20.854+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T23:59:20.858+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:59:20.857+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T23:59:20.869+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T23:59:20.887+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:59:20.887+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T23:59:20.896+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:59:20.896+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T23:59:20.906+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-29T23:59:51.368+0000] {processor.py:157} INFO - Started process (PID=51034) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-29T23:59:51.369+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-29T23:59:51.370+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:59:51.370+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-29T23:59:51.381+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-29T23:59:51.397+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:59:51.396+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T23:59:51.406+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:59:51.406+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-29T00:30:00+00:00, run_after=2024-07-30T00:30:00+00:00
[2024-07-29T23:59:51.414+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
