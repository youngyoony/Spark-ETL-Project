[2024-07-29T00:08:06.016+0000] {processor.py:157} INFO - Started process (PID=11940) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T00:08:06.018+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T00:08:06.036+0000] {logging_mixin.py:151} INFO - [2024-07-29T00:08:06.035+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T00:08:06.064+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T00:08:06.114+0000] {logging_mixin.py:151} INFO - [2024-07-29T00:08:06.113+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T00:08:06.133+0000] {logging_mixin.py:151} INFO - [2024-07-29T00:08:06.133+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-29T00:08:06.157+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.149 seconds
[2024-07-29T00:08:36.265+0000] {processor.py:157} INFO - Started process (PID=11966) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T00:08:36.267+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T00:08:36.269+0000] {logging_mixin.py:151} INFO - [2024-07-29T00:08:36.268+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T00:08:36.282+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T00:08:36.302+0000] {logging_mixin.py:151} INFO - [2024-07-29T00:08:36.302+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T00:08:36.313+0000] {logging_mixin.py:151} INFO - [2024-07-29T00:08:36.313+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-29T00:08:36.322+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-29T00:09:06.645+0000] {processor.py:157} INFO - Started process (PID=11991) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T00:09:06.646+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T00:09:06.647+0000] {logging_mixin.py:151} INFO - [2024-07-29T00:09:06.647+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T00:09:06.658+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T00:09:06.674+0000] {logging_mixin.py:151} INFO - [2024-07-29T00:09:06.674+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T00:09:06.686+0000] {logging_mixin.py:151} INFO - [2024-07-29T00:09:06.686+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-29T00:09:06.783+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.141 seconds
[2024-07-29T00:09:37.092+0000] {processor.py:157} INFO - Started process (PID=12016) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T00:09:37.094+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T00:09:37.097+0000] {logging_mixin.py:151} INFO - [2024-07-29T00:09:37.096+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T00:09:37.110+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T00:09:37.125+0000] {logging_mixin.py:151} INFO - [2024-07-29T00:09:37.125+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T00:09:37.204+0000] {logging_mixin.py:151} INFO - [2024-07-29T00:09:37.204+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-29T00:09:37.212+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-07-29T00:25:45.236+0000] {processor.py:157} INFO - Started process (PID=12041) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T00:25:45.239+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T00:25:45.249+0000] {logging_mixin.py:151} INFO - [2024-07-29T00:25:45.248+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T00:25:45.266+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T00:25:45.321+0000] {logging_mixin.py:151} INFO - [2024-07-29T00:25:45.321+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T00:25:45.541+0000] {logging_mixin.py:151} INFO - [2024-07-29T00:25:45.540+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-29T00:25:45.556+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.326 seconds
[2024-07-29T00:26:16.138+0000] {processor.py:157} INFO - Started process (PID=12066) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T00:26:16.141+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T00:26:16.144+0000] {logging_mixin.py:151} INFO - [2024-07-29T00:26:16.144+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T00:26:16.157+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T00:26:16.171+0000] {logging_mixin.py:151} INFO - [2024-07-29T00:26:16.171+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T00:26:16.183+0000] {logging_mixin.py:151} INFO - [2024-07-29T00:26:16.182+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-29T00:26:16.190+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-29T00:26:46.637+0000] {processor.py:157} INFO - Started process (PID=12091) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T00:26:46.638+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T00:26:46.641+0000] {logging_mixin.py:151} INFO - [2024-07-29T00:26:46.641+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T00:26:46.660+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T00:26:46.674+0000] {logging_mixin.py:151} INFO - [2024-07-29T00:26:46.674+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T00:26:46.683+0000] {logging_mixin.py:151} INFO - [2024-07-29T00:26:46.683+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-29T00:26:46.691+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-29T00:27:17.072+0000] {processor.py:157} INFO - Started process (PID=12116) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T00:27:17.076+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T00:27:17.078+0000] {logging_mixin.py:151} INFO - [2024-07-29T00:27:17.078+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T00:27:17.090+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T00:27:17.108+0000] {logging_mixin.py:151} INFO - [2024-07-29T00:27:17.107+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T00:27:17.119+0000] {logging_mixin.py:151} INFO - [2024-07-29T00:27:17.118+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-29T00:27:17.128+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-29T00:27:47.559+0000] {processor.py:157} INFO - Started process (PID=12141) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T00:27:47.560+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T00:27:47.562+0000] {logging_mixin.py:151} INFO - [2024-07-29T00:27:47.562+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T00:27:47.574+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T00:27:47.593+0000] {logging_mixin.py:151} INFO - [2024-07-29T00:27:47.593+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T00:27:47.603+0000] {logging_mixin.py:151} INFO - [2024-07-29T00:27:47.603+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-29T00:27:47.743+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.186 seconds
[2024-07-29T00:45:33.340+0000] {processor.py:157} INFO - Started process (PID=12166) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T00:45:33.343+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T00:45:33.345+0000] {logging_mixin.py:151} INFO - [2024-07-29T00:45:33.345+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T00:45:33.360+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T00:45:33.379+0000] {logging_mixin.py:151} INFO - [2024-07-29T00:45:33.379+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T00:45:33.511+0000] {logging_mixin.py:151} INFO - [2024-07-29T00:45:33.510+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-29T00:45:33.520+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.183 seconds
[2024-07-29T00:46:03.995+0000] {processor.py:157} INFO - Started process (PID=12583) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T00:46:03.996+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T00:46:03.998+0000] {logging_mixin.py:151} INFO - [2024-07-29T00:46:03.998+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T00:46:04.011+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T00:46:04.028+0000] {logging_mixin.py:151} INFO - [2024-07-29T00:46:04.028+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T00:46:04.039+0000] {logging_mixin.py:151} INFO - [2024-07-29T00:46:04.039+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-29T00:46:04.049+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-29T00:46:34.509+0000] {processor.py:157} INFO - Started process (PID=12608) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T00:46:34.510+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T00:46:34.513+0000] {logging_mixin.py:151} INFO - [2024-07-29T00:46:34.513+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T00:46:34.533+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T00:46:34.548+0000] {logging_mixin.py:151} INFO - [2024-07-29T00:46:34.548+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T00:46:34.559+0000] {logging_mixin.py:151} INFO - [2024-07-29T00:46:34.559+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-29T00:46:34.567+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-29T00:47:04.950+0000] {processor.py:157} INFO - Started process (PID=12633) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T00:47:04.952+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T00:47:04.954+0000] {logging_mixin.py:151} INFO - [2024-07-29T00:47:04.954+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T00:47:04.965+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T00:47:04.980+0000] {logging_mixin.py:151} INFO - [2024-07-29T00:47:04.980+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T00:47:04.990+0000] {logging_mixin.py:151} INFO - [2024-07-29T00:47:04.990+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-29T00:47:04.999+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-29T00:47:35.487+0000] {processor.py:157} INFO - Started process (PID=12658) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T00:47:35.490+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T00:47:35.493+0000] {logging_mixin.py:151} INFO - [2024-07-29T00:47:35.493+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T00:47:35.509+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T00:47:35.537+0000] {logging_mixin.py:151} INFO - [2024-07-29T00:47:35.536+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T00:47:35.547+0000] {logging_mixin.py:151} INFO - [2024-07-29T00:47:35.547+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-28T01:00:00+00:00, run_after=2024-07-29T01:00:00+00:00
[2024-07-29T00:47:35.557+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-29T01:03:14.385+0000] {processor.py:157} INFO - Started process (PID=12696) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T01:03:14.388+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T01:03:14.393+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:03:14.393+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T01:03:14.417+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T01:03:14.494+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:03:14.493+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T01:03:14.835+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:03:14.835+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T01:03:14.842+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.460 seconds
[2024-07-29T01:03:45.298+0000] {processor.py:157} INFO - Started process (PID=13103) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T01:03:45.303+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T01:03:45.305+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:03:45.305+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T01:03:45.339+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T01:03:45.390+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:03:45.390+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T01:03:45.527+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:03:45.527+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T01:03:45.534+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.241 seconds
[2024-07-29T01:04:16.137+0000] {processor.py:157} INFO - Started process (PID=13128) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T01:04:16.139+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T01:04:16.142+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:04:16.142+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T01:04:16.158+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T01:04:16.180+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:04:16.180+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T01:04:16.190+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:04:16.190+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T01:04:16.198+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-29T01:04:46.598+0000] {processor.py:157} INFO - Started process (PID=13153) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T01:04:46.600+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T01:04:46.601+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:04:46.601+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T01:04:46.617+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T01:04:46.631+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:04:46.631+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T01:04:46.641+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:04:46.641+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T01:04:46.649+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-29T01:05:17.117+0000] {processor.py:157} INFO - Started process (PID=13178) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T01:05:17.118+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T01:05:17.122+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:05:17.121+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T01:05:17.184+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T01:05:17.205+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:05:17.205+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T01:05:17.216+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:05:17.216+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T01:05:17.226+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-07-29T01:21:05.535+0000] {processor.py:157} INFO - Started process (PID=13205) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T01:21:05.537+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T01:21:05.540+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:21:05.540+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T01:21:05.576+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T01:21:05.611+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:21:05.611+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T01:21:05.636+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:21:05.636+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T01:21:05.752+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.222 seconds
[2024-07-29T01:21:36.231+0000] {processor.py:157} INFO - Started process (PID=13230) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T01:21:36.234+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T01:21:36.237+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:21:36.237+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T01:21:36.254+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T01:21:36.281+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:21:36.280+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T01:21:36.450+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:21:36.450+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T01:21:36.458+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.236 seconds
[2024-07-29T01:22:06.920+0000] {processor.py:157} INFO - Started process (PID=13255) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T01:22:06.921+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T01:22:06.924+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:22:06.923+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T01:22:06.936+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T01:22:06.976+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:22:06.976+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T01:22:07.067+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:22:07.067+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T01:22:07.074+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.157 seconds
[2024-07-29T01:22:37.602+0000] {processor.py:157} INFO - Started process (PID=13280) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T01:22:37.603+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T01:22:37.607+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:22:37.607+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T01:22:37.629+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T01:22:37.645+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:22:37.645+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T01:22:37.657+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:22:37.657+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T01:22:37.667+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-29T01:23:08.043+0000] {processor.py:157} INFO - Started process (PID=13305) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T01:23:08.045+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T01:23:08.053+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:23:08.052+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T01:23:08.068+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T01:23:08.084+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:23:08.084+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T01:23:08.098+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:23:08.098+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T01:23:08.108+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-29T01:31:22.474+0000] {processor.py:157} INFO - Started process (PID=13332) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T01:31:22.479+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T01:31:22.486+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:31:22.485+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T01:31:22.526+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T01:31:22.574+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:31:22.574+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T01:31:22.590+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:31:22.590+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T01:31:22.602+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-07-29T01:31:53.091+0000] {processor.py:157} INFO - Started process (PID=13357) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T01:31:53.093+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T01:31:53.096+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:31:53.095+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T01:31:53.124+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T01:31:53.149+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:31:53.149+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T01:31:53.165+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:31:53.165+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T01:31:53.322+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.235 seconds
[2024-07-29T01:32:23.886+0000] {processor.py:157} INFO - Started process (PID=13382) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T01:32:23.888+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T01:32:23.890+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:32:23.890+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T01:32:23.901+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T01:32:23.930+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:32:23.930+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T01:32:24.024+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:32:24.024+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T01:32:24.036+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.153 seconds
[2024-07-29T01:32:54.518+0000] {processor.py:157} INFO - Started process (PID=13407) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T01:32:54.520+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T01:32:54.523+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:32:54.522+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T01:32:54.536+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T01:32:54.556+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:32:54.556+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T01:32:54.660+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:32:54.660+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T01:32:54.667+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.153 seconds
[2024-07-29T01:33:25.173+0000] {processor.py:157} INFO - Started process (PID=13432) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T01:33:25.176+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T01:33:25.179+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:33:25.178+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T01:33:25.201+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T01:33:25.234+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:33:25.234+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T01:33:25.248+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:33:25.248+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T01:33:25.262+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-07-29T01:33:55.756+0000] {processor.py:157} INFO - Started process (PID=13457) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T01:33:55.757+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T01:33:55.761+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:33:55.761+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T01:33:55.783+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T01:33:55.812+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:33:55.812+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T01:33:55.826+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:33:55.826+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T01:33:55.836+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-07-29T01:34:26.291+0000] {processor.py:157} INFO - Started process (PID=13482) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T01:34:26.291+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T01:34:26.294+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:34:26.294+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T01:34:26.308+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T01:34:26.325+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:34:26.325+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T01:34:26.336+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:34:26.336+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T01:34:26.346+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-29T01:34:56.680+0000] {processor.py:157} INFO - Started process (PID=13507) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T01:34:56.681+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T01:34:56.683+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:34:56.683+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T01:34:56.698+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T01:34:56.712+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:34:56.712+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T01:34:56.881+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:34:56.880+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T01:34:56.890+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.213 seconds
[2024-07-29T01:51:20.274+0000] {processor.py:157} INFO - Started process (PID=13534) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T01:51:20.276+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T01:51:20.280+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:51:20.279+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T01:51:20.311+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T01:51:20.352+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:51:20.352+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T01:51:20.638+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:51:20.637+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T01:51:20.795+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.524 seconds
[2024-07-29T01:51:51.381+0000] {processor.py:157} INFO - Started process (PID=13559) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T01:51:51.383+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T01:51:51.406+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:51:51.402+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T01:51:51.430+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T01:51:51.608+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:51:51.608+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T01:51:51.616+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:51:51.616+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T01:51:51.624+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.248 seconds
[2024-07-29T01:52:22.059+0000] {processor.py:157} INFO - Started process (PID=13584) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T01:52:22.061+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T01:52:22.064+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:52:22.064+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T01:52:22.077+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T01:52:22.095+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:52:22.095+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T01:52:22.107+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:52:22.107+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T01:52:22.116+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-29T01:52:52.538+0000] {processor.py:157} INFO - Started process (PID=13609) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T01:52:52.540+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T01:52:52.542+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:52:52.542+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T01:52:52.564+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T01:52:52.584+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:52:52.584+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T01:52:52.597+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:52:52.597+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T01:52:52.607+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-29T01:53:22.927+0000] {processor.py:157} INFO - Started process (PID=13634) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T01:53:22.928+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T01:53:22.929+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:53:22.929+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T01:53:22.940+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T01:53:22.958+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:53:22.958+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T01:53:22.967+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:53:22.967+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T01:53:23.117+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.192 seconds
[2024-07-29T01:53:53.600+0000] {processor.py:157} INFO - Started process (PID=13658) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T01:53:53.601+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T01:53:53.603+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:53:53.603+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T01:53:53.614+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T01:53:53.628+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:53:53.628+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T01:53:53.709+0000] {logging_mixin.py:151} INFO - [2024-07-29T01:53:53.709+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T01:53:53.717+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-07-29T02:09:34.214+0000] {processor.py:157} INFO - Started process (PID=13683) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T02:09:34.218+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T02:09:34.230+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:09:34.229+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T02:09:34.253+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T02:09:34.299+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:09:34.299+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T02:09:34.575+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:09:34.575+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T02:09:34.590+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.387 seconds
[2024-07-29T02:10:05.400+0000] {processor.py:157} INFO - Started process (PID=13709) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T02:10:05.405+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T02:10:05.412+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:10:05.412+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T02:10:05.436+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T02:10:05.650+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:10:05.649+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T02:10:05.660+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:10:05.660+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T02:10:05.669+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.291 seconds
[2024-07-29T02:10:36.239+0000] {processor.py:157} INFO - Started process (PID=13734) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T02:10:36.240+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T02:10:36.243+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:10:36.242+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T02:10:36.255+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T02:10:36.271+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:10:36.271+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T02:10:36.280+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:10:36.280+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T02:10:36.289+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-29T02:11:06.731+0000] {processor.py:157} INFO - Started process (PID=13759) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T02:11:06.733+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T02:11:06.737+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:11:06.736+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T02:11:06.757+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T02:11:06.775+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:11:06.775+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T02:11:06.788+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:11:06.788+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T02:11:06.798+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-29T02:11:37.281+0000] {processor.py:157} INFO - Started process (PID=13784) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T02:11:37.283+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T02:11:37.286+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:11:37.286+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T02:11:37.298+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T02:11:37.315+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:11:37.315+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T02:11:37.328+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:11:37.328+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T02:11:37.490+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.212 seconds
[2024-07-29T02:29:26.001+0000] {processor.py:157} INFO - Started process (PID=13810) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T02:29:26.002+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T02:29:26.005+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:29:26.005+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T02:29:26.021+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T02:29:26.059+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:29:26.059+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T02:29:26.147+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:29:26.147+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T02:29:26.154+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.156 seconds
[2024-07-29T02:29:56.795+0000] {processor.py:157} INFO - Started process (PID=13835) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T02:29:56.796+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T02:29:56.807+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:29:56.801+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T02:29:56.832+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T02:29:56.883+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:29:56.883+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T02:29:57.045+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:29:57.044+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T02:29:57.055+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.266 seconds
[2024-07-29T02:30:27.605+0000] {processor.py:157} INFO - Started process (PID=13861) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T02:30:27.606+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T02:30:27.607+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:30:27.607+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T02:30:27.622+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T02:30:27.637+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:30:27.637+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T02:30:27.646+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:30:27.646+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T02:30:27.653+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-29T02:30:58.026+0000] {processor.py:157} INFO - Started process (PID=13886) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T02:30:58.030+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T02:30:58.032+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:30:58.032+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T02:30:58.052+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T02:30:58.071+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:30:58.071+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T02:30:58.084+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:30:58.084+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T02:30:58.094+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-29T02:31:28.509+0000] {processor.py:157} INFO - Started process (PID=13911) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T02:31:28.511+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T02:31:28.512+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:31:28.512+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T02:31:28.523+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T02:31:28.539+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:31:28.539+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T02:31:28.549+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:31:28.549+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T02:31:28.557+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-29T02:31:58.955+0000] {processor.py:157} INFO - Started process (PID=13936) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T02:31:58.955+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T02:31:58.957+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:31:58.957+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T02:31:58.968+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T02:31:58.984+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:31:58.984+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T02:31:58.995+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:31:58.995+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T02:31:59.158+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.206 seconds
[2024-07-29T02:43:04.187+0000] {processor.py:157} INFO - Started process (PID=13960) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T02:43:04.191+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T02:43:04.194+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:43:04.194+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T02:43:04.217+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T02:43:04.255+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:43:04.255+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T02:43:04.440+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:43:04.440+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T02:43:04.447+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.264 seconds
[2024-07-29T02:43:34.856+0000] {processor.py:157} INFO - Started process (PID=13986) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T02:43:34.859+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T02:43:34.862+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:43:34.862+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T02:43:34.883+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T02:43:35.103+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:43:35.103+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T02:43:35.112+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:43:35.112+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T02:43:35.121+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.269 seconds
[2024-07-29T02:44:05.560+0000] {processor.py:157} INFO - Started process (PID=14011) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T02:44:05.562+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T02:44:05.564+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:44:05.564+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T02:44:05.580+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T02:44:05.595+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:44:05.595+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T02:44:05.608+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:44:05.608+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T02:44:05.615+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-29T02:44:36.021+0000] {processor.py:157} INFO - Started process (PID=14036) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T02:44:36.023+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T02:44:36.029+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:44:36.028+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T02:44:36.045+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T02:44:36.068+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:44:36.068+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T02:44:36.080+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:44:36.080+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T02:44:36.089+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-29T02:45:06.556+0000] {processor.py:157} INFO - Started process (PID=14061) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T02:45:06.557+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T02:45:06.561+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:45:06.561+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T02:45:06.573+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T02:45:06.589+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:45:06.589+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T02:45:06.601+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:45:06.600+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T02:45:06.610+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-29T02:54:29.102+0000] {processor.py:157} INFO - Started process (PID=14087) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T02:54:29.105+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T02:54:29.115+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:54:29.113+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T02:54:29.143+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T02:54:29.216+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:54:29.216+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T02:54:29.384+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:54:29.384+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T02:54:29.394+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.298 seconds
[2024-07-29T02:54:59.854+0000] {processor.py:157} INFO - Started process (PID=14112) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T02:54:59.855+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T02:54:59.860+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:54:59.859+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T02:54:59.879+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T02:54:59.912+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:54:59.912+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T02:55:00.068+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:55:00.068+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T02:55:00.078+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.229 seconds
[2024-07-29T02:55:30.470+0000] {processor.py:157} INFO - Started process (PID=14138) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T02:55:30.471+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T02:55:30.472+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:55:30.472+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T02:55:30.489+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T02:55:30.573+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:55:30.573+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T02:55:30.583+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:55:30.583+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T02:55:30.591+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-07-29T02:56:01.122+0000] {processor.py:157} INFO - Started process (PID=14163) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T02:56:01.123+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T02:56:01.124+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:56:01.124+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T02:56:01.140+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T02:56:01.158+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:56:01.158+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T02:56:01.170+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:56:01.170+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T02:56:01.179+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-29T02:56:31.596+0000] {processor.py:157} INFO - Started process (PID=14188) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T02:56:31.597+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T02:56:31.599+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:56:31.599+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T02:56:31.609+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T02:56:31.625+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:56:31.625+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T02:56:31.634+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:56:31.634+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T02:56:31.642+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-29T02:57:02.003+0000] {processor.py:157} INFO - Started process (PID=14213) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T02:57:02.004+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T02:57:02.006+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:57:02.006+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T02:57:02.016+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T02:57:02.034+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:57:02.034+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T02:57:02.045+0000] {logging_mixin.py:151} INFO - [2024-07-29T02:57:02.045+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T02:57:02.123+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-07-29T03:02:23.928+0000] {processor.py:157} INFO - Started process (PID=14238) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T03:02:23.929+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T03:02:23.937+0000] {logging_mixin.py:151} INFO - [2024-07-29T03:02:23.936+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T03:02:23.960+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T03:02:24.008+0000] {logging_mixin.py:151} INFO - [2024-07-29T03:02:24.007+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T03:02:24.241+0000] {logging_mixin.py:151} INFO - [2024-07-29T03:02:24.241+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T03:02:24.255+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.330 seconds
[2024-07-29T03:02:54.925+0000] {processor.py:157} INFO - Started process (PID=14262) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T03:02:54.927+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T03:02:54.930+0000] {logging_mixin.py:151} INFO - [2024-07-29T03:02:54.930+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T03:02:54.951+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T03:02:54.977+0000] {logging_mixin.py:151} INFO - [2024-07-29T03:02:54.976+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T03:02:55.075+0000] {logging_mixin.py:151} INFO - [2024-07-29T03:02:55.075+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T03:02:55.084+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.164 seconds
[2024-07-29T03:15:42.792+0000] {processor.py:157} INFO - Started process (PID=14289) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T03:15:42.793+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T03:15:42.800+0000] {logging_mixin.py:151} INFO - [2024-07-29T03:15:42.799+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T03:15:42.828+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T03:15:43.038+0000] {logging_mixin.py:151} INFO - [2024-07-29T03:15:43.037+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T03:15:43.055+0000] {logging_mixin.py:151} INFO - [2024-07-29T03:15:43.055+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T03:15:43.070+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.281 seconds
[2024-07-29T03:32:14.604+0000] {processor.py:157} INFO - Started process (PID=14315) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T03:32:14.605+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T03:32:14.607+0000] {logging_mixin.py:151} INFO - [2024-07-29T03:32:14.607+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T03:32:14.625+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T03:32:14.645+0000] {logging_mixin.py:151} INFO - [2024-07-29T03:32:14.645+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T03:32:14.658+0000] {logging_mixin.py:151} INFO - [2024-07-29T03:32:14.658+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T03:32:14.667+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-29T03:32:45.089+0000] {processor.py:157} INFO - Started process (PID=14340) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T03:32:45.090+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T03:32:45.092+0000] {logging_mixin.py:151} INFO - [2024-07-29T03:32:45.092+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T03:32:45.105+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T03:32:45.123+0000] {logging_mixin.py:151} INFO - [2024-07-29T03:32:45.123+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T03:32:45.133+0000] {logging_mixin.py:151} INFO - [2024-07-29T03:32:45.133+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T03:32:45.143+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-29T03:42:55.066+0000] {processor.py:157} INFO - Started process (PID=14367) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T03:42:55.068+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T03:42:55.073+0000] {logging_mixin.py:151} INFO - [2024-07-29T03:42:55.072+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T03:42:55.096+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T03:42:55.141+0000] {logging_mixin.py:151} INFO - [2024-07-29T03:42:55.141+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T03:42:55.163+0000] {logging_mixin.py:151} INFO - [2024-07-29T03:42:55.162+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T03:42:55.402+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.345 seconds
[2024-07-29T03:43:26.158+0000] {processor.py:157} INFO - Started process (PID=14392) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T03:43:26.162+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T03:43:26.165+0000] {logging_mixin.py:151} INFO - [2024-07-29T03:43:26.165+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T03:43:26.184+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T03:43:26.206+0000] {logging_mixin.py:151} INFO - [2024-07-29T03:43:26.206+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T03:43:26.314+0000] {logging_mixin.py:151} INFO - [2024-07-29T03:43:26.314+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T03:43:26.322+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.169 seconds
[2024-07-29T04:00:14.362+0000] {processor.py:157} INFO - Started process (PID=14417) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:00:14.363+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T04:00:14.369+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:00:14.369+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:00:14.395+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:00:14.625+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:00:14.625+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:00:14.636+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:00:14.635+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T04:00:14.646+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.289 seconds
[2024-07-29T04:00:45.295+0000] {processor.py:157} INFO - Started process (PID=14442) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:00:45.299+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T04:00:45.303+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:00:45.303+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:00:45.321+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:00:45.350+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:00:45.350+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:00:45.362+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:00:45.362+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T04:00:45.373+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-07-29T04:01:15.785+0000] {processor.py:157} INFO - Started process (PID=14467) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:01:15.789+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T04:01:15.792+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:01:15.792+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:01:15.804+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:01:15.818+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:01:15.818+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:01:15.828+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:01:15.828+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T04:01:15.839+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-29T04:01:46.178+0000] {processor.py:157} INFO - Started process (PID=14492) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:01:46.180+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T04:01:46.183+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:01:46.183+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:01:46.201+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:01:46.219+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:01:46.219+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:01:46.234+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:01:46.234+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T04:01:46.374+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.198 seconds
[2024-07-29T04:02:16.801+0000] {processor.py:157} INFO - Started process (PID=14517) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:02:16.803+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T04:02:16.805+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:02:16.805+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:02:16.823+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:02:16.837+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:02:16.836+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:02:16.914+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:02:16.914+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T04:02:16.921+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-07-29T04:02:47.412+0000] {processor.py:157} INFO - Started process (PID=14542) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:02:47.418+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T04:02:47.420+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:02:47.419+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:02:47.429+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:02:47.442+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:02:47.442+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:02:47.517+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:02:47.517+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T04:02:47.523+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-07-29T04:03:18.082+0000] {processor.py:157} INFO - Started process (PID=14567) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:03:18.085+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T04:03:18.087+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:03:18.087+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:03:18.104+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:03:18.225+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:03:18.225+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:03:18.234+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:03:18.234+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T04:03:18.244+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.165 seconds
[2024-07-29T04:03:48.772+0000] {processor.py:157} INFO - Started process (PID=14592) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:03:48.774+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T04:03:48.776+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:03:48.776+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:03:48.791+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:03:48.805+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:03:48.805+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:03:48.816+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:03:48.816+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T04:03:48.826+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-29T04:04:19.168+0000] {processor.py:157} INFO - Started process (PID=14617) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:04:19.171+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T04:04:19.173+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:04:19.173+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:04:19.191+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:04:19.212+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:04:19.212+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:04:19.224+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:04:19.224+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T04:04:19.234+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-29T04:04:49.584+0000] {processor.py:157} INFO - Started process (PID=14642) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:04:49.587+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T04:04:49.589+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:04:49.589+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:04:49.602+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:04:49.620+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:04:49.619+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:04:49.632+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:04:49.632+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T04:04:49.709+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-07-29T04:05:20.161+0000] {processor.py:157} INFO - Started process (PID=14667) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:05:20.163+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T04:05:20.164+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:05:20.164+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:05:20.182+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:05:20.195+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:05:20.195+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:05:20.272+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:05:20.271+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T04:05:20.280+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-07-29T04:05:50.790+0000] {processor.py:157} INFO - Started process (PID=14692) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:05:50.792+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T04:05:50.794+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:05:50.793+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:05:50.808+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:05:50.824+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:05:50.824+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:05:50.928+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:05:50.928+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T04:05:50.937+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.150 seconds
[2024-07-29T04:06:21.339+0000] {processor.py:157} INFO - Started process (PID=14717) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:06:21.341+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T04:06:21.344+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:06:21.344+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:06:21.362+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:06:21.456+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:06:21.456+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:06:21.464+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:06:21.464+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T04:06:21.472+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.137 seconds
[2024-07-29T04:06:51.909+0000] {processor.py:157} INFO - Started process (PID=14742) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:06:51.910+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T04:06:51.912+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:06:51.912+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:06:51.928+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:06:51.942+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:06:51.942+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:06:51.955+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:06:51.955+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T04:06:51.962+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-29T04:07:22.314+0000] {processor.py:157} INFO - Started process (PID=14767) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:07:22.314+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T04:07:22.316+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:07:22.316+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:07:22.331+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:07:22.344+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:07:22.343+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:07:22.354+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:07:22.354+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T04:07:22.363+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-29T04:07:52.767+0000] {processor.py:157} INFO - Started process (PID=14792) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:07:52.768+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T04:07:52.770+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:07:52.770+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:07:52.783+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:07:52.804+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:07:52.804+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:07:52.913+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:07:52.913+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T04:07:52.922+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.157 seconds
[2024-07-29T04:08:23.462+0000] {processor.py:157} INFO - Started process (PID=14816) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:08:23.469+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T04:08:23.473+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:08:23.473+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:08:23.490+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:08:23.516+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:08:23.516+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:08:23.613+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:08:23.613+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T04:08:23.621+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.175 seconds
[2024-07-29T04:08:54.166+0000] {processor.py:157} INFO - Started process (PID=14842) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:08:54.169+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T04:08:54.172+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:08:54.172+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:08:54.186+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:08:54.310+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:08:54.310+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:08:54.321+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:08:54.321+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T04:08:54.330+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.167 seconds
[2024-07-29T04:09:24.857+0000] {processor.py:157} INFO - Started process (PID=14867) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:09:24.861+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T04:09:24.865+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:09:24.865+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:09:24.961+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:09:24.973+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:09:24.973+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:09:24.980+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:09:24.980+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T04:09:24.988+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-07-29T04:09:55.485+0000] {processor.py:157} INFO - Started process (PID=14892) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:09:55.485+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T04:09:55.487+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:09:55.487+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:09:55.503+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:09:55.532+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:09:55.532+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:09:55.542+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:09:55.542+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T04:09:55.550+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-29T04:10:25.932+0000] {processor.py:157} INFO - Started process (PID=14917) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:10:25.933+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T04:10:25.935+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:10:25.935+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:10:25.948+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:10:25.964+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:10:25.964+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:10:25.978+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:10:25.978+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T04:10:26.081+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.152 seconds
[2024-07-29T04:10:56.503+0000] {processor.py:157} INFO - Started process (PID=14942) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:10:56.505+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T04:10:56.507+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:10:56.507+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:10:56.524+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:10:56.545+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:10:56.545+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:10:56.629+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:10:56.629+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T04:10:56.637+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-07-29T04:11:27.071+0000] {processor.py:157} INFO - Started process (PID=14967) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:11:27.074+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T04:11:27.078+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:11:27.078+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:11:27.101+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:11:27.124+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:11:27.124+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:11:27.250+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:11:27.250+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T04:11:27.259+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.198 seconds
[2024-07-29T04:11:57.668+0000] {processor.py:157} INFO - Started process (PID=14992) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:11:57.671+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T04:11:57.673+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:11:57.673+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:11:57.685+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:11:57.801+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:11:57.801+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:11:57.809+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:11:57.809+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T04:11:57.817+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.153 seconds
[2024-07-29T04:12:28.212+0000] {processor.py:157} INFO - Started process (PID=15017) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:12:28.214+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T04:12:28.219+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:12:28.218+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:12:28.239+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:12:28.256+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:12:28.256+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:12:28.270+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:12:28.270+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T04:12:28.280+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-29T04:12:58.647+0000] {processor.py:157} INFO - Started process (PID=15041) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:12:58.649+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T04:12:58.652+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:12:58.652+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:12:58.687+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:12:58.712+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:12:58.712+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:12:58.724+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:12:58.724+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T04:12:58.734+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-07-29T04:13:29.152+0000] {processor.py:157} INFO - Started process (PID=15067) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:13:29.154+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T04:13:29.157+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:13:29.156+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:13:29.173+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:13:29.186+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:13:29.186+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:13:29.196+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:13:29.196+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T04:13:29.302+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.152 seconds
[2024-07-29T04:13:59.679+0000] {processor.py:157} INFO - Started process (PID=15092) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:13:59.681+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T04:13:59.683+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:13:59.683+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:13:59.698+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:13:59.716+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:13:59.716+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:13:59.803+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:13:59.803+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T04:13:59.811+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-07-29T04:14:30.252+0000] {processor.py:157} INFO - Started process (PID=15117) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:14:30.253+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T04:14:30.255+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:14:30.255+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:14:30.272+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:14:30.289+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:14:30.289+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:14:30.368+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:14:30.368+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T04:14:30.377+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-07-29T04:15:00.793+0000] {processor.py:157} INFO - Started process (PID=15142) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:15:00.796+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T04:15:00.799+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:15:00.799+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:15:00.818+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:15:00.945+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:15:00.944+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:15:00.953+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:15:00.953+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T04:15:00.962+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.171 seconds
[2024-07-29T04:15:31.444+0000] {processor.py:157} INFO - Started process (PID=15167) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:15:31.446+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T04:15:31.449+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:15:31.449+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:15:31.466+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:15:31.482+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:15:31.482+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:15:31.493+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:15:31.493+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T04:15:31.502+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-29T04:16:01.875+0000] {processor.py:157} INFO - Started process (PID=15192) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:16:01.878+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T04:16:01.887+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:16:01.887+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:16:01.907+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:16:01.942+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:16:01.942+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:16:01.954+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:16:01.954+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T04:16:01.965+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-07-29T04:16:32.360+0000] {processor.py:157} INFO - Started process (PID=15217) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:16:32.362+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T04:16:32.364+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:16:32.364+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:16:32.377+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:16:32.396+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:16:32.396+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:16:32.598+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:16:32.598+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T04:16:32.607+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.250 seconds
[2024-07-29T04:17:03.139+0000] {processor.py:157} INFO - Started process (PID=15242) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:17:03.140+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T04:17:03.143+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:17:03.142+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:17:03.160+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:17:03.175+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:17:03.175+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:17:03.264+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:17:03.264+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T04:17:03.272+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-07-29T04:17:33.713+0000] {processor.py:157} INFO - Started process (PID=15267) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:17:33.714+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T04:17:33.716+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:17:33.716+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:17:33.734+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:17:33.831+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:17:33.831+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:17:33.840+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:17:33.840+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T04:17:33.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-07-29T04:18:04.409+0000] {processor.py:157} INFO - Started process (PID=15292) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:18:04.410+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T04:18:04.412+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:18:04.412+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:18:04.503+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:18:04.513+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:18:04.513+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:18:04.520+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:18:04.520+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T04:18:04.529+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-07-29T04:18:34.882+0000] {processor.py:157} INFO - Started process (PID=15317) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:18:34.883+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T04:18:34.884+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:18:34.883+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:18:34.893+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:18:34.907+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:18:34.907+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:18:34.918+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:18:34.918+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T04:18:34.927+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-29T04:19:05.277+0000] {processor.py:157} INFO - Started process (PID=15342) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:19:05.278+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T04:19:05.280+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:19:05.279+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:19:05.298+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:19:05.313+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:19:05.313+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:19:05.324+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:19:05.324+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T04:19:05.442+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.169 seconds
[2024-07-29T04:19:35.906+0000] {processor.py:157} INFO - Started process (PID=15367) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:19:35.907+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T04:19:35.909+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:19:35.909+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:19:35.920+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:19:35.938+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:19:35.938+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:19:36.018+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:19:36.018+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T04:19:36.027+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-07-29T04:20:06.595+0000] {processor.py:157} INFO - Started process (PID=15392) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:20:06.596+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T04:20:06.600+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:20:06.599+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:20:06.615+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:20:06.637+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:20:06.637+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:20:06.717+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:20:06.717+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T04:20:06.724+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-07-29T04:20:37.283+0000] {processor.py:157} INFO - Started process (PID=15417) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:20:37.285+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T04:20:37.287+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:20:37.287+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:20:37.298+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:20:37.387+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:20:37.387+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:20:37.396+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:20:37.396+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T04:20:37.404+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-07-29T04:21:07.948+0000] {processor.py:157} INFO - Started process (PID=15442) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:21:07.949+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T04:21:07.950+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:21:07.950+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:21:08.057+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:21:08.069+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:21:08.069+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:21:08.076+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:21:08.076+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T04:21:08.086+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-07-29T04:21:38.633+0000] {processor.py:157} INFO - Started process (PID=15467) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:21:38.635+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T04:21:38.651+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:21:38.644+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:21:38.689+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:21:38.718+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:21:38.717+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:21:38.734+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:21:38.734+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T04:21:38.753+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-07-29T04:22:09.178+0000] {processor.py:157} INFO - Started process (PID=15492) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:22:09.179+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T04:22:09.184+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:22:09.184+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:22:09.203+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:22:09.228+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:22:09.228+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:22:09.241+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:22:09.241+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T04:22:09.252+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-07-29T04:22:39.707+0000] {processor.py:157} INFO - Started process (PID=15517) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:22:39.709+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T04:22:39.714+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:22:39.714+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:22:39.736+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:22:39.764+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:22:39.764+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:22:39.783+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:22:39.783+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T04:22:39.794+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-07-29T04:23:10.212+0000] {processor.py:157} INFO - Started process (PID=15542) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:23:10.212+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T04:23:10.216+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:23:10.216+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:23:10.230+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:23:10.255+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:23:10.254+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:23:10.272+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:23:10.272+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T04:23:10.284+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-29T04:23:40.770+0000] {processor.py:157} INFO - Started process (PID=15567) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:23:40.772+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T04:23:40.775+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:23:40.775+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:23:40.785+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:23:40.802+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:23:40.802+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:23:40.813+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:23:40.813+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T04:23:40.825+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-29T04:24:11.144+0000] {processor.py:157} INFO - Started process (PID=15591) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:24:11.146+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T04:24:11.150+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:24:11.150+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:24:11.166+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:24:11.198+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:24:11.198+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:24:11.212+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:24:11.212+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T04:24:11.223+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-07-29T04:24:41.663+0000] {processor.py:157} INFO - Started process (PID=15617) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:24:41.666+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T04:24:41.668+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:24:41.668+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:24:41.682+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:24:41.702+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:24:41.702+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:24:41.712+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:24:41.712+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T04:24:41.723+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-29T04:25:12.067+0000] {processor.py:157} INFO - Started process (PID=15642) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:25:12.068+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T04:25:12.070+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:25:12.070+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:25:12.082+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:25:12.099+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:25:12.099+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:25:12.113+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:25:12.113+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T04:25:12.121+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-29T04:25:42.502+0000] {processor.py:157} INFO - Started process (PID=15667) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:25:42.504+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T04:25:42.506+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:25:42.506+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:25:42.521+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:25:42.536+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:25:42.536+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:25:42.546+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:25:42.546+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T04:25:42.553+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-29T04:26:12.950+0000] {processor.py:157} INFO - Started process (PID=15692) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:26:12.954+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T04:26:12.957+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:26:12.957+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:26:12.974+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:26:12.992+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:26:12.992+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:26:13.005+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:26:13.005+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T04:26:13.015+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-29T04:26:43.394+0000] {processor.py:157} INFO - Started process (PID=15717) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:26:43.396+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T04:26:43.398+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:26:43.398+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:26:43.409+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:26:43.424+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:26:43.424+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:26:43.434+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:26:43.433+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T04:26:43.444+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-29T04:27:13.854+0000] {processor.py:157} INFO - Started process (PID=15742) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:27:13.855+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T04:27:13.857+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:27:13.856+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:27:13.867+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:27:13.884+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:27:13.884+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:27:13.894+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:27:13.894+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T04:27:13.904+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-29T04:27:44.214+0000] {processor.py:157} INFO - Started process (PID=15767) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:27:44.215+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T04:27:44.217+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:27:44.216+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:27:44.229+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:27:44.244+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:27:44.244+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:27:44.255+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:27:44.255+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T04:27:44.263+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-29T04:28:14.677+0000] {processor.py:157} INFO - Started process (PID=15792) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:28:14.680+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T04:28:14.682+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:28:14.682+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:28:14.698+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:28:14.719+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:28:14.719+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:28:14.732+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:28:14.732+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T04:28:14.741+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-29T04:28:45.095+0000] {processor.py:157} INFO - Started process (PID=15817) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:28:45.097+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T04:28:45.099+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:28:45.099+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:28:45.110+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:28:45.126+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:28:45.126+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:28:45.135+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:28:45.135+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T04:28:45.143+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-29T04:36:17.581+0000] {processor.py:157} INFO - Started process (PID=15842) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:36:17.582+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T04:36:17.586+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:36:17.586+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:36:17.601+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:36:17.622+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:36:17.622+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:36:17.635+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:36:17.635+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T04:36:17.646+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-29T04:52:29.723+0000] {processor.py:157} INFO - Started process (PID=15868) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:52:29.726+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T04:52:29.730+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:52:29.729+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:52:29.768+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:52:29.801+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:52:29.800+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:52:29.833+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:52:29.833+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T04:52:29.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-07-29T04:53:00.429+0000] {processor.py:157} INFO - Started process (PID=15894) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:53:00.430+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T04:53:00.434+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:53:00.433+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:53:00.451+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:53:00.473+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:53:00.472+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:53:00.496+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:53:00.496+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T04:53:00.507+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-07-29T04:53:30.836+0000] {processor.py:157} INFO - Started process (PID=15919) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:53:30.837+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T04:53:30.839+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:53:30.839+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:53:30.854+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:53:30.869+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:53:30.869+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:53:30.881+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:53:30.881+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T04:53:30.889+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-29T04:54:01.277+0000] {processor.py:157} INFO - Started process (PID=15944) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:54:01.278+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T04:54:01.280+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:54:01.280+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:54:01.289+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:54:01.305+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:54:01.305+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:54:01.316+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:54:01.316+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T04:54:01.325+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-29T04:54:31.741+0000] {processor.py:157} INFO - Started process (PID=15969) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:54:31.742+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T04:54:31.744+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:54:31.744+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:54:31.754+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T04:54:31.770+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:54:31.770+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T04:54:31.779+0000] {logging_mixin.py:151} INFO - [2024-07-29T04:54:31.779+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T04:54:31.788+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-29T05:05:23.303+0000] {processor.py:157} INFO - Started process (PID=15994) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T05:05:23.306+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T05:05:23.308+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:05:23.308+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T05:05:23.322+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T05:05:23.341+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:05:23.340+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T05:05:23.366+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:05:23.366+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T05:05:23.382+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-07-29T05:05:53.833+0000] {processor.py:157} INFO - Started process (PID=16021) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T05:05:53.835+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T05:05:53.839+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:05:53.838+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T05:05:53.859+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T05:05:53.885+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:05:53.885+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T05:05:53.898+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:05:53.898+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T05:05:53.907+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-07-29T05:06:24.346+0000] {processor.py:157} INFO - Started process (PID=16046) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T05:06:24.347+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T05:06:24.349+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:06:24.349+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T05:06:24.364+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T05:06:24.381+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:06:24.381+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T05:06:24.393+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:06:24.393+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T05:06:24.402+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-29T05:06:54.815+0000] {processor.py:157} INFO - Started process (PID=16071) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T05:06:54.815+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T05:06:54.817+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:06:54.817+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T05:06:54.827+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T05:06:54.842+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:06:54.842+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T05:06:54.852+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:06:54.852+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T05:06:54.861+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-29T05:07:25.266+0000] {processor.py:157} INFO - Started process (PID=16096) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T05:07:25.269+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T05:07:25.271+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:07:25.271+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T05:07:25.282+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T05:07:25.299+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:07:25.299+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T05:07:25.308+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:07:25.308+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T05:07:25.314+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-29T05:07:55.703+0000] {processor.py:157} INFO - Started process (PID=16121) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T05:07:55.705+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T05:07:55.707+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:07:55.707+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T05:07:55.719+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T05:07:55.734+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:07:55.734+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T05:07:55.744+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:07:55.744+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T05:07:55.754+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-29T05:24:30.594+0000] {processor.py:157} INFO - Started process (PID=16145) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T05:24:30.599+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T05:24:30.601+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:24:30.601+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T05:24:30.619+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T05:24:30.641+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:24:30.641+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T05:24:30.654+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:24:30.654+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T05:24:30.666+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-29T05:25:01.107+0000] {processor.py:157} INFO - Started process (PID=16173) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T05:25:01.111+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T05:25:01.115+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:25:01.114+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T05:25:01.133+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T05:25:01.155+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:25:01.155+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T05:25:01.168+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:25:01.168+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T05:25:01.180+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-29T05:25:31.600+0000] {processor.py:157} INFO - Started process (PID=16198) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T05:25:31.601+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T05:25:31.604+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:25:31.603+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T05:25:31.616+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T05:25:31.633+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:25:31.633+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T05:25:31.645+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:25:31.645+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T05:25:31.655+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-29T05:26:02.101+0000] {processor.py:157} INFO - Started process (PID=16223) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T05:26:02.103+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T05:26:02.104+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:26:02.104+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T05:26:02.114+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T05:26:02.131+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:26:02.131+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T05:26:02.141+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:26:02.141+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T05:26:02.152+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-29T05:26:32.528+0000] {processor.py:157} INFO - Started process (PID=16248) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T05:26:32.530+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T05:26:32.532+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:26:32.531+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T05:26:32.545+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T05:26:32.563+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:26:32.563+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T05:26:32.572+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:26:32.572+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T05:26:32.581+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-29T05:27:02.924+0000] {processor.py:157} INFO - Started process (PID=16273) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T05:27:02.927+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T05:27:02.929+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:27:02.929+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T05:27:02.940+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T05:27:02.959+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:27:02.959+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T05:27:02.968+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:27:02.968+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T05:27:02.975+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-29T05:27:33.423+0000] {processor.py:157} INFO - Started process (PID=16298) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T05:27:33.427+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T05:27:33.430+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:27:33.430+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T05:27:33.443+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T05:27:33.464+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:27:33.464+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T05:27:33.476+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:27:33.476+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T05:27:33.486+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-29T05:28:03.930+0000] {processor.py:157} INFO - Started process (PID=16323) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T05:28:03.931+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T05:28:03.933+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:28:03.933+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T05:28:03.948+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T05:28:03.961+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:28:03.961+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T05:28:03.972+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:28:03.972+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T05:28:03.983+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-29T05:28:34.418+0000] {processor.py:157} INFO - Started process (PID=16348) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T05:28:34.419+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T05:28:34.423+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:28:34.422+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T05:28:34.436+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T05:28:34.457+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:28:34.456+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T05:28:34.469+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:28:34.469+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T05:28:34.481+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-29T05:44:08.935+0000] {processor.py:157} INFO - Started process (PID=16373) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T05:44:08.939+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T05:44:08.942+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:44:08.941+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T05:44:08.964+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T05:44:08.999+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:44:08.999+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T05:44:09.030+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:44:09.030+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T05:44:09.048+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-07-29T05:44:39.568+0000] {processor.py:157} INFO - Started process (PID=16398) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T05:44:39.572+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T05:44:39.574+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:44:39.573+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T05:44:39.592+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T05:44:39.612+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:44:39.612+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T05:44:39.624+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:44:39.624+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T05:44:39.635+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-29T05:45:10.034+0000] {processor.py:157} INFO - Started process (PID=16423) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T05:45:10.035+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T05:45:10.037+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:45:10.037+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T05:45:10.051+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T05:45:10.067+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:45:10.067+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T05:45:10.080+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:45:10.080+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T05:45:10.088+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-29T05:45:40.503+0000] {processor.py:157} INFO - Started process (PID=16448) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T05:45:40.504+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T05:45:40.505+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:45:40.505+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T05:45:40.516+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T05:45:40.531+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:45:40.531+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T05:45:40.540+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:45:40.540+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T05:45:40.549+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-29T05:46:10.925+0000] {processor.py:157} INFO - Started process (PID=16473) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T05:46:10.927+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T05:46:10.929+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:46:10.929+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T05:46:10.945+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T05:46:10.965+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:46:10.965+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T05:46:10.981+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:46:10.981+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T05:46:10.991+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-29T05:47:03.668+0000] {processor.py:157} INFO - Started process (PID=16498) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T05:47:03.669+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T05:47:03.671+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:47:03.671+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T05:47:03.681+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T05:47:03.700+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:47:03.700+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T05:47:03.711+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:47:03.711+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T05:47:03.721+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-29T05:47:34.192+0000] {processor.py:157} INFO - Started process (PID=16523) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T05:47:34.194+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T05:47:34.197+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:47:34.197+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T05:47:34.211+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T05:47:34.229+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:47:34.229+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T05:47:34.240+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:47:34.240+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T05:47:34.248+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-29T05:48:04.695+0000] {processor.py:157} INFO - Started process (PID=16548) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T05:48:04.697+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T05:48:04.699+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:48:04.699+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T05:48:04.713+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T05:48:04.726+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:48:04.726+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T05:48:04.736+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:48:04.736+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T05:48:04.743+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-29T05:48:35.186+0000] {processor.py:157} INFO - Started process (PID=16573) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T05:48:35.188+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T05:48:35.191+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:48:35.191+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T05:48:35.207+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T05:48:35.227+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:48:35.227+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T05:48:35.238+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:48:35.238+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T05:48:35.250+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-29T05:49:05.746+0000] {processor.py:157} INFO - Started process (PID=16598) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T05:49:05.750+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T05:49:05.752+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:49:05.752+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T05:49:05.764+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T05:49:05.781+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:49:05.781+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T05:49:05.792+0000] {logging_mixin.py:151} INFO - [2024-07-29T05:49:05.792+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T05:49:05.804+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-29T06:02:46.507+0000] {processor.py:157} INFO - Started process (PID=16622) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T06:02:46.508+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T06:02:46.514+0000] {logging_mixin.py:151} INFO - [2024-07-29T06:02:46.513+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T06:02:46.552+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T06:02:46.594+0000] {logging_mixin.py:151} INFO - [2024-07-29T06:02:46.594+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T06:02:46.624+0000] {logging_mixin.py:151} INFO - [2024-07-29T06:02:46.624+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T06:02:46.636+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-07-29T06:03:17.164+0000] {processor.py:157} INFO - Started process (PID=16648) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T06:03:17.166+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T06:03:17.171+0000] {logging_mixin.py:151} INFO - [2024-07-29T06:03:17.171+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T06:03:17.190+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T06:03:17.212+0000] {logging_mixin.py:151} INFO - [2024-07-29T06:03:17.212+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T06:03:17.226+0000] {logging_mixin.py:151} INFO - [2024-07-29T06:03:17.226+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T06:03:17.235+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-07-29T06:03:47.613+0000] {processor.py:157} INFO - Started process (PID=16673) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T06:03:47.614+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T06:03:47.616+0000] {logging_mixin.py:151} INFO - [2024-07-29T06:03:47.616+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T06:03:47.629+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T06:03:47.643+0000] {logging_mixin.py:151} INFO - [2024-07-29T06:03:47.643+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T06:03:47.656+0000] {logging_mixin.py:151} INFO - [2024-07-29T06:03:47.656+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T06:03:47.674+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-29T06:04:18.057+0000] {processor.py:157} INFO - Started process (PID=16698) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T06:04:18.058+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T06:04:18.060+0000] {logging_mixin.py:151} INFO - [2024-07-29T06:04:18.059+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T06:04:18.068+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T06:04:18.083+0000] {logging_mixin.py:151} INFO - [2024-07-29T06:04:18.083+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T06:04:18.094+0000] {logging_mixin.py:151} INFO - [2024-07-29T06:04:18.094+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T06:04:18.103+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-29T06:11:18.650+0000] {processor.py:157} INFO - Started process (PID=16723) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T06:11:18.651+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T06:11:18.655+0000] {logging_mixin.py:151} INFO - [2024-07-29T06:11:18.654+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T06:11:18.670+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T06:11:18.701+0000] {logging_mixin.py:151} INFO - [2024-07-29T06:11:18.701+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T06:11:18.724+0000] {logging_mixin.py:151} INFO - [2024-07-29T06:11:18.724+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T06:11:18.739+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-07-29T06:11:49.283+0000] {processor.py:157} INFO - Started process (PID=16750) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T06:11:49.285+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T06:11:49.288+0000] {logging_mixin.py:151} INFO - [2024-07-29T06:11:49.287+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T06:11:49.299+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T06:11:49.315+0000] {logging_mixin.py:151} INFO - [2024-07-29T06:11:49.315+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T06:11:49.327+0000] {logging_mixin.py:151} INFO - [2024-07-29T06:11:49.327+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T06:11:49.336+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-29T06:29:04.398+0000] {processor.py:157} INFO - Started process (PID=16775) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T06:29:04.400+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T06:29:04.402+0000] {logging_mixin.py:151} INFO - [2024-07-29T06:29:04.402+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T06:29:04.424+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T06:29:04.460+0000] {logging_mixin.py:151} INFO - [2024-07-29T06:29:04.459+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T06:29:04.483+0000] {logging_mixin.py:151} INFO - [2024-07-29T06:29:04.482+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T06:29:04.498+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-07-29T06:44:53.818+0000] {processor.py:157} INFO - Started process (PID=16800) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T06:44:53.819+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T06:44:53.824+0000] {logging_mixin.py:151} INFO - [2024-07-29T06:44:53.824+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T06:44:53.841+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T06:44:53.865+0000] {logging_mixin.py:151} INFO - [2024-07-29T06:44:53.865+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T06:44:53.879+0000] {logging_mixin.py:151} INFO - [2024-07-29T06:44:53.878+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T06:44:53.889+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-29T06:45:24.260+0000] {processor.py:157} INFO - Started process (PID=16825) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T06:45:24.261+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T06:45:24.267+0000] {logging_mixin.py:151} INFO - [2024-07-29T06:45:24.267+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T06:45:24.287+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T06:45:24.313+0000] {logging_mixin.py:151} INFO - [2024-07-29T06:45:24.313+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T06:45:24.326+0000] {logging_mixin.py:151} INFO - [2024-07-29T06:45:24.326+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T06:45:24.336+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-07-29T06:45:54.802+0000] {processor.py:157} INFO - Started process (PID=16850) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T06:45:54.802+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T06:45:54.804+0000] {logging_mixin.py:151} INFO - [2024-07-29T06:45:54.804+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T06:45:54.815+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T06:45:54.831+0000] {logging_mixin.py:151} INFO - [2024-07-29T06:45:54.831+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T06:45:54.841+0000] {logging_mixin.py:151} INFO - [2024-07-29T06:45:54.841+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T06:45:54.850+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-29T06:46:25.261+0000] {processor.py:157} INFO - Started process (PID=16875) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T06:46:25.265+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T06:46:25.269+0000] {logging_mixin.py:151} INFO - [2024-07-29T06:46:25.268+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T06:46:25.287+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T06:46:25.306+0000] {logging_mixin.py:151} INFO - [2024-07-29T06:46:25.306+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T06:46:25.320+0000] {logging_mixin.py:151} INFO - [2024-07-29T06:46:25.320+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T06:46:25.331+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-29T06:46:55.744+0000] {processor.py:157} INFO - Started process (PID=16900) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T06:46:55.746+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T06:46:55.747+0000] {logging_mixin.py:151} INFO - [2024-07-29T06:46:55.747+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T06:46:55.761+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T06:46:55.774+0000] {logging_mixin.py:151} INFO - [2024-07-29T06:46:55.774+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T06:46:55.785+0000] {logging_mixin.py:151} INFO - [2024-07-29T06:46:55.785+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T06:46:55.792+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-29T07:03:27.256+0000] {processor.py:157} INFO - Started process (PID=16927) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:03:27.257+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T07:03:27.259+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:03:27.259+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:03:27.290+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:03:27.324+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:03:27.324+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T07:03:27.354+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:03:27.354+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T07:03:27.372+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-07-29T07:03:57.891+0000] {processor.py:157} INFO - Started process (PID=16952) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:03:57.893+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T07:03:57.895+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:03:57.895+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:03:57.907+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:03:57.925+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:03:57.925+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T07:03:57.936+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:03:57.936+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T07:03:57.946+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-29T07:04:28.343+0000] {processor.py:157} INFO - Started process (PID=16977) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:04:28.347+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T07:04:28.351+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:04:28.350+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:04:28.368+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:04:28.395+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:04:28.395+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T07:04:28.409+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:04:28.409+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T07:04:28.420+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-07-29T07:04:58.771+0000] {processor.py:157} INFO - Started process (PID=17002) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:04:58.772+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T07:04:58.774+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:04:58.774+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:04:58.790+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:04:58.805+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:04:58.805+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T07:04:58.814+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:04:58.814+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T07:04:58.824+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-29T07:21:01.133+0000] {processor.py:157} INFO - Started process (PID=17028) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:21:01.135+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T07:21:01.137+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:21:01.137+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:21:01.155+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:21:01.183+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:21:01.183+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T07:21:01.204+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:21:01.204+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T07:21:01.224+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-07-29T07:21:31.626+0000] {processor.py:157} INFO - Started process (PID=17054) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:21:31.627+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T07:21:31.629+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:21:31.629+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:21:31.639+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:21:31.655+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:21:31.655+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T07:21:31.666+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:21:31.666+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T07:21:31.675+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-29T07:22:02.071+0000] {processor.py:157} INFO - Started process (PID=17079) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:22:02.072+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T07:22:02.077+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:22:02.077+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:22:02.098+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:22:02.117+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:22:02.117+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T07:22:02.133+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:22:02.133+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T07:22:02.144+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-07-29T07:22:32.570+0000] {processor.py:157} INFO - Started process (PID=17104) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:22:32.571+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T07:22:32.572+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:22:32.572+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:22:32.582+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:22:32.598+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:22:32.598+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T07:22:32.608+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:22:32.608+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T07:22:32.618+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-29T07:23:02.997+0000] {processor.py:157} INFO - Started process (PID=17129) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:23:02.998+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T07:23:03.000+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:23:03.000+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:23:03.014+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:23:03.028+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:23:03.028+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T07:23:03.038+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:23:03.038+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T07:23:03.047+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-29T07:28:24.747+0000] {processor.py:157} INFO - Started process (PID=17155) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:28:24.748+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T07:28:24.752+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:28:24.752+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:28:24.766+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:28:24.788+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:28:24.788+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T07:28:24.799+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:28:24.799+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T07:28:24.810+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-29T07:28:55.176+0000] {processor.py:157} INFO - Started process (PID=17181) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:28:55.177+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T07:28:55.180+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:28:55.179+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:28:55.195+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:28:55.215+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:28:55.215+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T07:28:55.227+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:28:55.227+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T07:28:55.237+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-29T07:29:25.660+0000] {processor.py:157} INFO - Started process (PID=17206) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:29:25.661+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T07:29:25.664+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:29:25.663+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:29:25.675+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:29:25.691+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:29:25.691+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T07:29:25.702+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:29:25.702+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T07:29:25.711+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-29T07:29:56.059+0000] {processor.py:157} INFO - Started process (PID=17231) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:29:56.060+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T07:29:56.062+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:29:56.062+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:29:56.070+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:29:56.086+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:29:56.086+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T07:29:56.095+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:29:56.095+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T07:29:56.104+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-29T07:30:26.401+0000] {processor.py:157} INFO - Started process (PID=17256) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:30:26.402+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T07:30:26.404+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:30:26.404+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:30:26.419+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:30:26.433+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:30:26.433+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T07:30:26.444+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:30:26.444+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T07:30:26.453+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-29T07:30:56.840+0000] {processor.py:157} INFO - Started process (PID=17281) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:30:56.842+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T07:30:56.844+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:30:56.844+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:30:56.855+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:30:56.871+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:30:56.870+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T07:30:56.880+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:30:56.880+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T07:30:56.889+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-29T07:31:27.230+0000] {processor.py:157} INFO - Started process (PID=17306) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:31:27.231+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T07:31:27.232+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:31:27.232+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:31:27.246+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:31:27.259+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:31:27.259+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T07:31:27.270+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:31:27.270+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T07:31:27.280+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-29T07:31:57.671+0000] {processor.py:157} INFO - Started process (PID=17331) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:31:57.672+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T07:31:57.673+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:31:57.673+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:31:57.689+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:31:57.704+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:31:57.704+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T07:31:57.717+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:31:57.717+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T07:31:57.724+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-29T07:32:28.062+0000] {processor.py:157} INFO - Started process (PID=17356) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:32:28.069+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T07:32:28.071+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:32:28.070+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:32:28.078+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:32:28.092+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:32:28.092+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T07:32:28.102+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:32:28.102+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T07:32:28.109+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-29T07:32:58.461+0000] {processor.py:157} INFO - Started process (PID=17381) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:32:58.462+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T07:32:58.463+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:32:58.463+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:32:58.479+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:32:58.492+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:32:58.491+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T07:32:58.500+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:32:58.500+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T07:32:58.510+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-29T07:33:28.993+0000] {processor.py:157} INFO - Started process (PID=17406) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:33:28.994+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T07:33:28.998+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:33:28.997+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:33:29.019+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:33:29.037+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:33:29.037+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T07:33:29.050+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:33:29.050+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T07:33:29.060+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-29T07:33:59.471+0000] {processor.py:157} INFO - Started process (PID=17431) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:33:59.474+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T07:33:59.475+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:33:59.475+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:33:59.484+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:33:59.502+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:33:59.502+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T07:33:59.512+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:33:59.512+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T07:33:59.521+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-29T07:34:29.918+0000] {processor.py:157} INFO - Started process (PID=17456) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:34:29.918+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T07:34:29.920+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:34:29.920+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:34:29.930+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:34:29.948+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:34:29.948+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T07:34:29.957+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:34:29.957+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T07:34:29.966+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-29T07:35:00.348+0000] {processor.py:157} INFO - Started process (PID=17481) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:35:00.351+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T07:35:00.354+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:35:00.353+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:35:00.374+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:35:00.391+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:35:00.391+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T07:35:00.404+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:35:00.404+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T07:35:00.413+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-29T07:35:30.779+0000] {processor.py:157} INFO - Started process (PID=17506) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:35:30.781+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T07:35:30.783+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:35:30.782+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:35:30.795+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:35:30.811+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:35:30.811+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T07:35:30.823+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:35:30.823+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T07:35:30.835+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-29T07:36:01.184+0000] {processor.py:157} INFO - Started process (PID=17531) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:36:01.185+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T07:36:01.186+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:36:01.186+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:36:01.198+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:36:01.214+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:36:01.214+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T07:36:01.225+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:36:01.225+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T07:36:01.234+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-29T07:36:31.607+0000] {processor.py:157} INFO - Started process (PID=17556) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:36:31.608+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T07:36:31.610+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:36:31.610+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:36:31.621+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:36:31.636+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:36:31.636+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T07:36:31.648+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:36:31.648+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T07:36:31.655+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-29T07:37:02.028+0000] {processor.py:157} INFO - Started process (PID=17581) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:37:02.028+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T07:37:02.030+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:37:02.030+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:37:02.045+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:37:02.058+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:37:02.058+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T07:37:02.067+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:37:02.067+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T07:37:02.075+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-29T07:37:32.405+0000] {processor.py:157} INFO - Started process (PID=17606) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:37:32.406+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T07:37:32.407+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:37:32.407+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:37:32.421+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:37:32.436+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:37:32.436+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T07:37:32.447+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:37:32.446+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T07:37:32.455+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-29T07:38:02.862+0000] {processor.py:157} INFO - Started process (PID=17631) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:38:02.863+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T07:38:02.865+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:38:02.865+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:38:02.875+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:38:02.889+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:38:02.889+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T07:38:02.898+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:38:02.898+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T07:38:02.908+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-29T07:38:33.323+0000] {processor.py:157} INFO - Started process (PID=17656) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:38:33.326+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T07:38:33.329+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:38:33.329+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:38:33.352+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:38:33.369+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:38:33.369+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T07:38:33.383+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:38:33.383+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T07:38:33.393+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-29T07:39:03.828+0000] {processor.py:157} INFO - Started process (PID=17681) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:39:03.830+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T07:39:03.832+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:39:03.832+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:39:03.842+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:39:03.857+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:39:03.857+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T07:39:03.871+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:39:03.871+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T07:39:03.880+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-29T07:39:34.305+0000] {processor.py:157} INFO - Started process (PID=17706) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:39:34.306+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T07:39:34.307+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:39:34.307+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:39:34.321+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:39:34.336+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:39:34.336+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T07:39:34.346+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:39:34.346+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T07:39:34.354+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-29T07:40:04.742+0000] {processor.py:157} INFO - Started process (PID=17731) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:40:04.743+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T07:40:04.745+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:40:04.745+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:40:04.753+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:40:04.771+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:40:04.771+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T07:40:04.780+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:40:04.780+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T07:40:04.792+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-29T07:40:35.203+0000] {processor.py:157} INFO - Started process (PID=17756) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:40:35.204+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T07:40:35.205+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:40:35.205+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:40:35.217+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:40:35.232+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:40:35.232+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T07:40:35.243+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:40:35.243+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T07:40:35.251+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-29T07:41:05.615+0000] {processor.py:157} INFO - Started process (PID=17781) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:41:05.617+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T07:41:05.619+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:41:05.619+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:41:05.636+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:41:05.658+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:41:05.658+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T07:41:05.670+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:41:05.670+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T07:41:05.679+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-29T07:41:36.139+0000] {processor.py:157} INFO - Started process (PID=17806) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:41:36.144+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T07:41:36.150+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:41:36.150+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:41:36.186+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:41:36.207+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:41:36.207+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T07:41:36.219+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:41:36.219+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T07:41:36.227+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-07-29T07:42:06.572+0000] {processor.py:157} INFO - Started process (PID=17831) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:42:06.573+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T07:42:06.574+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:42:06.574+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:42:06.586+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:42:06.603+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:42:06.602+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T07:42:06.614+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:42:06.614+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T07:42:06.623+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-29T07:42:37.069+0000] {processor.py:157} INFO - Started process (PID=17856) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:42:37.071+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T07:42:37.073+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:42:37.073+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:42:37.084+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:42:37.100+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:42:37.100+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T07:42:37.112+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:42:37.112+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T07:42:37.121+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-29T07:43:07.524+0000] {processor.py:157} INFO - Started process (PID=17881) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:43:07.529+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T07:43:07.536+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:43:07.535+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:43:07.555+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:43:07.580+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:43:07.580+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T07:43:07.593+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:43:07.592+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T07:43:07.603+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-07-29T07:43:53.347+0000] {processor.py:157} INFO - Started process (PID=17908) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:43:53.348+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T07:43:53.350+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:43:53.349+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:43:53.364+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:43:53.380+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:43:53.380+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T07:43:53.389+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:43:53.389+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T07:43:53.395+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-29T07:45:51.576+0000] {processor.py:157} INFO - Started process (PID=17933) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:45:51.577+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T07:45:51.579+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:45:51.579+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:45:51.589+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:45:51.609+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:45:51.609+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T07:45:51.619+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:45:51.619+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T07:45:51.627+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-29T07:46:22.050+0000] {processor.py:157} INFO - Started process (PID=17958) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:46:22.051+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T07:46:22.053+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:46:22.052+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:46:22.066+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T07:46:22.087+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:46:22.087+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T07:46:22.099+0000] {logging_mixin.py:151} INFO - [2024-07-29T07:46:22.099+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T07:46:22.107+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-29T08:02:09.281+0000] {processor.py:157} INFO - Started process (PID=17983) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:02:09.282+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T08:02:09.284+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:02:09.283+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:02:09.299+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:02:09.316+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:02:09.316+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:02:09.327+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:02:09.327+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T08:02:09.339+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-29T08:02:39.758+0000] {processor.py:157} INFO - Started process (PID=18008) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:02:39.760+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T08:02:39.763+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:02:39.763+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:02:39.786+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:02:39.819+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:02:39.819+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:02:39.832+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:02:39.832+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T08:02:39.840+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-07-29T08:18:39.688+0000] {processor.py:157} INFO - Started process (PID=18033) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:18:39.694+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T08:18:39.696+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:18:39.696+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:18:39.711+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:18:39.728+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:18:39.728+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:18:39.749+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:18:39.749+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T08:18:39.757+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-29T08:19:10.171+0000] {processor.py:157} INFO - Started process (PID=18059) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:19:10.175+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T08:19:10.178+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:19:10.178+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:19:10.196+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:19:10.227+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:19:10.227+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:19:10.256+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:19:10.255+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T08:19:10.267+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-07-29T08:19:40.804+0000] {processor.py:157} INFO - Started process (PID=18085) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:19:40.806+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T08:19:40.808+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:19:40.808+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:19:40.821+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:19:40.838+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:19:40.838+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:19:40.848+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:19:40.848+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T08:19:40.857+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-29T08:20:11.282+0000] {processor.py:157} INFO - Started process (PID=18110) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:20:11.284+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T08:20:11.286+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:20:11.286+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:20:11.299+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:20:11.317+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:20:11.316+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:20:11.327+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:20:11.327+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T08:20:11.335+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-29T08:26:04.100+0000] {processor.py:157} INFO - Started process (PID=18135) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:26:04.101+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T08:26:04.106+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:26:04.106+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:26:04.138+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:26:04.183+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:26:04.183+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:26:04.199+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:26:04.199+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T08:26:04.210+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-07-29T08:26:34.649+0000] {processor.py:157} INFO - Started process (PID=18160) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:26:34.651+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T08:26:34.655+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:26:34.654+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:26:34.670+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:26:34.697+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:26:34.696+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:26:34.711+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:26:34.711+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T08:26:34.722+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-07-29T08:27:05.051+0000] {processor.py:157} INFO - Started process (PID=18185) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:27:05.055+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T08:27:05.058+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:27:05.057+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:27:05.065+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:27:05.079+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:27:05.079+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:27:05.088+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:27:05.088+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T08:27:05.098+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-29T08:27:35.602+0000] {processor.py:157} INFO - Started process (PID=18210) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:27:35.604+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T08:27:35.606+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:27:35.606+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:27:35.619+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:27:35.634+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:27:35.634+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:27:35.645+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:27:35.645+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T08:27:35.654+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-29T08:28:06.128+0000] {processor.py:157} INFO - Started process (PID=18235) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:28:06.130+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T08:28:06.140+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:28:06.139+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:28:06.155+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:28:06.172+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:28:06.172+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:28:06.185+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:28:06.185+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T08:28:06.193+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-29T08:28:36.572+0000] {processor.py:157} INFO - Started process (PID=18260) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:28:36.572+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T08:28:36.577+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:28:36.577+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:28:36.591+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:28:36.603+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:28:36.603+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:28:36.612+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:28:36.612+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T08:28:36.620+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-29T08:29:07.041+0000] {processor.py:157} INFO - Started process (PID=18285) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:29:07.042+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T08:29:07.044+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:29:07.044+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:29:07.057+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:29:07.071+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:29:07.071+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:29:07.082+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:29:07.082+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T08:29:07.091+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-29T08:29:37.490+0000] {processor.py:157} INFO - Started process (PID=18310) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:29:37.490+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T08:29:37.493+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:29:37.493+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:29:37.502+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:29:37.516+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:29:37.516+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:29:37.526+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:29:37.526+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T08:29:37.536+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-29T08:30:07.905+0000] {processor.py:157} INFO - Started process (PID=18335) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:30:07.905+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T08:30:07.908+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:30:07.908+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:30:07.921+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:30:07.936+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:30:07.936+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:30:07.945+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:30:07.945+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T08:30:07.954+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-29T08:30:38.282+0000] {processor.py:157} INFO - Started process (PID=18360) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:30:38.282+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T08:30:38.284+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:30:38.284+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:30:38.289+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:30:38.303+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:30:38.303+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:30:38.312+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:30:38.311+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T08:30:38.321+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.041 seconds
[2024-07-29T08:31:08.756+0000] {processor.py:157} INFO - Started process (PID=18385) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:31:08.756+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T08:31:08.758+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:31:08.758+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:31:08.771+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:31:08.787+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:31:08.787+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:31:08.797+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:31:08.797+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T08:31:08.807+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-29T08:31:39.237+0000] {processor.py:157} INFO - Started process (PID=18410) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:31:39.238+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T08:31:39.240+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:31:39.240+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:31:39.252+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:31:39.274+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:31:39.274+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:31:39.287+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:31:39.287+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T08:31:39.297+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-29T08:32:09.738+0000] {processor.py:157} INFO - Started process (PID=18435) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:32:09.739+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T08:32:09.740+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:32:09.740+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:32:09.750+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:32:09.767+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:32:09.767+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:32:09.778+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:32:09.778+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T08:32:09.786+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-29T08:32:40.218+0000] {processor.py:157} INFO - Started process (PID=18460) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:32:40.220+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T08:32:40.222+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:32:40.222+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:32:40.234+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:32:40.252+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:32:40.252+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:32:40.263+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:32:40.263+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T08:32:40.270+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-29T08:33:10.705+0000] {processor.py:157} INFO - Started process (PID=18485) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:33:10.706+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T08:33:10.709+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:33:10.708+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:33:10.725+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:33:10.738+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:33:10.738+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:33:10.748+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:33:10.748+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T08:33:10.758+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-29T08:33:41.168+0000] {processor.py:157} INFO - Started process (PID=18510) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:33:41.168+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T08:33:41.170+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:33:41.170+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:33:41.179+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:33:41.195+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:33:41.195+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:33:41.204+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:33:41.204+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T08:33:41.213+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-29T08:34:11.619+0000] {processor.py:157} INFO - Started process (PID=18535) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:34:11.621+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T08:34:11.624+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:34:11.623+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:34:11.640+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:34:11.662+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:34:11.662+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:34:11.675+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:34:11.675+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T08:34:11.686+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-29T08:34:42.164+0000] {processor.py:157} INFO - Started process (PID=18560) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:34:42.167+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T08:34:42.172+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:34:42.172+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:34:42.183+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:34:42.197+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:34:42.197+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:34:42.206+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:34:42.206+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T08:34:42.217+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-29T08:35:12.654+0000] {processor.py:157} INFO - Started process (PID=18585) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:35:12.654+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T08:35:12.656+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:35:12.656+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:35:12.667+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:35:12.684+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:35:12.684+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:35:12.694+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:35:12.694+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T08:35:12.703+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-29T08:35:43.112+0000] {processor.py:157} INFO - Started process (PID=18610) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:35:43.113+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T08:35:43.115+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:35:43.115+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:35:43.130+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:35:43.152+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:35:43.152+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:35:43.165+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:35:43.165+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T08:35:43.176+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-29T08:36:13.592+0000] {processor.py:157} INFO - Started process (PID=18635) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:36:13.592+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T08:36:13.594+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:36:13.594+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:36:13.606+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:36:13.622+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:36:13.622+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:36:13.632+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:36:13.632+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T08:36:13.640+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-29T08:36:44.008+0000] {processor.py:157} INFO - Started process (PID=18660) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:36:44.008+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T08:36:44.011+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:36:44.010+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:36:44.021+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:36:44.038+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:36:44.038+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:36:44.050+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:36:44.050+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T08:36:44.062+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-29T08:37:14.528+0000] {processor.py:157} INFO - Started process (PID=18685) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:37:14.529+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T08:37:14.531+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:37:14.530+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:37:14.548+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:37:14.563+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:37:14.563+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:37:14.573+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:37:14.573+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T08:37:14.583+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-29T08:37:44.946+0000] {processor.py:157} INFO - Started process (PID=18710) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:37:44.946+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T08:37:44.948+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:37:44.948+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:37:44.963+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:37:44.976+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:37:44.976+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:37:44.988+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:37:44.988+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T08:37:44.997+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-29T08:38:15.426+0000] {processor.py:157} INFO - Started process (PID=18735) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:38:15.426+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T08:38:15.428+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:38:15.428+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:38:15.439+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:38:15.455+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:38:15.455+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:38:15.466+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:38:15.466+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T08:38:15.476+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-29T08:38:45.768+0000] {processor.py:157} INFO - Started process (PID=18760) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:38:45.768+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T08:38:45.772+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:38:45.771+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:38:45.789+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:38:45.802+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:38:45.802+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:38:45.812+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:38:45.812+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T08:38:45.821+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-29T08:39:16.323+0000] {processor.py:157} INFO - Started process (PID=18785) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:39:16.324+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T08:39:16.327+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:39:16.327+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:39:16.338+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:39:16.362+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:39:16.361+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:39:16.375+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:39:16.375+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T08:39:16.385+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-29T08:39:46.778+0000] {processor.py:157} INFO - Started process (PID=18809) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:39:46.781+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T08:39:46.783+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:39:46.783+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:39:46.800+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:39:46.814+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:39:46.814+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:39:46.826+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:39:46.826+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T08:39:46.833+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-29T08:40:17.259+0000] {processor.py:157} INFO - Started process (PID=18835) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:40:17.259+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T08:40:17.262+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:40:17.262+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:40:17.271+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:40:17.289+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:40:17.289+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:40:17.301+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:40:17.301+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T08:40:17.310+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-29T08:40:47.763+0000] {processor.py:157} INFO - Started process (PID=18860) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:40:47.764+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T08:40:47.765+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:40:47.765+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:40:47.776+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:40:47.788+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:40:47.787+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:40:47.795+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:40:47.795+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T08:40:47.802+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.040 seconds
[2024-07-29T08:41:18.243+0000] {processor.py:157} INFO - Started process (PID=18885) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:41:18.246+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T08:41:18.248+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:41:18.248+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:41:18.266+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:41:18.287+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:41:18.287+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:41:18.300+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:41:18.300+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T08:41:18.309+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-29T08:41:48.781+0000] {processor.py:157} INFO - Started process (PID=18910) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:41:48.783+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T08:41:48.785+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:41:48.785+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:41:48.796+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:41:48.812+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:41:48.812+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:41:48.822+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:41:48.822+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T08:41:48.832+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-29T08:42:19.268+0000] {processor.py:157} INFO - Started process (PID=18935) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:42:19.269+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T08:42:19.271+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:42:19.271+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:42:19.289+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:42:19.302+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:42:19.302+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:42:19.313+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:42:19.312+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T08:42:19.323+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-29T08:42:49.737+0000] {processor.py:157} INFO - Started process (PID=18960) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:42:49.738+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T08:42:49.740+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:42:49.740+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:42:49.750+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:42:49.767+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:42:49.766+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:42:49.776+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:42:49.776+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T08:42:49.785+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-29T08:43:20.139+0000] {processor.py:157} INFO - Started process (PID=18985) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:43:20.141+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T08:43:20.143+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:43:20.143+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:43:20.156+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:43:20.178+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:43:20.178+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:43:20.191+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:43:20.191+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T08:43:20.200+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-29T08:43:50.677+0000] {processor.py:157} INFO - Started process (PID=19010) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:43:50.678+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T08:43:50.680+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:43:50.680+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:43:50.695+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:43:50.710+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:43:50.710+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:43:50.722+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:43:50.722+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T08:43:50.733+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-29T08:44:21.079+0000] {processor.py:157} INFO - Started process (PID=19034) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:44:21.079+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T08:44:21.081+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:44:21.081+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:44:21.088+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:44:21.107+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:44:21.106+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:44:21.119+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:44:21.119+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T08:44:21.126+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-29T08:44:51.523+0000] {processor.py:157} INFO - Started process (PID=19060) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:44:51.523+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T08:44:51.526+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:44:51.526+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:44:51.537+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:44:51.553+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:44:51.553+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:44:51.565+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:44:51.565+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T08:44:51.574+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-29T08:45:21.981+0000] {processor.py:157} INFO - Started process (PID=19085) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:45:21.981+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T08:45:21.989+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:45:21.989+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:45:21.999+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:45:22.013+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:45:22.013+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:45:22.022+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:45:22.022+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T08:45:22.030+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-29T08:45:52.465+0000] {processor.py:157} INFO - Started process (PID=19110) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:45:52.466+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T08:45:52.467+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:45:52.467+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:45:52.479+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:45:52.497+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:45:52.497+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:45:52.509+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:45:52.509+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T08:45:52.518+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-29T08:46:22.980+0000] {processor.py:157} INFO - Started process (PID=19135) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:46:22.981+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T08:46:22.988+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:46:22.988+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:46:23.006+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:46:23.028+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:46:23.028+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:46:23.040+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:46:23.040+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T08:46:23.049+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-29T08:46:53.486+0000] {processor.py:157} INFO - Started process (PID=19160) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:46:53.487+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T08:46:53.489+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:46:53.489+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:46:53.500+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:46:53.518+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:46:53.518+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:46:53.529+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:46:53.529+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T08:46:53.539+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-29T08:47:23.865+0000] {processor.py:157} INFO - Started process (PID=19185) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:47:23.866+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T08:47:23.868+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:47:23.868+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:47:23.881+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:47:23.898+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:47:23.898+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:47:23.909+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:47:23.908+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T08:47:23.917+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-29T08:47:54.241+0000] {processor.py:157} INFO - Started process (PID=19210) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:47:54.244+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T08:47:54.249+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:47:54.249+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:47:54.261+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:47:54.278+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:47:54.278+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:47:54.289+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:47:54.289+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T08:47:54.299+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-29T08:48:24.775+0000] {processor.py:157} INFO - Started process (PID=19235) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:48:24.776+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T08:48:24.779+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:48:24.779+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:48:24.789+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:48:24.806+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:48:24.805+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:48:24.815+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:48:24.815+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T08:48:24.824+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-29T08:48:55.224+0000] {processor.py:157} INFO - Started process (PID=19260) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:48:55.225+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T08:48:55.227+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:48:55.227+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:48:55.238+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:48:55.254+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:48:55.254+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:48:55.264+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:48:55.264+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T08:48:55.273+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-29T08:49:25.690+0000] {processor.py:157} INFO - Started process (PID=19285) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:49:25.692+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T08:49:25.694+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:49:25.693+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:49:25.709+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:49:25.725+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:49:25.725+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:49:25.736+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:49:25.736+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T08:49:25.746+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-29T08:49:56.102+0000] {processor.py:157} INFO - Started process (PID=19310) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:49:56.103+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T08:49:56.106+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:49:56.106+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:49:56.123+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:49:56.146+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:49:56.146+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:49:56.159+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:49:56.159+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T08:49:56.168+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-29T08:50:26.605+0000] {processor.py:157} INFO - Started process (PID=19335) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:50:26.606+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T08:50:26.609+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:50:26.609+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:50:26.623+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:50:26.640+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:50:26.640+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:50:26.652+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:50:26.652+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T08:50:26.662+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-29T08:50:57.147+0000] {processor.py:157} INFO - Started process (PID=19360) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:50:57.148+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T08:50:57.149+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:50:57.149+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:50:57.158+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:50:57.174+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:50:57.174+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:50:57.186+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:50:57.186+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T08:50:57.194+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-29T08:51:27.617+0000] {processor.py:157} INFO - Started process (PID=19385) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:51:27.618+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T08:51:27.621+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:51:27.621+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:51:27.636+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:51:27.656+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:51:27.656+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:51:27.668+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:51:27.668+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T08:51:27.677+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-29T08:51:58.111+0000] {processor.py:157} INFO - Started process (PID=19410) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:51:58.112+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T08:51:58.118+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:51:58.118+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:51:58.129+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:51:58.143+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:51:58.143+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:51:58.153+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:51:58.153+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T08:51:58.161+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-29T08:52:28.600+0000] {processor.py:157} INFO - Started process (PID=19435) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:52:28.601+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T08:52:28.603+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:52:28.603+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:52:28.620+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:52:28.634+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:52:28.634+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:52:28.643+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:52:28.643+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T08:52:28.651+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-29T08:52:59.100+0000] {processor.py:157} INFO - Started process (PID=19460) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:52:59.104+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T08:52:59.108+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:52:59.108+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:52:59.116+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:52:59.129+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:52:59.129+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:52:59.139+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:52:59.139+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T08:52:59.148+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-29T08:53:29.496+0000] {processor.py:157} INFO - Started process (PID=19485) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:53:29.498+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T08:53:29.500+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:53:29.500+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:53:29.511+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:53:29.526+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:53:29.526+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:53:29.536+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:53:29.536+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T08:53:29.545+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-29T08:53:59.956+0000] {processor.py:157} INFO - Started process (PID=19510) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:53:59.958+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T08:53:59.959+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:53:59.959+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:53:59.974+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:53:59.989+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:53:59.989+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:54:00.000+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:54:00.000+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T08:54:00.009+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-29T08:54:30.447+0000] {processor.py:157} INFO - Started process (PID=19535) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:54:30.447+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T08:54:30.454+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:54:30.454+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:54:30.460+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:54:30.471+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:54:30.471+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:54:30.479+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:54:30.479+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T08:54:30.488+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.043 seconds
[2024-07-29T08:55:00.959+0000] {processor.py:157} INFO - Started process (PID=19560) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:55:00.960+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T08:55:00.963+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:55:00.963+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:55:00.976+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:55:00.998+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:55:00.998+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:55:01.011+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:55:01.010+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T08:55:01.022+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-29T08:55:31.450+0000] {processor.py:157} INFO - Started process (PID=19585) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:55:31.452+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T08:55:31.454+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:55:31.454+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:55:31.468+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:55:31.482+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:55:31.481+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:55:31.492+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:55:31.492+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T08:55:31.501+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-29T08:56:01.928+0000] {processor.py:157} INFO - Started process (PID=19610) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:56:01.929+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T08:56:01.937+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:56:01.936+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:56:01.947+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:56:01.962+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:56:01.962+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:56:01.972+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:56:01.972+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T08:56:01.982+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-29T08:56:32.320+0000] {processor.py:157} INFO - Started process (PID=19635) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:56:32.322+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T08:56:32.324+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:56:32.324+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:56:32.335+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:56:32.352+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:56:32.352+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:56:32.364+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:56:32.364+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T08:56:32.373+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-29T08:57:02.749+0000] {processor.py:157} INFO - Started process (PID=19660) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:57:02.749+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T08:57:02.751+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:57:02.750+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:57:02.766+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:57:02.779+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:57:02.779+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:57:02.790+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:57:02.789+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T08:57:02.800+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-29T08:57:33.299+0000] {processor.py:157} INFO - Started process (PID=19685) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:57:33.303+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T08:57:33.305+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:57:33.305+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:57:33.313+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:57:33.326+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:57:33.326+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:57:33.335+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:57:33.335+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T08:57:33.344+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-29T08:58:03.902+0000] {processor.py:157} INFO - Started process (PID=19710) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:58:03.906+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T08:58:03.909+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:58:03.909+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:58:03.918+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:58:03.936+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:58:03.936+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:58:03.945+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:58:03.945+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T08:58:03.955+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-29T08:58:34.449+0000] {processor.py:157} INFO - Started process (PID=19735) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:58:34.455+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T08:58:34.457+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:58:34.457+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:58:34.464+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:58:34.477+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:58:34.477+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:58:34.486+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:58:34.486+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T08:58:34.494+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-29T08:59:04.911+0000] {processor.py:157} INFO - Started process (PID=19760) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:59:04.911+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T08:59:04.913+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:59:04.913+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:59:04.925+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:59:04.946+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:59:04.946+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:59:04.958+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:59:04.958+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T08:59:04.966+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-29T08:59:35.423+0000] {processor.py:157} INFO - Started process (PID=19785) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:59:35.425+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T08:59:35.427+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:59:35.427+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:59:35.440+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T08:59:35.456+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:59:35.456+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T08:59:35.467+0000] {logging_mixin.py:151} INFO - [2024-07-29T08:59:35.467+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T08:59:35.476+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-29T09:00:05.970+0000] {processor.py:157} INFO - Started process (PID=19810) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:00:05.971+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:00:05.973+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:00:05.973+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:00:05.983+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:00:05.998+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:00:05.998+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:00:06.008+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:00:06.008+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:00:06.015+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-29T09:00:36.429+0000] {processor.py:157} INFO - Started process (PID=19835) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:00:36.434+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:00:36.439+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:00:36.439+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:00:36.451+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:00:36.465+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:00:36.465+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:00:36.476+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:00:36.476+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:00:36.485+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-29T09:01:06.887+0000] {processor.py:157} INFO - Started process (PID=19860) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:01:06.894+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:01:06.895+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:01:06.895+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:01:06.903+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:01:06.916+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:01:06.916+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:01:06.926+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:01:06.926+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:01:06.936+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-29T09:01:37.370+0000] {processor.py:157} INFO - Started process (PID=19885) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:01:37.371+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:01:37.373+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:01:37.373+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:01:37.390+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:01:37.404+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:01:37.404+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:01:37.416+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:01:37.416+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:01:37.424+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-29T09:02:07.763+0000] {processor.py:157} INFO - Started process (PID=19910) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:02:07.767+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:02:07.771+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:02:07.770+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:02:07.783+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:02:07.798+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:02:07.798+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:02:07.809+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:02:07.808+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:02:07.819+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-29T09:02:38.260+0000] {processor.py:157} INFO - Started process (PID=19935) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:02:38.261+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:02:38.268+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:02:38.268+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:02:38.275+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:02:38.288+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:02:38.288+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:02:38.298+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:02:38.298+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:02:38.305+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-29T09:03:08.737+0000] {processor.py:157} INFO - Started process (PID=19959) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:03:08.738+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:03:08.740+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:03:08.740+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:03:08.751+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:03:08.775+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:03:08.775+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:03:08.786+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:03:08.786+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:03:08.795+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-29T09:03:39.249+0000] {processor.py:157} INFO - Started process (PID=19985) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:03:39.251+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:03:39.253+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:03:39.253+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:03:39.266+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:03:39.281+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:03:39.281+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:03:39.291+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:03:39.291+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:03:39.300+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-29T09:04:09.720+0000] {processor.py:157} INFO - Started process (PID=20010) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:04:09.721+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:04:09.722+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:04:09.722+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:04:09.732+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:04:09.747+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:04:09.747+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:04:09.759+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:04:09.759+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:04:09.770+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-29T09:04:40.181+0000] {processor.py:157} INFO - Started process (PID=20035) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:04:40.183+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:04:40.185+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:04:40.184+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:04:40.196+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:04:40.212+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:04:40.212+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:04:40.222+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:04:40.222+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:04:40.231+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-29T09:05:10.658+0000] {processor.py:157} INFO - Started process (PID=20060) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:05:10.665+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:05:10.666+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:05:10.666+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:05:10.673+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:05:10.686+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:05:10.686+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:05:10.695+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:05:10.695+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:05:10.705+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-29T09:05:41.067+0000] {processor.py:157} INFO - Started process (PID=20085) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:05:41.068+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:05:41.070+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:05:41.069+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:05:41.087+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:05:41.105+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:05:41.105+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:05:41.115+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:05:41.115+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:05:41.123+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-29T09:06:11.564+0000] {processor.py:157} INFO - Started process (PID=20110) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:06:11.570+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:06:11.572+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:06:11.572+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:06:11.580+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:06:11.595+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:06:11.595+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:06:11.606+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:06:11.606+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:06:11.613+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-29T09:06:41.957+0000] {processor.py:157} INFO - Started process (PID=20135) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:06:41.958+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:06:41.960+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:06:41.960+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:06:41.975+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:06:41.991+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:06:41.991+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:06:42.003+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:06:42.003+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:06:42.012+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-29T09:07:12.467+0000] {processor.py:157} INFO - Started process (PID=20160) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:07:12.468+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:07:12.472+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:07:12.472+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:07:12.481+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:07:12.497+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:07:12.497+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:07:12.508+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:07:12.508+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:07:12.517+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-29T09:07:42.977+0000] {processor.py:157} INFO - Started process (PID=20185) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:07:42.978+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:07:42.979+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:07:42.979+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:07:42.989+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:07:42.999+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:07:42.999+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:07:43.011+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:07:43.011+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:07:43.020+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-07-29T09:08:13.381+0000] {processor.py:157} INFO - Started process (PID=20210) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:08:13.385+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:08:13.387+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:08:13.387+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:08:13.398+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:08:13.411+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:08:13.411+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:08:13.422+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:08:13.422+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:08:13.432+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-29T09:08:43.878+0000] {processor.py:157} INFO - Started process (PID=20235) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:08:43.878+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:08:43.881+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:08:43.880+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:08:43.891+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:08:43.907+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:08:43.907+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:08:43.917+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:08:43.916+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:08:43.926+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-29T09:09:14.279+0000] {processor.py:157} INFO - Started process (PID=20260) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:09:14.280+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:09:14.285+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:09:14.285+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:09:14.299+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:09:14.320+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:09:14.320+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:09:14.332+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:09:14.332+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:09:14.340+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-29T09:09:44.824+0000] {processor.py:157} INFO - Started process (PID=20285) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:09:44.828+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:09:44.832+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:09:44.831+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:09:44.839+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:09:44.852+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:09:44.852+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:09:44.861+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:09:44.861+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:09:44.870+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-29T09:10:15.230+0000] {processor.py:157} INFO - Started process (PID=20310) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:10:15.233+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:10:15.236+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:10:15.236+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:10:15.244+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:10:15.257+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:10:15.257+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:10:15.266+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:10:15.266+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:10:15.275+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-29T09:10:45.755+0000] {processor.py:157} INFO - Started process (PID=20335) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:10:45.756+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:10:45.758+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:10:45.758+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:10:45.771+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:10:45.786+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:10:45.786+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:10:45.798+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:10:45.798+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:10:45.805+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-29T09:11:16.173+0000] {processor.py:157} INFO - Started process (PID=20360) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:11:16.174+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:11:16.175+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:11:16.174+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:11:16.183+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:11:16.197+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:11:16.196+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:11:16.207+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:11:16.207+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:11:16.216+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.044 seconds
[2024-07-29T09:11:46.607+0000] {processor.py:157} INFO - Started process (PID=20385) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:11:46.612+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:11:46.615+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:11:46.615+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:11:46.626+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:11:46.642+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:11:46.642+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:11:46.653+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:11:46.653+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:11:46.662+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-29T09:12:17.031+0000] {processor.py:157} INFO - Started process (PID=20410) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:12:17.032+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:12:17.039+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:12:17.039+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:12:17.046+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:12:17.059+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:12:17.059+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:12:17.068+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:12:17.068+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:12:17.079+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-29T09:12:47.553+0000] {processor.py:157} INFO - Started process (PID=20435) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:12:47.554+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:12:47.556+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:12:47.556+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:12:47.570+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:12:47.584+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:12:47.584+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:12:47.594+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:12:47.594+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:12:47.603+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-29T09:13:18.023+0000] {processor.py:157} INFO - Started process (PID=20460) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:13:18.029+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:13:18.031+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:13:18.031+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:13:18.039+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:13:18.053+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:13:18.053+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:13:18.062+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:13:18.062+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:13:18.073+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-29T09:13:48.421+0000] {processor.py:157} INFO - Started process (PID=20485) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:13:48.424+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:13:48.426+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:13:48.426+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:13:48.438+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:13:48.455+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:13:48.455+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:13:48.467+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:13:48.467+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:13:48.476+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-29T09:14:18.932+0000] {processor.py:157} INFO - Started process (PID=20510) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:14:18.933+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:14:18.934+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:14:18.934+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:14:18.942+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:14:18.961+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:14:18.961+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:14:18.974+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:14:18.974+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:14:18.983+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-29T09:14:49.292+0000] {processor.py:157} INFO - Started process (PID=20535) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:14:49.292+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:14:49.294+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:14:49.294+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:14:49.305+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:14:49.323+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:14:49.323+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:14:49.334+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:14:49.334+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:14:49.344+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-29T09:15:19.737+0000] {processor.py:157} INFO - Started process (PID=20560) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:15:19.738+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:15:19.746+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:15:19.746+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:15:19.753+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:15:19.765+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:15:19.765+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:15:19.774+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:15:19.774+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:15:19.784+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-29T09:15:50.221+0000] {processor.py:157} INFO - Started process (PID=20585) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:15:50.221+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:15:50.226+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:15:50.226+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:15:50.242+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:15:50.256+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:15:50.256+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:15:50.266+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:15:50.266+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:15:50.276+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-29T09:16:20.686+0000] {processor.py:157} INFO - Started process (PID=20610) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:16:20.688+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:16:20.690+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:16:20.690+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:16:20.700+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:16:20.718+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:16:20.718+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:16:20.731+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:16:20.731+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:16:20.738+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-29T09:16:51.144+0000] {processor.py:157} INFO - Started process (PID=20635) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:16:51.151+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:16:51.153+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:16:51.152+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:16:51.161+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:16:51.175+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:16:51.175+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:16:51.186+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:16:51.186+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:16:51.197+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-29T09:17:21.600+0000] {processor.py:157} INFO - Started process (PID=20660) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:17:21.601+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:17:21.605+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:17:21.604+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:17:21.620+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:17:21.643+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:17:21.643+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:17:21.653+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:17:21.653+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:17:21.662+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-29T09:17:52.208+0000] {processor.py:157} INFO - Started process (PID=20685) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:17:52.208+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:17:52.211+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:17:52.210+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:17:52.220+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:17:52.240+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:17:52.240+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:17:52.252+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:17:52.252+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:17:52.262+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-29T09:18:22.599+0000] {processor.py:157} INFO - Started process (PID=20710) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:18:22.599+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:18:22.600+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:18:22.600+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:18:22.607+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:18:22.622+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:18:22.622+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:18:22.632+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:18:22.632+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:18:22.641+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.044 seconds
[2024-07-29T09:18:53.093+0000] {processor.py:157} INFO - Started process (PID=20735) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:18:53.095+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:18:53.096+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:18:53.096+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:18:53.107+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:18:53.123+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:18:53.123+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:18:53.136+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:18:53.136+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:18:53.145+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-29T09:19:23.586+0000] {processor.py:157} INFO - Started process (PID=20760) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:19:23.587+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:19:23.590+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:19:23.590+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:19:23.605+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:19:23.630+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:19:23.630+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:19:23.643+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:19:23.643+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:19:23.654+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-29T09:19:54.103+0000] {processor.py:157} INFO - Started process (PID=20785) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:19:54.104+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:19:54.110+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:19:54.110+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:19:54.123+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:19:54.140+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:19:54.140+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:19:54.152+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:19:54.151+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:19:54.161+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-29T09:20:24.561+0000] {processor.py:157} INFO - Started process (PID=20810) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:20:24.561+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:20:24.563+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:20:24.563+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:20:24.577+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:20:24.592+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:20:24.591+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:20:24.603+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:20:24.603+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:20:24.611+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-29T09:20:54.958+0000] {processor.py:157} INFO - Started process (PID=20835) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:20:54.959+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:20:54.961+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:20:54.961+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:20:54.977+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:20:54.991+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:20:54.991+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:20:55.002+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:20:55.002+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:20:55.012+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-29T09:21:25.502+0000] {processor.py:157} INFO - Started process (PID=20860) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:21:25.503+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:21:25.506+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:21:25.506+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:21:25.523+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:21:25.544+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:21:25.544+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:21:25.557+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:21:25.557+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:21:25.567+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-29T09:21:55.862+0000] {processor.py:157} INFO - Started process (PID=20885) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:21:55.862+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:21:55.863+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:21:55.863+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:21:55.874+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:21:55.888+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:21:55.888+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:21:55.897+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:21:55.897+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:21:55.904+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.044 seconds
[2024-07-29T09:22:26.378+0000] {processor.py:157} INFO - Started process (PID=20910) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:22:26.379+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:22:26.387+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:22:26.387+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:22:26.399+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:22:26.414+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:22:26.414+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:22:26.426+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:22:26.426+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:22:26.434+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-29T09:22:56.844+0000] {processor.py:157} INFO - Started process (PID=20935) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:22:56.845+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:22:56.848+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:22:56.848+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:22:56.863+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:22:56.884+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:22:56.884+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:22:56.895+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:22:56.895+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:22:56.903+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-29T09:23:27.273+0000] {processor.py:157} INFO - Started process (PID=20960) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:23:27.279+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:23:27.281+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:23:27.281+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:23:27.288+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:23:27.301+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:23:27.301+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:23:27.310+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:23:27.310+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:23:27.317+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-29T09:23:57.778+0000] {processor.py:157} INFO - Started process (PID=20985) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:23:57.784+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:23:57.787+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:23:57.787+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:23:57.795+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:23:57.808+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:23:57.808+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:23:57.818+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:23:57.818+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:23:57.828+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-29T09:24:28.283+0000] {processor.py:157} INFO - Started process (PID=21010) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:24:28.283+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:24:28.286+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:24:28.286+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:24:28.298+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:24:28.317+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:24:28.317+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:24:28.329+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:24:28.329+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:24:28.338+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-29T09:24:58.805+0000] {processor.py:157} INFO - Started process (PID=21035) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:24:58.805+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:24:58.807+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:24:58.807+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:24:58.814+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:24:58.830+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:24:58.830+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:24:58.840+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:24:58.840+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:24:58.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-07-29T09:25:29.285+0000] {processor.py:157} INFO - Started process (PID=21060) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:25:29.290+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:25:29.294+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:25:29.294+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:25:29.303+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:25:29.317+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:25:29.317+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:25:29.327+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:25:29.327+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:25:29.337+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-29T09:25:59.774+0000] {processor.py:157} INFO - Started process (PID=21085) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:25:59.775+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:25:59.777+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:25:59.777+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:25:59.793+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:25:59.817+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:25:59.816+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:25:59.827+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:25:59.827+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:25:59.836+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-29T09:26:30.377+0000] {processor.py:157} INFO - Started process (PID=21109) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:26:30.378+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:26:30.383+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:26:30.382+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:26:30.404+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:26:30.438+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:26:30.438+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:26:30.451+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:26:30.451+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:26:30.461+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-07-29T09:27:00.926+0000] {processor.py:157} INFO - Started process (PID=21135) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:27:00.927+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:27:00.930+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:27:00.930+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:27:00.948+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:27:00.975+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:27:00.975+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:27:00.990+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:27:00.990+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:27:01.002+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-07-29T09:27:31.364+0000] {processor.py:157} INFO - Started process (PID=21160) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:27:31.365+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:27:31.367+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:27:31.367+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:27:31.377+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:27:31.393+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:27:31.393+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:27:31.403+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:27:31.403+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:27:31.413+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-29T09:28:01.841+0000] {processor.py:157} INFO - Started process (PID=21185) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:28:01.842+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:28:01.844+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:28:01.844+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:28:01.860+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:28:01.874+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:28:01.874+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:28:01.884+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:28:01.883+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:28:01.892+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-29T09:28:32.188+0000] {processor.py:157} INFO - Started process (PID=21210) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:28:32.189+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:28:32.191+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:28:32.191+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:28:32.202+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:28:32.225+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:28:32.225+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:28:32.237+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:28:32.237+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:28:32.248+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-29T09:29:02.687+0000] {processor.py:157} INFO - Started process (PID=21235) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:29:02.688+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:29:02.690+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:29:02.690+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:29:02.706+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:29:02.719+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:29:02.719+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:29:02.728+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:29:02.728+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:29:02.738+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-29T09:29:33.143+0000] {processor.py:157} INFO - Started process (PID=21260) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:29:33.145+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:29:33.147+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:29:33.147+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:29:33.160+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:29:33.174+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:29:33.174+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:29:33.189+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:29:33.189+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:29:33.197+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-29T09:30:03.615+0000] {processor.py:157} INFO - Started process (PID=21285) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:30:03.616+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:30:03.618+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:30:03.618+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:30:03.630+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:30:03.645+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:30:03.645+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:30:03.655+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:30:03.655+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:30:03.665+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-29T09:30:34.085+0000] {processor.py:157} INFO - Started process (PID=21310) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:30:34.086+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:30:34.095+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:30:34.095+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:30:34.105+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:30:34.119+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:30:34.119+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:30:34.128+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:30:34.128+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:30:34.137+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-29T09:31:04.569+0000] {processor.py:157} INFO - Started process (PID=21335) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:31:04.575+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:31:04.578+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:31:04.578+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:31:04.589+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:31:04.608+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:31:04.608+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:31:04.620+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:31:04.620+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:31:04.628+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-29T09:31:35.010+0000] {processor.py:157} INFO - Started process (PID=21360) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:31:35.010+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:31:35.013+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:31:35.013+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:31:35.025+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:31:35.042+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:31:35.042+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:31:35.052+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:31:35.052+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:31:35.062+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-29T09:32:05.373+0000] {processor.py:157} INFO - Started process (PID=21385) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:32:05.373+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:32:05.375+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:32:05.375+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:32:05.381+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:32:05.396+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:32:05.396+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:32:05.406+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:32:05.406+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:32:05.416+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-07-29T09:32:35.841+0000] {processor.py:157} INFO - Started process (PID=21410) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:32:35.842+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:32:35.844+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:32:35.844+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:32:35.857+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:32:35.872+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:32:35.872+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:32:35.882+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:32:35.882+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:32:35.893+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-29T09:33:06.308+0000] {processor.py:157} INFO - Started process (PID=21435) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:33:06.308+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:33:06.310+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:33:06.310+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:33:06.323+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:33:06.339+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:33:06.338+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:33:06.352+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:33:06.352+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:33:06.360+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-29T09:33:36.782+0000] {processor.py:157} INFO - Started process (PID=21460) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:33:36.783+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:33:36.787+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:33:36.787+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:33:36.805+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:33:36.828+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:33:36.828+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:33:36.841+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:33:36.841+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:33:36.850+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-29T09:34:07.305+0000] {processor.py:157} INFO - Started process (PID=21485) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:34:07.306+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:34:07.315+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:34:07.315+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:34:07.324+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:34:07.338+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:34:07.338+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:34:07.348+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:34:07.348+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:34:07.356+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-29T09:34:37.822+0000] {processor.py:157} INFO - Started process (PID=21510) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:34:37.822+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:34:37.826+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:34:37.826+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:34:37.840+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:34:37.859+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:34:37.859+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:34:37.870+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:34:37.870+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:34:37.878+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-29T09:35:08.249+0000] {processor.py:157} INFO - Started process (PID=21535) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:35:08.250+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:35:08.252+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:35:08.252+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:35:08.263+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:35:08.282+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:35:08.282+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:35:08.302+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:35:08.302+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:35:08.315+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-29T09:35:38.699+0000] {processor.py:157} INFO - Started process (PID=21560) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:35:38.701+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:35:38.704+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:35:38.704+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:35:38.718+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:35:38.733+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:35:38.733+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:35:38.747+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:35:38.747+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:35:38.756+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-29T09:36:09.298+0000] {processor.py:157} INFO - Started process (PID=21585) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:36:09.299+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:36:09.301+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:36:09.301+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:36:09.317+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:36:09.332+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:36:09.332+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:36:09.343+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:36:09.343+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:36:09.354+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-29T09:36:39.720+0000] {processor.py:157} INFO - Started process (PID=21609) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:36:39.721+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:36:39.725+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:36:39.725+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:36:39.743+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:36:39.769+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:36:39.769+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:36:39.785+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:36:39.785+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:36:39.795+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-07-29T09:37:10.195+0000] {processor.py:157} INFO - Started process (PID=21635) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:37:10.196+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:37:10.197+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:37:10.197+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:37:10.210+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:37:10.225+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:37:10.225+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:37:10.234+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:37:10.234+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:37:10.247+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-29T09:37:40.705+0000] {processor.py:157} INFO - Started process (PID=21660) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:37:40.706+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:37:40.707+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:37:40.707+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:37:40.718+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:37:40.734+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:37:40.734+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:37:40.744+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:37:40.744+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:37:40.755+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-29T09:38:11.227+0000] {processor.py:157} INFO - Started process (PID=21685) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:38:11.227+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:38:11.229+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:38:11.229+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:38:11.238+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:38:11.255+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:38:11.255+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:38:11.269+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:38:11.269+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:38:11.278+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-29T09:38:41.664+0000] {processor.py:157} INFO - Started process (PID=21710) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:38:41.665+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:38:41.666+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:38:41.666+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:38:41.673+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:38:41.685+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:38:41.685+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:38:41.695+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:38:41.695+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:38:41.704+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.041 seconds
[2024-07-29T09:39:12.082+0000] {processor.py:157} INFO - Started process (PID=21735) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:39:12.082+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:39:12.085+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:39:12.084+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:39:12.094+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:39:12.113+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:39:12.113+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:39:12.126+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:39:12.126+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:39:12.135+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-29T09:39:42.609+0000] {processor.py:157} INFO - Started process (PID=21760) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:39:42.614+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:39:42.618+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:39:42.618+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:39:42.631+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:39:42.648+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:39:42.648+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:39:42.660+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:39:42.660+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:39:42.670+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-29T09:40:13.092+0000] {processor.py:157} INFO - Started process (PID=21785) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:40:13.093+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:40:13.098+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:40:13.098+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:40:13.106+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:40:13.122+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:40:13.122+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:40:13.133+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:40:13.133+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:40:13.142+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-29T09:40:43.659+0000] {processor.py:157} INFO - Started process (PID=21810) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:40:43.661+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:40:43.662+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:40:43.662+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:40:43.676+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:40:43.690+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:40:43.690+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:40:43.703+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:40:43.703+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:40:43.714+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-29T09:41:14.166+0000] {processor.py:157} INFO - Started process (PID=21835) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:41:14.167+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:41:14.169+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:41:14.168+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:41:14.180+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:41:14.195+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:41:14.195+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:41:14.206+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:41:14.206+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:41:14.215+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-29T09:41:44.624+0000] {processor.py:157} INFO - Started process (PID=21860) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:41:44.624+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:41:44.627+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:41:44.627+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:41:44.639+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:41:44.659+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:41:44.659+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:41:44.670+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:41:44.670+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:41:44.680+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-29T09:42:15.090+0000] {processor.py:157} INFO - Started process (PID=21885) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:42:15.092+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:42:15.094+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:42:15.094+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:42:15.109+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:42:15.127+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:42:15.127+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:42:15.140+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:42:15.140+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:42:15.150+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-29T09:42:45.589+0000] {processor.py:157} INFO - Started process (PID=21910) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:42:45.590+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:42:45.592+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:42:45.592+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:42:45.603+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:42:45.620+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:42:45.620+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:42:45.633+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:42:45.632+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:42:45.643+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-29T09:43:15.982+0000] {processor.py:157} INFO - Started process (PID=21935) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:43:15.984+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:43:15.986+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:43:15.986+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:43:16.002+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:43:16.015+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:43:16.015+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:43:16.027+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:43:16.027+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:43:16.033+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-29T09:43:46.398+0000] {processor.py:157} INFO - Started process (PID=21960) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:43:46.398+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:43:46.400+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:43:46.400+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:43:46.412+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:43:46.427+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:43:46.427+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:43:46.437+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:43:46.436+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:43:46.447+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-29T09:44:16.956+0000] {processor.py:157} INFO - Started process (PID=21985) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:44:16.957+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:44:16.959+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:44:16.959+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:44:16.971+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:44:16.988+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:44:16.988+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:44:16.999+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:44:16.999+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:44:17.008+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-29T09:44:47.460+0000] {processor.py:157} INFO - Started process (PID=22010) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:44:47.461+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:44:47.463+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:44:47.463+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:44:47.479+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:44:47.492+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:44:47.492+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:44:47.501+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:44:47.501+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:44:47.509+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-29T09:45:17.908+0000] {processor.py:157} INFO - Started process (PID=22035) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:45:17.908+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:45:17.910+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:45:17.910+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:45:17.918+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:45:17.931+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:45:17.931+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:45:17.941+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:45:17.941+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:45:17.949+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.043 seconds
[2024-07-29T09:45:48.336+0000] {processor.py:157} INFO - Started process (PID=22060) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:45:48.337+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:45:48.340+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:45:48.339+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:45:48.351+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:45:48.368+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:45:48.368+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:45:48.381+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:45:48.381+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:45:48.390+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-29T09:46:18.776+0000] {processor.py:157} INFO - Started process (PID=22085) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:46:18.776+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:46:18.779+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:46:18.779+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:46:18.790+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:46:18.806+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:46:18.806+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:46:18.816+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:46:18.816+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:46:18.825+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-29T09:46:49.228+0000] {processor.py:157} INFO - Started process (PID=22110) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:46:49.229+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:46:49.235+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:46:49.235+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:46:49.256+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:46:49.270+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:46:49.270+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:46:49.280+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:46:49.280+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:46:49.290+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-29T09:47:19.714+0000] {processor.py:157} INFO - Started process (PID=22135) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:47:19.716+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:47:19.718+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:47:19.718+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:47:19.730+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:47:19.748+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:47:19.748+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:47:19.761+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:47:19.761+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:47:19.769+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-29T09:47:50.154+0000] {processor.py:157} INFO - Started process (PID=22160) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:47:50.159+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:47:50.161+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:47:50.161+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:47:50.169+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:47:50.183+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:47:50.183+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:47:50.192+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:47:50.192+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:47:50.202+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-29T09:48:20.644+0000] {processor.py:157} INFO - Started process (PID=22185) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:48:20.644+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:48:20.646+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:48:20.646+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:48:20.657+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:48:20.678+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:48:20.678+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:48:20.689+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:48:20.689+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:48:20.696+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-29T09:48:51.054+0000] {processor.py:157} INFO - Started process (PID=22210) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:48:51.054+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:48:51.056+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:48:51.055+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:48:51.063+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:48:51.074+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:48:51.074+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:48:51.085+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:48:51.085+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:48:51.092+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.040 seconds
[2024-07-29T09:49:21.481+0000] {processor.py:157} INFO - Started process (PID=22235) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:49:21.483+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:49:21.485+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:49:21.485+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:49:21.499+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:49:21.514+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:49:21.514+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:49:21.524+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:49:21.524+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:49:21.533+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-29T09:49:51.999+0000] {processor.py:157} INFO - Started process (PID=22260) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:49:52.000+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:49:52.002+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:49:52.002+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:49:52.012+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:49:52.027+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:49:52.027+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:49:52.037+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:49:52.037+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:49:52.045+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-29T09:50:22.537+0000] {processor.py:157} INFO - Started process (PID=22285) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:50:22.537+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:50:22.540+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:50:22.539+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:50:22.551+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:50:22.568+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:50:22.568+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:50:22.579+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:50:22.579+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:50:22.589+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-29T09:50:52.972+0000] {processor.py:157} INFO - Started process (PID=22310) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:50:52.974+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:50:52.976+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:50:52.976+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:50:52.992+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:50:53.004+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:50:53.004+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:50:53.014+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:50:53.014+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:50:53.023+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-29T09:51:23.383+0000] {processor.py:157} INFO - Started process (PID=22335) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:51:23.385+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:51:23.387+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:51:23.387+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:51:23.399+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:51:23.414+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:51:23.414+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:51:23.426+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:51:23.426+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:51:23.436+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-29T09:51:53.885+0000] {processor.py:157} INFO - Started process (PID=22360) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:51:53.887+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:51:53.888+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:51:53.888+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:51:53.900+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:51:53.915+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:51:53.915+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:51:53.925+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:51:53.925+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:51:53.937+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-29T09:52:24.332+0000] {processor.py:157} INFO - Started process (PID=22385) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:52:24.334+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:52:24.335+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:52:24.335+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:52:24.347+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:52:24.359+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:52:24.358+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:52:24.368+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:52:24.368+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:52:24.378+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-29T09:52:54.758+0000] {processor.py:157} INFO - Started process (PID=22410) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:52:54.762+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:52:54.764+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:52:54.764+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:52:54.774+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:52:54.795+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:52:54.795+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:52:54.807+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:52:54.807+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:52:54.816+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-29T09:53:25.280+0000] {processor.py:157} INFO - Started process (PID=22435) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:53:25.283+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:53:25.284+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:53:25.284+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:53:25.296+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:53:25.313+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:53:25.313+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:53:25.324+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:53:25.324+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:53:25.332+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-29T09:53:55.717+0000] {processor.py:157} INFO - Started process (PID=22460) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:53:55.720+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:53:55.721+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:53:55.721+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:53:55.737+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:53:55.752+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:53:55.752+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:53:55.762+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:53:55.762+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:53:55.771+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-29T09:54:26.241+0000] {processor.py:157} INFO - Started process (PID=22485) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:54:26.241+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:54:26.248+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:54:26.248+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:54:26.257+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:54:26.271+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:54:26.271+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:54:26.280+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:54:26.280+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:54:26.290+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-29T09:54:56.646+0000] {processor.py:157} INFO - Started process (PID=22510) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:54:56.647+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:54:56.648+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:54:56.648+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:54:56.658+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:54:56.673+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:54:56.673+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:54:56.683+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:54:56.683+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:54:56.692+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-29T09:55:27.124+0000] {processor.py:157} INFO - Started process (PID=22535) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:55:27.126+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:55:27.128+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:55:27.127+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:55:27.140+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:55:27.156+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:55:27.156+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:55:27.167+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:55:27.166+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:55:27.176+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-29T09:55:57.515+0000] {processor.py:157} INFO - Started process (PID=22560) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:55:57.517+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:55:57.518+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:55:57.518+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:55:57.530+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:55:57.542+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:55:57.542+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:55:57.551+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:55:57.551+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:55:57.563+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-29T09:56:27.938+0000] {processor.py:157} INFO - Started process (PID=22585) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:56:27.940+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:56:27.942+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:56:27.942+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:56:27.953+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:56:27.969+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:56:27.969+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:56:27.978+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:56:27.978+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:56:27.990+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-29T09:56:58.428+0000] {processor.py:157} INFO - Started process (PID=22610) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:56:58.433+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:56:58.435+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:56:58.435+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:56:58.442+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:56:58.455+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:56:58.455+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:56:58.464+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:56:58.464+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:56:58.473+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-29T09:57:28.836+0000] {processor.py:157} INFO - Started process (PID=22635) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:57:28.839+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:57:28.841+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:57:28.841+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:57:28.854+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:57:28.871+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:57:28.871+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:57:28.881+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:57:28.881+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:57:28.890+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-29T09:57:59.325+0000] {processor.py:157} INFO - Started process (PID=22660) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:57:59.325+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:57:59.330+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:57:59.330+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:57:59.346+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:57:59.370+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:57:59.370+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:57:59.384+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:57:59.384+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:57:59.395+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-29T09:58:29.786+0000] {processor.py:157} INFO - Started process (PID=22685) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:58:29.787+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:58:29.795+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:58:29.794+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:58:29.802+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:58:29.815+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:58:29.815+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:58:29.825+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:58:29.825+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:58:29.833+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-29T09:59:00.286+0000] {processor.py:157} INFO - Started process (PID=22710) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:59:00.287+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:59:00.288+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:59:00.288+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:59:00.299+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:59:00.314+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:59:00.314+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:59:00.327+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:59:00.326+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:59:00.336+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-29T09:59:30.762+0000] {processor.py:157} INFO - Started process (PID=22735) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:59:30.762+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T09:59:30.763+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:59:30.763+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:59:30.772+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T09:59:30.786+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:59:30.786+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T09:59:30.797+0000] {logging_mixin.py:151} INFO - [2024-07-29T09:59:30.797+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T09:59:30.805+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.044 seconds
[2024-07-29T10:00:01.190+0000] {processor.py:157} INFO - Started process (PID=22760) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:00:01.190+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T10:00:01.192+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:00:01.192+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:00:01.206+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:00:01.223+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:00:01.223+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:00:01.235+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:00:01.235+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T10:00:01.245+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-29T10:00:31.709+0000] {processor.py:157} INFO - Started process (PID=22785) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:00:31.711+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T10:00:31.713+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:00:31.713+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:00:31.724+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:00:31.740+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:00:31.740+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:00:31.750+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:00:31.750+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T10:00:31.760+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-29T10:01:02.192+0000] {processor.py:157} INFO - Started process (PID=22810) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:01:02.193+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T10:01:02.195+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:01:02.195+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:01:02.208+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:01:02.227+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:01:02.227+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:01:02.240+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:01:02.240+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T10:01:02.249+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-29T10:01:32.646+0000] {processor.py:157} INFO - Started process (PID=22835) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:01:32.648+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T10:01:32.650+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:01:32.650+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:01:32.666+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:01:32.678+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:01:32.678+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:01:32.689+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:01:32.689+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T10:01:32.698+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-29T10:02:03.132+0000] {processor.py:157} INFO - Started process (PID=22860) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:02:03.133+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T10:02:03.135+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:02:03.135+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:02:03.146+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:02:03.165+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:02:03.165+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:02:03.175+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:02:03.175+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T10:02:03.183+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-29T10:02:33.537+0000] {processor.py:157} INFO - Started process (PID=22885) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:02:33.538+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T10:02:33.542+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:02:33.542+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:02:33.554+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:02:33.567+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:02:33.567+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:02:33.577+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:02:33.577+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T10:02:33.587+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-29T10:03:04.017+0000] {processor.py:157} INFO - Started process (PID=22910) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:03:04.018+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T10:03:04.021+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:03:04.021+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:03:04.036+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:03:04.057+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:03:04.057+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:03:04.069+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:03:04.069+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T10:03:04.079+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-29T10:03:34.476+0000] {processor.py:157} INFO - Started process (PID=22935) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:03:34.477+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T10:03:34.479+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:03:34.478+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:03:34.489+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:03:34.508+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:03:34.508+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:03:34.521+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:03:34.520+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T10:03:34.530+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-29T10:04:04.980+0000] {processor.py:157} INFO - Started process (PID=22960) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:04:04.981+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T10:04:04.983+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:04:04.983+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:04:04.999+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:04:05.013+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:04:05.013+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:04:05.023+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:04:05.023+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T10:04:05.035+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-29T10:04:35.440+0000] {processor.py:157} INFO - Started process (PID=22985) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:04:35.442+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T10:04:35.444+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:04:35.444+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:04:35.461+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:04:35.474+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:04:35.474+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:04:35.484+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:04:35.484+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T10:04:35.494+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-29T10:05:05.915+0000] {processor.py:157} INFO - Started process (PID=23010) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:05:05.916+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T10:05:05.923+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:05:05.923+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:05:05.932+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:05:05.944+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:05:05.944+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:05:05.954+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:05:05.954+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T10:05:05.962+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-29T10:05:36.432+0000] {processor.py:157} INFO - Started process (PID=23035) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:05:36.432+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T10:05:36.435+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:05:36.434+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:05:36.445+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:05:36.464+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:05:36.464+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:05:36.475+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:05:36.475+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T10:05:36.484+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-29T10:06:06.990+0000] {processor.py:157} INFO - Started process (PID=23060) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:06:06.991+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T10:06:06.993+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:06:06.993+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:06:07.012+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:06:07.029+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:06:07.029+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:06:07.041+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:06:07.041+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T10:06:07.051+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-29T10:06:37.521+0000] {processor.py:157} INFO - Started process (PID=23085) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:06:37.522+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T10:06:37.530+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:06:37.529+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:06:37.538+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:06:37.552+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:06:37.552+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:06:37.562+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:06:37.562+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T10:06:37.572+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-29T10:07:07.980+0000] {processor.py:157} INFO - Started process (PID=23110) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:07:07.981+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T10:07:07.983+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:07:07.983+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:07:07.998+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:07:08.020+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:07:08.019+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:07:08.030+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:07:08.030+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T10:07:08.039+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-29T10:07:38.530+0000] {processor.py:157} INFO - Started process (PID=23135) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:07:38.537+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T10:07:38.540+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:07:38.540+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:07:38.548+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:07:38.563+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:07:38.563+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:07:38.574+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:07:38.574+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T10:07:38.583+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-29T10:08:09.007+0000] {processor.py:157} INFO - Started process (PID=23160) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:08:09.011+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T10:08:09.015+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:08:09.015+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:08:09.023+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:08:09.037+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:08:09.037+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:08:09.047+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:08:09.046+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T10:08:09.058+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-29T10:08:39.386+0000] {processor.py:157} INFO - Started process (PID=23185) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:08:39.387+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T10:08:39.390+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:08:39.389+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:08:39.401+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:08:39.418+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:08:39.418+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:08:39.432+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:08:39.432+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T10:08:39.442+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-29T10:09:09.813+0000] {processor.py:157} INFO - Started process (PID=23210) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:09:09.814+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T10:09:09.821+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:09:09.820+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:09:09.831+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:09:09.844+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:09:09.844+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:09:09.853+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:09:09.853+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T10:09:09.862+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-29T10:09:40.240+0000] {processor.py:157} INFO - Started process (PID=23235) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:09:40.241+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T10:09:40.242+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:09:40.242+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:09:40.249+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:09:40.260+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:09:40.260+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:09:40.269+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:09:40.269+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T10:09:40.279+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.040 seconds
[2024-07-29T10:10:10.620+0000] {processor.py:157} INFO - Started process (PID=23260) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:10:10.622+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T10:10:10.624+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:10:10.624+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:10:10.641+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:10:10.654+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:10:10.654+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:10:10.665+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:10:10.665+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T10:10:10.675+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-29T10:10:41.093+0000] {processor.py:157} INFO - Started process (PID=23285) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:10:41.094+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T10:10:41.097+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:10:41.096+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:10:41.108+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:10:41.126+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:10:41.126+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:10:41.136+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:10:41.136+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T10:10:41.145+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-29T10:11:11.604+0000] {processor.py:157} INFO - Started process (PID=23310) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:11:11.605+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T10:11:11.607+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:11:11.607+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:11:11.621+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:11:11.637+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:11:11.637+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:11:11.647+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:11:11.647+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T10:11:11.655+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-29T10:11:42.063+0000] {processor.py:157} INFO - Started process (PID=23334) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:11:42.064+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T10:11:42.067+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:11:42.067+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:11:42.085+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:11:42.106+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:11:42.106+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:11:42.117+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:11:42.117+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T10:11:42.126+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-29T10:12:12.533+0000] {processor.py:157} INFO - Started process (PID=23360) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:12:12.534+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T10:12:12.536+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:12:12.536+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:12:12.545+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:12:12.561+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:12:12.561+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:12:12.571+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:12:12.571+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T10:12:12.581+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-29T10:12:42.939+0000] {processor.py:157} INFO - Started process (PID=23385) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:12:42.940+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T10:12:42.942+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:12:42.942+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:12:42.953+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:12:42.969+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:12:42.969+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:12:42.980+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:12:42.980+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T10:12:42.989+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-29T10:13:13.336+0000] {processor.py:157} INFO - Started process (PID=23410) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:13:13.337+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T10:13:13.339+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:13:13.338+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:13:13.349+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:13:13.368+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:13:13.368+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:13:13.381+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:13:13.381+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T10:13:13.391+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-29T10:13:43.873+0000] {processor.py:157} INFO - Started process (PID=23435) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:13:43.874+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T10:13:43.876+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:13:43.875+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:13:43.886+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:13:43.901+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:13:43.901+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:13:43.911+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:13:43.911+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T10:13:43.920+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-29T10:14:14.366+0000] {processor.py:157} INFO - Started process (PID=23460) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:14:14.367+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T10:14:14.369+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:14:14.369+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:14:14.386+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:14:14.401+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:14:14.401+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:14:14.412+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:14:14.412+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T10:14:14.420+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-29T10:14:44.821+0000] {processor.py:157} INFO - Started process (PID=23485) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:14:44.822+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T10:14:44.828+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:14:44.828+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:14:44.837+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:14:44.850+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:14:44.850+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:14:44.860+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:14:44.860+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T10:14:44.868+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-29T10:15:15.300+0000] {processor.py:157} INFO - Started process (PID=23510) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:15:15.301+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T10:15:15.303+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:15:15.303+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:15:15.321+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:15:15.334+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:15:15.334+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:15:15.345+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:15:15.345+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T10:15:15.354+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-29T10:15:45.690+0000] {processor.py:157} INFO - Started process (PID=23535) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:15:45.691+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T10:15:45.693+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:15:45.692+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:15:45.700+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:15:45.715+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:15:45.715+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:15:45.725+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:15:45.725+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T10:15:45.735+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-29T10:16:16.184+0000] {processor.py:157} INFO - Started process (PID=23560) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:16:16.189+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T10:16:16.192+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:16:16.192+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:16:16.199+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:16:16.212+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:16:16.212+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:16:16.221+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:16:16.221+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T10:16:16.232+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-29T10:16:46.590+0000] {processor.py:157} INFO - Started process (PID=23585) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:16:46.590+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T10:16:46.591+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:16:46.591+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:16:46.599+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:16:46.613+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:16:46.613+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:16:46.623+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:16:46.623+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T10:16:46.630+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.042 seconds
[2024-07-29T10:17:16.974+0000] {processor.py:157} INFO - Started process (PID=23610) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:17:16.975+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T10:17:16.976+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:17:16.976+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:17:16.987+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:17:17.009+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:17:17.009+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:17:17.018+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:17:17.018+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T10:17:17.026+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-29T10:17:47.452+0000] {processor.py:157} INFO - Started process (PID=23635) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:17:47.453+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T10:17:47.456+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:17:47.455+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:17:47.469+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:17:47.491+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:17:47.491+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:17:47.502+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:17:47.502+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T10:17:47.513+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-29T10:18:17.895+0000] {processor.py:157} INFO - Started process (PID=23660) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:18:17.896+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T10:18:17.899+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:18:17.899+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:18:17.917+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:18:17.938+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:18:17.938+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:18:17.950+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:18:17.950+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T10:18:17.958+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-29T10:18:48.396+0000] {processor.py:157} INFO - Started process (PID=23685) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:18:48.397+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T10:18:48.399+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:18:48.399+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:18:48.410+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:18:48.426+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:18:48.426+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:18:48.440+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:18:48.440+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T10:18:48.448+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-29T10:19:18.812+0000] {processor.py:157} INFO - Started process (PID=23710) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:19:18.819+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T10:19:18.823+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:19:18.823+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:19:18.830+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:19:18.844+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:19:18.843+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:19:18.852+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:19:18.852+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T10:19:18.861+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-29T10:19:49.294+0000] {processor.py:157} INFO - Started process (PID=23735) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:19:49.295+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T10:19:49.296+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:19:49.296+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:19:49.307+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:19:49.322+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:19:49.322+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:19:49.332+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:19:49.332+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T10:19:49.341+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-29T10:20:19.736+0000] {processor.py:157} INFO - Started process (PID=23760) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:20:19.737+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T10:20:19.738+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:20:19.738+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:20:19.745+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:20:19.761+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:20:19.760+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:20:19.771+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:20:19.771+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T10:20:19.780+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-29T10:20:50.226+0000] {processor.py:157} INFO - Started process (PID=23785) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:20:50.226+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T10:20:50.229+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:20:50.228+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:20:50.242+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:20:50.256+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:20:50.256+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:20:50.267+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:20:50.267+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T10:20:50.279+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-29T10:21:20.719+0000] {processor.py:157} INFO - Started process (PID=23810) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:21:20.720+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T10:21:20.723+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:21:20.722+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:21:20.732+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:21:20.749+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:21:20.749+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:21:20.760+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:21:20.760+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T10:21:20.769+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-29T10:21:51.201+0000] {processor.py:157} INFO - Started process (PID=23835) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:21:51.204+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T10:21:51.206+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:21:51.206+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:21:51.217+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:21:51.235+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:21:51.235+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:21:51.248+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:21:51.247+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T10:21:51.256+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-29T10:22:21.676+0000] {processor.py:157} INFO - Started process (PID=23860) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:22:21.677+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T10:22:21.681+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:22:21.681+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:22:21.699+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:22:21.718+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:22:21.717+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:22:21.727+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:22:21.727+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T10:22:21.735+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-29T10:22:52.036+0000] {processor.py:157} INFO - Started process (PID=23885) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:22:52.037+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T10:22:52.044+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:22:52.044+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:22:52.055+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:22:52.077+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:22:52.077+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:22:52.088+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:22:52.088+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T10:22:52.098+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-29T10:23:22.653+0000] {processor.py:157} INFO - Started process (PID=23910) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:23:22.654+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T10:23:22.657+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:23:22.657+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:23:22.678+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:23:22.702+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:23:22.702+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:23:22.715+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:23:22.715+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T10:23:22.724+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-29T10:23:53.194+0000] {processor.py:157} INFO - Started process (PID=23935) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:23:53.195+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T10:23:53.196+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:23:53.196+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:23:53.203+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:23:53.216+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:23:53.216+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:23:53.227+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:23:53.227+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T10:23:53.237+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.044 seconds
[2024-07-29T10:24:46.100+0000] {processor.py:157} INFO - Started process (PID=23961) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:24:46.102+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T10:24:46.106+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:24:46.105+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:24:46.124+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:24:46.152+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:24:46.152+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:24:46.172+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:24:46.172+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T10:24:46.183+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-07-29T10:25:16.549+0000] {processor.py:157} INFO - Started process (PID=23987) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:25:16.550+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T10:25:16.551+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:25:16.551+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:25:16.560+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:25:16.577+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:25:16.577+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:25:16.587+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:25:16.587+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T10:25:16.595+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-29T10:27:33.722+0000] {processor.py:157} INFO - Started process (PID=24012) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:27:33.725+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T10:27:33.728+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:27:33.727+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:27:33.749+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:27:33.805+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:27:33.805+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:27:33.832+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:27:33.832+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T10:27:33.851+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-07-29T10:28:04.708+0000] {processor.py:157} INFO - Started process (PID=24037) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:28:04.709+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T10:28:04.712+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:28:04.712+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:28:04.730+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:28:04.755+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:28:04.755+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:28:04.766+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:28:04.766+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T10:28:04.775+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-29T10:28:35.224+0000] {processor.py:157} INFO - Started process (PID=24062) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:28:35.225+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T10:28:35.227+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:28:35.227+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:28:35.241+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:28:35.257+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:28:35.257+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:28:35.270+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:28:35.270+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T10:28:35.280+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-29T10:29:38.972+0000] {processor.py:157} INFO - Started process (PID=24086) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:29:38.973+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T10:29:38.978+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:29:38.977+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:29:39.010+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:29:39.041+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:29:39.041+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:29:39.056+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:29:39.056+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T10:29:39.067+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-07-29T10:30:37.984+0000] {processor.py:157} INFO - Started process (PID=24114) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:30:37.986+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T10:30:37.987+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:30:37.987+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:30:38.004+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:30:38.017+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:30:38.017+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:30:38.031+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:30:38.031+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T10:30:38.039+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-29T10:42:49.982+0000] {processor.py:157} INFO - Started process (PID=24139) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:42:49.983+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T10:42:49.992+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:42:49.991+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:42:50.027+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:42:50.083+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:42:50.083+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:42:50.112+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:42:50.112+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T10:42:50.143+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.168 seconds
[2024-07-29T10:43:20.784+0000] {processor.py:157} INFO - Started process (PID=24164) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:43:20.786+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T10:43:20.791+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:43:20.790+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:43:20.814+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:43:20.848+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:43:20.848+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:43:20.864+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:43:20.864+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T10:43:20.874+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-07-29T10:43:51.244+0000] {processor.py:157} INFO - Started process (PID=24189) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:43:51.246+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T10:43:51.248+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:43:51.247+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:43:51.264+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:43:51.279+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:43:51.279+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:43:51.290+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:43:51.289+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T10:43:51.299+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-29T10:44:21.650+0000] {processor.py:157} INFO - Started process (PID=24214) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:44:21.654+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T10:44:21.657+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:44:21.657+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:44:21.676+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:44:21.700+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:44:21.700+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:44:21.713+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:44:21.713+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T10:44:21.725+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-07-29T10:44:52.050+0000] {processor.py:157} INFO - Started process (PID=24239) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:44:52.051+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T10:44:52.053+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:44:52.052+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:44:52.064+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:44:52.080+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:44:52.080+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:44:52.090+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:44:52.090+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T10:44:52.102+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-29T10:45:22.551+0000] {processor.py:157} INFO - Started process (PID=24264) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:45:22.552+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T10:45:22.554+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:45:22.554+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:45:22.572+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:45:22.594+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:45:22.594+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:45:22.608+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:45:22.607+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T10:45:22.614+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-29T10:45:52.914+0000] {processor.py:157} INFO - Started process (PID=24289) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:45:52.915+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T10:45:52.917+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:45:52.917+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:45:52.926+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:45:52.940+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:45:52.940+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:45:52.948+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:45:52.948+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T10:45:52.957+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-07-29T10:46:23.364+0000] {processor.py:157} INFO - Started process (PID=24314) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:46:23.366+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T10:46:23.369+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:46:23.369+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:46:23.391+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:46:23.410+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:46:23.410+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:46:23.422+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:46:23.422+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T10:46:23.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-29T10:46:53.876+0000] {processor.py:157} INFO - Started process (PID=24339) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:46:53.878+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T10:46:53.881+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:46:53.881+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:46:53.897+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:46:53.912+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:46:53.912+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:46:53.923+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:46:53.923+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T10:46:53.932+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-29T10:47:24.240+0000] {processor.py:157} INFO - Started process (PID=24364) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:47:24.241+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T10:47:24.243+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:47:24.242+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:47:24.258+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:47:24.274+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:47:24.274+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:47:24.286+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:47:24.286+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T10:47:24.295+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-29T10:47:54.672+0000] {processor.py:157} INFO - Started process (PID=24389) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:47:54.673+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T10:47:54.674+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:47:54.674+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:47:54.688+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:47:54.701+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:47:54.701+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:47:54.710+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:47:54.710+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T10:47:54.719+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-29T10:48:25.087+0000] {processor.py:157} INFO - Started process (PID=24414) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:48:25.088+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T10:48:25.090+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:48:25.090+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:48:25.103+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:48:25.122+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:48:25.122+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:48:25.131+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:48:25.131+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T10:48:25.140+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-29T10:48:55.570+0000] {processor.py:157} INFO - Started process (PID=24439) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:48:55.572+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T10:48:55.575+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:48:55.575+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:48:55.593+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:48:55.614+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:48:55.614+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:48:55.627+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:48:55.627+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T10:48:55.637+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-29T10:49:25.967+0000] {processor.py:157} INFO - Started process (PID=24464) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:49:25.969+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T10:49:25.970+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:49:25.970+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:49:25.980+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:49:25.994+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:49:25.994+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:49:26.007+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:49:26.007+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T10:49:26.016+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-29T10:49:56.436+0000] {processor.py:157} INFO - Started process (PID=24489) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:49:56.438+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T10:49:56.440+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:49:56.440+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:49:56.455+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:49:56.470+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:49:56.470+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:49:56.481+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:49:56.481+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T10:49:56.490+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-29T10:50:26.894+0000] {processor.py:157} INFO - Started process (PID=24514) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:50:26.896+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T10:50:26.899+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:50:26.899+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:50:26.911+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:50:26.927+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:50:26.927+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:50:26.940+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:50:26.940+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T10:50:26.951+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-29T10:50:57.364+0000] {processor.py:157} INFO - Started process (PID=24539) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:50:57.365+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T10:50:57.368+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:50:57.368+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:50:57.386+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:50:57.408+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:50:57.408+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:50:57.420+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:50:57.420+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T10:50:57.431+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-29T10:51:27.821+0000] {processor.py:157} INFO - Started process (PID=24564) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:51:27.823+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T10:51:27.824+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:51:27.824+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:51:27.840+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:51:27.855+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:51:27.855+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:51:27.865+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:51:27.865+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T10:51:27.873+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-29T10:51:58.298+0000] {processor.py:157} INFO - Started process (PID=24589) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:51:58.301+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T10:51:58.304+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:51:58.304+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:51:58.324+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:51:58.346+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:51:58.346+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:51:58.359+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:51:58.359+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T10:51:58.369+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-29T10:52:28.767+0000] {processor.py:157} INFO - Started process (PID=24614) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:52:28.769+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T10:52:28.773+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:52:28.773+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:52:28.786+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:52:28.802+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:52:28.802+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:52:28.814+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:52:28.813+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T10:52:28.823+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-29T10:52:59.148+0000] {processor.py:157} INFO - Started process (PID=24639) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:52:59.148+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T10:52:59.150+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:52:59.150+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:52:59.159+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:52:59.173+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:52:59.173+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:52:59.184+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:52:59.184+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T10:52:59.193+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-29T10:53:29.550+0000] {processor.py:157} INFO - Started process (PID=24664) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:53:29.555+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T10:53:29.557+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:53:29.557+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:53:29.567+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:53:29.581+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:53:29.581+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:53:29.592+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:53:29.591+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T10:53:29.601+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-29T10:54:00.025+0000] {processor.py:157} INFO - Started process (PID=24689) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:54:00.026+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T10:54:00.028+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:54:00.027+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:54:00.038+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:54:00.054+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:54:00.054+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:54:00.066+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:54:00.066+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T10:54:00.075+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-29T10:54:30.433+0000] {processor.py:157} INFO - Started process (PID=24714) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:54:30.439+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T10:54:30.441+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:54:30.441+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:54:30.451+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:54:30.466+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:54:30.466+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:54:30.476+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:54:30.476+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T10:54:30.484+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-29T10:55:00.841+0000] {processor.py:157} INFO - Started process (PID=24739) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:55:00.842+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T10:55:00.844+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:55:00.844+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:55:00.855+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:55:00.871+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:55:00.871+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:55:00.883+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:55:00.883+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T10:55:00.891+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-29T10:55:31.336+0000] {processor.py:157} INFO - Started process (PID=24764) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:55:31.337+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T10:55:31.339+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:55:31.339+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:55:31.352+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:55:31.366+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:55:31.366+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:55:31.378+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:55:31.378+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T10:55:31.387+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-29T10:56:01.730+0000] {processor.py:157} INFO - Started process (PID=24789) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:56:01.734+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T10:56:01.735+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:56:01.735+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:56:01.749+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:56:01.764+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:56:01.764+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:56:01.777+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:56:01.777+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T10:56:01.784+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-29T10:56:32.231+0000] {processor.py:157} INFO - Started process (PID=24813) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:56:32.232+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T10:56:32.236+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:56:32.236+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:56:32.260+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:56:32.287+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:56:32.287+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:56:32.302+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:56:32.302+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T10:56:32.312+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-07-29T10:57:02.666+0000] {processor.py:157} INFO - Started process (PID=24839) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:57:02.667+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T10:57:02.669+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:57:02.668+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:57:02.682+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:57:02.698+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:57:02.698+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:57:02.708+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:57:02.708+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T10:57:02.716+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-29T10:57:33.119+0000] {processor.py:157} INFO - Started process (PID=24864) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:57:33.120+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T10:57:33.122+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:57:33.122+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:57:33.135+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:57:33.152+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:57:33.152+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:57:33.162+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:57:33.162+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T10:57:33.171+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-29T10:58:03.580+0000] {processor.py:157} INFO - Started process (PID=24889) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:58:03.581+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T10:58:03.583+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:58:03.583+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:58:03.595+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:58:03.611+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:58:03.611+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:58:03.621+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:58:03.621+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T10:58:03.629+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-29T10:58:34.021+0000] {processor.py:157} INFO - Started process (PID=24914) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:58:34.022+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T10:58:34.024+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:58:34.024+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:58:34.036+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:58:34.052+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:58:34.052+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:58:34.062+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:58:34.062+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T10:58:34.074+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-29T10:59:04.542+0000] {processor.py:157} INFO - Started process (PID=24939) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:59:04.543+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T10:59:04.545+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:59:04.544+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:59:04.556+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:59:04.573+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:59:04.573+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:59:04.583+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:59:04.583+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T10:59:04.593+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-29T10:59:35.024+0000] {processor.py:157} INFO - Started process (PID=24964) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:59:35.028+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T10:59:35.030+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:59:35.029+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:59:35.043+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T10:59:35.058+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:59:35.058+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T10:59:35.068+0000] {logging_mixin.py:151} INFO - [2024-07-29T10:59:35.068+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T10:59:35.077+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-29T11:00:05.478+0000] {processor.py:157} INFO - Started process (PID=24989) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:00:05.479+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:00:05.481+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:00:05.481+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:00:05.495+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:00:05.518+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:00:05.518+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:00:05.532+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:00:05.531+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:00:05.541+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-29T11:00:35.909+0000] {processor.py:157} INFO - Started process (PID=25014) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:00:35.910+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:00:35.912+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:00:35.912+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:00:35.927+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:00:35.941+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:00:35.941+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:00:35.952+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:00:35.952+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:00:35.961+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-29T11:01:06.342+0000] {processor.py:157} INFO - Started process (PID=25039) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:01:06.343+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:01:06.345+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:01:06.345+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:01:06.355+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:01:06.370+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:01:06.370+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:01:06.381+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:01:06.381+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:01:06.390+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-29T11:01:36.704+0000] {processor.py:157} INFO - Started process (PID=25064) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:01:36.704+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:01:36.706+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:01:36.706+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:01:36.717+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:01:36.731+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:01:36.730+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:01:36.741+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:01:36.741+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:01:36.753+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-29T11:02:07.129+0000] {processor.py:157} INFO - Started process (PID=25089) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:02:07.132+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:02:07.134+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:02:07.134+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:02:07.146+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:02:07.160+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:02:07.160+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:02:07.170+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:02:07.170+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:02:07.179+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-29T11:02:37.660+0000] {processor.py:157} INFO - Started process (PID=25114) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:02:37.660+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:02:37.662+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:02:37.662+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:02:37.677+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:02:37.690+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:02:37.690+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:02:37.703+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:02:37.703+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:02:37.712+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-29T11:03:08.187+0000] {processor.py:157} INFO - Started process (PID=25139) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:03:08.188+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:03:08.191+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:03:08.191+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:03:08.208+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:03:08.238+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:03:08.238+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:03:08.250+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:03:08.250+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:03:08.260+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-29T11:03:38.710+0000] {processor.py:157} INFO - Started process (PID=25164) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:03:38.711+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:03:38.712+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:03:38.712+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:03:38.727+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:03:38.741+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:03:38.741+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:03:38.751+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:03:38.751+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:03:38.760+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-29T11:04:09.238+0000] {processor.py:157} INFO - Started process (PID=25189) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:04:09.239+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:04:09.242+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:04:09.242+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:04:09.256+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:04:09.272+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:04:09.272+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:04:09.281+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:04:09.281+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:04:09.290+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-29T11:04:39.701+0000] {processor.py:157} INFO - Started process (PID=25214) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:04:39.704+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:04:39.706+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:04:39.706+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:04:39.719+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:04:39.734+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:04:39.734+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:04:39.744+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:04:39.744+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:04:39.752+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-29T11:05:10.186+0000] {processor.py:157} INFO - Started process (PID=25239) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:05:10.189+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:05:10.193+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:05:10.192+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:05:10.208+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:05:10.231+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:05:10.230+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:05:10.242+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:05:10.242+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:05:10.250+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-29T11:05:40.784+0000] {processor.py:157} INFO - Started process (PID=25264) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:05:40.784+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:05:40.786+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:05:40.786+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:05:40.798+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:05:40.816+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:05:40.816+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:05:40.830+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:05:40.830+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:05:40.839+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-29T11:06:11.273+0000] {processor.py:157} INFO - Started process (PID=25289) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:06:11.275+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:06:11.277+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:06:11.276+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:06:11.291+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:06:11.310+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:06:11.310+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:06:11.322+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:06:11.322+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:06:11.330+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-29T11:06:41.741+0000] {processor.py:157} INFO - Started process (PID=25314) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:06:41.742+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:06:41.744+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:06:41.744+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:06:41.760+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:06:41.776+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:06:41.775+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:06:41.788+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:06:41.788+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:06:41.797+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-29T11:07:12.183+0000] {processor.py:157} INFO - Started process (PID=25339) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:07:12.185+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:07:12.186+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:07:12.186+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:07:12.199+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:07:12.214+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:07:12.214+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:07:12.225+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:07:12.225+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:07:12.235+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-29T11:07:42.584+0000] {processor.py:157} INFO - Started process (PID=25364) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:07:42.585+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:07:42.588+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:07:42.587+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:07:42.599+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:07:42.614+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:07:42.614+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:07:42.624+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:07:42.624+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:07:42.634+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-29T11:08:13.053+0000] {processor.py:157} INFO - Started process (PID=25389) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:08:13.055+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:08:13.059+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:08:13.058+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:08:13.085+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:08:13.110+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:08:13.110+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:08:13.125+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:08:13.125+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:08:13.135+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-07-29T11:08:43.565+0000] {processor.py:157} INFO - Started process (PID=25414) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:08:43.566+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:08:43.568+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:08:43.568+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:08:43.583+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:08:43.597+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:08:43.597+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:08:43.610+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:08:43.610+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:08:43.619+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-29T11:09:13.990+0000] {processor.py:157} INFO - Started process (PID=25439) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:09:13.991+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:09:13.993+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:09:13.993+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:09:14.006+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:09:14.022+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:09:14.022+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:09:14.031+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:09:14.031+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:09:14.041+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-29T11:09:44.384+0000] {processor.py:157} INFO - Started process (PID=25464) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:09:44.386+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:09:44.387+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:09:44.387+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:09:44.397+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:09:44.414+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:09:44.414+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:09:44.424+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:09:44.424+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:09:44.435+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-29T11:10:14.846+0000] {processor.py:157} INFO - Started process (PID=25489) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:10:14.847+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:10:14.848+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:10:14.848+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:10:14.862+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:10:14.878+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:10:14.878+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:10:14.888+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:10:14.888+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:10:14.898+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-29T11:10:45.241+0000] {processor.py:157} INFO - Started process (PID=25514) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:10:45.242+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:10:45.246+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:10:45.245+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:10:45.267+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:10:45.296+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:10:45.296+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:10:45.320+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:10:45.320+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:10:45.331+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-07-29T11:11:15.851+0000] {processor.py:157} INFO - Started process (PID=25539) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:11:15.854+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:11:15.856+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:11:15.856+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:11:15.882+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:11:15.911+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:11:15.911+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:11:15.924+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:11:15.924+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:11:15.935+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-07-29T11:11:46.367+0000] {processor.py:157} INFO - Started process (PID=25564) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:11:46.373+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:11:46.377+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:11:46.377+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:11:46.406+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:11:46.476+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:11:46.475+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:11:46.491+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:11:46.491+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:11:46.507+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.147 seconds
[2024-07-29T11:12:17.023+0000] {processor.py:157} INFO - Started process (PID=25589) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:12:17.027+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:12:17.038+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:12:17.036+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:12:17.092+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:12:17.123+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:12:17.123+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:12:17.142+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:12:17.142+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:12:17.154+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.163 seconds
[2024-07-29T11:12:47.640+0000] {processor.py:157} INFO - Started process (PID=25614) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:12:47.642+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:12:47.647+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:12:47.646+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:12:47.672+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:12:47.700+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:12:47.700+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:12:47.715+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:12:47.715+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:12:47.726+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-07-29T11:13:18.206+0000] {processor.py:157} INFO - Started process (PID=25639) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:13:18.210+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:13:18.213+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:13:18.213+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:13:18.235+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:13:18.278+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:13:18.278+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:13:18.294+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:13:18.294+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:13:18.305+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-07-29T11:13:48.698+0000] {processor.py:157} INFO - Started process (PID=25664) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:13:48.700+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:13:48.727+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:13:48.726+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:13:48.755+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:13:48.819+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:13:48.819+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:13:48.838+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:13:48.838+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:13:48.850+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.158 seconds
[2024-07-29T11:14:19.273+0000] {processor.py:157} INFO - Started process (PID=25689) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:14:19.275+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:14:19.279+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:14:19.279+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:14:19.299+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:14:19.327+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:14:19.327+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:14:19.348+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:14:19.348+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:14:19.357+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-07-29T11:14:49.783+0000] {processor.py:157} INFO - Started process (PID=25714) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:14:49.784+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:14:49.786+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:14:49.786+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:14:49.799+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:14:49.814+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:14:49.814+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:14:49.824+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:14:49.824+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:14:49.833+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-29T11:15:20.226+0000] {processor.py:157} INFO - Started process (PID=25739) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:15:20.232+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:15:20.234+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:15:20.234+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:15:20.243+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:15:20.256+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:15:20.256+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:15:20.265+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:15:20.265+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:15:20.274+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-29T11:15:50.637+0000] {processor.py:157} INFO - Started process (PID=25764) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:15:50.638+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:15:50.641+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:15:50.640+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:15:50.651+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:15:50.668+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:15:50.668+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:15:50.679+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:15:50.678+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:15:50.689+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-29T11:16:21.138+0000] {processor.py:157} INFO - Started process (PID=25789) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:16:21.143+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:16:21.149+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:16:21.148+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:16:21.181+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:16:21.220+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:16:21.220+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:16:21.237+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:16:21.236+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:16:21.249+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-07-29T11:16:51.631+0000] {processor.py:157} INFO - Started process (PID=25814) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:16:51.632+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:16:51.634+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:16:51.634+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:16:51.648+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:16:51.662+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:16:51.662+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:16:51.674+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:16:51.674+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:16:51.683+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-29T11:17:22.128+0000] {processor.py:157} INFO - Started process (PID=25839) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:17:22.130+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:17:22.132+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:17:22.132+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:17:22.143+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:17:22.162+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:17:22.162+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:17:22.175+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:17:22.175+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:17:22.184+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-29T11:17:52.541+0000] {processor.py:157} INFO - Started process (PID=25864) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:17:52.546+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:17:52.548+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:17:52.548+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:17:52.570+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:17:52.619+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:17:52.619+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:17:52.632+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:17:52.632+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:17:52.641+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-07-29T11:18:23.081+0000] {processor.py:157} INFO - Started process (PID=25888) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:18:23.088+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:18:23.092+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:18:23.092+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:18:23.113+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:18:23.140+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:18:23.140+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:18:23.154+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:18:23.154+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:18:23.163+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-07-29T11:18:53.562+0000] {processor.py:157} INFO - Started process (PID=25914) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:18:53.569+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:18:53.573+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:18:53.572+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:18:53.584+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:18:53.606+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:18:53.606+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:18:53.620+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:18:53.620+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:18:53.630+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-29T11:19:24.045+0000] {processor.py:157} INFO - Started process (PID=25939) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:19:24.047+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:19:24.049+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:19:24.049+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:19:24.061+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:19:24.077+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:19:24.077+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:19:24.088+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:19:24.088+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:19:24.096+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-29T11:19:54.465+0000] {processor.py:157} INFO - Started process (PID=25964) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:19:54.466+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:19:54.469+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:19:54.469+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:19:54.483+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:19:54.504+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:19:54.504+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:19:54.515+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:19:54.515+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:19:54.526+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-29T11:20:24.942+0000] {processor.py:157} INFO - Started process (PID=25989) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:20:24.944+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:20:24.947+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:20:24.947+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:20:24.966+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:20:24.985+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:20:24.985+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:20:24.999+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:20:24.998+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:20:25.008+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-29T11:20:55.465+0000] {processor.py:157} INFO - Started process (PID=26014) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:20:55.467+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:20:55.470+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:20:55.469+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:20:55.489+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:20:55.511+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:20:55.511+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:20:55.524+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:20:55.524+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:20:55.533+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-29T11:21:26.310+0000] {processor.py:157} INFO - Started process (PID=26039) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:21:26.312+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:21:26.318+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:21:26.317+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:21:26.349+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:21:26.378+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:21:26.378+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:21:26.397+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:21:26.397+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:21:26.410+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-07-29T11:21:56.879+0000] {processor.py:157} INFO - Started process (PID=26064) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:21:56.886+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:21:56.890+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:21:56.889+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:21:56.916+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:21:56.936+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:21:56.935+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:21:56.950+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:21:56.950+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:21:56.962+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-07-29T11:22:27.386+0000] {processor.py:157} INFO - Started process (PID=26089) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:22:27.388+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:22:27.390+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:22:27.389+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:22:27.401+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:22:27.422+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:22:27.422+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:22:27.437+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:22:27.437+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:22:27.446+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-29T11:22:57.955+0000] {processor.py:157} INFO - Started process (PID=26114) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:22:57.958+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:22:57.961+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:22:57.961+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:22:57.982+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:22:58.007+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:22:58.006+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:22:58.022+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:22:58.022+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:22:58.033+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-07-29T11:23:28.402+0000] {processor.py:157} INFO - Started process (PID=26139) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:23:28.403+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:23:28.405+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:23:28.405+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:23:28.417+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:23:28.435+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:23:28.435+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:23:28.445+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:23:28.445+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:23:28.455+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-29T11:23:58.850+0000] {processor.py:157} INFO - Started process (PID=26164) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:23:58.853+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:23:58.856+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:23:58.856+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:23:58.876+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:23:58.901+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:23:58.901+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:23:58.913+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:23:58.913+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:23:58.923+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-29T11:24:29.490+0000] {processor.py:157} INFO - Started process (PID=26189) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:24:29.494+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:24:29.500+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:24:29.499+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:24:29.522+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:24:29.555+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:24:29.555+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:24:29.570+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:24:29.570+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:24:29.580+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-07-29T11:24:59.960+0000] {processor.py:157} INFO - Started process (PID=26214) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:24:59.961+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:24:59.963+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:24:59.963+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:24:59.976+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:24:59.995+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:24:59.995+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:25:00.007+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:25:00.007+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:25:00.017+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-29T11:25:30.425+0000] {processor.py:157} INFO - Started process (PID=26239) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:25:30.427+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:25:30.429+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:25:30.429+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:25:30.443+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:25:30.465+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:25:30.465+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:25:30.477+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:25:30.477+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:25:30.487+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-29T11:26:00.932+0000] {processor.py:157} INFO - Started process (PID=26264) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:26:00.934+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:26:00.937+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:26:00.937+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:26:00.955+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:26:00.979+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:26:00.979+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:26:00.992+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:26:00.992+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:26:01.002+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-29T11:26:31.552+0000] {processor.py:157} INFO - Started process (PID=26289) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:26:31.554+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:26:31.560+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:26:31.559+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:26:31.582+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:26:31.611+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:26:31.611+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:26:31.629+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:26:31.629+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:26:31.641+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-07-29T11:27:02.128+0000] {processor.py:157} INFO - Started process (PID=26314) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:27:02.132+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:27:02.138+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:27:02.138+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:27:02.196+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:27:02.259+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:27:02.259+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:27:02.274+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:27:02.274+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:27:02.284+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.162 seconds
[2024-07-29T11:27:32.670+0000] {processor.py:157} INFO - Started process (PID=26339) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:27:32.675+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:27:32.679+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:27:32.678+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:27:32.699+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:27:32.727+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:27:32.727+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:27:32.742+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:27:32.742+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:27:32.752+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-07-29T11:28:03.266+0000] {processor.py:157} INFO - Started process (PID=26364) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:28:03.269+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:28:03.274+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:28:03.273+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:28:03.298+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:28:03.340+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:28:03.340+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:28:03.358+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:28:03.358+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:28:03.368+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-07-29T11:28:33.792+0000] {processor.py:157} INFO - Started process (PID=26389) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:28:33.796+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:28:33.807+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:28:33.806+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:28:33.849+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:28:33.892+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:28:33.891+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:28:33.908+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:28:33.908+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:28:33.919+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-07-29T11:29:04.307+0000] {processor.py:157} INFO - Started process (PID=26414) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:29:04.308+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:29:04.309+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:29:04.309+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:29:04.324+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:29:04.338+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:29:04.338+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:29:04.349+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:29:04.349+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:29:04.357+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-29T11:29:34.696+0000] {processor.py:157} INFO - Started process (PID=26439) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:29:34.698+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:29:34.700+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:29:34.700+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:29:34.716+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:29:34.739+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:29:34.739+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:29:34.752+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:29:34.752+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:29:34.763+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-29T11:30:05.195+0000] {processor.py:157} INFO - Started process (PID=26464) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:30:05.196+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:30:05.198+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:30:05.197+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:30:05.216+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:30:05.245+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:30:05.245+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:30:05.260+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:30:05.260+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:30:05.273+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-07-29T11:30:35.644+0000] {processor.py:157} INFO - Started process (PID=26489) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:30:35.646+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:30:35.648+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:30:35.648+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:30:35.663+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:30:35.677+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:30:35.677+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:30:35.690+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:30:35.690+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:30:35.698+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-29T11:31:06.053+0000] {processor.py:157} INFO - Started process (PID=26514) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:31:06.056+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:31:06.059+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:31:06.059+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:31:06.069+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:31:06.087+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:31:06.087+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:31:06.097+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:31:06.097+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:31:06.108+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-29T11:31:36.535+0000] {processor.py:157} INFO - Started process (PID=26539) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:31:36.539+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:31:36.542+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:31:36.542+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:31:36.560+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:31:36.576+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:31:36.576+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:31:36.589+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:31:36.588+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:31:36.596+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-29T11:32:06.890+0000] {processor.py:157} INFO - Started process (PID=26564) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:32:06.892+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:32:06.894+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:32:06.894+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:32:06.911+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:32:06.930+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:32:06.929+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:32:06.944+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:32:06.944+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:32:06.955+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-29T11:32:37.389+0000] {processor.py:157} INFO - Started process (PID=26589) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:32:37.390+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:32:37.392+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:32:37.392+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:32:37.409+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:32:37.424+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:32:37.423+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:32:37.435+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:32:37.435+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:32:37.443+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-29T11:33:07.879+0000] {processor.py:157} INFO - Started process (PID=26614) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:33:07.881+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:33:07.886+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:33:07.886+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:33:07.910+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:33:07.934+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:33:07.934+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:33:07.954+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:33:07.954+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:33:07.976+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-07-29T11:33:38.343+0000] {processor.py:157} INFO - Started process (PID=26639) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:33:38.345+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:33:38.347+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:33:38.347+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:33:38.361+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:33:38.379+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:33:38.379+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:33:38.391+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:33:38.391+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:33:38.402+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-29T11:34:08.862+0000] {processor.py:157} INFO - Started process (PID=26664) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:34:08.864+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:34:08.867+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:34:08.866+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:34:08.886+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:34:08.916+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:34:08.916+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:34:08.938+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:34:08.938+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:34:08.950+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-07-29T11:34:39.389+0000] {processor.py:157} INFO - Started process (PID=26689) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:34:39.394+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:34:39.401+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:34:39.400+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:34:39.441+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:34:39.498+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:34:39.498+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:34:39.512+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:34:39.512+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:34:39.525+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.142 seconds
[2024-07-29T11:35:09.970+0000] {processor.py:157} INFO - Started process (PID=26714) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:35:09.972+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:35:09.975+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:35:09.975+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:35:09.993+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:35:10.020+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:35:10.020+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:35:10.036+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:35:10.036+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:35:10.049+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-07-29T11:35:40.531+0000] {processor.py:157} INFO - Started process (PID=26739) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:35:40.535+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:35:40.542+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:35:40.541+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:35:40.564+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:35:40.593+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:35:40.593+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:35:40.607+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:35:40.607+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:35:40.619+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-07-29T11:36:11.047+0000] {processor.py:157} INFO - Started process (PID=26764) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:36:11.049+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:36:11.052+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:36:11.052+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:36:11.072+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:36:11.096+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:36:11.096+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:36:11.109+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:36:11.109+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:36:11.120+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-29T11:36:41.629+0000] {processor.py:157} INFO - Started process (PID=26789) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:36:41.631+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:36:41.635+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:36:41.634+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:36:41.661+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:36:41.688+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:36:41.688+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:36:41.704+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:36:41.704+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:36:41.713+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-07-29T11:37:12.078+0000] {processor.py:157} INFO - Started process (PID=26814) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:37:12.080+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:37:12.082+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:37:12.082+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:37:12.093+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:37:12.111+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:37:12.111+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:37:12.123+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:37:12.123+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:37:12.132+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-29T11:37:42.471+0000] {processor.py:157} INFO - Started process (PID=26839) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:37:42.472+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:37:42.474+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:37:42.473+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:37:42.489+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:37:42.502+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:37:42.502+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:37:42.514+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:37:42.514+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:37:42.525+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-29T11:38:12.946+0000] {processor.py:157} INFO - Started process (PID=26864) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:38:12.948+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:38:12.951+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:38:12.951+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:38:12.969+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:38:12.994+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:38:12.994+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:38:13.008+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:38:13.008+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:38:13.019+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-29T11:38:43.470+0000] {processor.py:157} INFO - Started process (PID=26889) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:38:43.474+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:38:43.479+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:38:43.478+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:38:43.499+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:38:43.531+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:38:43.530+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:38:43.546+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:38:43.546+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:38:43.560+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-07-29T11:39:14.362+0000] {processor.py:157} INFO - Started process (PID=26914) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:39:14.367+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:39:14.370+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:39:14.369+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:39:14.390+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:39:14.424+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:39:14.424+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:39:14.442+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:39:14.442+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:39:14.453+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-07-29T11:39:44.951+0000] {processor.py:157} INFO - Started process (PID=26939) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:39:44.953+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:39:44.956+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:39:44.955+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:39:44.978+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:39:44.997+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:39:44.997+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:39:45.011+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:39:45.011+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:39:45.023+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-29T11:40:15.443+0000] {processor.py:157} INFO - Started process (PID=26964) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:40:15.447+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:40:15.449+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:40:15.449+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:40:15.462+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:40:15.477+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:40:15.477+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:40:15.488+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:40:15.488+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:40:15.496+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-29T11:40:45.877+0000] {processor.py:157} INFO - Started process (PID=26989) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:40:45.879+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:40:45.881+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:40:45.881+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:40:45.893+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:40:45.909+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:40:45.908+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:40:45.918+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:40:45.918+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:40:45.927+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-29T11:41:16.277+0000] {processor.py:157} INFO - Started process (PID=27013) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:41:16.279+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:41:16.281+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:41:16.281+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:41:16.294+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:41:16.318+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:41:16.318+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:41:16.332+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:41:16.332+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:41:16.342+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-29T11:41:46.762+0000] {processor.py:157} INFO - Started process (PID=27039) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:41:46.763+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:41:46.765+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:41:46.764+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:41:46.774+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:41:46.791+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:41:46.791+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:41:46.802+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:41:46.802+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:41:46.811+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-29T11:42:17.195+0000] {processor.py:157} INFO - Started process (PID=27064) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:42:17.196+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:42:17.197+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:42:17.197+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:42:17.205+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:42:17.220+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:42:17.220+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:42:17.230+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:42:17.230+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:42:17.237+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.044 seconds
[2024-07-29T11:42:47.672+0000] {processor.py:157} INFO - Started process (PID=27089) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:42:47.673+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:42:47.676+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:42:47.676+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:42:47.687+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:42:47.705+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:42:47.705+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:42:47.717+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:42:47.717+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:42:47.726+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-29T11:43:18.155+0000] {processor.py:157} INFO - Started process (PID=27114) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:43:18.158+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:43:18.161+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:43:18.161+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:43:18.175+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:43:18.192+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:43:18.192+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:43:18.205+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:43:18.205+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:43:18.214+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-29T11:43:48.658+0000] {processor.py:157} INFO - Started process (PID=27139) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:43:48.660+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:43:48.662+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:43:48.662+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:43:48.686+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:43:48.703+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:43:48.703+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:43:48.716+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:43:48.716+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:43:48.726+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-29T11:44:19.165+0000] {processor.py:157} INFO - Started process (PID=27164) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:44:19.165+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:44:19.166+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:44:19.166+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:44:19.173+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:44:19.186+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:44:19.186+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:44:19.195+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:44:19.195+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:44:19.204+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.041 seconds
[2024-07-29T11:44:49.628+0000] {processor.py:157} INFO - Started process (PID=27189) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:44:49.630+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:44:49.633+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:44:49.633+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:44:49.648+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:44:49.663+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:44:49.662+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:44:49.672+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:44:49.672+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:44:49.679+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-29T11:45:20.145+0000] {processor.py:157} INFO - Started process (PID=27214) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:45:20.147+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:45:20.148+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:45:20.148+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:45:20.158+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:45:20.174+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:45:20.174+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:45:20.184+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:45:20.184+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:45:20.192+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-29T11:45:50.628+0000] {processor.py:157} INFO - Started process (PID=27239) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:45:50.629+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:45:50.631+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:45:50.631+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:45:50.646+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:45:50.662+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:45:50.662+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:45:50.671+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:45:50.671+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:45:50.679+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-29T11:46:21.122+0000] {processor.py:157} INFO - Started process (PID=27264) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:46:21.125+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:46:21.128+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:46:21.128+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:46:21.141+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:46:21.158+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:46:21.157+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:46:21.169+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:46:21.169+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:46:21.179+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-29T11:46:51.557+0000] {processor.py:157} INFO - Started process (PID=27289) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:46:51.558+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:46:51.560+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:46:51.560+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:46:51.583+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:46:51.600+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:46:51.600+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:46:51.615+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:46:51.615+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:46:51.625+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-29T11:47:22.109+0000] {processor.py:157} INFO - Started process (PID=27314) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:47:22.111+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:47:22.112+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:47:22.112+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:47:22.122+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:47:22.138+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:47:22.138+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:47:22.148+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:47:22.148+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:47:22.156+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-29T11:47:52.471+0000] {processor.py:157} INFO - Started process (PID=27339) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:47:52.472+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:47:52.474+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:47:52.473+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:47:52.480+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:47:52.493+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:47:52.493+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:47:52.501+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:47:52.501+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:47:52.509+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.040 seconds
[2024-07-29T11:48:22.841+0000] {processor.py:157} INFO - Started process (PID=27364) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:48:22.843+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:48:22.845+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:48:22.845+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:48:22.857+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:48:22.871+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:48:22.871+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:48:22.881+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:48:22.881+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:48:22.890+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-29T11:48:53.317+0000] {processor.py:157} INFO - Started process (PID=27389) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:48:53.319+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:48:53.321+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:48:53.321+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:48:53.334+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:48:53.349+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:48:53.349+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:48:53.358+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:48:53.358+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:48:53.365+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-29T11:49:23.683+0000] {processor.py:157} INFO - Started process (PID=27414) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:49:23.684+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:49:23.686+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:49:23.686+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:49:23.698+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:49:23.711+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:49:23.711+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:49:23.720+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:49:23.720+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:49:23.729+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-29T11:49:54.163+0000] {processor.py:157} INFO - Started process (PID=27439) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:49:54.166+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:49:54.169+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:49:54.169+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:49:54.190+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:49:54.206+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:49:54.206+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:49:54.219+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:49:54.219+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:49:54.229+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-29T11:50:24.641+0000] {processor.py:157} INFO - Started process (PID=27464) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:50:24.642+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:50:24.644+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:50:24.644+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:50:24.656+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:50:24.671+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:50:24.671+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:50:24.682+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:50:24.682+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:50:24.693+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-29T11:50:55.173+0000] {processor.py:157} INFO - Started process (PID=27489) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:50:55.175+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:50:55.176+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:50:55.176+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:50:55.185+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:50:55.201+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:50:55.201+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:50:55.212+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:50:55.212+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:50:55.220+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-29T11:51:25.587+0000] {processor.py:157} INFO - Started process (PID=27514) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:51:25.589+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:51:25.590+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:51:25.590+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:51:25.597+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:51:25.613+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:51:25.613+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:51:25.623+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:51:25.623+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:51:25.633+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-29T11:51:56.057+0000] {processor.py:157} INFO - Started process (PID=27539) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:51:56.059+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:51:56.060+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:51:56.060+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:51:56.070+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:51:56.086+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:51:56.086+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:51:56.096+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:51:56.096+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:51:56.105+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-29T11:52:26.529+0000] {processor.py:157} INFO - Started process (PID=27564) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:52:26.530+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:52:26.532+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:52:26.532+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:52:26.543+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:52:26.559+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:52:26.559+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:52:26.568+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:52:26.568+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:52:26.576+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-29T11:52:56.983+0000] {processor.py:157} INFO - Started process (PID=27589) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:52:56.984+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:52:56.987+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:52:56.987+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:52:56.998+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:52:57.014+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:52:57.014+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:52:57.026+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:52:57.026+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:52:57.037+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-29T11:53:27.365+0000] {processor.py:157} INFO - Started process (PID=27614) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:53:27.366+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:53:27.368+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:53:27.368+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:53:27.379+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:53:27.395+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:53:27.395+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:53:27.406+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:53:27.406+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:53:27.414+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-29T11:53:57.785+0000] {processor.py:157} INFO - Started process (PID=27639) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:53:57.787+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:53:57.789+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:53:57.789+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:53:57.801+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:53:57.818+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:53:57.818+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:53:57.830+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:53:57.830+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:53:57.839+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-29T11:54:28.278+0000] {processor.py:157} INFO - Started process (PID=27664) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:54:28.279+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:54:28.282+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:54:28.282+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:54:28.307+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:54:28.323+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:54:28.323+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:54:28.336+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:54:28.336+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:54:28.347+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-29T11:54:58.726+0000] {processor.py:157} INFO - Started process (PID=27689) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:54:58.726+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:54:58.727+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:54:58.727+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:54:58.736+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:54:58.749+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:54:58.749+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:54:58.758+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:54:58.758+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:54:58.768+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.044 seconds
[2024-07-29T11:55:29.157+0000] {processor.py:157} INFO - Started process (PID=27714) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:55:29.159+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:55:29.160+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:55:29.160+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:55:29.171+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:55:29.187+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:55:29.187+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:55:29.197+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:55:29.197+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:55:29.205+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-29T11:55:59.651+0000] {processor.py:157} INFO - Started process (PID=27739) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:55:59.652+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:55:59.654+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:55:59.654+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:55:59.664+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:55:59.680+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:55:59.679+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:55:59.690+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:55:59.690+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:55:59.699+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-29T11:56:30.031+0000] {processor.py:157} INFO - Started process (PID=27764) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:56:30.032+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:56:30.035+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:56:30.035+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:56:30.045+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:56:30.060+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:56:30.060+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:56:30.070+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:56:30.070+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:56:30.079+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-29T11:57:00.449+0000] {processor.py:157} INFO - Started process (PID=27789) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:57:00.450+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:57:00.451+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:57:00.451+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:57:00.462+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:57:00.479+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:57:00.479+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:57:00.490+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:57:00.490+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:57:00.500+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-29T11:57:30.874+0000] {processor.py:157} INFO - Started process (PID=27814) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:57:30.875+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:57:30.877+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:57:30.876+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:57:30.887+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:57:30.904+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:57:30.904+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:57:30.916+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:57:30.916+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:57:30.927+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-29T11:58:01.277+0000] {processor.py:157} INFO - Started process (PID=27839) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:58:01.280+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:58:01.281+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:58:01.281+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:58:01.298+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:58:01.313+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:58:01.313+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:58:01.322+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:58:01.322+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:58:01.330+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-29T11:58:31.756+0000] {processor.py:157} INFO - Started process (PID=27864) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:58:31.758+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:58:31.760+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:58:31.760+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:58:31.772+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:58:31.790+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:58:31.790+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:58:31.803+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:58:31.803+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:58:31.812+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-29T11:59:02.130+0000] {processor.py:157} INFO - Started process (PID=27889) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:59:02.132+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:59:02.134+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:59:02.133+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:59:02.145+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:59:02.160+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:59:02.160+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:59:02.170+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:59:02.170+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:59:02.180+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-29T11:59:32.548+0000] {processor.py:157} INFO - Started process (PID=27914) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:59:32.552+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T11:59:32.555+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:59:32.555+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:59:32.567+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T11:59:32.583+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:59:32.583+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T11:59:32.596+0000] {logging_mixin.py:151} INFO - [2024-07-29T11:59:32.596+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T11:59:32.605+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-29T12:00:03.067+0000] {processor.py:157} INFO - Started process (PID=27939) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:00:03.070+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:00:03.072+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:00:03.072+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:00:03.088+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:00:03.110+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:00:03.110+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:00:03.125+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:00:03.125+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:00:03.134+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-29T12:00:33.530+0000] {processor.py:157} INFO - Started process (PID=27964) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:00:33.532+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:00:33.534+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:00:33.533+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:00:33.546+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:00:33.564+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:00:33.564+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:00:33.575+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:00:33.575+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:00:33.583+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-29T12:01:04.017+0000] {processor.py:157} INFO - Started process (PID=27989) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:01:04.019+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:01:04.021+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:01:04.021+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:01:04.030+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:01:04.045+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:01:04.045+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:01:04.054+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:01:04.054+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:01:04.065+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-29T12:01:34.483+0000] {processor.py:157} INFO - Started process (PID=28014) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:01:34.485+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:01:34.486+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:01:34.486+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:01:34.498+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:01:34.514+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:01:34.514+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:01:34.523+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:01:34.523+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:01:34.532+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-29T12:02:04.976+0000] {processor.py:157} INFO - Started process (PID=28039) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:02:04.976+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:02:04.979+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:02:04.979+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:02:04.991+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:02:05.007+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:02:05.007+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:02:05.017+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:02:05.017+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:02:05.026+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-29T12:02:35.460+0000] {processor.py:157} INFO - Started process (PID=28064) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:02:35.462+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:02:35.464+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:02:35.464+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:02:35.475+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:02:35.493+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:02:35.493+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:02:35.503+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:02:35.503+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:02:35.511+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-29T12:03:06.041+0000] {processor.py:157} INFO - Started process (PID=28089) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:03:06.044+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:03:06.047+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:03:06.046+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:03:06.057+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:03:06.075+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:03:06.075+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:03:06.085+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:03:06.085+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:03:06.092+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-29T12:03:36.452+0000] {processor.py:157} INFO - Started process (PID=28114) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:03:36.454+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:03:36.457+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:03:36.457+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:03:36.474+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:03:36.494+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:03:36.493+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:03:36.506+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:03:36.506+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:03:36.515+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-29T12:04:06.909+0000] {processor.py:157} INFO - Started process (PID=28139) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:04:06.910+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:04:06.912+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:04:06.912+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:04:06.928+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:04:06.941+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:04:06.941+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:04:06.951+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:04:06.951+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:04:06.961+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-29T12:04:37.375+0000] {processor.py:157} INFO - Started process (PID=28164) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:04:37.377+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:04:37.379+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:04:37.378+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:04:37.392+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:04:37.406+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:04:37.406+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:04:37.416+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:04:37.416+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:04:37.424+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-29T12:05:07.922+0000] {processor.py:157} INFO - Started process (PID=28189) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:05:07.923+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:05:07.925+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:05:07.924+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:05:07.936+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:05:07.950+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:05:07.950+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:05:07.960+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:05:07.960+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:05:07.970+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-29T12:05:38.397+0000] {processor.py:157} INFO - Started process (PID=28214) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:05:38.398+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:05:38.399+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:05:38.399+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:05:38.408+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:05:38.422+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:05:38.422+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:05:38.431+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:05:38.431+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:05:38.441+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-07-29T12:06:08.782+0000] {processor.py:157} INFO - Started process (PID=28239) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:06:08.783+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:06:08.785+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:06:08.784+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:06:08.796+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:06:08.813+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:06:08.813+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:06:08.823+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:06:08.823+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:06:08.832+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-29T12:06:39.197+0000] {processor.py:157} INFO - Started process (PID=28264) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:06:39.199+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:06:39.201+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:06:39.200+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:06:39.211+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:06:39.227+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:06:39.227+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:06:39.238+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:06:39.238+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:06:39.246+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-29T12:07:09.659+0000] {processor.py:157} INFO - Started process (PID=28289) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:07:09.660+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:07:09.662+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:07:09.662+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:07:09.677+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:07:09.693+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:07:09.693+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:07:09.704+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:07:09.704+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:07:09.712+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-29T12:07:40.092+0000] {processor.py:157} INFO - Started process (PID=28314) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:07:40.093+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:07:40.095+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:07:40.095+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:07:40.108+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:07:40.123+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:07:40.122+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:07:40.133+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:07:40.133+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:07:40.141+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-29T12:08:10.573+0000] {processor.py:157} INFO - Started process (PID=28339) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:08:10.576+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:08:10.579+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:08:10.578+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:08:10.601+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:08:10.618+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:08:10.618+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:08:10.632+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:08:10.632+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:08:10.641+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-29T12:08:41.067+0000] {processor.py:157} INFO - Started process (PID=28364) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:08:41.068+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:08:41.070+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:08:41.070+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:08:41.080+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:08:41.097+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:08:41.097+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:08:41.107+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:08:41.107+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:08:41.118+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-29T12:09:11.473+0000] {processor.py:157} INFO - Started process (PID=28389) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:09:11.474+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:09:11.475+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:09:11.475+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:09:11.483+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:09:11.496+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:09:11.496+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:09:11.506+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:09:11.506+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:09:11.516+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.044 seconds
[2024-07-29T12:09:41.971+0000] {processor.py:157} INFO - Started process (PID=28414) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:09:41.973+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:09:41.974+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:09:41.974+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:09:41.987+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:09:42.002+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:09:42.002+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:09:42.012+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:09:42.012+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:09:42.020+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-29T12:10:12.411+0000] {processor.py:157} INFO - Started process (PID=28439) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:10:12.412+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:10:12.415+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:10:12.414+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:10:12.424+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:10:12.441+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:10:12.441+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:10:12.450+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:10:12.450+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:10:12.461+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-29T12:10:42.837+0000] {processor.py:157} INFO - Started process (PID=28464) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:10:42.839+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:10:42.840+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:10:42.840+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:10:42.854+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:10:42.870+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:10:42.870+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:10:42.881+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:10:42.881+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:10:42.890+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-29T12:11:13.381+0000] {processor.py:157} INFO - Started process (PID=28489) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:11:13.382+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:11:13.384+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:11:13.384+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:11:13.394+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:11:13.411+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:11:13.411+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:11:13.421+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:11:13.421+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:11:13.430+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-29T12:11:43.816+0000] {processor.py:157} INFO - Started process (PID=28514) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:11:43.817+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:11:43.820+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:11:43.819+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:11:43.829+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:11:43.845+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:11:43.845+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:11:43.854+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:11:43.854+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:11:43.861+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-29T12:12:14.258+0000] {processor.py:157} INFO - Started process (PID=28539) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:12:14.262+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:12:14.265+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:12:14.265+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:12:14.281+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:12:14.304+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:12:14.304+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:12:14.317+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:12:14.317+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:12:14.327+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-29T12:12:44.755+0000] {processor.py:157} INFO - Started process (PID=28564) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:12:44.756+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:12:44.757+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:12:44.757+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:12:44.763+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:12:44.776+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:12:44.776+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:12:44.784+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:12:44.784+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:12:44.794+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.041 seconds
[2024-07-29T12:13:15.239+0000] {processor.py:157} INFO - Started process (PID=28588) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:13:15.241+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:13:15.242+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:13:15.242+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:13:15.251+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:13:15.267+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:13:15.267+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:13:15.276+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:13:15.276+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:13:15.285+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-29T12:13:45.694+0000] {processor.py:157} INFO - Started process (PID=28614) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:13:45.696+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:13:45.698+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:13:45.698+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:13:45.714+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:13:45.728+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:13:45.728+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:13:45.740+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:13:45.740+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:13:45.750+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-29T12:14:16.090+0000] {processor.py:157} INFO - Started process (PID=28639) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:14:16.091+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:14:16.093+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:14:16.092+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:14:16.108+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:14:16.123+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:14:16.123+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:14:16.132+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:14:16.132+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:14:16.140+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-29T12:14:46.627+0000] {processor.py:157} INFO - Started process (PID=28664) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:14:46.629+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:14:46.631+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:14:46.631+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:14:46.650+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:14:46.664+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:14:46.664+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:14:46.674+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:14:46.674+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:14:46.684+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-29T12:15:17.074+0000] {processor.py:157} INFO - Started process (PID=28689) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:15:17.076+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:15:17.078+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:15:17.078+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:15:17.089+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:15:17.107+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:15:17.107+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:15:17.119+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:15:17.119+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:15:17.127+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-29T12:15:47.541+0000] {processor.py:157} INFO - Started process (PID=28714) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:15:47.543+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:15:47.545+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:15:47.545+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:15:47.557+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:15:47.574+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:15:47.574+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:15:47.588+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:15:47.588+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:15:47.596+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-29T12:16:18.016+0000] {processor.py:157} INFO - Started process (PID=28739) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:16:18.018+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:16:18.019+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:16:18.019+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:16:18.029+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:16:18.044+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:16:18.044+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:16:18.054+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:16:18.054+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:16:18.063+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-29T12:16:48.910+0000] {processor.py:157} INFO - Started process (PID=28764) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:16:48.917+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:16:48.925+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:16:48.925+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:16:48.953+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:16:48.992+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:16:48.992+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:16:49.018+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:16:49.018+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:16:49.039+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-07-29T12:17:19.501+0000] {processor.py:157} INFO - Started process (PID=28789) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:17:19.503+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:17:19.508+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:17:19.507+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:17:19.546+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:17:19.574+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:17:19.574+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:17:19.593+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:17:19.593+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:17:19.608+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-07-29T12:17:49.985+0000] {processor.py:157} INFO - Started process (PID=28814) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:17:49.986+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:17:49.988+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:17:49.988+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:17:50.005+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:17:50.024+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:17:50.024+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:17:50.041+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:17:50.041+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:17:50.053+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-29T12:18:20.480+0000] {processor.py:157} INFO - Started process (PID=28839) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:18:20.485+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:18:20.489+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:18:20.489+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:18:20.515+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:18:20.541+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:18:20.541+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:18:20.555+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:18:20.555+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:18:20.570+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-07-29T12:18:50.919+0000] {processor.py:157} INFO - Started process (PID=28864) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:18:50.920+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:18:50.923+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:18:50.923+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:18:50.932+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:18:50.945+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:18:50.945+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:18:50.958+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:18:50.958+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:18:50.965+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-29T12:19:21.427+0000] {processor.py:157} INFO - Started process (PID=28889) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:19:21.431+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:19:21.434+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:19:21.433+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:19:21.451+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:19:21.471+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:19:21.471+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:19:21.486+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:19:21.486+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:19:21.497+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-29T12:19:51.988+0000] {processor.py:157} INFO - Started process (PID=28914) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:19:51.998+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:19:52.002+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:19:52.002+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:19:52.026+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:19:52.055+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:19:52.055+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:19:52.076+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:19:52.076+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:19:52.089+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-07-29T12:20:22.884+0000] {processor.py:157} INFO - Started process (PID=28939) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:20:22.889+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:20:22.894+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:20:22.893+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:20:22.921+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:20:22.960+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:20:22.959+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:20:22.990+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:20:22.990+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:20:23.001+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.147 seconds
[2024-07-29T12:20:53.427+0000] {processor.py:157} INFO - Started process (PID=28964) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:20:53.431+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:20:53.434+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:20:53.434+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:20:53.452+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:20:53.476+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:20:53.476+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:20:53.489+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:20:53.489+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:20:53.502+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-07-29T12:21:24.025+0000] {processor.py:157} INFO - Started process (PID=28989) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:21:24.031+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:21:24.041+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:21:24.040+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:21:24.083+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:21:24.152+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:21:24.152+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:21:24.173+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:21:24.172+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:21:24.192+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.174 seconds
[2024-07-29T12:21:54.605+0000] {processor.py:157} INFO - Started process (PID=29014) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:21:54.607+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:21:54.611+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:21:54.610+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:21:54.644+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:21:54.675+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:21:54.675+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:21:54.698+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:21:54.698+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:21:54.710+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-07-29T12:22:25.162+0000] {processor.py:157} INFO - Started process (PID=29039) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:22:25.165+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:22:25.171+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:22:25.170+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:22:25.204+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:22:25.245+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:22:25.245+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:22:25.261+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:22:25.261+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:22:25.273+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-07-29T12:22:55.728+0000] {processor.py:157} INFO - Started process (PID=29064) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:22:55.732+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:22:55.736+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:22:55.736+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:22:55.757+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:22:55.780+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:22:55.780+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:22:55.794+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:22:55.794+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:22:55.804+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-07-29T12:23:26.272+0000] {processor.py:157} INFO - Started process (PID=29089) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:23:26.274+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:23:26.280+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:23:26.280+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:23:26.316+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:23:26.362+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:23:26.361+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:23:26.382+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:23:26.382+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:23:26.398+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-07-29T12:23:56.901+0000] {processor.py:157} INFO - Started process (PID=29114) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:23:56.905+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:23:56.908+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:23:56.908+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:23:56.931+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:23:56.956+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:23:56.956+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:23:56.969+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:23:56.969+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:23:56.979+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-07-29T12:24:27.472+0000] {processor.py:157} INFO - Started process (PID=29139) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:24:27.474+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:24:27.478+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:24:27.478+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:24:27.502+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:24:27.550+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:24:27.550+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:24:27.566+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:24:27.565+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:24:27.578+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-07-29T12:24:58.071+0000] {processor.py:157} INFO - Started process (PID=29164) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:24:58.074+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:24:58.080+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:24:58.079+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:24:58.105+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:24:58.139+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:24:58.139+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:24:58.168+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:24:58.167+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:24:58.179+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-07-29T12:25:28.708+0000] {processor.py:157} INFO - Started process (PID=29189) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:25:28.713+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:25:28.721+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:25:28.720+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:25:28.752+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:25:28.813+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:25:28.813+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:25:28.898+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:25:28.897+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:25:28.957+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.255 seconds
[2024-07-29T12:25:59.365+0000] {processor.py:157} INFO - Started process (PID=29214) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:25:59.367+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:25:59.371+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:25:59.371+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:25:59.398+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:25:59.423+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:25:59.423+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:25:59.441+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:25:59.441+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:25:59.451+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-07-29T12:26:29.872+0000] {processor.py:157} INFO - Started process (PID=29239) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:26:29.873+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:26:29.877+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:26:29.877+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:26:29.898+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:26:29.914+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:26:29.914+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:26:29.928+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:26:29.927+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:26:29.939+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-29T12:27:00.376+0000] {processor.py:157} INFO - Started process (PID=29264) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:27:00.380+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:27:00.383+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:27:00.383+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:27:00.405+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:27:00.453+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:27:00.453+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:27:00.467+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:27:00.467+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:27:00.479+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-07-29T12:27:31.044+0000] {processor.py:157} INFO - Started process (PID=29289) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:27:31.046+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:27:31.049+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:27:31.049+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:27:31.092+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:27:31.123+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:27:31.123+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:27:31.137+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:27:31.137+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:27:31.148+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-07-29T12:28:01.605+0000] {processor.py:157} INFO - Started process (PID=29314) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:28:01.606+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:28:01.611+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:28:01.611+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:28:01.631+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:28:01.671+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:28:01.671+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:28:01.695+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:28:01.695+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:28:01.706+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-07-29T12:28:32.218+0000] {processor.py:157} INFO - Started process (PID=29339) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:28:32.220+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:28:32.230+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:28:32.230+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:28:32.246+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:28:32.275+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:28:32.275+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:28:32.295+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:28:32.295+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:28:32.306+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-07-29T12:29:02.796+0000] {processor.py:157} INFO - Started process (PID=29364) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:29:02.797+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:29:02.801+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:29:02.801+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:29:02.822+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:29:02.855+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:29:02.855+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:29:02.868+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:29:02.868+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:29:02.880+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-07-29T12:29:33.314+0000] {processor.py:157} INFO - Started process (PID=29389) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:29:33.315+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:29:33.320+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:29:33.320+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:29:33.339+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:29:33.367+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:29:33.367+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:29:33.389+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:29:33.389+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:29:33.400+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-07-29T12:30:03.860+0000] {processor.py:157} INFO - Started process (PID=29414) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:30:03.866+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:30:03.881+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:30:03.881+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:30:03.900+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:30:03.926+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:30:03.926+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:30:03.939+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:30:03.939+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:30:03.950+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-07-29T12:30:34.417+0000] {processor.py:157} INFO - Started process (PID=29439) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:30:34.424+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:30:34.429+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:30:34.429+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:30:34.457+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:30:34.491+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:30:34.491+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:30:34.505+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:30:34.504+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:30:34.515+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-07-29T12:31:05.089+0000] {processor.py:157} INFO - Started process (PID=29464) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:31:05.090+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:31:05.093+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:31:05.093+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:31:05.112+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:31:05.135+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:31:05.135+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:31:05.149+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:31:05.149+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:31:05.159+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-29T12:31:35.507+0000] {processor.py:157} INFO - Started process (PID=29489) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:31:35.508+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:31:35.510+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:31:35.510+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:31:35.529+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:31:35.547+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:31:35.547+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:31:35.559+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:31:35.559+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:31:35.567+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-29T12:32:05.959+0000] {processor.py:157} INFO - Started process (PID=29514) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:32:05.959+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:32:05.961+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:32:05.961+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:32:05.972+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:32:05.987+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:32:05.987+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:32:05.996+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:32:05.996+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:32:06.003+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-29T12:32:36.543+0000] {processor.py:157} INFO - Started process (PID=29539) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:32:36.544+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:32:36.547+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:32:36.547+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:32:36.567+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:32:36.594+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:32:36.594+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:32:36.609+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:32:36.609+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:32:36.622+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-07-29T12:33:07.101+0000] {processor.py:157} INFO - Started process (PID=29564) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:33:07.105+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:33:07.109+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:33:07.109+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:33:07.139+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:33:07.194+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:33:07.194+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:33:07.220+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:33:07.219+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:33:07.232+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.151 seconds
[2024-07-29T12:33:37.744+0000] {processor.py:157} INFO - Started process (PID=29589) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:33:37.746+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:33:37.750+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:33:37.750+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:33:37.768+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:33:37.799+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:33:37.799+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:33:37.815+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:33:37.815+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:33:37.827+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-07-29T12:34:08.321+0000] {processor.py:157} INFO - Started process (PID=29614) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:34:08.326+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:34:08.332+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:34:08.331+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:34:08.363+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:34:08.420+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:34:08.420+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:34:08.437+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:34:08.437+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:34:08.447+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-07-29T12:34:38.831+0000] {processor.py:157} INFO - Started process (PID=29639) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:34:38.836+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:34:38.840+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:34:38.840+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:34:38.860+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:34:38.889+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:34:38.889+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:34:38.907+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:34:38.907+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:34:38.922+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-07-29T12:35:09.378+0000] {processor.py:157} INFO - Started process (PID=29664) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:35:09.380+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:35:09.381+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:35:09.381+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:35:09.396+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:35:09.411+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:35:09.411+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:35:09.423+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:35:09.423+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:35:09.434+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-29T12:35:39.802+0000] {processor.py:157} INFO - Started process (PID=29689) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:35:39.802+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:35:39.804+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:35:39.803+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:35:39.817+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:35:39.830+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:35:39.829+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:35:39.839+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:35:39.839+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:35:39.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-29T12:36:10.207+0000] {processor.py:157} INFO - Started process (PID=29714) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:36:10.208+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:36:10.209+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:36:10.209+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:36:10.223+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:36:10.237+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:36:10.237+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:36:10.248+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:36:10.248+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:36:10.257+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-29T12:36:40.664+0000] {processor.py:157} INFO - Started process (PID=29737) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:36:40.668+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:36:40.684+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:36:40.683+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:36:40.708+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:36:40.752+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:36:40.752+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:36:40.767+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:36:40.767+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:36:40.776+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-07-29T12:37:11.264+0000] {processor.py:157} INFO - Started process (PID=29764) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:37:11.268+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:37:11.271+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:37:11.271+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:37:11.293+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:37:11.320+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:37:11.319+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:37:11.332+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:37:11.332+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:37:11.343+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-07-29T12:37:41.885+0000] {processor.py:157} INFO - Started process (PID=29788) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:37:41.887+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:37:41.892+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:37:41.891+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:37:41.913+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:37:41.942+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:37:41.942+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:37:41.963+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:37:41.962+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:37:41.974+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-07-29T12:38:12.482+0000] {processor.py:157} INFO - Started process (PID=29814) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:38:12.484+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:38:12.494+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:38:12.491+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:38:12.523+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:38:12.562+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:38:12.562+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:38:12.581+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:38:12.581+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:38:12.594+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-07-29T12:38:43.017+0000] {processor.py:157} INFO - Started process (PID=29839) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:38:43.019+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:38:43.024+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:38:43.024+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:38:43.056+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:38:43.095+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:38:43.095+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:38:43.111+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:38:43.111+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:38:43.125+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-07-29T12:39:13.588+0000] {processor.py:157} INFO - Started process (PID=29863) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:39:13.591+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:39:13.594+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:39:13.593+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:39:13.613+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:39:13.640+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:39:13.640+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:39:13.662+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:39:13.662+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:39:13.674+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-07-29T12:39:44.082+0000] {processor.py:157} INFO - Started process (PID=29889) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:39:44.084+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:39:44.085+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:39:44.085+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:39:44.100+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:39:44.115+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:39:44.115+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:39:44.127+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:39:44.126+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:39:44.137+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-29T12:40:14.581+0000] {processor.py:157} INFO - Started process (PID=29914) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:40:14.584+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:40:14.588+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:40:14.587+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:40:14.608+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:40:14.634+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:40:14.634+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:40:14.650+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:40:14.650+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:40:14.662+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-07-29T12:40:45.100+0000] {processor.py:157} INFO - Started process (PID=29939) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:40:45.103+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:40:45.107+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:40:45.107+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:40:45.130+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:40:45.149+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:40:45.149+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:40:45.163+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:40:45.163+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:40:45.173+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-07-29T12:41:15.624+0000] {processor.py:157} INFO - Started process (PID=29964) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:41:15.625+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:41:15.627+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:41:15.627+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:41:15.643+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:41:15.659+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:41:15.659+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:41:15.668+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:41:15.668+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:41:15.678+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-29T12:41:46.295+0000] {processor.py:157} INFO - Started process (PID=29988) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:41:46.297+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:41:46.301+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:41:46.300+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:41:46.322+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:41:46.356+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:41:46.356+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:41:46.374+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:41:46.373+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:41:46.386+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-07-29T12:42:16.835+0000] {processor.py:157} INFO - Started process (PID=30014) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:42:16.838+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:42:16.840+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:42:16.840+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:42:16.852+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:42:16.868+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:42:16.868+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:42:16.879+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:42:16.879+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:42:16.888+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-29T12:42:47.344+0000] {processor.py:157} INFO - Started process (PID=30038) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:42:47.346+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:42:47.349+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:42:47.348+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:42:47.370+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:42:47.409+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:42:47.409+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:42:47.424+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:42:47.424+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:42:47.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-07-29T12:43:17.930+0000] {processor.py:157} INFO - Started process (PID=30064) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:43:17.931+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:43:17.935+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:43:17.935+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:43:17.956+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:43:17.987+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:43:17.987+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:43:18.001+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:43:18.001+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:43:18.011+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-07-29T12:43:48.469+0000] {processor.py:157} INFO - Started process (PID=30088) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:43:48.472+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:43:48.476+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:43:48.475+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:43:48.503+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:43:48.531+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:43:48.531+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:43:48.545+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:43:48.545+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:43:48.555+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-07-29T12:44:18.947+0000] {processor.py:157} INFO - Started process (PID=30114) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:44:18.948+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:44:18.950+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:44:18.950+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:44:18.958+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:44:18.974+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:44:18.974+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:44:18.988+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:44:18.988+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:44:19.001+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-29T12:44:49.506+0000] {processor.py:157} INFO - Started process (PID=30139) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:44:49.508+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:44:49.514+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:44:49.514+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:44:49.561+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:44:49.591+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:44:49.591+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:44:49.616+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:44:49.616+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:44:49.628+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-07-29T12:45:20.038+0000] {processor.py:157} INFO - Started process (PID=30164) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:45:20.040+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:45:20.044+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:45:20.044+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:45:20.064+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:45:20.093+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:45:20.093+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:45:20.107+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:45:20.107+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:45:20.120+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-07-29T12:45:50.659+0000] {processor.py:157} INFO - Started process (PID=30189) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:45:50.663+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:45:50.666+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:45:50.665+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:45:50.681+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:45:50.710+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:45:50.709+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:45:50.730+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:45:50.730+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:45:50.741+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-07-29T12:46:21.100+0000] {processor.py:157} INFO - Started process (PID=30214) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:46:21.102+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:46:21.103+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:46:21.103+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:46:21.115+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:46:21.135+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:46:21.135+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:46:21.144+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:46:21.144+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:46:21.154+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-29T12:46:51.621+0000] {processor.py:157} INFO - Started process (PID=30239) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:46:51.622+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:46:51.627+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:46:51.626+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:46:51.650+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:46:51.684+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:46:51.684+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:46:51.701+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:46:51.701+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:46:51.711+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-07-29T12:47:22.111+0000] {processor.py:157} INFO - Started process (PID=30264) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:47:22.112+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:47:22.116+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:47:22.116+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:47:22.153+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:47:22.206+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:47:22.206+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:47:22.222+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:47:22.222+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:47:22.233+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-07-29T12:47:52.750+0000] {processor.py:157} INFO - Started process (PID=30288) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:47:52.754+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:47:52.760+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:47:52.759+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:47:52.796+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:47:52.850+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:47:52.850+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:47:52.866+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:47:52.866+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:47:52.879+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-07-29T12:48:23.343+0000] {processor.py:157} INFO - Started process (PID=30314) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:48:23.348+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:48:23.351+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:48:23.351+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:48:23.379+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:48:23.410+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:48:23.410+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:48:23.427+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:48:23.427+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:48:23.439+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-07-29T12:48:53.867+0000] {processor.py:157} INFO - Started process (PID=30339) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:48:53.870+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:48:53.875+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:48:53.875+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:48:53.900+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:48:53.939+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:48:53.939+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:48:53.954+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:48:53.954+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:48:53.964+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-07-29T12:49:24.379+0000] {processor.py:157} INFO - Started process (PID=30363) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:49:24.382+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:49:24.385+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:49:24.385+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:49:24.405+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:49:24.435+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:49:24.435+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:49:24.449+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:49:24.449+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:49:24.459+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-07-29T12:49:54.882+0000] {processor.py:157} INFO - Started process (PID=30389) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:49:54.885+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:49:54.889+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:49:54.889+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:49:54.900+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:49:54.915+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:49:54.915+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:49:54.925+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:49:54.925+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:49:54.936+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-29T12:50:25.660+0000] {processor.py:157} INFO - Started process (PID=30414) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:50:25.662+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:50:25.667+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:50:25.667+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:50:25.704+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:50:25.733+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:50:25.733+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:50:25.761+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:50:25.760+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:50:25.776+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-07-29T12:50:56.527+0000] {processor.py:157} INFO - Started process (PID=30439) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:50:56.529+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:50:56.549+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:50:56.548+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:50:56.569+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:50:56.598+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:50:56.598+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:50:56.612+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:50:56.612+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:50:56.622+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-07-29T12:51:27.055+0000] {processor.py:157} INFO - Started process (PID=30464) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:51:27.058+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:51:27.061+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:51:27.060+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:51:27.080+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:51:27.105+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:51:27.104+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:51:27.120+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:51:27.119+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:51:27.132+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-07-29T12:51:58.006+0000] {processor.py:157} INFO - Started process (PID=30487) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:51:58.007+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:51:58.011+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:51:58.010+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:51:58.034+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:51:58.067+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:51:58.067+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:51:58.083+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:51:58.083+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:51:58.094+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-07-29T12:52:28.531+0000] {processor.py:157} INFO - Started process (PID=30514) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:52:28.532+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:52:28.537+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:52:28.536+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:52:28.557+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:52:28.590+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:52:28.590+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:52:28.604+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:52:28.604+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:52:28.615+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-07-29T12:52:59.048+0000] {processor.py:157} INFO - Started process (PID=30539) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:52:59.049+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:52:59.053+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:52:59.052+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:52:59.071+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:52:59.095+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:52:59.094+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:52:59.109+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:52:59.109+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:52:59.121+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-07-29T12:53:29.798+0000] {processor.py:157} INFO - Started process (PID=30564) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:53:29.812+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:53:29.821+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:53:29.821+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:53:29.851+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:53:29.893+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:53:29.893+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:53:29.915+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:53:29.914+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:53:29.937+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.147 seconds
[2024-07-29T12:54:22.290+0000] {processor.py:157} INFO - Started process (PID=30589) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:54:22.291+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:54:22.295+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:54:22.295+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:54:22.310+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:54:22.334+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:54:22.334+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:54:22.347+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:54:22.347+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:54:22.356+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-29T12:56:02.227+0000] {processor.py:157} INFO - Started process (PID=30616) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:56:02.228+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:56:02.237+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:56:02.235+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:56:02.260+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:56:02.292+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:56:02.292+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:56:02.313+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:56:02.313+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:56:02.326+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-07-29T12:56:32.813+0000] {processor.py:157} INFO - Started process (PID=30639) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:56:32.814+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:56:32.819+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:56:32.818+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:56:32.837+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:56:32.863+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:56:32.862+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:56:32.877+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:56:32.877+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:56:32.890+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-07-29T12:57:03.356+0000] {processor.py:157} INFO - Started process (PID=30666) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:57:03.357+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:57:03.364+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:57:03.364+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:57:03.381+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:57:03.415+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:57:03.415+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:57:03.430+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:57:03.430+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:57:03.447+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-07-29T12:57:33.912+0000] {processor.py:157} INFO - Started process (PID=30691) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:57:33.913+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:57:33.915+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:57:33.915+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:57:33.934+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:57:33.969+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:57:33.969+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:57:33.983+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:57:33.983+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:57:33.996+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-07-29T12:58:04.349+0000] {processor.py:157} INFO - Started process (PID=30716) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:58:04.350+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:58:04.351+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:58:04.351+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:58:04.361+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:58:04.378+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:58:04.378+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:58:04.389+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:58:04.389+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:58:04.399+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-29T12:58:34.835+0000] {processor.py:157} INFO - Started process (PID=30741) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:58:34.837+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:58:34.840+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:58:34.839+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:58:34.856+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:58:34.892+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:58:34.892+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:58:34.915+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:58:34.915+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:58:34.925+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-07-29T12:59:05.556+0000] {processor.py:157} INFO - Started process (PID=30766) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:59:05.558+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:59:05.564+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:59:05.563+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:59:05.589+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:59:05.617+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:59:05.617+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:59:05.635+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:59:05.635+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:59:05.647+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-07-29T12:59:36.127+0000] {processor.py:157} INFO - Started process (PID=30791) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:59:36.128+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T12:59:36.131+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:59:36.131+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:59:36.152+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T12:59:36.199+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:59:36.199+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T12:59:36.216+0000] {logging_mixin.py:151} INFO - [2024-07-29T12:59:36.215+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T12:59:36.226+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-07-29T13:00:06.652+0000] {processor.py:157} INFO - Started process (PID=30816) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:00:06.653+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:00:06.657+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:00:06.656+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:00:06.676+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:00:06.701+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:00:06.701+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:00:06.720+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:00:06.720+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:00:06.731+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-07-29T13:00:37.100+0000] {processor.py:157} INFO - Started process (PID=30841) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:00:37.103+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:00:37.110+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:00:37.109+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:00:37.161+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:00:37.212+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:00:37.212+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:00:37.235+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:00:37.235+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:00:37.251+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.159 seconds
[2024-07-29T13:01:07.646+0000] {processor.py:157} INFO - Started process (PID=30866) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:01:07.647+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:01:07.649+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:01:07.649+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:01:07.662+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:01:07.683+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:01:07.682+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:01:07.700+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:01:07.699+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:01:07.710+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-29T13:01:38.168+0000] {processor.py:157} INFO - Started process (PID=30891) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:01:38.169+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:01:38.176+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:01:38.176+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:01:38.206+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:01:38.247+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:01:38.246+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:01:38.279+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:01:38.278+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:01:38.301+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.141 seconds
[2024-07-29T13:02:08.630+0000] {processor.py:157} INFO - Started process (PID=30916) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:02:08.631+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:02:08.635+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:02:08.635+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:02:08.653+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:02:08.677+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:02:08.677+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:02:08.695+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:02:08.695+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:02:08.708+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-07-29T13:02:39.205+0000] {processor.py:157} INFO - Started process (PID=30941) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:02:39.209+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:02:39.214+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:02:39.213+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:02:39.239+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:02:39.270+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:02:39.270+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:02:39.286+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:02:39.285+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:02:39.311+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-07-29T13:03:09.764+0000] {processor.py:157} INFO - Started process (PID=30966) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:03:09.766+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:03:09.772+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:03:09.772+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:03:09.797+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:03:09.827+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:03:09.827+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:03:09.843+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:03:09.843+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:03:09.853+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-07-29T13:03:40.262+0000] {processor.py:157} INFO - Started process (PID=30991) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:03:40.264+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:03:40.291+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:03:40.287+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:03:40.332+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:03:40.397+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:03:40.397+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:03:40.418+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:03:40.418+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:03:40.439+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.197 seconds
[2024-07-29T13:04:10.994+0000] {processor.py:157} INFO - Started process (PID=31014) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:04:11.000+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:04:11.004+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:04:11.004+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:04:11.034+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:04:11.065+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:04:11.065+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:04:11.082+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:04:11.082+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:04:11.093+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-07-29T13:04:41.494+0000] {processor.py:157} INFO - Started process (PID=31041) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:04:41.496+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:04:41.504+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:04:41.504+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:04:41.566+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:04:41.607+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:04:41.607+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:04:41.625+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:04:41.625+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:04:41.652+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.166 seconds
[2024-07-29T13:05:12.177+0000] {processor.py:157} INFO - Started process (PID=31065) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:05:12.179+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:05:12.187+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:05:12.186+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:05:12.225+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:05:12.290+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:05:12.290+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:05:12.308+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:05:12.308+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:05:12.323+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.165 seconds
[2024-07-29T13:05:42.764+0000] {processor.py:157} INFO - Started process (PID=31090) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:05:42.766+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:05:42.772+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:05:42.771+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:05:42.795+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:05:42.825+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:05:42.825+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:05:42.840+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:05:42.840+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:05:42.854+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-07-29T13:06:13.323+0000] {processor.py:157} INFO - Started process (PID=31114) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:06:13.328+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:06:13.332+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:06:13.332+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:06:13.363+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:06:13.428+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:06:13.428+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:06:13.455+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:06:13.455+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:06:13.479+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.162 seconds
[2024-07-29T13:06:43.935+0000] {processor.py:157} INFO - Started process (PID=31141) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:06:43.936+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:06:43.941+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:06:43.940+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:06:43.962+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:06:43.992+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:06:43.992+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:06:44.010+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:06:44.010+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:06:44.021+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-07-29T13:07:14.444+0000] {processor.py:157} INFO - Started process (PID=31166) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:07:14.445+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:07:14.449+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:07:14.448+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:07:14.464+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:07:14.491+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:07:14.491+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:07:14.507+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:07:14.507+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:07:14.518+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-07-29T13:07:44.953+0000] {processor.py:157} INFO - Started process (PID=31191) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:07:44.954+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:07:44.960+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:07:44.960+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:07:45.011+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:07:45.088+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:07:45.088+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:07:45.144+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:07:45.143+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:07:45.169+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.223 seconds
[2024-07-29T13:08:15.705+0000] {processor.py:157} INFO - Started process (PID=31216) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:08:15.706+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:08:15.712+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:08:15.712+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:08:15.739+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:08:15.774+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:08:15.774+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:08:15.794+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:08:15.794+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:08:15.810+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-07-29T13:08:46.256+0000] {processor.py:157} INFO - Started process (PID=31241) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:08:46.257+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:08:46.262+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:08:46.261+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:08:46.295+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:08:46.344+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:08:46.343+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:08:46.368+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:08:46.368+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:08:46.394+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.146 seconds
[2024-07-29T13:09:16.824+0000] {processor.py:157} INFO - Started process (PID=31266) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:09:16.826+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:09:16.830+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:09:16.829+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:09:16.853+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:09:16.890+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:09:16.890+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:09:16.906+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:09:16.906+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:09:16.916+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-07-29T13:09:47.373+0000] {processor.py:157} INFO - Started process (PID=31291) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:09:47.374+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:09:47.379+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:09:47.378+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:09:47.425+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:09:47.467+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:09:47.467+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:09:47.490+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:09:47.490+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:09:47.546+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.179 seconds
[2024-07-29T13:10:18.101+0000] {processor.py:157} INFO - Started process (PID=31316) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:10:18.103+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:10:18.106+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:10:18.106+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:10:18.124+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:10:18.159+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:10:18.159+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:10:18.175+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:10:18.175+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:10:18.188+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-07-29T13:10:48.605+0000] {processor.py:157} INFO - Started process (PID=31341) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:10:48.606+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:10:48.611+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:10:48.610+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:10:48.627+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:10:48.650+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:10:48.649+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:10:48.664+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:10:48.663+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:10:48.677+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-29T13:11:19.098+0000] {processor.py:157} INFO - Started process (PID=31366) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:11:19.100+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:11:19.108+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:11:19.107+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:11:19.144+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:11:19.174+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:11:19.174+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:11:19.190+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:11:19.190+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:11:19.202+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-07-29T13:11:49.664+0000] {processor.py:157} INFO - Started process (PID=31391) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:11:49.665+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:11:49.670+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:11:49.670+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:11:49.692+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:11:49.729+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:11:49.729+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:11:49.742+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:11:49.742+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:11:49.753+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-07-29T13:12:20.219+0000] {processor.py:157} INFO - Started process (PID=31416) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:12:20.220+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:12:20.225+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:12:20.224+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:12:20.244+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:12:20.270+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:12:20.270+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:12:20.293+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:12:20.293+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:12:20.301+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-07-29T13:12:50.775+0000] {processor.py:157} INFO - Started process (PID=31441) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:12:50.776+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:12:50.779+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:12:50.779+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:12:50.793+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:12:50.815+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:12:50.815+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:12:50.828+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:12:50.828+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:12:50.838+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-29T13:13:21.303+0000] {processor.py:157} INFO - Started process (PID=31466) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:13:21.304+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:13:21.310+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:13:21.309+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:13:21.341+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:13:21.380+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:13:21.380+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:13:21.396+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:13:21.396+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:13:21.406+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-07-29T13:13:51.837+0000] {processor.py:157} INFO - Started process (PID=31491) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:13:51.839+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:13:51.841+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:13:51.841+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:13:51.859+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:13:51.885+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:13:51.885+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:13:51.898+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:13:51.898+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:13:51.913+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-07-29T13:14:22.375+0000] {processor.py:157} INFO - Started process (PID=31515) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:14:22.378+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:14:22.387+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:14:22.386+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:14:22.441+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:14:22.491+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:14:22.490+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:14:22.517+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:14:22.517+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:14:22.530+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.168 seconds
[2024-07-29T13:14:52.925+0000] {processor.py:157} INFO - Started process (PID=31541) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:14:52.926+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:14:52.929+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:14:52.929+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:14:52.948+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:14:52.982+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:14:52.982+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:14:52.997+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:14:52.997+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:14:53.008+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-07-29T13:15:23.580+0000] {processor.py:157} INFO - Started process (PID=31566) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:15:23.582+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:15:23.590+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:15:23.590+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:15:23.633+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:15:23.681+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:15:23.680+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:15:23.706+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:15:23.706+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:15:23.718+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.144 seconds
[2024-07-29T13:15:54.176+0000] {processor.py:157} INFO - Started process (PID=31591) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:15:54.181+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:15:54.240+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:15:54.237+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:15:54.281+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:15:54.359+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:15:54.359+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:15:54.379+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:15:54.379+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:15:54.401+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.258 seconds
[2024-07-29T13:16:24.895+0000] {processor.py:157} INFO - Started process (PID=31615) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:16:24.896+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:16:24.902+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:16:24.901+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:16:24.931+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:16:24.958+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:16:24.958+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:16:24.977+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:16:24.977+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:16:24.988+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-07-29T13:16:55.363+0000] {processor.py:157} INFO - Started process (PID=31640) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:16:55.364+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:16:55.368+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:16:55.368+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:16:55.385+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:16:55.410+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:16:55.410+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:16:55.423+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:16:55.423+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:16:55.434+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-29T13:17:25.921+0000] {processor.py:157} INFO - Started process (PID=31666) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:17:25.922+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:17:25.927+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:17:25.926+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:17:25.958+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:17:26.003+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:17:26.003+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:17:26.020+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:17:26.020+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:17:26.033+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-07-29T13:17:56.556+0000] {processor.py:157} INFO - Started process (PID=31690) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:17:56.556+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:17:56.560+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:17:56.559+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:17:56.585+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:17:56.623+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:17:56.623+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:17:56.639+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:17:56.639+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:17:56.650+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-07-29T13:18:27.156+0000] {processor.py:157} INFO - Started process (PID=31716) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:18:27.157+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:18:27.162+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:18:27.161+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:18:27.197+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:18:27.225+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:18:27.225+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:18:27.239+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:18:27.239+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:18:27.250+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-07-29T13:18:57.797+0000] {processor.py:157} INFO - Started process (PID=31740) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:18:57.798+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:18:57.819+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:18:57.817+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:18:57.839+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:18:57.866+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:18:57.866+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:18:57.880+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:18:57.880+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:18:57.892+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-07-29T13:19:28.358+0000] {processor.py:157} INFO - Started process (PID=31765) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:19:28.368+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:19:28.395+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:19:28.395+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:19:28.425+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:19:28.475+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:19:28.475+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:19:28.491+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:19:28.491+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:19:28.504+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.160 seconds
[2024-07-29T13:19:59.042+0000] {processor.py:157} INFO - Started process (PID=31791) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:19:59.043+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:19:59.048+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:19:59.048+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:19:59.092+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:19:59.133+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:19:59.133+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:19:59.147+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:19:59.147+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:19:59.157+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-07-29T13:20:29.639+0000] {processor.py:157} INFO - Started process (PID=31815) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:20:29.641+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:20:29.646+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:20:29.646+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:20:29.669+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:20:29.699+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:20:29.699+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:20:29.713+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:20:29.713+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:20:29.724+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-07-29T13:21:00.104+0000] {processor.py:157} INFO - Started process (PID=31841) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:21:00.104+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:21:00.110+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:21:00.110+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:21:00.120+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:21:00.137+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:21:00.137+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:21:00.148+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:21:00.148+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:21:00.159+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-29T13:21:30.554+0000] {processor.py:157} INFO - Started process (PID=31865) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:21:30.555+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:21:30.560+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:21:30.560+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:21:30.586+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:21:30.613+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:21:30.613+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:21:30.628+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:21:30.628+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:21:30.638+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-07-29T13:22:01.120+0000] {processor.py:157} INFO - Started process (PID=31891) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:22:01.122+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:22:01.128+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:22:01.127+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:22:01.162+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:22:01.198+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:22:01.197+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:22:01.226+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:22:01.226+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:22:01.239+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-07-29T13:22:31.677+0000] {processor.py:157} INFO - Started process (PID=31916) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:22:31.678+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:22:31.685+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:22:31.685+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:22:31.726+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:22:31.779+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:22:31.779+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:22:31.803+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:22:31.803+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:22:31.818+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.148 seconds
[2024-07-29T13:23:02.228+0000] {processor.py:157} INFO - Started process (PID=31939) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:23:02.230+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:23:02.235+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:23:02.234+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:23:02.255+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:23:02.291+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:23:02.291+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:23:02.306+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:23:02.306+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:23:02.318+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-07-29T13:23:32.726+0000] {processor.py:157} INFO - Started process (PID=31965) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:23:32.729+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:23:32.743+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:23:32.742+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:23:32.785+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:23:32.847+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:23:32.847+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:23:32.870+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:23:32.869+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:23:32.884+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.172 seconds
[2024-07-29T13:24:03.357+0000] {processor.py:157} INFO - Started process (PID=31990) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:24:03.367+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:24:03.386+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:24:03.385+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:24:03.415+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:24:03.459+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:24:03.458+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:24:03.480+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:24:03.480+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:24:03.493+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.148 seconds
[2024-07-29T13:24:33.929+0000] {processor.py:157} INFO - Started process (PID=32016) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:24:33.932+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:24:33.960+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:24:33.960+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:24:33.993+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:24:34.034+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:24:34.034+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:24:34.054+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:24:34.054+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:24:34.071+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.152 seconds
[2024-07-29T13:25:04.550+0000] {processor.py:157} INFO - Started process (PID=32040) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:25:04.553+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:25:04.559+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:25:04.558+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:25:04.608+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:25:04.652+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:25:04.652+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:25:04.672+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:25:04.672+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:25:04.687+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.147 seconds
[2024-07-29T13:25:35.061+0000] {processor.py:157} INFO - Started process (PID=32066) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:25:35.062+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:25:35.067+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:25:35.067+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:25:35.087+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:25:35.115+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:25:35.115+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:25:35.131+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:25:35.131+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:25:35.143+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-07-29T13:26:05.589+0000] {processor.py:157} INFO - Started process (PID=32091) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:26:05.590+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:26:05.596+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:26:05.595+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:26:05.628+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:26:05.682+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:26:05.682+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:26:05.714+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:26:05.714+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:26:05.727+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.145 seconds
[2024-07-29T13:26:36.134+0000] {processor.py:157} INFO - Started process (PID=32114) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:26:36.136+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:26:36.143+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:26:36.142+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:26:36.175+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:26:36.230+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:26:36.230+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:26:36.255+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:26:36.255+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:26:36.269+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.144 seconds
[2024-07-29T13:27:06.676+0000] {processor.py:157} INFO - Started process (PID=32141) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:27:06.679+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:27:06.684+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:27:06.683+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:27:06.704+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:27:06.728+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:27:06.728+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:27:06.744+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:27:06.744+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:27:06.756+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-07-29T13:27:37.185+0000] {processor.py:157} INFO - Started process (PID=32166) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:27:37.186+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:27:37.191+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:27:37.191+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:27:37.221+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:27:37.258+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:27:37.258+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:27:37.273+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:27:37.273+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:27:37.285+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-07-29T13:28:07.763+0000] {processor.py:157} INFO - Started process (PID=32191) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:28:07.764+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:28:07.769+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:28:07.768+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:28:07.790+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:28:07.817+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:28:07.817+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:28:07.833+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:28:07.832+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:28:07.844+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-07-29T13:28:38.244+0000] {processor.py:157} INFO - Started process (PID=32215) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:28:38.245+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:28:38.251+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:28:38.251+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:28:38.279+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:28:38.314+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:28:38.314+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:28:38.349+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:28:38.349+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:28:38.361+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-07-29T13:29:08.833+0000] {processor.py:157} INFO - Started process (PID=32241) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:29:08.834+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:29:08.840+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:29:08.839+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:29:08.894+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:29:08.935+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:29:08.935+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:29:08.964+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:29:08.964+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:29:08.981+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.155 seconds
[2024-07-29T13:29:39.454+0000] {processor.py:157} INFO - Started process (PID=32266) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:29:39.455+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:29:39.460+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:29:39.459+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:29:39.483+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:29:39.514+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:29:39.514+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:29:39.532+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:29:39.532+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:29:39.547+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-07-29T13:30:09.985+0000] {processor.py:157} INFO - Started process (PID=32291) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:30:09.986+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:30:09.990+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:30:09.989+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:30:10.008+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:30:10.031+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:30:10.031+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:30:10.044+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:30:10.044+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:30:10.054+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-29T13:30:40.478+0000] {processor.py:157} INFO - Started process (PID=32316) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:30:40.479+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:30:40.485+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:30:40.484+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:30:40.506+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:30:40.534+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:30:40.534+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:30:40.552+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:30:40.552+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:30:40.564+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-07-29T13:31:10.936+0000] {processor.py:157} INFO - Started process (PID=32341) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:31:10.937+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:31:10.944+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:31:10.944+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:31:10.960+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:31:10.981+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:31:10.981+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:31:10.994+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:31:10.994+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:31:11.010+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-07-29T13:31:41.443+0000] {processor.py:157} INFO - Started process (PID=32365) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:31:41.445+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:31:41.450+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:31:41.450+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:31:41.481+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:31:41.534+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:31:41.534+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:31:41.559+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:31:41.559+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:31:41.574+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.154 seconds
[2024-07-29T13:32:12.008+0000] {processor.py:157} INFO - Started process (PID=32390) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:32:12.011+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:32:12.018+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:32:12.017+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:32:12.051+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:32:12.116+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:32:12.116+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:32:12.138+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:32:12.138+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:32:12.151+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.151 seconds
[2024-07-29T13:32:42.563+0000] {processor.py:157} INFO - Started process (PID=32416) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:32:42.564+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:32:42.570+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:32:42.569+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:32:42.596+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:32:42.635+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:32:42.635+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:32:42.656+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:32:42.656+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:32:42.671+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-07-29T13:33:13.178+0000] {processor.py:157} INFO - Started process (PID=32441) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:33:13.179+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:33:13.185+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:33:13.185+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:33:13.206+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:33:13.236+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:33:13.236+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:33:13.254+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:33:13.254+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:33:13.266+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-07-29T13:33:43.753+0000] {processor.py:157} INFO - Started process (PID=32466) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:33:43.757+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:33:43.762+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:33:43.762+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:33:43.784+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:33:43.819+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:33:43.819+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:33:43.841+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:33:43.841+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:33:43.855+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-07-29T13:34:14.286+0000] {processor.py:157} INFO - Started process (PID=32489) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:34:14.289+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:34:14.296+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:34:14.296+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:34:14.332+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:34:14.423+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:34:14.418+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:34:14.462+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:34:14.462+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:34:14.476+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.212 seconds
[2024-07-29T13:34:44.936+0000] {processor.py:157} INFO - Started process (PID=32516) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:34:44.938+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:34:44.944+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:34:44.943+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:34:44.977+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:34:45.022+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:34:45.022+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:34:45.051+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:34:45.051+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:34:45.069+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-07-29T13:35:15.580+0000] {processor.py:157} INFO - Started process (PID=32541) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:35:15.581+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:35:15.592+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:35:15.591+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:35:15.620+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:35:15.656+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:35:15.656+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:35:15.683+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:35:15.683+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:35:15.702+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.144 seconds
[2024-07-29T13:35:46.288+0000] {processor.py:157} INFO - Started process (PID=32566) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:35:46.290+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:35:46.295+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:35:46.294+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:35:46.319+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:35:46.352+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:35:46.351+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:35:46.369+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:35:46.369+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:35:46.383+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-07-29T13:36:16.847+0000] {processor.py:157} INFO - Started process (PID=32590) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:36:16.849+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:36:16.855+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:36:16.854+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:36:16.887+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:36:16.927+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:36:16.927+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:36:16.950+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:36:16.950+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:36:16.962+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-07-29T13:36:47.420+0000] {processor.py:157} INFO - Started process (PID=32615) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:36:47.430+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:36:47.442+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:36:47.442+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:36:47.475+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:36:47.544+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:36:47.543+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:36:47.588+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:36:47.588+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:36:47.602+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.210 seconds
[2024-07-29T13:37:18.137+0000] {processor.py:157} INFO - Started process (PID=32641) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:37:18.138+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:37:18.143+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:37:18.143+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:37:18.171+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:37:18.232+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:37:18.232+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:37:18.256+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:37:18.255+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:37:18.271+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-07-29T13:37:48.626+0000] {processor.py:157} INFO - Started process (PID=32666) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:37:48.626+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:37:48.629+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:37:48.629+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:37:48.641+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:37:48.660+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:37:48.660+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:37:48.672+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:37:48.672+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:37:48.683+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-29T13:38:19.123+0000] {processor.py:157} INFO - Started process (PID=32691) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:38:19.124+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:38:19.127+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:38:19.126+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:38:19.146+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:38:19.184+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:38:19.184+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:38:19.202+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:38:19.202+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:38:19.217+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-07-29T13:38:49.630+0000] {processor.py:157} INFO - Started process (PID=32716) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:38:49.632+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:38:49.639+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:38:49.638+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:38:49.659+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:38:49.693+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:38:49.692+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:38:49.710+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:38:49.710+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:38:49.725+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-07-29T13:39:20.230+0000] {processor.py:157} INFO - Started process (PID=32741) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:39:20.231+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:39:20.236+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:39:20.235+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:39:20.267+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:39:20.306+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:39:20.306+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:39:20.328+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:39:20.328+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:39:20.344+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-07-29T13:39:50.822+0000] {processor.py:157} INFO - Started process (PID=32766) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:39:50.824+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:39:50.828+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:39:50.828+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:39:50.849+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:39:50.881+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:39:50.881+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:39:50.897+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:39:50.897+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:39:50.912+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-07-29T13:40:21.367+0000] {processor.py:157} INFO - Started process (PID=32791) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:40:21.370+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:40:21.374+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:40:21.374+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:40:21.397+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:40:21.430+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:40:21.430+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:40:21.448+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:40:21.447+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:40:21.462+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-07-29T13:40:51.882+0000] {processor.py:157} INFO - Started process (PID=32816) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:40:51.883+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:40:51.888+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:40:51.886+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:40:51.935+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:40:51.978+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:40:51.978+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:40:52.021+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:40:52.021+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:40:52.032+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.156 seconds
[2024-07-29T13:41:22.564+0000] {processor.py:157} INFO - Started process (PID=32841) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:41:22.565+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:41:22.570+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:41:22.569+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:41:22.601+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:41:22.643+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:41:22.643+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:41:22.680+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:41:22.680+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:41:22.698+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.142 seconds
[2024-07-29T13:41:53.092+0000] {processor.py:157} INFO - Started process (PID=32866) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:41:53.093+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:41:53.097+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:41:53.097+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:41:53.145+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:41:53.174+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:41:53.174+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:41:53.189+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:41:53.189+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:41:53.200+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-07-29T13:42:23.678+0000] {processor.py:157} INFO - Started process (PID=32891) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:42:23.679+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:42:23.683+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:42:23.682+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:42:23.704+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:42:23.775+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:42:23.775+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:42:23.802+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:42:23.802+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:42:23.812+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-07-29T13:42:54.315+0000] {processor.py:157} INFO - Started process (PID=32915) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:42:54.317+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:42:54.320+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:42:54.320+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:42:54.348+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:42:54.378+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:42:54.378+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:42:54.396+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:42:54.396+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:42:54.407+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-07-29T13:43:24.961+0000] {processor.py:157} INFO - Started process (PID=32941) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:43:24.963+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:43:24.968+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:43:24.968+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:43:25.001+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:43:25.054+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:43:25.054+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:43:25.075+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:43:25.075+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:43:25.088+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-07-29T13:43:55.515+0000] {processor.py:157} INFO - Started process (PID=32966) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:43:55.517+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:43:55.520+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:43:55.520+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:43:55.537+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:43:55.561+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:43:55.561+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:43:55.579+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:43:55.579+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:43:55.588+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-29T13:44:25.946+0000] {processor.py:157} INFO - Started process (PID=32991) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:44:25.947+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:44:25.949+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:44:25.949+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:44:25.961+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:44:25.976+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:44:25.976+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:44:25.986+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:44:25.986+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:44:25.998+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-29T13:44:56.507+0000] {processor.py:157} INFO - Started process (PID=33016) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:44:56.510+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:44:56.518+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:44:56.517+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:44:56.553+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:44:56.600+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:44:56.600+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:44:56.616+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:44:56.615+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:44:56.623+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-07-29T13:45:27.095+0000] {processor.py:157} INFO - Started process (PID=33041) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:45:27.100+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:45:27.105+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:45:27.105+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:45:27.121+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:45:27.153+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:45:27.153+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:45:27.167+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:45:27.167+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:45:27.176+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-07-29T13:45:57.967+0000] {processor.py:157} INFO - Started process (PID=33066) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:45:57.969+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:45:57.976+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:45:57.975+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:45:58.011+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:45:58.053+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:45:58.053+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:45:58.071+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:45:58.071+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:45:58.084+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-07-29T13:46:28.509+0000] {processor.py:157} INFO - Started process (PID=33091) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:46:28.510+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:46:28.515+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:46:28.515+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:46:28.543+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:46:28.577+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:46:28.577+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:46:28.596+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:46:28.596+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:46:28.609+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-07-29T13:46:59.042+0000] {processor.py:157} INFO - Started process (PID=33116) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:46:59.043+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:46:59.048+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:46:59.048+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:46:59.067+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:46:59.102+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:46:59.102+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:46:59.116+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:46:59.116+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:46:59.126+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-07-29T13:47:29.565+0000] {processor.py:157} INFO - Started process (PID=33141) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:47:29.567+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:47:29.569+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:47:29.569+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:47:29.586+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:47:29.604+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:47:29.603+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:47:29.615+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:47:29.615+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:47:29.625+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-29T13:47:59.985+0000] {processor.py:157} INFO - Started process (PID=33166) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:47:59.987+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:47:59.989+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:47:59.989+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:48:00.008+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:48:00.029+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:48:00.029+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:48:00.044+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:48:00.044+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:48:00.053+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-29T13:48:30.449+0000] {processor.py:157} INFO - Started process (PID=33191) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:48:30.450+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:48:30.454+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:48:30.453+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:48:30.472+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:48:30.498+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:48:30.498+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:48:30.518+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:48:30.518+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:48:30.533+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-07-29T13:49:01.026+0000] {processor.py:157} INFO - Started process (PID=33216) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:49:01.027+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:49:01.032+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:49:01.032+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:49:01.048+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:49:01.072+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:49:01.072+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:49:01.087+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:49:01.087+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:49:01.100+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-07-29T13:49:31.527+0000] {processor.py:157} INFO - Started process (PID=33241) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:49:31.528+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:49:31.531+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:49:31.531+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:49:31.542+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:49:31.557+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:49:31.557+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:49:31.570+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:49:31.570+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:49:31.578+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-29T13:50:02.024+0000] {processor.py:157} INFO - Started process (PID=33266) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:50:02.026+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:50:02.030+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:50:02.030+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:50:02.052+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:50:02.093+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:50:02.093+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:50:02.108+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:50:02.108+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:50:02.118+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-07-29T13:50:32.646+0000] {processor.py:157} INFO - Started process (PID=33291) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:50:32.647+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:50:32.650+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:50:32.650+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:50:32.669+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:50:32.703+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:50:32.703+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:50:32.718+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:50:32.718+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:50:32.728+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-07-29T13:51:03.187+0000] {processor.py:157} INFO - Started process (PID=33316) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:51:03.189+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:51:03.199+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:51:03.197+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:51:03.223+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:51:03.266+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:51:03.266+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:51:03.280+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:51:03.279+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:51:03.289+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-07-29T13:51:33.775+0000] {processor.py:157} INFO - Started process (PID=33341) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:51:33.776+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:51:33.780+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:51:33.780+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:51:33.800+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:51:33.823+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:51:33.823+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:51:33.837+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:51:33.837+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:51:33.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-29T13:52:04.236+0000] {processor.py:157} INFO - Started process (PID=33366) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:52:04.238+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:52:04.241+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:52:04.241+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:52:04.260+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:52:04.284+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:52:04.284+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:52:04.298+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:52:04.298+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:52:04.308+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-29T13:52:34.740+0000] {processor.py:157} INFO - Started process (PID=33391) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:52:34.741+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:52:34.745+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:52:34.744+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:52:34.768+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:52:34.787+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:52:34.787+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:52:34.802+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:52:34.802+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:52:34.810+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-29T13:53:05.145+0000] {processor.py:157} INFO - Started process (PID=33416) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:53:05.145+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:53:05.152+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:53:05.152+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:53:05.160+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:53:05.172+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:53:05.172+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:53:05.183+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:53:05.183+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:53:05.192+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-29T13:53:35.575+0000] {processor.py:157} INFO - Started process (PID=33441) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:53:35.575+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:53:35.578+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:53:35.578+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:53:35.599+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:53:35.623+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:53:35.622+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:53:35.638+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:53:35.638+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:53:35.648+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-29T13:54:06.099+0000] {processor.py:157} INFO - Started process (PID=33466) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:54:06.100+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:54:06.103+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:54:06.103+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:54:06.126+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:54:06.153+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:54:06.153+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:54:06.167+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:54:06.167+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:54:06.179+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-07-29T13:54:36.578+0000] {processor.py:157} INFO - Started process (PID=33491) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:54:36.584+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:54:36.589+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:54:36.588+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:54:36.602+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:54:36.622+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:54:36.621+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:54:36.636+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:54:36.636+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:54:36.647+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-29T13:55:07.048+0000] {processor.py:157} INFO - Started process (PID=33516) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:55:07.050+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:55:07.053+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:55:07.053+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:55:07.073+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:55:07.113+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:55:07.113+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:55:07.128+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:55:07.128+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:55:07.138+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-07-29T13:55:37.555+0000] {processor.py:157} INFO - Started process (PID=33541) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:55:37.556+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:55:37.559+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:55:37.558+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:55:37.573+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:55:37.586+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:55:37.586+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:55:37.598+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:55:37.598+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:55:37.607+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-29T13:56:07.958+0000] {processor.py:157} INFO - Started process (PID=33566) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:56:07.959+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:56:07.968+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:56:07.967+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:56:07.975+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:56:07.989+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:56:07.989+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:56:07.998+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:56:07.998+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:56:08.008+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-29T13:56:38.296+0000] {processor.py:157} INFO - Started process (PID=33591) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:56:38.296+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:56:38.297+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:56:38.297+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:56:38.304+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:56:38.317+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:56:38.317+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:56:38.325+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:56:38.325+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:56:38.332+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.037 seconds
[2024-07-29T13:57:08.723+0000] {processor.py:157} INFO - Started process (PID=33616) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:57:08.724+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:57:08.727+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:57:08.727+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:57:08.737+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:57:08.753+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:57:08.753+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:57:08.763+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:57:08.763+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:57:08.774+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-29T13:57:39.156+0000] {processor.py:157} INFO - Started process (PID=33641) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:57:39.157+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:57:39.159+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:57:39.159+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:57:39.178+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:57:39.197+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:57:39.197+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:57:39.210+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:57:39.210+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:57:39.220+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-29T13:58:09.554+0000] {processor.py:157} INFO - Started process (PID=33666) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:58:09.557+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:58:09.559+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:58:09.558+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:58:09.572+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:58:09.586+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:58:09.586+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:58:09.598+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:58:09.598+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:58:09.606+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-29T13:58:40.029+0000] {processor.py:157} INFO - Started process (PID=33691) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:58:40.030+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:58:40.032+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:58:40.032+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:58:40.043+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:58:40.059+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:58:40.059+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:58:40.069+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:58:40.069+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:58:40.079+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-29T13:59:10.477+0000] {processor.py:157} INFO - Started process (PID=33716) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:59:10.478+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:59:10.481+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:59:10.481+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:59:10.495+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:59:10.510+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:59:10.510+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:59:10.521+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:59:10.521+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:59:10.530+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-29T13:59:40.887+0000] {processor.py:157} INFO - Started process (PID=33741) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:59:40.888+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T13:59:40.894+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:59:40.894+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:59:40.903+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T13:59:40.916+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:59:40.916+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T13:59:40.926+0000] {logging_mixin.py:151} INFO - [2024-07-29T13:59:40.926+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T13:59:40.935+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-29T14:00:11.296+0000] {processor.py:157} INFO - Started process (PID=33766) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:00:11.297+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:00:11.300+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:00:11.300+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:00:11.319+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:00:11.341+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:00:11.341+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:00:11.354+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:00:11.354+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:00:11.364+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-29T14:00:41.774+0000] {processor.py:157} INFO - Started process (PID=33791) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:00:41.778+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:00:41.780+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:00:41.780+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:00:41.792+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:00:41.807+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:00:41.807+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:00:41.817+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:00:41.817+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:00:41.826+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-29T14:01:12.308+0000] {processor.py:157} INFO - Started process (PID=33816) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:01:12.309+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:01:12.311+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:01:12.311+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:01:12.325+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:01:12.349+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:01:12.349+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:01:12.360+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:01:12.360+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:01:12.367+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-29T14:01:42.745+0000] {processor.py:157} INFO - Started process (PID=33841) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:01:42.746+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:01:42.754+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:01:42.753+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:01:42.761+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:01:42.774+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:01:42.774+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:01:42.784+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:01:42.784+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:01:42.796+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-29T14:02:13.123+0000] {processor.py:157} INFO - Started process (PID=33866) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:02:13.124+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:02:13.127+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:02:13.127+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:02:13.142+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:02:13.161+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:02:13.161+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:02:13.173+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:02:13.173+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:02:13.183+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-29T14:02:43.581+0000] {processor.py:157} INFO - Started process (PID=33891) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:02:43.583+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:02:43.585+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:02:43.584+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:02:43.597+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:02:43.613+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:02:43.613+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:02:43.625+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:02:43.625+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:02:43.635+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-29T14:03:14.014+0000] {processor.py:157} INFO - Started process (PID=33916) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:03:14.018+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:03:14.020+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:03:14.020+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:03:14.033+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:03:14.048+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:03:14.048+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:03:14.057+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:03:14.057+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:03:14.067+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-29T14:03:44.515+0000] {processor.py:157} INFO - Started process (PID=33941) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:03:44.516+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:03:44.518+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:03:44.518+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:03:44.529+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:03:44.548+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:03:44.548+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:03:44.560+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:03:44.560+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:03:44.569+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-29T14:04:15.091+0000] {processor.py:157} INFO - Started process (PID=33966) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:04:15.097+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:04:15.102+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:04:15.102+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:04:15.111+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:04:15.124+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:04:15.124+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:04:15.134+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:04:15.134+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:04:15.140+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-29T14:04:45.501+0000] {processor.py:157} INFO - Started process (PID=33991) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:04:45.502+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:04:45.504+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:04:45.503+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:04:45.514+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:04:45.530+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:04:45.530+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:04:45.542+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:04:45.542+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:04:45.550+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-29T14:05:15.993+0000] {processor.py:157} INFO - Started process (PID=34016) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:05:15.994+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:05:15.996+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:05:15.996+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:05:16.034+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:05:16.052+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:05:16.052+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:05:16.064+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:05:16.064+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:05:16.072+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-07-29T14:05:46.432+0000] {processor.py:157} INFO - Started process (PID=34041) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:05:46.435+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:05:46.437+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:05:46.437+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:05:46.452+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:05:46.471+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:05:46.471+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:05:46.484+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:05:46.484+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:05:46.495+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-29T14:06:16.930+0000] {processor.py:157} INFO - Started process (PID=34066) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:06:16.931+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:06:16.935+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:06:16.935+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:06:16.948+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:06:16.961+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:06:16.961+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:06:16.971+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:06:16.971+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:06:16.980+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-29T14:06:47.411+0000] {processor.py:157} INFO - Started process (PID=34091) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:06:47.413+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:06:47.415+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:06:47.415+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:06:47.426+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:06:47.442+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:06:47.442+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:06:47.455+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:06:47.455+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:06:47.463+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-29T14:07:17.813+0000] {processor.py:157} INFO - Started process (PID=34116) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:07:17.813+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:07:17.815+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:07:17.815+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:07:17.825+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:07:17.836+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:07:17.836+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:07:17.846+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:07:17.846+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:07:17.854+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.043 seconds
[2024-07-29T14:07:48.342+0000] {processor.py:157} INFO - Started process (PID=34141) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:07:48.344+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:07:48.346+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:07:48.346+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:07:48.363+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:07:48.376+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:07:48.376+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:07:48.385+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:07:48.385+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:07:48.394+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-29T14:08:18.820+0000] {processor.py:157} INFO - Started process (PID=34166) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:08:18.821+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:08:18.822+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:08:18.822+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:08:18.830+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:08:18.846+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:08:18.846+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:08:18.855+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:08:18.855+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:08:18.864+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-29T14:08:49.300+0000] {processor.py:157} INFO - Started process (PID=34191) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:08:49.301+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:08:49.303+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:08:49.303+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:08:49.320+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:08:49.337+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:08:49.337+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:08:49.347+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:08:49.347+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:08:49.358+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-29T14:09:19.737+0000] {processor.py:157} INFO - Started process (PID=34216) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:09:19.738+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:09:19.742+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:09:19.741+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:09:19.758+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:09:19.780+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:09:19.780+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:09:19.794+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:09:19.794+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:09:19.805+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-29T14:09:50.114+0000] {processor.py:157} INFO - Started process (PID=34241) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:09:50.115+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:09:50.116+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:09:50.116+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:09:50.127+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:09:50.142+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:09:50.142+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:09:50.153+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:09:50.153+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:09:50.164+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-29T14:10:20.667+0000] {processor.py:157} INFO - Started process (PID=34266) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:10:20.668+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:10:20.671+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:10:20.671+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:10:20.691+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:10:20.722+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:10:20.722+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:10:20.737+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:10:20.737+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:10:20.748+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-07-29T14:10:51.138+0000] {processor.py:157} INFO - Started process (PID=34291) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:10:51.140+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:10:51.143+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:10:51.142+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:10:51.153+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:10:51.169+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:10:51.169+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:10:51.179+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:10:51.179+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:10:51.189+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-29T14:11:21.561+0000] {processor.py:157} INFO - Started process (PID=34316) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:11:21.562+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:11:21.566+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:11:21.566+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:11:21.584+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:11:21.610+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:11:21.610+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:11:21.627+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:11:21.627+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:11:21.639+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-07-29T14:11:51.980+0000] {processor.py:157} INFO - Started process (PID=34341) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:11:51.981+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:11:51.983+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:11:51.983+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:11:51.995+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:11:52.010+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:11:52.010+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:11:52.020+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:11:52.020+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:11:52.029+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-29T14:12:22.471+0000] {processor.py:157} INFO - Started process (PID=34366) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:12:22.472+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:12:22.475+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:12:22.475+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:12:22.491+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:12:22.513+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:12:22.512+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:12:22.526+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:12:22.526+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:12:22.536+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-29T14:12:52.887+0000] {processor.py:157} INFO - Started process (PID=34391) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:12:52.888+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:12:52.889+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:12:52.889+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:12:52.904+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:12:52.916+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:12:52.916+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:12:52.927+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:12:52.926+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:12:52.937+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-29T14:13:23.260+0000] {processor.py:157} INFO - Started process (PID=34416) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:13:23.262+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:13:23.264+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:13:23.263+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:13:23.274+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:13:23.291+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:13:23.291+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:13:23.303+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:13:23.303+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:13:23.313+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-29T14:13:53.695+0000] {processor.py:157} INFO - Started process (PID=34441) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:13:53.696+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:13:53.698+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:13:53.698+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:13:53.706+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:13:53.720+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:13:53.720+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:13:53.731+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:13:53.730+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:13:53.740+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-29T14:14:24.097+0000] {processor.py:157} INFO - Started process (PID=34466) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:14:24.098+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:14:24.100+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:14:24.100+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:14:24.116+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:14:24.137+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:14:24.137+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:14:24.149+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:14:24.149+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:14:24.158+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-29T14:14:54.576+0000] {processor.py:157} INFO - Started process (PID=34491) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:14:54.577+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:14:54.579+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:14:54.578+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:14:54.588+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:14:54.604+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:14:54.604+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:14:54.615+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:14:54.615+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:14:54.626+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-29T14:15:25.001+0000] {processor.py:157} INFO - Started process (PID=34516) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:15:25.002+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:15:25.004+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:15:25.004+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:15:25.015+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:15:25.031+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:15:25.031+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:15:25.042+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:15:25.042+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:15:25.051+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-29T14:15:55.386+0000] {processor.py:157} INFO - Started process (PID=34541) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:15:55.388+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:15:55.389+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:15:55.389+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:15:55.398+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:15:55.415+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:15:55.415+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:15:55.427+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:15:55.427+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:15:55.436+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-29T14:16:25.782+0000] {processor.py:157} INFO - Started process (PID=34566) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:16:25.788+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:16:25.791+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:16:25.791+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:16:25.800+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:16:25.813+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:16:25.813+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:16:25.822+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:16:25.822+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:16:25.833+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-29T14:16:56.168+0000] {processor.py:157} INFO - Started process (PID=34591) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:16:56.169+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:16:56.171+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:16:56.171+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:16:56.181+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:16:56.196+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:16:56.196+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:16:56.207+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:16:56.207+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:16:56.218+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-29T14:17:26.630+0000] {processor.py:157} INFO - Started process (PID=34616) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:17:26.631+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:17:26.633+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:17:26.633+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:17:26.644+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:17:26.659+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:17:26.659+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:17:26.668+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:17:26.668+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:17:26.678+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-29T14:17:57.061+0000] {processor.py:157} INFO - Started process (PID=34641) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:17:57.061+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:17:57.063+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:17:57.063+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:17:57.071+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:17:57.085+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:17:57.085+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:17:57.094+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:17:57.094+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:17:57.103+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-07-29T14:18:27.535+0000] {processor.py:157} INFO - Started process (PID=34666) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:18:27.537+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:18:27.540+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:18:27.540+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:18:27.564+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:18:27.587+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:18:27.587+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:18:27.599+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:18:27.599+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:18:27.606+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-29T14:18:57.998+0000] {processor.py:157} INFO - Started process (PID=34691) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:18:57.999+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:18:58.008+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:18:58.007+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:18:58.016+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:18:58.029+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:18:58.029+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:18:58.038+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:18:58.038+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:18:58.048+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-29T14:19:28.374+0000] {processor.py:157} INFO - Started process (PID=34716) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:19:28.375+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:19:28.377+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:19:28.377+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:19:28.391+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:19:28.402+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:19:28.402+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:19:28.411+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:19:28.411+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:19:28.421+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-29T14:19:58.898+0000] {processor.py:157} INFO - Started process (PID=34741) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:19:58.899+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:19:58.901+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:19:58.901+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:19:58.912+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:19:58.927+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:19:58.927+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:19:58.938+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:19:58.938+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:19:58.949+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-29T14:20:29.281+0000] {processor.py:157} INFO - Started process (PID=34766) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:20:29.283+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:20:29.285+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:20:29.285+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:20:29.303+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:20:29.323+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:20:29.323+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:20:29.337+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:20:29.337+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:20:29.347+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-29T14:20:59.801+0000] {processor.py:157} INFO - Started process (PID=34791) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:20:59.802+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:20:59.804+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:20:59.804+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:20:59.819+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:20:59.832+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:20:59.832+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:20:59.842+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:20:59.842+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:20:59.852+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-29T14:21:30.247+0000] {processor.py:157} INFO - Started process (PID=34816) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:21:30.248+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:21:30.249+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:21:30.249+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:21:30.258+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:21:30.272+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:21:30.272+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:21:30.281+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:21:30.281+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:21:30.289+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.044 seconds
[2024-07-29T14:22:00.722+0000] {processor.py:157} INFO - Started process (PID=34841) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:22:00.723+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:22:00.744+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:22:00.744+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:22:00.762+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:22:00.779+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:22:00.779+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:22:00.790+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:22:00.790+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:22:00.804+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-07-29T14:22:31.191+0000] {processor.py:157} INFO - Started process (PID=34866) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:22:31.192+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:22:31.194+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:22:31.194+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:22:31.205+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:22:31.220+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:22:31.220+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:22:31.229+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:22:31.229+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:22:31.239+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-29T14:23:01.580+0000] {processor.py:157} INFO - Started process (PID=34891) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:23:01.587+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:23:01.589+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:23:01.589+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:23:01.596+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:23:01.608+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:23:01.608+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:23:01.618+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:23:01.617+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:23:01.629+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-29T14:23:32.057+0000] {processor.py:157} INFO - Started process (PID=34916) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:23:32.057+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:23:32.059+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:23:32.059+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:23:32.072+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:23:32.088+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:23:32.088+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:23:32.102+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:23:32.102+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:23:32.112+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-29T14:24:02.453+0000] {processor.py:157} INFO - Started process (PID=34941) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:24:02.454+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:24:02.457+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:24:02.456+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:24:02.473+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:24:02.495+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:24:02.494+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:24:02.508+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:24:02.508+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:24:02.519+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-29T14:24:32.998+0000] {processor.py:157} INFO - Started process (PID=34964) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:24:33.000+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:24:33.008+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:24:33.006+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:24:33.035+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:24:33.052+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:24:33.052+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:24:33.063+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:24:33.063+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:24:33.070+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-07-29T14:25:03.461+0000] {processor.py:157} INFO - Started process (PID=34991) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:25:03.462+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:25:03.463+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:25:03.463+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:25:03.475+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:25:03.490+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:25:03.489+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:25:03.501+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:25:03.501+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:25:03.510+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-29T14:25:33.920+0000] {processor.py:157} INFO - Started process (PID=35016) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:25:33.922+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:25:33.924+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:25:33.923+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:25:33.937+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:25:33.953+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:25:33.953+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:25:33.966+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:25:33.966+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:25:33.973+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-29T14:26:04.330+0000] {processor.py:157} INFO - Started process (PID=35041) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:26:04.331+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:26:04.333+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:26:04.333+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:26:04.342+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:26:04.358+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:26:04.358+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:26:04.370+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:26:04.370+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:26:04.379+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-29T14:26:34.684+0000] {processor.py:157} INFO - Started process (PID=35066) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:26:34.685+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:26:34.694+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:26:34.694+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:26:34.706+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:26:34.722+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:26:34.721+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:26:34.734+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:26:34.734+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:26:34.743+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-29T14:27:05.174+0000] {processor.py:157} INFO - Started process (PID=35091) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:27:05.178+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:27:05.181+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:27:05.181+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:27:05.188+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:27:05.200+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:27:05.200+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:27:05.211+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:27:05.211+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:27:05.218+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-29T14:27:35.620+0000] {processor.py:157} INFO - Started process (PID=35116) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:27:35.621+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:27:35.623+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:27:35.622+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:27:35.641+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:27:35.657+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:27:35.657+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:27:35.665+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:27:35.665+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:27:35.675+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-29T14:28:06.076+0000] {processor.py:157} INFO - Started process (PID=35141) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:28:06.077+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:28:06.078+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:28:06.078+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:28:06.089+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:28:06.106+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:28:06.106+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:28:06.117+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:28:06.117+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:28:06.126+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-29T14:28:36.484+0000] {processor.py:157} INFO - Started process (PID=35166) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:28:36.484+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:28:36.485+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:28:36.485+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:28:36.496+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:28:36.507+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:28:36.507+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:28:36.517+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:28:36.517+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:28:36.524+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.042 seconds
[2024-07-29T14:29:06.902+0000] {processor.py:157} INFO - Started process (PID=35191) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:29:06.904+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:29:06.905+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:29:06.905+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:29:06.917+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:29:06.934+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:29:06.934+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:29:06.944+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:29:06.944+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:29:06.953+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-29T14:29:37.368+0000] {processor.py:157} INFO - Started process (PID=35216) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:29:37.368+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:29:37.370+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:29:37.370+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:29:37.385+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:29:37.400+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:29:37.400+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:29:37.413+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:29:37.413+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:29:37.422+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-29T14:30:07.820+0000] {processor.py:157} INFO - Started process (PID=35241) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:30:07.821+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:30:07.826+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:30:07.826+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:30:07.836+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:30:07.849+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:30:07.849+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:30:07.859+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:30:07.859+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:30:07.867+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-29T14:30:38.265+0000] {processor.py:157} INFO - Started process (PID=35266) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:30:38.266+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:30:38.267+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:30:38.267+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:30:38.277+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:30:38.292+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:30:38.292+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:30:38.302+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:30:38.302+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:30:38.310+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-29T14:31:09.055+0000] {processor.py:157} INFO - Started process (PID=35291) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:31:09.060+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:31:09.063+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:31:09.062+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:31:09.085+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:31:09.113+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:31:09.113+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:31:09.128+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:31:09.127+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:31:09.138+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-07-29T14:31:39.593+0000] {processor.py:157} INFO - Started process (PID=35316) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:31:39.594+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:31:39.602+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:31:39.602+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:31:39.609+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:31:39.621+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:31:39.621+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:31:39.631+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:31:39.631+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:31:39.640+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-29T14:32:10.049+0000] {processor.py:157} INFO - Started process (PID=35341) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:32:10.050+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:32:10.053+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:32:10.052+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:32:10.069+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:32:10.090+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:32:10.090+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:32:10.101+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:32:10.101+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:32:10.110+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-29T14:32:40.477+0000] {processor.py:157} INFO - Started process (PID=35366) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:32:40.478+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:32:40.480+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:32:40.479+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:32:40.491+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:32:40.510+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:32:40.510+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:32:40.524+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:32:40.524+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:32:40.533+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-29T14:33:10.840+0000] {processor.py:157} INFO - Started process (PID=35391) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:33:10.840+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:33:10.842+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:33:10.842+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:33:10.851+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:33:10.867+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:33:10.867+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:33:10.877+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:33:10.877+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:33:10.885+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-29T14:33:41.343+0000] {processor.py:157} INFO - Started process (PID=35416) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:33:41.345+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:33:41.347+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:33:41.347+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:33:41.357+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:33:41.374+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:33:41.374+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:33:41.384+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:33:41.384+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:33:41.394+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-29T14:34:11.805+0000] {processor.py:157} INFO - Started process (PID=35441) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:34:11.806+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:34:11.809+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:34:11.809+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:34:11.830+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:34:11.856+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:34:11.856+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:34:11.871+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:34:11.871+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:34:11.883+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-07-29T14:34:42.336+0000] {processor.py:157} INFO - Started process (PID=35466) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:34:42.336+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:34:42.341+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:34:42.341+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:34:42.353+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:34:42.366+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:34:42.366+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:34:42.376+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:34:42.376+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:34:42.391+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-29T14:35:12.736+0000] {processor.py:157} INFO - Started process (PID=35491) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:35:12.737+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:35:12.740+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:35:12.740+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:35:12.759+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:35:12.777+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:35:12.777+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:35:12.793+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:35:12.793+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:35:12.803+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-29T14:35:43.203+0000] {processor.py:157} INFO - Started process (PID=35516) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:35:43.205+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:35:43.206+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:35:43.206+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:35:43.217+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:35:43.235+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:35:43.235+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:35:43.248+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:35:43.247+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:35:43.256+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-29T14:36:13.597+0000] {processor.py:157} INFO - Started process (PID=35541) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:36:13.602+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:36:13.605+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:36:13.605+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:36:13.615+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:36:13.628+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:36:13.628+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:36:13.641+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:36:13.641+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:36:13.648+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-29T14:36:43.942+0000] {processor.py:157} INFO - Started process (PID=35566) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:36:43.947+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:36:43.949+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:36:43.949+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:36:43.958+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:36:43.970+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:36:43.970+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:36:43.980+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:36:43.979+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:36:43.987+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-29T14:37:14.402+0000] {processor.py:157} INFO - Started process (PID=35591) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:37:14.404+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:37:14.408+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:37:14.407+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:37:14.425+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:37:14.447+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:37:14.447+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:37:14.461+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:37:14.461+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:37:14.470+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-29T14:37:44.909+0000] {processor.py:157} INFO - Started process (PID=35616) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:37:44.912+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:37:44.916+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:37:44.916+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:37:44.942+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:37:44.967+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:37:44.967+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:37:44.982+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:37:44.982+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:37:44.992+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-07-29T14:38:15.460+0000] {processor.py:157} INFO - Started process (PID=35641) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:38:15.461+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:38:15.467+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:38:15.466+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:38:15.497+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:38:15.531+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:38:15.531+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:38:15.548+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:38:15.548+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:38:15.560+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-07-29T14:38:45.907+0000] {processor.py:157} INFO - Started process (PID=35666) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:38:45.908+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:38:45.912+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:38:45.911+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:38:45.926+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:38:45.951+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:38:45.951+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:38:45.966+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:38:45.966+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:38:45.977+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-29T14:39:16.423+0000] {processor.py:157} INFO - Started process (PID=35691) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:39:16.424+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:39:16.428+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:39:16.428+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:39:16.449+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:39:16.476+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:39:16.475+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:39:16.489+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:39:16.489+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:39:16.500+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-07-29T14:39:46.923+0000] {processor.py:157} INFO - Started process (PID=35716) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:39:46.924+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:39:46.927+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:39:46.927+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:39:46.941+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:39:46.963+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:39:46.963+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:39:46.977+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:39:46.977+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:39:46.986+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-29T14:40:17.376+0000] {processor.py:157} INFO - Started process (PID=35741) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:40:17.377+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:40:17.380+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:40:17.380+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:40:17.393+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:40:17.412+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:40:17.412+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:40:17.422+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:40:17.422+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:40:17.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-29T14:40:47.833+0000] {processor.py:157} INFO - Started process (PID=35766) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:40:47.834+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:40:47.839+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:40:47.838+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:40:47.864+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:40:47.921+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:40:47.921+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:40:47.968+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:40:47.967+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:40:47.982+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.164 seconds
[2024-07-29T14:41:18.446+0000] {processor.py:157} INFO - Started process (PID=35791) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:41:18.448+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:41:18.452+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:41:18.452+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:41:18.470+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:41:18.499+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:41:18.499+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:41:18.517+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:41:18.517+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:41:18.530+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-07-29T14:41:48.946+0000] {processor.py:157} INFO - Started process (PID=35816) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:41:48.949+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:41:48.953+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:41:48.953+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:41:48.960+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:41:48.972+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:41:48.972+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:41:48.981+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:41:48.981+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:41:48.991+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-29T14:42:19.415+0000] {processor.py:157} INFO - Started process (PID=35841) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:42:19.418+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:42:19.424+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:42:19.423+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:42:19.449+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:42:19.479+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:42:19.479+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:42:19.495+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:42:19.495+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:42:19.515+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-07-29T14:42:49.876+0000] {processor.py:157} INFO - Started process (PID=35866) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:42:49.877+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:42:49.881+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:42:49.880+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:42:49.898+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:42:49.919+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:42:49.918+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:42:49.931+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:42:49.931+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:42:49.941+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-29T14:43:20.388+0000] {processor.py:157} INFO - Started process (PID=35891) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:43:20.389+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:43:20.393+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:43:20.393+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:43:20.415+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:43:20.444+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:43:20.444+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:43:20.461+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:43:20.461+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:43:20.473+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-07-29T14:43:50.870+0000] {processor.py:157} INFO - Started process (PID=35916) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:43:50.872+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:43:50.878+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:43:50.878+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:43:50.893+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:43:50.913+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:43:50.913+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:43:50.927+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:43:50.926+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:43:50.940+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-29T14:44:21.436+0000] {processor.py:157} INFO - Started process (PID=35941) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:44:21.437+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:44:21.442+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:44:21.442+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:44:21.462+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:44:21.488+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:44:21.487+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:44:21.503+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:44:21.503+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:44:21.517+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-07-29T14:44:51.978+0000] {processor.py:157} INFO - Started process (PID=35966) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:44:51.979+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:44:51.983+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:44:51.983+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:44:52.000+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:44:52.026+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:44:52.026+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:44:52.040+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:44:52.040+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:44:52.051+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-07-29T14:45:22.477+0000] {processor.py:157} INFO - Started process (PID=35991) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:45:22.478+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:45:22.483+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:45:22.482+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:45:22.501+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:45:22.530+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:45:22.530+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:45:22.546+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:45:22.546+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:45:22.559+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-07-29T14:45:52.953+0000] {processor.py:157} INFO - Started process (PID=36016) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:45:52.954+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:45:52.958+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:45:52.958+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:45:52.979+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:45:53.001+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:45:53.001+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:45:53.014+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:45:53.014+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:45:53.025+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-07-29T14:46:23.398+0000] {processor.py:157} INFO - Started process (PID=36041) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:46:23.399+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:46:23.406+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:46:23.405+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:46:23.436+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:46:23.475+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:46:23.475+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:46:23.496+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:46:23.495+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:46:23.512+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-07-29T14:46:53.934+0000] {processor.py:157} INFO - Started process (PID=36066) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:46:53.935+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:46:53.938+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:46:53.938+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:46:53.955+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:46:53.990+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:46:53.990+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:46:54.016+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:46:54.016+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:46:54.050+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-07-29T14:47:24.554+0000] {processor.py:157} INFO - Started process (PID=36091) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:47:24.555+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:47:24.558+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:47:24.557+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:47:24.578+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:47:24.608+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:47:24.608+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:47:24.624+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:47:24.624+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:47:24.638+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-07-29T14:47:55.066+0000] {processor.py:157} INFO - Started process (PID=36116) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:47:55.067+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:47:55.072+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:47:55.071+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:47:55.092+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:47:55.118+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:47:55.118+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:47:55.132+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:47:55.132+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:47:55.143+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-07-29T14:48:25.513+0000] {processor.py:157} INFO - Started process (PID=36141) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:48:25.516+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:48:25.519+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:48:25.519+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:48:25.545+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:48:25.578+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:48:25.578+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:48:25.600+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:48:25.599+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:48:25.613+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-07-29T14:48:55.986+0000] {processor.py:157} INFO - Started process (PID=36166) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:48:55.989+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:48:55.993+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:48:55.992+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:48:56.016+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:48:56.047+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:48:56.047+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:48:56.062+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:48:56.062+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:48:56.074+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-07-29T14:49:26.555+0000] {processor.py:157} INFO - Started process (PID=36191) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:49:26.560+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:49:26.566+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:49:26.565+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:49:26.591+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:49:26.629+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:49:26.629+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:49:26.652+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:49:26.652+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:49:26.664+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-07-29T14:49:57.150+0000] {processor.py:157} INFO - Started process (PID=36216) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:49:57.151+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:49:57.154+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:49:57.154+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:49:57.172+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:49:57.196+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:49:57.196+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:49:57.209+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:49:57.209+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:49:57.220+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-29T14:50:27.626+0000] {processor.py:157} INFO - Started process (PID=36241) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:50:27.627+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:50:27.629+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:50:27.629+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:50:27.641+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:50:27.664+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:50:27.664+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:50:27.680+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:50:27.680+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:50:27.692+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-29T14:50:58.113+0000] {processor.py:157} INFO - Started process (PID=36266) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:50:58.114+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:50:58.119+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:50:58.119+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:50:58.137+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:50:58.163+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:50:58.163+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:50:58.179+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:50:58.179+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:50:58.192+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-07-29T14:51:28.650+0000] {processor.py:157} INFO - Started process (PID=36291) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:51:28.653+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:51:28.656+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:51:28.656+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:51:28.675+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:51:28.697+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:51:28.697+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:51:28.711+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:51:28.711+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:51:28.723+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-29T14:51:59.197+0000] {processor.py:157} INFO - Started process (PID=36315) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:51:59.198+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:51:59.204+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:51:59.204+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:51:59.213+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:51:59.228+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:51:59.228+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:51:59.242+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:51:59.242+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:51:59.253+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-29T14:52:29.556+0000] {processor.py:157} INFO - Started process (PID=36341) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:52:29.559+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:52:29.563+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:52:29.563+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:52:29.578+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:52:29.601+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:52:29.601+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:52:29.613+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:52:29.613+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:52:29.624+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-29T14:52:59.968+0000] {processor.py:157} INFO - Started process (PID=36366) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:52:59.969+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:52:59.974+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:52:59.973+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:52:59.995+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:53:00.029+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:53:00.029+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:53:00.048+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:53:00.048+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:53:00.062+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-07-29T14:53:30.460+0000] {processor.py:157} INFO - Started process (PID=36391) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:53:30.461+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:53:30.469+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:53:30.469+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:53:30.483+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:53:30.496+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:53:30.496+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:53:30.507+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:53:30.507+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:53:30.518+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-29T14:54:00.871+0000] {processor.py:157} INFO - Started process (PID=36416) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:54:00.872+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:54:00.875+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:54:00.875+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:54:00.889+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:54:00.915+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:54:00.915+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:54:00.930+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:54:00.930+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:54:00.943+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-29T14:54:31.363+0000] {processor.py:157} INFO - Started process (PID=36440) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:54:31.364+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:54:31.368+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:54:31.368+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:54:31.393+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:54:31.422+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:54:31.422+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:54:31.438+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:54:31.437+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:54:31.453+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-07-29T14:55:01.848+0000] {processor.py:157} INFO - Started process (PID=36466) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:55:01.849+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:55:01.852+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:55:01.851+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:55:01.869+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:55:01.894+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:55:01.894+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:55:01.910+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:55:01.910+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:55:01.921+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-29T14:55:32.358+0000] {processor.py:157} INFO - Started process (PID=36491) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:55:32.361+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:55:32.365+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:55:32.365+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:55:32.389+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:55:32.426+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:55:32.425+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:55:32.451+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:55:32.451+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:55:32.467+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-07-29T14:56:02.862+0000] {processor.py:157} INFO - Started process (PID=36516) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:56:02.863+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:56:02.869+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:56:02.869+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:56:02.903+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:56:02.942+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:56:02.942+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:56:02.964+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:56:02.964+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:56:02.977+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-07-29T14:56:33.418+0000] {processor.py:157} INFO - Started process (PID=36541) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:56:33.419+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:56:33.424+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:56:33.424+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:56:33.439+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:56:33.460+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:56:33.460+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:56:33.478+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:56:33.478+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:56:33.490+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-29T14:57:03.914+0000] {processor.py:157} INFO - Started process (PID=36565) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:57:03.916+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:57:03.922+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:57:03.921+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:57:03.953+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:57:03.998+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:57:03.998+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:57:04.020+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:57:04.020+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:57:04.032+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-07-29T14:57:34.503+0000] {processor.py:157} INFO - Started process (PID=36591) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:57:34.503+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:57:34.512+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:57:34.511+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:57:34.518+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:57:34.530+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:57:34.530+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:57:34.539+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:57:34.539+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:57:34.551+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-29T14:58:04.920+0000] {processor.py:157} INFO - Started process (PID=36616) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:58:04.921+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:58:04.925+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:58:04.925+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:58:04.944+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:58:04.975+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:58:04.975+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:58:04.988+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:58:04.988+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:58:04.998+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-07-29T14:58:35.423+0000] {processor.py:157} INFO - Started process (PID=36641) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:58:35.424+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:58:35.425+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:58:35.425+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:58:35.435+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:58:35.451+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:58:35.451+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:58:35.461+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:58:35.461+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:58:35.469+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-29T14:59:05.868+0000] {processor.py:157} INFO - Started process (PID=36666) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:59:05.868+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:59:05.870+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:59:05.870+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:59:05.880+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:59:05.894+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:59:05.894+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:59:05.903+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:59:05.903+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:59:05.911+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-07-29T14:59:36.364+0000] {processor.py:157} INFO - Started process (PID=36691) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:59:36.365+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T14:59:36.368+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:59:36.368+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:59:36.385+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T14:59:36.406+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:59:36.406+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T14:59:36.419+0000] {logging_mixin.py:151} INFO - [2024-07-29T14:59:36.419+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T14:59:36.428+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-29T15:00:06.849+0000] {processor.py:157} INFO - Started process (PID=36716) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:00:06.853+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:00:06.858+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:00:06.858+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:00:06.890+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:00:06.931+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:00:06.931+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:00:06.950+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:00:06.950+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:00:06.965+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-07-29T15:00:37.512+0000] {processor.py:157} INFO - Started process (PID=36741) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:00:37.514+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:00:37.520+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:00:37.519+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:00:37.549+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:00:37.597+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:00:37.597+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:00:37.617+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:00:37.617+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:00:37.637+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.147 seconds
[2024-07-29T15:01:08.095+0000] {processor.py:157} INFO - Started process (PID=36766) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:01:08.096+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:01:08.102+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:01:08.102+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:01:08.125+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:01:08.152+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:01:08.152+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:01:08.166+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:01:08.166+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:01:08.177+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-07-29T15:01:38.611+0000] {processor.py:157} INFO - Started process (PID=36791) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:01:38.612+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:01:38.616+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:01:38.616+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:01:38.633+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:01:38.661+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:01:38.661+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:01:38.676+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:01:38.676+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:01:38.687+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-07-29T15:02:09.132+0000] {processor.py:157} INFO - Started process (PID=36815) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:02:09.133+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:02:09.139+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:02:09.138+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:02:09.161+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:02:09.203+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:02:09.203+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:02:09.222+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:02:09.221+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:02:09.233+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-07-29T15:02:39.643+0000] {processor.py:157} INFO - Started process (PID=36841) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:02:39.644+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:02:39.648+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:02:39.647+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:02:39.663+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:02:39.678+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:02:39.678+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:02:39.697+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:02:39.697+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:02:39.709+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-29T15:03:10.097+0000] {processor.py:157} INFO - Started process (PID=36866) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:03:10.099+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:03:10.109+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:03:10.109+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:03:10.133+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:03:10.155+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:03:10.155+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:03:10.169+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:03:10.169+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:03:10.180+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-07-29T15:03:40.619+0000] {processor.py:157} INFO - Started process (PID=36891) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:03:40.620+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:03:40.622+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:03:40.622+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:03:40.644+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:03:40.678+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:03:40.677+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:03:40.719+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:03:40.719+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:03:40.750+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-07-29T15:04:11.246+0000] {processor.py:157} INFO - Started process (PID=36916) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:04:11.247+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:04:11.252+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:04:11.251+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:04:11.269+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:04:11.296+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:04:11.296+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:04:11.311+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:04:11.311+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:04:11.323+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-07-29T15:04:41.753+0000] {processor.py:157} INFO - Started process (PID=36940) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:04:41.756+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:04:41.762+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:04:41.762+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:04:41.820+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:04:41.854+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:04:41.854+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:04:41.870+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:04:41.870+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:04:41.881+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-07-29T15:05:12.335+0000] {processor.py:157} INFO - Started process (PID=36966) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:05:12.336+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:05:12.341+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:05:12.341+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:05:12.384+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:05:12.411+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:05:12.411+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:05:12.424+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:05:12.424+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:05:12.434+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-07-29T15:05:42.914+0000] {processor.py:157} INFO - Started process (PID=36991) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:05:42.916+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:05:42.921+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:05:42.921+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:05:42.945+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:05:42.981+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:05:42.981+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:05:43.007+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:05:43.007+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:05:43.023+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-07-29T15:06:13.530+0000] {processor.py:157} INFO - Started process (PID=37016) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:06:13.535+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:06:13.548+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:06:13.546+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:06:13.605+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:06:13.659+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:06:13.659+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:06:13.684+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:06:13.684+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:06:13.700+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.177 seconds
[2024-07-29T15:06:44.097+0000] {processor.py:157} INFO - Started process (PID=37041) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:06:44.103+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:06:44.106+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:06:44.106+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:06:44.136+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:06:44.206+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:06:44.206+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:06:44.226+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:06:44.226+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:06:44.241+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.172 seconds
[2024-07-29T15:07:14.741+0000] {processor.py:157} INFO - Started process (PID=37066) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:07:14.744+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:07:14.748+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:07:14.748+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:07:14.778+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:07:14.814+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:07:14.814+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:07:14.840+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:07:14.840+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:07:14.853+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-07-29T15:07:45.272+0000] {processor.py:157} INFO - Started process (PID=37091) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:07:45.273+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:07:45.275+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:07:45.275+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:07:45.297+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:07:45.322+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:07:45.322+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:07:45.341+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:07:45.341+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:07:45.359+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-07-29T15:08:15.832+0000] {processor.py:157} INFO - Started process (PID=37116) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:08:15.836+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:08:15.841+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:08:15.841+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:08:15.864+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:08:15.889+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:08:15.889+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:08:15.903+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:08:15.903+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:08:15.920+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-07-29T15:08:46.395+0000] {processor.py:157} INFO - Started process (PID=37141) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:08:46.399+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:08:46.403+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:08:46.403+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:08:46.428+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:08:46.458+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:08:46.458+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:08:46.477+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:08:46.477+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:08:46.489+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-07-29T15:09:16.947+0000] {processor.py:157} INFO - Started process (PID=37166) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:09:16.949+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:09:16.952+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:09:16.952+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:09:16.968+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:09:16.991+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:09:16.991+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:09:17.008+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:09:17.008+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:09:17.019+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-29T15:09:47.484+0000] {processor.py:157} INFO - Started process (PID=37191) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:09:47.490+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:09:47.496+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:09:47.496+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:09:47.524+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:09:47.576+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:09:47.576+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:09:47.594+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:09:47.594+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:09:47.606+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-07-29T15:10:18.031+0000] {processor.py:157} INFO - Started process (PID=37214) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:10:18.032+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:10:18.036+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:10:18.036+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:10:18.063+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:10:18.103+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:10:18.103+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:10:18.119+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:10:18.119+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:10:18.128+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-07-29T15:10:48.621+0000] {processor.py:157} INFO - Started process (PID=37241) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:10:48.622+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:10:48.627+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:10:48.626+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:10:48.651+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:10:48.677+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:10:48.676+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:10:48.692+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:10:48.692+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:10:48.703+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-07-29T15:11:19.044+0000] {processor.py:157} INFO - Started process (PID=37266) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:11:19.045+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:11:19.047+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:11:19.046+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:11:19.058+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:11:19.074+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:11:19.074+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:11:19.085+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:11:19.084+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:11:19.095+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-29T15:11:49.569+0000] {processor.py:157} INFO - Started process (PID=37291) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:11:49.572+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:11:49.580+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:11:49.579+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:11:49.600+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:11:49.626+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:11:49.626+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:11:49.641+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:11:49.641+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:11:49.652+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-07-29T15:12:20.133+0000] {processor.py:157} INFO - Started process (PID=37316) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:12:20.135+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:12:20.139+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:12:20.138+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:12:20.190+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:12:20.291+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:12:20.291+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:12:20.372+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:12:20.371+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:12:20.389+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.261 seconds
[2024-07-29T15:12:50.824+0000] {processor.py:157} INFO - Started process (PID=37341) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:12:50.826+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:12:50.834+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:12:50.834+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:12:50.859+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:12:50.920+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:12:50.920+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:12:50.945+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:12:50.945+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:12:50.961+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.161 seconds
[2024-07-29T15:13:21.422+0000] {processor.py:157} INFO - Started process (PID=37365) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:13:21.423+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:13:21.427+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:13:21.427+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:13:21.450+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:13:21.478+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:13:21.478+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:13:21.491+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:13:21.491+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:13:21.500+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-07-29T15:13:51.964+0000] {processor.py:157} INFO - Started process (PID=37391) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:13:51.966+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:13:51.970+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:13:51.970+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:13:51.991+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:13:52.036+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:13:52.036+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:13:52.057+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:13:52.057+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:13:52.070+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-07-29T15:14:22.546+0000] {processor.py:157} INFO - Started process (PID=37415) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:14:22.549+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:14:22.555+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:14:22.554+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:14:22.580+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:14:22.605+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:14:22.605+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:14:22.620+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:14:22.620+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:14:22.631+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-07-29T15:14:53.052+0000] {processor.py:157} INFO - Started process (PID=37441) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:14:53.054+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:14:53.057+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:14:53.057+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:14:53.077+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:14:53.101+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:14:53.101+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:14:53.114+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:14:53.114+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:14:53.124+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-29T15:15:23.593+0000] {processor.py:157} INFO - Started process (PID=37466) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:15:23.594+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:15:23.598+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:15:23.597+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:15:23.617+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:15:23.638+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:15:23.638+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:15:23.651+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:15:23.651+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:15:23.661+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-29T15:15:54.067+0000] {processor.py:157} INFO - Started process (PID=37490) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:15:54.068+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:15:54.070+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:15:54.070+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:15:54.079+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:15:54.095+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:15:54.094+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:15:54.108+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:15:54.107+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:15:54.116+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-29T15:16:24.424+0000] {processor.py:157} INFO - Started process (PID=37516) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:16:24.426+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:16:24.428+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:16:24.427+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:16:24.438+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:16:24.455+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:16:24.455+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:16:24.467+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:16:24.467+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:16:24.477+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-29T15:16:54.911+0000] {processor.py:157} INFO - Started process (PID=37541) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:16:54.915+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:16:54.920+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:16:54.920+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:16:54.965+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:16:55.005+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:16:55.004+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:16:55.022+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:16:55.021+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:16:55.041+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-07-29T15:17:25.513+0000] {processor.py:157} INFO - Started process (PID=37566) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:17:25.514+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:17:25.517+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:17:25.517+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:17:25.529+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:17:25.546+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:17:25.546+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:17:25.557+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:17:25.557+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:17:25.567+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-29T15:17:55.988+0000] {processor.py:157} INFO - Started process (PID=37591) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:17:55.990+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:17:55.994+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:17:55.993+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:17:56.020+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:17:56.041+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:17:56.041+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:17:56.056+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:17:56.056+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:17:56.066+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-07-29T15:18:26.430+0000] {processor.py:157} INFO - Started process (PID=37616) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:18:26.431+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:18:26.436+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:18:26.436+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:18:26.458+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:18:26.485+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:18:26.485+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:18:26.501+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:18:26.501+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:18:26.513+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-07-29T15:18:56.931+0000] {processor.py:157} INFO - Started process (PID=37641) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:18:56.932+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:18:56.935+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:18:56.935+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:18:56.950+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:18:56.974+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:18:56.974+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:18:56.991+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:18:56.990+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:18:57.007+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-07-29T15:19:27.475+0000] {processor.py:157} INFO - Started process (PID=37666) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:19:27.484+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:19:27.499+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:19:27.499+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:19:27.520+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:19:27.550+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:19:27.550+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:19:27.563+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:19:27.563+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:19:27.572+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-07-29T15:19:57.952+0000] {processor.py:157} INFO - Started process (PID=37691) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:19:57.954+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:19:57.958+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:19:57.957+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:19:57.976+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:19:57.999+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:19:57.999+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:19:58.015+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:19:58.015+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:19:58.026+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-07-29T15:20:28.370+0000] {processor.py:157} INFO - Started process (PID=37716) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:20:28.374+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:20:28.378+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:20:28.377+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:20:28.398+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:20:28.421+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:20:28.420+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:20:28.434+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:20:28.434+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:20:28.443+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-07-29T15:20:58.899+0000] {processor.py:157} INFO - Started process (PID=37741) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:20:58.901+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:20:58.903+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:20:58.903+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:20:58.914+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:20:58.929+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:20:58.929+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:20:58.940+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:20:58.940+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:20:58.950+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-29T15:21:29.315+0000] {processor.py:157} INFO - Started process (PID=37766) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:21:29.316+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:21:29.320+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:21:29.319+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:21:29.335+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:21:29.359+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:21:29.359+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:21:29.371+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:21:29.371+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:21:29.381+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-29T15:21:59.885+0000] {processor.py:157} INFO - Started process (PID=37791) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:21:59.885+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:21:59.893+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:21:59.893+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:21:59.902+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:21:59.914+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:21:59.914+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:21:59.925+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:21:59.925+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:21:59.933+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-29T15:22:30.357+0000] {processor.py:157} INFO - Started process (PID=37816) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:22:30.358+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:22:30.361+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:22:30.361+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:22:30.371+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:22:30.388+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:22:30.388+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:22:30.398+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:22:30.398+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:22:30.408+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-29T15:23:00.813+0000] {processor.py:157} INFO - Started process (PID=37841) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:23:00.813+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:23:00.816+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:23:00.816+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:23:00.833+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:23:00.854+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:23:00.854+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:23:00.866+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:23:00.866+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:23:00.877+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-29T15:23:31.352+0000] {processor.py:157} INFO - Started process (PID=37866) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:23:31.352+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:23:31.356+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:23:31.355+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:23:31.371+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:23:31.396+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:23:31.396+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:23:31.409+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:23:31.409+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:23:31.420+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-29T15:24:01.917+0000] {processor.py:157} INFO - Started process (PID=37891) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:24:01.918+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:24:01.922+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:24:01.922+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:24:01.944+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:24:01.983+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:24:01.983+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:24:01.997+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:24:01.997+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:24:02.011+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-07-29T15:24:32.528+0000] {processor.py:157} INFO - Started process (PID=37916) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:24:32.531+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:24:32.543+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:24:32.542+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:24:32.565+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:24:32.606+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:24:32.606+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:24:32.624+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:24:32.624+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:24:32.647+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-07-29T15:25:03.135+0000] {processor.py:157} INFO - Started process (PID=37941) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:25:03.137+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:25:03.142+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:25:03.142+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:25:03.161+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:25:03.183+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:25:03.183+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:25:03.198+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:25:03.197+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:25:03.210+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-07-29T15:25:33.633+0000] {processor.py:157} INFO - Started process (PID=37966) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:25:33.635+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:25:33.639+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:25:33.639+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:25:33.669+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:25:33.708+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:25:33.708+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:25:33.729+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:25:33.729+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:25:33.742+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-07-29T15:26:04.191+0000] {processor.py:157} INFO - Started process (PID=37991) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:26:04.193+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:26:04.196+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:26:04.196+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:26:04.212+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:26:04.234+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:26:04.234+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:26:04.247+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:26:04.247+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:26:04.258+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-29T15:26:34.608+0000] {processor.py:157} INFO - Started process (PID=38015) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:26:34.608+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:26:34.611+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:26:34.610+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:26:34.621+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:26:34.641+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:26:34.641+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:26:34.653+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:26:34.653+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:26:34.664+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-29T15:27:05.074+0000] {processor.py:157} INFO - Started process (PID=38041) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:27:05.075+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:27:05.078+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:27:05.077+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:27:05.088+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:27:05.104+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:27:05.104+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:27:05.113+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:27:05.113+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:27:05.123+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-29T15:27:35.510+0000] {processor.py:157} INFO - Started process (PID=38066) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:27:35.511+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:27:35.515+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:27:35.515+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:27:35.529+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:27:35.548+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:27:35.548+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:27:35.558+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:27:35.558+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:27:35.566+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-29T15:28:05.989+0000] {processor.py:157} INFO - Started process (PID=38091) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:28:05.990+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:28:05.992+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:28:05.992+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:28:06.009+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:28:06.026+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:28:06.026+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:28:06.040+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:28:06.039+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:28:06.053+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-29T15:28:36.473+0000] {processor.py:157} INFO - Started process (PID=38116) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:28:36.475+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:28:36.477+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:28:36.477+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:28:36.493+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:28:36.512+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:28:36.512+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:28:36.522+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:28:36.522+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:28:36.531+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-29T15:29:06.960+0000] {processor.py:157} INFO - Started process (PID=38141) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:29:06.960+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:29:06.962+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:29:06.962+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:29:06.975+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:29:06.997+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:29:06.997+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:29:07.009+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:29:07.009+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:29:07.020+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-29T15:29:37.418+0000] {processor.py:157} INFO - Started process (PID=38166) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:29:37.419+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:29:37.423+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:29:37.423+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:29:37.442+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:29:37.463+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:29:37.463+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:29:37.473+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:29:37.473+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:29:37.482+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-29T15:30:07.857+0000] {processor.py:157} INFO - Started process (PID=38191) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:30:07.865+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:30:07.867+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:30:07.866+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:30:07.875+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:30:07.891+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:30:07.891+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:30:07.903+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:30:07.903+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:30:07.911+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-29T15:30:38.383+0000] {processor.py:157} INFO - Started process (PID=38216) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:30:38.384+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:30:38.387+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:30:38.387+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:30:38.412+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:30:38.435+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:30:38.435+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:30:38.446+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:30:38.446+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:30:38.456+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-29T15:31:08.887+0000] {processor.py:157} INFO - Started process (PID=38241) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:31:08.888+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:31:08.893+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:31:08.893+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:31:08.916+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:31:08.956+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:31:08.956+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:31:08.973+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:31:08.973+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:31:08.990+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-07-29T15:31:39.394+0000] {processor.py:157} INFO - Started process (PID=38266) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:31:39.395+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:31:39.401+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:31:39.400+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:31:39.425+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:31:39.457+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:31:39.457+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:31:39.472+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:31:39.472+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:31:39.486+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-07-29T15:32:09.902+0000] {processor.py:157} INFO - Started process (PID=38291) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:32:09.903+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:32:09.908+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:32:09.908+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:32:09.927+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:32:09.952+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:32:09.952+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:32:09.966+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:32:09.966+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:32:09.976+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-07-29T15:32:40.445+0000] {processor.py:157} INFO - Started process (PID=38315) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:32:40.450+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:32:40.455+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:32:40.454+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:32:40.484+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:32:40.519+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:32:40.519+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:32:40.538+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:32:40.538+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:32:40.558+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-07-29T15:33:11.052+0000] {processor.py:157} INFO - Started process (PID=38341) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:33:11.060+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:33:11.071+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:33:11.070+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:33:11.104+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:33:11.139+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:33:11.138+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:33:11.160+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:33:11.160+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:33:11.177+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.143 seconds
[2024-07-29T15:33:41.671+0000] {processor.py:157} INFO - Started process (PID=38366) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:33:41.672+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:33:41.681+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:33:41.680+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:33:41.752+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:33:41.801+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:33:41.801+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:33:41.823+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:33:41.823+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:33:41.835+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.175 seconds
[2024-07-29T15:34:12.298+0000] {processor.py:157} INFO - Started process (PID=38391) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:34:12.303+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:34:12.310+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:34:12.309+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:34:12.343+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:34:12.387+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:34:12.387+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:34:12.408+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:34:12.408+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:34:12.423+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-07-29T15:34:42.900+0000] {processor.py:157} INFO - Started process (PID=38416) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:34:42.902+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:34:42.907+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:34:42.906+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:34:42.934+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:34:42.970+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:34:42.970+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:34:42.992+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:34:42.992+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:34:43.005+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-07-29T15:35:13.453+0000] {processor.py:157} INFO - Started process (PID=38441) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:35:13.455+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:35:13.461+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:35:13.460+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:35:13.491+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:35:13.523+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:35:13.523+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:35:13.561+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:35:13.561+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:35:13.574+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-07-29T15:35:43.985+0000] {processor.py:157} INFO - Started process (PID=38465) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:35:43.987+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:35:43.993+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:35:43.993+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:35:44.010+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:35:44.035+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:35:44.034+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:35:44.050+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:35:44.050+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:35:44.064+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-07-29T15:36:14.478+0000] {processor.py:157} INFO - Started process (PID=38491) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:36:14.478+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:36:14.484+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:36:14.484+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:36:14.493+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:36:14.510+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:36:14.510+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:36:14.521+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:36:14.521+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:36:14.529+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-29T15:36:44.914+0000] {processor.py:157} INFO - Started process (PID=38516) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:36:44.915+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:36:44.917+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:36:44.917+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:36:44.930+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:36:44.949+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:36:44.949+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:36:44.960+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:36:44.960+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:36:44.969+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-29T15:37:15.381+0000] {processor.py:157} INFO - Started process (PID=38541) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:37:15.381+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:37:15.383+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:37:15.383+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:37:15.394+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:37:15.409+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:37:15.409+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:37:15.419+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:37:15.418+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:37:15.428+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-29T15:37:45.765+0000] {processor.py:157} INFO - Started process (PID=38566) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:37:45.766+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:37:45.767+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:37:45.767+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:37:45.775+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:37:45.792+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:37:45.791+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:37:45.802+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:37:45.802+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:37:45.812+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-29T15:38:16.164+0000] {processor.py:157} INFO - Started process (PID=38591) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:38:16.168+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:38:16.171+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:38:16.171+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:38:16.191+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:38:16.214+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:38:16.214+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:38:16.228+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:38:16.228+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:38:16.244+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-07-29T15:38:46.680+0000] {processor.py:157} INFO - Started process (PID=38616) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:38:46.681+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:38:46.684+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:38:46.683+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:38:46.695+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:38:46.710+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:38:46.710+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:38:46.721+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:38:46.721+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:38:46.729+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-29T15:39:17.160+0000] {processor.py:157} INFO - Started process (PID=38641) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:39:17.160+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:39:17.166+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:39:17.166+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:39:17.183+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:39:17.201+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:39:17.201+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:39:17.216+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:39:17.216+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:39:17.225+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-29T15:39:47.706+0000] {processor.py:157} INFO - Started process (PID=38666) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:39:47.707+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:39:47.711+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:39:47.710+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:39:47.753+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:39:47.779+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:39:47.779+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:39:47.791+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:39:47.791+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:39:47.801+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-07-29T15:40:18.199+0000] {processor.py:157} INFO - Started process (PID=38691) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:40:18.200+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:40:18.203+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:40:18.203+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:40:18.218+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:40:18.239+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:40:18.239+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:40:18.255+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:40:18.255+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:40:18.264+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-29T15:40:48.731+0000] {processor.py:157} INFO - Started process (PID=38716) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:40:48.732+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:40:48.734+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:40:48.734+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:40:48.750+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:40:48.762+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:40:48.762+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:40:48.772+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:40:48.772+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:40:48.783+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-29T15:41:19.164+0000] {processor.py:157} INFO - Started process (PID=38741) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:41:19.165+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:41:19.167+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:41:19.167+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:41:19.181+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:41:19.195+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:41:19.195+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:41:19.208+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:41:19.207+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:41:19.215+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-29T15:41:49.606+0000] {processor.py:157} INFO - Started process (PID=38765) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:41:49.607+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:41:49.610+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:41:49.609+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:41:49.629+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:41:49.656+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:41:49.656+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:41:49.672+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:41:49.672+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:41:49.682+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-07-29T15:42:20.067+0000] {processor.py:157} INFO - Started process (PID=38791) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:42:20.067+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:42:20.075+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:42:20.075+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:42:20.084+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:42:20.098+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:42:20.098+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:42:20.108+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:42:20.108+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:42:20.118+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-29T15:42:50.511+0000] {processor.py:157} INFO - Started process (PID=38816) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:42:50.512+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:42:50.516+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:42:50.515+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:42:50.532+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:42:50.553+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:42:50.553+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:42:50.565+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:42:50.565+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:42:50.574+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-29T15:43:21.032+0000] {processor.py:157} INFO - Started process (PID=38841) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:43:21.033+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:43:21.035+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:43:21.035+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:43:21.042+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:43:21.059+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:43:21.059+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:43:21.073+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:43:21.073+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:43:21.080+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-29T15:43:51.471+0000] {processor.py:157} INFO - Started process (PID=38866) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:43:51.472+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:43:51.474+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:43:51.474+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:43:51.484+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:43:51.499+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:43:51.499+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:43:51.510+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:43:51.510+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:43:51.519+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-29T15:44:21.881+0000] {processor.py:157} INFO - Started process (PID=38891) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:44:21.885+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:44:21.890+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:44:21.889+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:44:21.903+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:44:21.920+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:44:21.920+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:44:21.933+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:44:21.933+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:44:21.943+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-29T15:44:52.322+0000] {processor.py:157} INFO - Started process (PID=38915) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:44:52.323+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:44:52.326+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:44:52.326+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:44:52.357+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:44:52.398+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:44:52.398+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:44:52.418+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:44:52.418+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:44:52.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-07-29T15:45:22.898+0000] {processor.py:157} INFO - Started process (PID=38941) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:45:22.900+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:45:22.902+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:45:22.902+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:45:22.919+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:45:22.940+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:45:22.940+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:45:22.954+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:45:22.954+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:45:22.963+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-29T15:45:53.341+0000] {processor.py:157} INFO - Started process (PID=38966) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:45:53.343+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:45:53.344+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:45:53.344+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:45:53.357+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:45:53.371+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:45:53.371+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:45:53.383+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:45:53.383+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:45:53.390+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-29T15:46:23.892+0000] {processor.py:157} INFO - Started process (PID=38991) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:46:23.894+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:46:23.897+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:46:23.896+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:46:23.914+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:46:23.929+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:46:23.929+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:46:23.939+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:46:23.939+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:46:23.948+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-29T15:46:54.343+0000] {processor.py:157} INFO - Started process (PID=39016) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:46:54.343+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:46:54.346+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:46:54.346+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:46:54.363+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:46:54.388+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:46:54.388+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:46:54.400+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:46:54.400+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:46:54.410+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-29T15:47:24.785+0000] {processor.py:157} INFO - Started process (PID=39040) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:47:24.786+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:47:24.789+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:47:24.789+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:47:24.803+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:47:24.818+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:47:24.818+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:47:24.827+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:47:24.827+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:47:24.835+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-29T15:47:55.276+0000] {processor.py:157} INFO - Started process (PID=39066) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:47:55.277+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:47:55.280+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:47:55.280+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:47:55.290+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:47:55.313+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:47:55.313+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:47:55.326+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:47:55.326+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:47:55.334+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-29T15:48:25.779+0000] {processor.py:157} INFO - Started process (PID=39091) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:48:25.781+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:48:25.783+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:48:25.783+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:48:25.796+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:48:25.811+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:48:25.811+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:48:25.821+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:48:25.820+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:48:25.828+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-29T15:48:56.185+0000] {processor.py:157} INFO - Started process (PID=39116) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:48:56.186+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:48:56.189+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:48:56.189+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:48:56.212+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:48:56.231+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:48:56.231+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:48:56.244+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:48:56.244+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:48:56.254+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-29T15:49:26.761+0000] {processor.py:157} INFO - Started process (PID=39141) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:49:26.762+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:49:26.764+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:49:26.763+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:49:26.774+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:49:26.790+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:49:26.790+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:49:26.801+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:49:26.801+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:49:26.811+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-29T15:49:57.259+0000] {processor.py:157} INFO - Started process (PID=39166) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:49:57.260+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:49:57.267+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:49:57.267+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:49:57.281+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:49:57.298+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:49:57.298+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:49:57.311+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:49:57.311+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:49:57.322+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-29T15:50:27.856+0000] {processor.py:157} INFO - Started process (PID=39191) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:50:27.857+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:50:27.858+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:50:27.858+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:50:27.869+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:50:27.888+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:50:27.888+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:50:27.902+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:50:27.902+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:50:27.910+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-29T15:50:58.331+0000] {processor.py:157} INFO - Started process (PID=39216) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:50:58.331+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:50:58.339+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:50:58.338+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:50:58.347+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:50:58.361+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:50:58.361+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:50:58.370+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:50:58.370+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:50:58.379+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-29T15:51:28.874+0000] {processor.py:157} INFO - Started process (PID=39241) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:51:28.875+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:51:28.878+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:51:28.878+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:51:28.895+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:51:28.908+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:51:28.907+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:51:28.916+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:51:28.916+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:51:28.924+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-29T15:51:59.418+0000] {processor.py:157} INFO - Started process (PID=39266) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:51:59.419+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:51:59.423+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:51:59.422+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:51:59.439+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:51:59.461+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:51:59.460+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:51:59.474+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:51:59.474+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:51:59.484+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-29T15:52:29.965+0000] {processor.py:157} INFO - Started process (PID=39291) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:52:29.966+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:52:29.973+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:52:29.973+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:52:29.982+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:52:29.995+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:52:29.994+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:52:30.005+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:52:30.005+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:52:30.014+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-29T15:53:00.460+0000] {processor.py:157} INFO - Started process (PID=39316) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:53:00.461+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:53:00.463+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:53:00.463+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:53:00.474+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:53:00.490+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:53:00.490+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:53:00.501+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:53:00.501+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:53:00.510+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-29T15:53:30.980+0000] {processor.py:157} INFO - Started process (PID=39341) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:53:30.983+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:53:30.985+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:53:30.985+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:53:31.003+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:53:31.023+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:53:31.023+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:53:31.035+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:53:31.035+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:53:31.045+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-29T15:54:01.496+0000] {processor.py:157} INFO - Started process (PID=39366) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:54:01.496+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:54:01.499+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:54:01.498+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:54:01.509+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:54:01.524+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:54:01.524+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:54:01.536+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:54:01.536+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:54:01.545+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-29T15:54:31.988+0000] {processor.py:157} INFO - Started process (PID=39390) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:54:31.990+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:54:31.994+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:54:31.994+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:54:32.012+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:54:32.038+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:54:32.038+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:54:32.050+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:54:32.050+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:54:32.060+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-07-29T15:55:02.476+0000] {processor.py:157} INFO - Started process (PID=39416) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:55:02.478+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:55:02.480+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:55:02.480+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:55:02.495+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:55:02.510+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:55:02.510+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:55:02.522+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:55:02.522+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:55:02.530+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-29T15:55:32.971+0000] {processor.py:157} INFO - Started process (PID=39441) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:55:32.972+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:55:32.975+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:55:32.975+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:55:32.992+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:55:33.014+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:55:33.014+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:55:33.026+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:55:33.026+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:55:33.035+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-29T15:56:03.474+0000] {processor.py:157} INFO - Started process (PID=39466) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:56:03.475+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:56:03.478+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:56:03.478+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:56:03.492+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:56:03.511+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:56:03.511+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:56:03.522+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:56:03.521+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:56:03.531+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-29T15:56:33.938+0000] {processor.py:157} INFO - Started process (PID=39491) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:56:33.940+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:56:33.941+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:56:33.941+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:56:33.954+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:56:33.968+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:56:33.968+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:56:33.978+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:56:33.978+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:56:33.988+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-29T15:57:04.443+0000] {processor.py:157} INFO - Started process (PID=39516) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:57:04.448+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:57:04.450+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:57:04.450+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:57:04.469+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:57:04.491+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:57:04.491+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:57:04.504+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:57:04.504+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:57:04.515+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-29T15:57:34.930+0000] {processor.py:157} INFO - Started process (PID=39541) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:57:34.931+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:57:34.933+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:57:34.933+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:57:34.949+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:57:34.966+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:57:34.966+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:57:34.975+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:57:34.975+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:57:34.982+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-29T15:58:05.518+0000] {processor.py:157} INFO - Started process (PID=39566) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:58:05.520+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:58:05.522+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:58:05.522+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:58:05.537+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:58:05.564+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:58:05.564+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:58:05.577+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:58:05.577+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:58:05.587+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-29T15:58:36.056+0000] {processor.py:157} INFO - Started process (PID=39591) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:58:36.056+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:58:36.059+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:58:36.059+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:58:36.072+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:58:36.089+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:58:36.089+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:58:36.099+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:58:36.099+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:58:36.109+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-29T15:59:06.502+0000] {processor.py:157} INFO - Started process (PID=39616) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:59:06.503+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:59:06.506+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:59:06.506+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:59:06.523+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:59:06.547+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:59:06.546+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:59:06.560+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:59:06.560+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:59:06.571+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-29T15:59:36.985+0000] {processor.py:157} INFO - Started process (PID=39641) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:59:36.985+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T15:59:36.987+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:59:36.987+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:59:36.998+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T15:59:37.023+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:59:37.023+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T15:59:37.033+0000] {logging_mixin.py:151} INFO - [2024-07-29T15:59:37.033+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T15:59:37.042+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-29T16:00:07.510+0000] {processor.py:157} INFO - Started process (PID=39665) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:00:07.511+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:00:07.514+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:00:07.514+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:00:07.556+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:00:07.586+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:00:07.586+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:00:07.599+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:00:07.599+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:00:07.609+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-07-29T16:00:38.085+0000] {processor.py:157} INFO - Started process (PID=39691) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:00:38.086+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:00:38.088+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:00:38.088+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:00:38.100+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:00:38.118+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:00:38.118+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:00:38.127+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:00:38.127+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:00:38.138+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-29T16:01:08.509+0000] {processor.py:157} INFO - Started process (PID=39716) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:01:08.509+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:01:08.512+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:01:08.512+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:01:08.529+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:01:08.552+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:01:08.552+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:01:08.564+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:01:08.564+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:01:08.573+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-29T16:01:38.967+0000] {processor.py:157} INFO - Started process (PID=39741) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:01:38.969+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:01:38.971+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:01:38.971+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:01:38.985+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:01:39.003+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:01:39.003+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:01:39.013+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:01:39.013+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:01:39.022+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-29T16:02:09.544+0000] {processor.py:157} INFO - Started process (PID=39766) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:02:09.547+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:02:09.550+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:02:09.550+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:02:09.568+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:02:09.595+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:02:09.595+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:02:09.607+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:02:09.607+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:02:09.617+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-29T16:02:40.120+0000] {processor.py:157} INFO - Started process (PID=39791) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:02:40.121+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:02:40.123+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:02:40.123+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:02:40.135+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:02:40.152+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:02:40.151+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:02:40.166+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:02:40.166+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:02:40.177+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-29T16:03:10.596+0000] {processor.py:157} INFO - Started process (PID=39816) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:03:10.597+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:03:10.601+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:03:10.601+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:03:10.619+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:03:10.641+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:03:10.641+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:03:10.654+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:03:10.654+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:03:10.666+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-29T16:03:41.131+0000] {processor.py:157} INFO - Started process (PID=39841) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:03:41.132+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:03:41.138+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:03:41.138+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:03:41.150+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:03:41.174+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:03:41.174+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:03:41.185+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:03:41.185+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:03:41.195+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-29T16:04:11.551+0000] {processor.py:157} INFO - Started process (PID=39865) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:04:11.552+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:04:11.555+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:04:11.555+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:04:11.574+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:04:11.598+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:04:11.598+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:04:11.613+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:04:11.613+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:04:11.623+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-29T16:04:42.094+0000] {processor.py:157} INFO - Started process (PID=39891) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:04:42.094+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:04:42.097+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:04:42.097+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:04:42.109+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:04:42.128+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:04:42.128+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:04:42.143+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:04:42.142+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:04:42.153+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-29T16:05:12.547+0000] {processor.py:157} INFO - Started process (PID=39916) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:05:12.548+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:05:12.563+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:05:12.561+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:05:12.586+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:05:12.613+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:05:12.613+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:05:12.625+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:05:12.625+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:05:12.635+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-07-29T16:05:43.149+0000] {processor.py:157} INFO - Started process (PID=39941) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:05:43.151+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:05:43.158+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:05:43.157+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:05:43.169+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:05:43.194+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:05:43.194+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:05:43.208+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:05:43.208+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:05:43.218+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-29T16:06:13.661+0000] {processor.py:157} INFO - Started process (PID=39965) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:06:13.662+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:06:13.666+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:06:13.665+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:06:13.682+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:06:13.704+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:06:13.704+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:06:13.717+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:06:13.717+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:06:13.726+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-29T16:06:44.050+0000] {processor.py:157} INFO - Started process (PID=39991) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:06:44.051+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:06:44.054+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:06:44.054+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:06:44.073+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:06:44.098+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:06:44.098+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:06:44.113+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:06:44.113+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:06:44.122+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-29T16:07:14.503+0000] {processor.py:157} INFO - Started process (PID=40016) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:07:14.509+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:07:14.512+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:07:14.512+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:07:14.519+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:07:14.531+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:07:14.531+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:07:14.540+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:07:14.540+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:07:14.551+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-29T16:07:44.981+0000] {processor.py:157} INFO - Started process (PID=40040) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:07:44.982+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:07:44.986+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:07:44.986+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:07:45.006+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:07:45.032+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:07:45.032+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:07:45.045+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:07:45.044+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:07:45.053+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-07-29T16:08:15.409+0000] {processor.py:157} INFO - Started process (PID=40066) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:08:15.410+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:08:15.416+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:08:15.416+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:08:15.427+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:08:15.443+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:08:15.443+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:08:15.453+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:08:15.453+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:08:15.463+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-29T16:08:45.874+0000] {processor.py:157} INFO - Started process (PID=40090) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:08:45.875+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:08:45.880+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:08:45.879+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:08:45.898+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:08:45.933+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:08:45.933+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:08:45.951+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:08:45.951+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:08:45.962+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-07-29T16:09:16.450+0000] {processor.py:157} INFO - Started process (PID=40116) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:09:16.451+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:09:16.455+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:09:16.454+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:09:16.475+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:09:16.502+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:09:16.502+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:09:16.516+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:09:16.516+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:09:16.537+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-07-29T16:09:47.062+0000] {processor.py:157} INFO - Started process (PID=40141) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:09:47.063+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:09:47.067+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:09:47.067+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:09:47.096+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:09:47.137+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:09:47.137+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:09:47.151+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:09:47.151+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:09:47.161+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-07-29T16:10:17.649+0000] {processor.py:157} INFO - Started process (PID=40166) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:10:17.650+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:10:17.653+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:10:17.652+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:10:17.670+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:10:17.693+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:10:17.693+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:10:17.710+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:10:17.710+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:10:17.719+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-29T16:10:48.147+0000] {processor.py:157} INFO - Started process (PID=40191) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:10:48.148+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:10:48.149+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:10:48.149+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:10:48.161+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:10:48.179+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:10:48.179+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:10:48.190+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:10:48.190+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:10:48.198+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-29T16:11:18.567+0000] {processor.py:157} INFO - Started process (PID=40216) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:11:18.569+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:11:18.573+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:11:18.572+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:11:18.591+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:11:18.615+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:11:18.615+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:11:18.627+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:11:18.627+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:11:18.637+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-29T16:11:49.094+0000] {processor.py:157} INFO - Started process (PID=40241) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:11:49.095+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:11:49.097+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:11:49.096+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:11:49.107+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:11:49.132+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:11:49.132+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:11:49.156+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:11:49.156+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:11:49.168+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-29T16:12:19.566+0000] {processor.py:157} INFO - Started process (PID=40266) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:12:19.569+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:12:19.572+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:12:19.571+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:12:19.586+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:12:19.603+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:12:19.603+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:12:19.613+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:12:19.613+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:12:19.621+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-29T16:12:50.120+0000] {processor.py:157} INFO - Started process (PID=40291) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:12:50.122+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:12:50.124+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:12:50.124+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:12:50.136+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:12:50.159+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:12:50.159+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:12:50.171+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:12:50.171+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:12:50.181+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-29T16:13:20.564+0000] {processor.py:157} INFO - Started process (PID=40315) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:13:20.565+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:13:20.569+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:13:20.568+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:13:20.586+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:13:20.604+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:13:20.604+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:13:20.615+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:13:20.615+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:13:20.623+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-29T16:13:51.069+0000] {processor.py:157} INFO - Started process (PID=40341) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:13:51.070+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:13:51.074+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:13:51.074+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:13:51.086+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:13:51.108+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:13:51.108+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:13:51.120+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:13:51.120+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:13:51.132+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-29T16:14:21.625+0000] {processor.py:157} INFO - Started process (PID=40365) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:14:21.626+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:14:21.631+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:14:21.631+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:14:21.649+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:14:21.692+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:14:21.691+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:14:21.704+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:14:21.704+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:14:21.712+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-07-29T16:14:52.231+0000] {processor.py:157} INFO - Started process (PID=40391) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:14:52.232+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:14:52.236+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:14:52.236+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:14:52.256+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:14:52.313+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:14:52.313+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:14:52.347+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:14:52.347+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:14:52.382+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.155 seconds
[2024-07-29T16:15:22.745+0000] {processor.py:157} INFO - Started process (PID=40416) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:15:22.745+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:15:22.747+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:15:22.747+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:15:22.763+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:15:22.777+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:15:22.777+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:15:22.790+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:15:22.789+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:15:22.798+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-29T16:15:53.280+0000] {processor.py:157} INFO - Started process (PID=40441) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:15:53.281+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:15:53.283+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:15:53.283+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:15:53.299+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:15:53.323+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:15:53.323+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:15:53.336+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:15:53.336+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:15:53.361+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-07-29T16:16:23.835+0000] {processor.py:157} INFO - Started process (PID=40466) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:16:23.839+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:16:23.843+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:16:23.843+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:16:23.853+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:16:23.867+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:16:23.867+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:16:23.876+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:16:23.876+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:16:23.886+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-29T16:16:54.429+0000] {processor.py:157} INFO - Started process (PID=40491) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:16:54.430+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:16:54.436+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:16:54.436+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:16:54.456+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:16:54.475+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:16:54.475+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:16:54.488+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:16:54.488+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:16:54.497+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-29T16:17:24.908+0000] {processor.py:157} INFO - Started process (PID=40516) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:17:24.909+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:17:24.912+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:17:24.912+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:17:24.921+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:17:24.941+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:17:24.941+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:17:24.955+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:17:24.955+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:17:24.964+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-29T16:17:55.337+0000] {processor.py:157} INFO - Started process (PID=40540) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:17:55.340+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:17:55.344+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:17:55.344+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:17:55.360+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:17:55.391+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:17:55.391+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:17:55.403+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:17:55.403+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:17:55.413+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-07-29T16:18:25.805+0000] {processor.py:157} INFO - Started process (PID=40566) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:18:25.806+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:18:25.808+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:18:25.808+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:18:25.820+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:18:25.843+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:18:25.843+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:18:25.858+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:18:25.858+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:18:25.869+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-29T16:18:56.329+0000] {processor.py:157} INFO - Started process (PID=40591) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:18:56.331+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:18:56.335+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:18:56.335+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:18:56.351+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:18:56.369+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:18:56.369+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:18:56.380+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:18:56.380+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:18:56.388+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-29T16:19:26.729+0000] {processor.py:157} INFO - Started process (PID=40616) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:19:26.730+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:19:26.733+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:19:26.732+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:19:26.751+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:19:26.777+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:19:26.777+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:19:26.790+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:19:26.790+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:19:26.800+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-29T16:19:57.223+0000] {processor.py:157} INFO - Started process (PID=40641) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:19:57.224+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:19:57.227+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:19:57.227+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:19:57.247+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:19:57.261+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:19:57.261+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:19:57.274+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:19:57.274+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:19:57.282+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-29T16:20:27.813+0000] {processor.py:157} INFO - Started process (PID=40666) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:20:27.814+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:20:27.817+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:20:27.816+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:20:27.832+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:20:27.859+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:20:27.859+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:20:27.871+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:20:27.871+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:20:27.882+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-29T16:20:58.413+0000] {processor.py:157} INFO - Started process (PID=40691) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:20:58.413+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:20:58.416+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:20:58.416+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:20:58.429+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:20:58.446+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:20:58.446+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:20:58.456+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:20:58.456+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:20:58.464+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-29T16:21:28.961+0000] {processor.py:157} INFO - Started process (PID=40716) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:21:28.965+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:21:28.969+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:21:28.969+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:21:28.983+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:21:29.006+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:21:29.006+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:21:29.019+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:21:29.019+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:21:29.026+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-29T16:21:59.524+0000] {processor.py:157} INFO - Started process (PID=40741) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:21:59.525+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:21:59.528+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:21:59.528+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:21:59.546+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:21:59.564+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:21:59.564+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:21:59.577+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:21:59.577+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:21:59.586+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-29T16:22:29.971+0000] {processor.py:157} INFO - Started process (PID=40766) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:22:29.973+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:22:29.975+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:22:29.975+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:22:29.991+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:22:30.016+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:22:30.016+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:22:30.031+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:22:30.030+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:22:30.039+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-29T16:23:00.505+0000] {processor.py:157} INFO - Started process (PID=40791) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:23:00.506+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:23:00.509+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:23:00.509+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:23:00.522+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:23:00.544+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:23:00.544+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:23:00.555+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:23:00.555+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:23:00.566+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-07-29T16:23:31.094+0000] {processor.py:157} INFO - Started process (PID=40816) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:23:31.101+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:23:31.112+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:23:31.112+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:23:31.126+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:23:31.152+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:23:31.152+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:23:31.165+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:23:31.165+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:23:31.175+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-07-29T16:24:01.625+0000] {processor.py:157} INFO - Started process (PID=40841) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:24:01.626+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:24:01.629+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:24:01.629+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:24:01.640+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:24:01.668+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:24:01.668+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:24:01.691+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:24:01.691+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:24:01.701+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-07-29T16:24:32.071+0000] {processor.py:157} INFO - Started process (PID=40866) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:24:32.072+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:24:32.087+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:24:32.087+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:24:32.104+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:24:32.141+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:24:32.141+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:24:32.153+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:24:32.153+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:24:32.164+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-07-29T16:25:02.605+0000] {processor.py:157} INFO - Started process (PID=40891) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:25:02.605+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:25:02.607+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:25:02.607+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:25:02.620+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:25:02.639+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:25:02.638+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:25:02.648+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:25:02.648+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:25:02.658+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-29T16:25:33.091+0000] {processor.py:157} INFO - Started process (PID=40916) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:25:33.092+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:25:33.095+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:25:33.095+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:25:33.110+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:25:33.166+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:25:33.166+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:25:33.179+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:25:33.179+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:25:33.190+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-07-29T16:26:03.669+0000] {processor.py:157} INFO - Started process (PID=40941) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:26:03.670+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:26:03.673+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:26:03.673+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:26:03.688+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:26:03.726+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:26:03.725+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:26:03.736+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:26:03.736+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:26:03.747+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-07-29T16:26:34.188+0000] {processor.py:157} INFO - Started process (PID=40966) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:26:34.189+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:26:34.192+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:26:34.191+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:26:34.207+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:26:34.240+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:26:34.240+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:26:34.256+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:26:34.256+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:26:34.267+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-07-29T16:27:04.707+0000] {processor.py:157} INFO - Started process (PID=40991) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:27:04.708+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:27:04.711+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:27:04.711+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:27:04.724+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:27:04.747+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:27:04.747+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:27:04.758+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:27:04.758+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:27:04.766+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-29T16:27:35.215+0000] {processor.py:157} INFO - Started process (PID=41016) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:27:35.218+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:27:35.225+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:27:35.225+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:27:35.241+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:27:35.268+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:27:35.268+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:27:35.280+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:27:35.280+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:27:35.290+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-07-29T16:28:05.701+0000] {processor.py:157} INFO - Started process (PID=41041) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:28:05.702+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:28:05.710+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:28:05.710+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:28:05.720+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:28:05.735+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:28:05.735+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:28:05.745+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:28:05.745+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:28:05.756+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-29T16:28:36.156+0000] {processor.py:157} INFO - Started process (PID=41066) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:28:36.157+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:28:36.159+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:28:36.159+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:28:36.172+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:28:36.195+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:28:36.195+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:28:36.208+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:28:36.208+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:28:36.220+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-29T16:29:06.583+0000] {processor.py:157} INFO - Started process (PID=41091) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:29:06.584+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:29:06.586+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:29:06.586+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:29:06.599+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:29:06.615+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:29:06.615+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:29:06.625+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:29:06.625+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:29:06.635+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-29T16:29:37.156+0000] {processor.py:157} INFO - Started process (PID=41116) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:29:37.158+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:29:37.170+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:29:37.169+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:29:37.190+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:29:37.221+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:29:37.221+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:29:37.246+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:29:37.246+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:29:37.257+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-07-29T16:30:07.705+0000] {processor.py:157} INFO - Started process (PID=41141) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:30:07.706+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:30:07.708+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:30:07.708+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:30:07.720+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:30:07.738+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:30:07.738+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:30:07.749+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:30:07.748+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:30:07.759+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-29T16:30:38.173+0000] {processor.py:157} INFO - Started process (PID=41166) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:30:38.176+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:30:38.179+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:30:38.179+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:30:38.203+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:30:38.226+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:30:38.226+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:30:38.238+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:30:38.238+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:30:38.249+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-07-29T16:31:08.735+0000] {processor.py:157} INFO - Started process (PID=41191) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:31:08.736+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:31:08.739+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:31:08.739+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:31:08.752+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:31:08.772+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:31:08.772+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:31:08.782+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:31:08.782+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:31:08.790+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-29T16:31:39.234+0000] {processor.py:157} INFO - Started process (PID=41216) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:31:39.236+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:31:39.239+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:31:39.239+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:31:39.257+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:31:39.284+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:31:39.284+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:31:39.298+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:31:39.298+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:31:39.308+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-29T16:32:09.722+0000] {processor.py:157} INFO - Started process (PID=41241) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:32:09.728+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:32:09.732+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:32:09.732+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:32:09.742+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:32:09.756+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:32:09.756+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:32:09.765+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:32:09.765+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:32:09.774+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-29T16:32:40.225+0000] {processor.py:157} INFO - Started process (PID=41265) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:32:40.228+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:32:40.234+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:32:40.234+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:32:40.251+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:32:40.278+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:32:40.277+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:32:40.290+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:32:40.290+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:32:40.299+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-07-29T16:33:10.767+0000] {processor.py:157} INFO - Started process (PID=41291) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:33:10.767+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:33:10.775+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:33:10.774+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:33:10.787+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:33:10.810+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:33:10.810+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:33:10.820+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:33:10.819+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:33:10.829+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-29T16:33:41.317+0000] {processor.py:157} INFO - Started process (PID=41316) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:33:41.320+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:33:41.323+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:33:41.322+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:33:41.366+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:33:41.391+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:33:41.391+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:33:41.403+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:33:41.402+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:33:41.412+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-07-29T16:34:11.936+0000] {processor.py:157} INFO - Started process (PID=41339) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:34:11.937+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:34:11.941+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:34:11.941+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:34:11.969+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:34:12.010+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:34:12.009+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:34:12.023+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:34:12.023+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:34:12.033+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-07-29T16:34:42.519+0000] {processor.py:157} INFO - Started process (PID=41366) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:34:42.520+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:34:42.525+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:34:42.525+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:34:42.545+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:34:42.587+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:34:42.587+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:34:42.602+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:34:42.602+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:34:42.614+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-07-29T16:35:13.085+0000] {processor.py:157} INFO - Started process (PID=41391) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:35:13.088+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:35:13.090+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:35:13.090+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:35:13.100+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:35:13.118+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:35:13.117+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:35:13.130+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:35:13.130+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:35:13.139+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-29T16:35:43.651+0000] {processor.py:157} INFO - Started process (PID=41416) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:35:43.653+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:35:43.656+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:35:43.656+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:35:43.676+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:35:43.702+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:35:43.702+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:35:43.715+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:35:43.714+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:35:43.726+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-07-29T16:36:14.163+0000] {processor.py:157} INFO - Started process (PID=41441) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:36:14.168+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:36:14.171+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:36:14.171+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:36:14.181+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:36:14.194+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:36:14.194+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:36:14.203+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:36:14.203+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:36:14.213+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-29T16:36:44.771+0000] {processor.py:157} INFO - Started process (PID=41466) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:36:44.774+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:36:44.784+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:36:44.784+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:36:44.802+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:36:44.831+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:36:44.831+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:36:44.851+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:36:44.851+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:36:44.863+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-07-29T16:37:15.337+0000] {processor.py:157} INFO - Started process (PID=41491) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:37:15.338+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:37:15.344+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:37:15.344+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:37:15.355+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:37:15.368+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:37:15.368+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:37:15.377+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:37:15.377+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:37:15.390+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-29T16:37:45.783+0000] {processor.py:157} INFO - Started process (PID=41516) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:37:45.787+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:37:45.790+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:37:45.790+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:37:45.825+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:37:45.851+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:37:45.851+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:37:45.863+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:37:45.863+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:37:45.875+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-07-29T16:38:16.242+0000] {processor.py:157} INFO - Started process (PID=41541) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:38:16.245+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:38:16.247+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:38:16.247+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:38:16.255+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:38:16.272+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:38:16.272+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:38:16.284+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:38:16.284+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:38:16.292+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-29T16:38:46.753+0000] {processor.py:157} INFO - Started process (PID=41566) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:38:46.755+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:38:46.759+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:38:46.759+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:38:46.782+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:38:46.810+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:38:46.810+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:38:46.824+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:38:46.824+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:38:46.833+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-07-29T16:39:17.239+0000] {processor.py:157} INFO - Started process (PID=41591) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:39:17.244+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:39:17.253+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:39:17.253+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:39:17.281+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:39:17.303+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:39:17.303+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:39:17.315+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:39:17.314+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:39:17.326+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-07-29T16:39:47.814+0000] {processor.py:157} INFO - Started process (PID=41616) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:39:47.817+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:39:47.821+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:39:47.821+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:39:47.839+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:39:47.868+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:39:47.868+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:39:47.881+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:39:47.881+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:39:47.891+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-07-29T16:40:18.249+0000] {processor.py:157} INFO - Started process (PID=41641) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:40:18.250+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:40:18.252+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:40:18.251+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:40:18.271+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:40:18.285+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:40:18.285+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:40:18.298+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:40:18.298+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:40:18.306+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-29T16:40:48.733+0000] {processor.py:157} INFO - Started process (PID=41666) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:40:48.735+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:40:48.737+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:40:48.737+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:40:48.763+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:40:48.781+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:40:48.781+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:40:48.795+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:40:48.794+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:40:48.806+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-29T16:41:19.284+0000] {processor.py:157} INFO - Started process (PID=41690) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:41:19.287+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:41:19.290+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:41:19.290+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:41:19.310+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:41:19.352+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:41:19.352+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:41:19.367+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:41:19.367+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:41:19.375+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-07-29T16:41:49.807+0000] {processor.py:157} INFO - Started process (PID=41716) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:41:49.810+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:41:49.823+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:41:49.821+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:41:49.877+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:41:49.917+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:41:49.917+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:41:49.938+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:41:49.938+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:41:49.957+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.158 seconds
[2024-07-29T16:42:20.344+0000] {processor.py:157} INFO - Started process (PID=41741) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:42:20.346+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:42:20.349+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:42:20.349+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:42:20.365+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:42:20.379+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:42:20.379+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:42:20.391+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:42:20.391+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:42:20.399+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-29T16:42:50.761+0000] {processor.py:157} INFO - Started process (PID=41766) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:42:50.774+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:42:50.786+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:42:50.785+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:42:50.817+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:42:50.865+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:42:50.865+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:42:50.881+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:42:50.881+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:42:50.893+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-07-29T16:43:21.311+0000] {processor.py:157} INFO - Started process (PID=41791) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:43:21.316+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:43:21.327+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:43:21.326+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:43:21.357+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:43:21.397+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:43:21.397+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:43:21.430+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:43:21.430+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:43:21.442+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.150 seconds
[2024-07-29T16:43:51.857+0000] {processor.py:157} INFO - Started process (PID=41816) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:43:51.862+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:43:51.865+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:43:51.865+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:43:51.875+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:43:51.889+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:43:51.889+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:43:51.901+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:43:51.901+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:43:51.909+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-29T16:44:22.323+0000] {processor.py:157} INFO - Started process (PID=41841) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:44:22.329+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:44:22.333+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:44:22.333+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:44:22.388+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:44:22.421+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:44:22.421+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:44:22.437+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:44:22.436+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:44:22.450+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-07-29T16:44:52.925+0000] {processor.py:157} INFO - Started process (PID=41866) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:44:52.928+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:44:52.932+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:44:52.932+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:44:52.967+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:44:53.038+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:44:53.038+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:44:53.059+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:44:53.059+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:44:53.071+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.154 seconds
[2024-07-29T16:45:23.543+0000] {processor.py:157} INFO - Started process (PID=41891) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:45:23.544+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:45:23.550+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:45:23.550+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:45:23.570+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:45:23.610+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:45:23.610+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:45:23.624+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:45:23.624+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:45:23.635+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-07-29T16:45:54.039+0000] {processor.py:157} INFO - Started process (PID=41916) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:45:54.039+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:45:54.044+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:45:54.044+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:45:54.065+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:45:54.097+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:45:54.097+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:45:54.115+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:45:54.115+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:45:54.127+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-07-29T16:46:24.460+0000] {processor.py:157} INFO - Started process (PID=41941) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:46:24.462+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:46:24.467+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:46:24.467+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:46:24.507+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:46:24.536+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:46:24.536+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:46:24.558+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:46:24.558+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:46:24.571+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-07-29T16:46:55.001+0000] {processor.py:157} INFO - Started process (PID=41966) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:46:55.003+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:46:55.009+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:46:55.008+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:46:55.043+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:46:55.097+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:46:55.097+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:46:55.122+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:46:55.122+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:46:55.139+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.142 seconds
[2024-07-29T16:47:25.638+0000] {processor.py:157} INFO - Started process (PID=41991) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:47:25.640+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:47:25.656+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:47:25.655+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:47:25.690+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:47:25.742+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:47:25.741+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:47:25.761+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:47:25.761+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:47:25.776+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.150 seconds
[2024-07-29T16:47:56.249+0000] {processor.py:157} INFO - Started process (PID=42016) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:47:56.251+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:47:56.258+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:47:56.257+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:47:56.302+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:47:56.348+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:47:56.347+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:47:56.393+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:47:56.393+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:47:56.406+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.164 seconds
[2024-07-29T16:48:26.873+0000] {processor.py:157} INFO - Started process (PID=42041) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:48:26.874+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:48:26.876+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:48:26.876+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:48:26.896+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:48:26.929+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:48:26.929+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:48:26.942+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:48:26.942+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:48:26.953+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-07-29T16:48:57.426+0000] {processor.py:157} INFO - Started process (PID=42066) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:48:57.428+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:48:57.433+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:48:57.433+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:48:57.452+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:48:57.497+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:48:57.496+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:48:57.511+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:48:57.511+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:48:57.520+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-07-29T16:49:27.984+0000] {processor.py:157} INFO - Started process (PID=42091) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:49:27.986+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:49:27.989+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:49:27.989+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:49:28.022+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:49:28.047+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:49:28.047+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:49:28.065+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:49:28.065+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:49:28.075+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-07-29T16:49:58.513+0000] {processor.py:157} INFO - Started process (PID=42116) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:49:58.514+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:49:58.520+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:49:58.520+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:49:58.550+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:49:58.622+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:49:58.622+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:49:58.639+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:49:58.639+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:49:58.653+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.145 seconds
[2024-07-29T16:50:29.120+0000] {processor.py:157} INFO - Started process (PID=42141) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:50:29.125+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:50:29.129+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:50:29.128+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:50:29.137+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:50:29.151+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:50:29.150+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:50:29.160+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:50:29.160+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:50:29.170+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-29T16:50:59.544+0000] {processor.py:157} INFO - Started process (PID=42165) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:50:59.545+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:50:59.550+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:50:59.549+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:50:59.581+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:50:59.636+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:50:59.636+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:50:59.653+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:50:59.653+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:50:59.667+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-07-29T16:51:30.098+0000] {processor.py:157} INFO - Started process (PID=42191) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:51:30.101+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:51:30.106+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:51:30.105+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:51:30.129+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:51:30.183+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:51:30.183+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:51:30.200+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:51:30.199+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:51:30.212+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-07-29T16:52:00.667+0000] {processor.py:157} INFO - Started process (PID=42216) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:52:00.668+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:52:00.673+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:52:00.672+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:52:00.695+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:52:00.737+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:52:00.737+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:52:00.750+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:52:00.750+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:52:00.761+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-07-29T16:52:31.212+0000] {processor.py:157} INFO - Started process (PID=42241) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:52:31.214+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:52:31.236+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:52:31.236+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:52:31.260+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:52:31.290+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:52:31.290+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:52:31.307+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:52:31.307+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:52:31.318+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-07-29T16:53:01.758+0000] {processor.py:157} INFO - Started process (PID=42266) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:53:01.760+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:53:01.763+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:53:01.763+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:53:01.792+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:53:01.830+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:53:01.830+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:53:01.859+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:53:01.859+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:53:01.870+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-07-29T16:53:32.362+0000] {processor.py:157} INFO - Started process (PID=42291) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:53:32.367+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:53:32.386+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:53:32.386+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:53:32.408+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:53:32.441+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:53:32.441+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:53:32.458+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:53:32.458+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:53:32.470+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-07-29T16:54:02.811+0000] {processor.py:157} INFO - Started process (PID=42316) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:54:02.812+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:54:02.817+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:54:02.816+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:54:02.834+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:54:02.859+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:54:02.859+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:54:02.873+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:54:02.872+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:54:02.885+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-07-29T16:54:33.311+0000] {processor.py:157} INFO - Started process (PID=42341) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:54:33.312+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:54:33.316+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:54:33.315+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:54:33.345+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:54:33.384+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:54:33.384+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:54:33.399+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:54:33.399+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:54:33.411+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-07-29T16:55:03.752+0000] {processor.py:157} INFO - Started process (PID=42365) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:55:03.755+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:55:03.757+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:55:03.756+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:55:03.777+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:55:03.811+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:55:03.811+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:55:03.829+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:55:03.829+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:55:03.841+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-07-29T16:55:34.313+0000] {processor.py:157} INFO - Started process (PID=42391) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:55:34.315+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:55:34.323+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:55:34.323+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:55:34.356+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:55:34.407+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:55:34.407+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:55:34.424+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:55:34.424+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:55:34.435+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-07-29T16:56:04.842+0000] {processor.py:157} INFO - Started process (PID=42416) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:56:04.843+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:56:04.846+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:56:04.846+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:56:04.867+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:56:04.911+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:56:04.911+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:56:04.927+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:56:04.926+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:56:04.936+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-07-29T16:56:35.403+0000] {processor.py:157} INFO - Started process (PID=42441) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:56:35.407+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:56:35.415+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:56:35.414+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:56:35.457+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:56:35.529+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:56:35.529+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:56:35.551+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:56:35.551+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:56:35.567+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.171 seconds
[2024-07-29T16:57:06.091+0000] {processor.py:157} INFO - Started process (PID=42465) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:57:06.095+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:57:06.103+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:57:06.101+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:57:06.122+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:57:06.150+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:57:06.150+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:57:06.164+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:57:06.164+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:57:06.177+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-07-29T16:57:36.596+0000] {processor.py:157} INFO - Started process (PID=42491) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:57:36.598+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:57:36.601+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:57:36.600+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:57:36.616+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:57:36.641+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:57:36.641+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:57:36.656+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:57:36.656+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:57:36.668+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-29T16:58:07.120+0000] {processor.py:157} INFO - Started process (PID=42516) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:58:07.121+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:58:07.125+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:58:07.124+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:58:07.149+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:58:07.202+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:58:07.202+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:58:07.219+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:58:07.219+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:58:07.230+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-07-29T16:58:37.742+0000] {processor.py:157} INFO - Started process (PID=42541) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:58:37.744+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:58:37.752+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:58:37.751+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:58:37.774+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:58:37.818+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:58:37.818+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:58:37.838+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:58:37.837+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:58:37.853+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-07-29T16:59:08.379+0000] {processor.py:157} INFO - Started process (PID=42565) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:59:08.383+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:59:08.399+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:59:08.399+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:59:08.440+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:59:08.499+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:59:08.499+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:59:08.516+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:59:08.516+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:59:08.531+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.164 seconds
[2024-07-29T16:59:38.953+0000] {processor.py:157} INFO - Started process (PID=42591) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:59:38.955+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T16:59:38.964+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:59:38.964+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:59:38.977+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T16:59:39.015+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:59:39.015+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T16:59:39.028+0000] {logging_mixin.py:151} INFO - [2024-07-29T16:59:39.028+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T16:59:39.039+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-07-29T17:00:09.526+0000] {processor.py:157} INFO - Started process (PID=42615) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:00:09.528+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:00:09.534+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:00:09.533+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:00:09.552+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:00:09.585+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:00:09.585+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:00:09.600+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:00:09.600+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:00:09.610+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-07-29T17:00:40.029+0000] {processor.py:157} INFO - Started process (PID=42641) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:00:40.029+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:00:40.033+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:00:40.033+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:00:40.054+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:00:40.070+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:00:40.070+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:00:40.079+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:00:40.079+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:00:40.088+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-29T17:01:10.581+0000] {processor.py:157} INFO - Started process (PID=42666) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:01:10.583+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:01:10.590+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:01:10.589+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:01:10.635+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:01:10.672+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:01:10.672+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:01:10.696+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:01:10.696+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:01:10.710+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-07-29T17:01:41.066+0000] {processor.py:157} INFO - Started process (PID=42691) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:01:41.068+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:01:41.087+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:01:41.085+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:01:41.113+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:01:41.157+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:01:41.156+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:01:41.172+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:01:41.172+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:01:41.182+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-07-29T17:02:11.641+0000] {processor.py:157} INFO - Started process (PID=42715) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:02:11.642+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:02:11.647+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:02:11.646+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:02:11.666+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:02:11.700+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:02:11.699+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:02:11.712+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:02:11.712+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:02:11.723+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-07-29T17:02:42.083+0000] {processor.py:157} INFO - Started process (PID=42741) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:02:42.084+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:02:42.090+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:02:42.090+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:02:42.100+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:02:42.113+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:02:42.113+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:02:42.122+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:02:42.122+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:02:42.132+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-29T17:03:12.543+0000] {processor.py:157} INFO - Started process (PID=42766) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:03:12.549+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:03:12.551+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:03:12.551+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:03:12.559+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:03:12.571+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:03:12.571+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:03:12.579+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:03:12.579+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:03:12.590+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-29T17:03:42.987+0000] {processor.py:157} INFO - Started process (PID=42791) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:03:42.988+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:03:42.999+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:03:42.999+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:03:43.019+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:03:43.046+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:03:43.046+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:03:43.068+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:03:43.068+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:03:43.079+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-07-29T17:04:13.480+0000] {processor.py:157} INFO - Started process (PID=42816) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:04:13.483+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:04:13.485+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:04:13.485+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:04:13.501+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:04:13.516+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:04:13.516+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:04:13.526+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:04:13.526+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:04:13.535+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-29T17:04:44.009+0000] {processor.py:157} INFO - Started process (PID=42841) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:04:44.011+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:04:44.016+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:04:44.016+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:04:44.041+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:04:44.091+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:04:44.091+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:04:44.110+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:04:44.110+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:04:44.123+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-07-29T17:05:14.642+0000] {processor.py:157} INFO - Started process (PID=42866) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:05:14.647+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:05:14.655+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:05:14.654+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:05:14.680+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:05:14.713+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:05:14.713+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:05:14.732+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:05:14.732+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:05:14.744+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-07-29T17:05:45.182+0000] {processor.py:157} INFO - Started process (PID=42891) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:05:45.184+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:05:45.189+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:05:45.188+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:05:45.220+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:05:45.372+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:05:45.372+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:05:45.402+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:05:45.402+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:05:45.423+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.249 seconds
[2024-07-29T17:06:15.931+0000] {processor.py:157} INFO - Started process (PID=42916) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:06:15.933+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:06:15.937+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:06:15.937+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:06:15.961+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:06:15.993+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:06:15.993+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:06:16.012+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:06:16.012+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:06:16.025+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-07-29T17:06:46.391+0000] {processor.py:157} INFO - Started process (PID=42941) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:06:46.394+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:06:46.401+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:06:46.401+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:06:46.435+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:06:46.460+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:06:46.460+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:06:46.478+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:06:46.477+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:06:46.488+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-07-29T17:07:16.980+0000] {processor.py:157} INFO - Started process (PID=42966) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:07:16.985+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:07:17.000+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:07:17.000+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:07:17.018+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:07:17.046+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:07:17.046+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:07:17.062+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:07:17.062+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:07:17.071+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-07-29T17:07:47.557+0000] {processor.py:157} INFO - Started process (PID=42991) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:07:47.559+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:07:47.563+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:07:47.563+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:07:47.580+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:07:47.605+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:07:47.605+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:07:47.640+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:07:47.640+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:07:47.655+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-07-29T17:08:18.141+0000] {processor.py:157} INFO - Started process (PID=43016) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:08:18.142+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:08:18.146+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:08:18.146+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:08:18.157+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:08:18.181+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:08:18.181+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:08:18.194+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:08:18.193+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:08:18.203+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-29T17:08:48.627+0000] {processor.py:157} INFO - Started process (PID=43041) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:08:48.628+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:08:48.633+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:08:48.633+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:08:48.651+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:08:48.667+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:08:48.667+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:08:48.676+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:08:48.676+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:08:48.685+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-29T17:09:19.107+0000] {processor.py:157} INFO - Started process (PID=43065) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:09:19.107+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:09:19.111+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:09:19.110+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:09:19.140+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:09:19.163+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:09:19.163+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:09:19.179+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:09:19.179+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:09:19.194+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-07-29T17:09:49.643+0000] {processor.py:157} INFO - Started process (PID=43091) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:09:49.644+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:09:49.646+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:09:49.646+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:09:49.674+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:09:49.720+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:09:49.719+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:09:49.732+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:09:49.732+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:09:49.743+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-07-29T17:10:20.144+0000] {processor.py:157} INFO - Started process (PID=43115) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:10:20.145+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:10:20.149+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:10:20.149+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:10:20.171+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:10:20.214+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:10:20.214+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:10:20.227+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:10:20.227+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:10:20.238+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-07-29T17:10:50.630+0000] {processor.py:157} INFO - Started process (PID=43141) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:10:50.632+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:10:50.641+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:10:50.640+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:10:50.687+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:10:50.731+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:10:50.731+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:10:50.748+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:10:50.748+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:10:50.760+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-07-29T17:11:21.168+0000] {processor.py:157} INFO - Started process (PID=43166) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:11:21.169+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:11:21.172+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:11:21.172+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:11:21.183+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:11:21.207+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:11:21.206+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:11:21.219+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:11:21.219+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:11:21.229+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-29T17:11:51.665+0000] {processor.py:157} INFO - Started process (PID=43191) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:11:51.671+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:11:51.674+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:11:51.674+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:11:51.682+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:11:51.697+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:11:51.697+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:11:51.708+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:11:51.708+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:11:51.716+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-29T17:12:22.095+0000] {processor.py:157} INFO - Started process (PID=43216) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:12:22.097+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:12:22.105+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:12:22.105+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:12:22.121+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:12:22.138+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:12:22.138+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:12:22.152+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:12:22.152+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:12:22.159+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-29T17:12:52.581+0000] {processor.py:157} INFO - Started process (PID=43241) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:12:52.582+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:12:52.589+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:12:52.589+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:12:52.602+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:12:52.617+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:12:52.617+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:12:52.628+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:12:52.628+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:12:52.638+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-29T17:13:23.110+0000] {processor.py:157} INFO - Started process (PID=43266) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:13:23.112+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:13:23.114+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:13:23.114+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:13:23.129+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:13:23.178+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:13:23.178+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:13:23.189+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:13:23.189+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:13:23.198+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-07-29T17:13:53.591+0000] {processor.py:157} INFO - Started process (PID=43291) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:13:53.592+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:13:53.599+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:13:53.599+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:13:53.608+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:13:53.623+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:13:53.623+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:13:53.632+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:13:53.632+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:13:53.641+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-29T17:14:24.126+0000] {processor.py:157} INFO - Started process (PID=43315) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:14:24.127+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:14:24.132+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:14:24.131+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:14:24.153+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:14:24.190+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:14:24.190+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:14:24.204+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:14:24.204+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:14:24.215+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-07-29T17:14:54.571+0000] {processor.py:157} INFO - Started process (PID=43341) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:14:54.572+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:14:54.576+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:14:54.576+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:14:54.592+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:14:54.622+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:14:54.621+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:14:54.635+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:14:54.635+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:14:54.644+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-29T17:15:25.106+0000] {processor.py:157} INFO - Started process (PID=43366) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:15:25.110+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:15:25.127+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:15:25.127+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:15:25.155+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:15:25.210+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:15:25.210+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:15:25.234+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:15:25.233+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:15:25.250+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.158 seconds
[2024-07-29T17:15:55.632+0000] {processor.py:157} INFO - Started process (PID=43391) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:15:55.632+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:15:55.636+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:15:55.635+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:15:55.654+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:15:55.683+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:15:55.683+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:15:55.695+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:15:55.695+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:15:55.704+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-29T17:16:26.161+0000] {processor.py:157} INFO - Started process (PID=43416) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:16:26.163+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:16:26.168+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:16:26.168+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:16:26.184+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:16:26.216+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:16:26.216+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:16:26.234+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:16:26.234+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:16:26.248+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-07-29T17:16:56.582+0000] {processor.py:157} INFO - Started process (PID=43441) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:16:56.582+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:16:56.584+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:16:56.584+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:16:56.605+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:16:56.628+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:16:56.628+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:16:56.639+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:16:56.639+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:16:56.649+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-29T17:17:27.028+0000] {processor.py:157} INFO - Started process (PID=43466) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:17:27.028+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:17:27.030+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:17:27.030+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:17:27.052+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:17:27.071+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:17:27.071+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:17:27.084+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:17:27.084+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:17:27.095+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-29T17:17:57.471+0000] {processor.py:157} INFO - Started process (PID=43491) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:17:57.472+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:17:57.474+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:17:57.474+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:17:57.489+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:17:57.505+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:17:57.505+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:17:57.515+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:17:57.515+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:17:57.523+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-29T17:18:27.942+0000] {processor.py:157} INFO - Started process (PID=43516) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:18:27.948+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:18:27.951+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:18:27.951+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:18:27.959+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:18:27.976+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:18:27.976+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:18:27.987+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:18:27.987+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:18:27.996+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-29T17:18:58.446+0000] {processor.py:157} INFO - Started process (PID=43541) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:18:58.446+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:18:58.450+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:18:58.450+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:18:58.470+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:18:58.487+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:18:58.487+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:18:58.497+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:18:58.497+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:18:58.506+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-29T17:19:28.871+0000] {processor.py:157} INFO - Started process (PID=43566) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:19:28.871+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:19:28.877+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:19:28.877+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:19:28.886+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:19:28.899+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:19:28.899+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:19:28.909+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:19:28.909+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:19:28.920+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-29T17:19:59.305+0000] {processor.py:157} INFO - Started process (PID=43591) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:19:59.306+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:19:59.308+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:19:59.308+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:19:59.325+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:19:59.341+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:19:59.341+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:19:59.356+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:19:59.356+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:19:59.366+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-29T17:20:29.704+0000] {processor.py:157} INFO - Started process (PID=43616) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:20:29.706+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:20:29.707+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:20:29.707+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:20:29.719+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:20:29.744+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:20:29.744+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:20:29.758+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:20:29.758+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:20:29.768+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-29T17:21:00.183+0000] {processor.py:157} INFO - Started process (PID=43641) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:21:00.184+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:21:00.193+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:21:00.192+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:21:00.200+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:21:00.213+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:21:00.213+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:21:00.224+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:21:00.224+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:21:00.233+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-29T17:21:30.543+0000] {processor.py:157} INFO - Started process (PID=43666) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:21:30.544+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:21:30.549+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:21:30.549+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:21:30.561+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:21:30.580+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:21:30.580+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:21:30.593+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:21:30.593+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:21:30.605+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-29T17:22:01.105+0000] {processor.py:157} INFO - Started process (PID=43691) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:22:01.108+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:22:01.113+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:22:01.112+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:22:01.137+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:22:01.188+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:22:01.188+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:22:01.213+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:22:01.213+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:22:01.229+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-07-29T17:22:31.672+0000] {processor.py:157} INFO - Started process (PID=43716) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:22:31.673+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:22:31.677+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:22:31.677+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:22:31.700+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:22:31.739+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:22:31.739+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:22:31.753+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:22:31.753+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:22:31.769+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-07-29T17:23:02.200+0000] {processor.py:157} INFO - Started process (PID=43741) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:23:02.201+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:23:02.203+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:23:02.203+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:23:02.215+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:23:02.234+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:23:02.234+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:23:02.243+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:23:02.243+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:23:02.251+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-29T17:23:32.664+0000] {processor.py:157} INFO - Started process (PID=43765) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:23:32.665+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:23:32.669+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:23:32.669+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:23:32.686+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:23:32.718+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:23:32.718+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:23:32.735+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:23:32.735+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:23:32.745+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-07-29T17:24:03.215+0000] {processor.py:157} INFO - Started process (PID=43791) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:24:03.219+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:24:03.220+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:24:03.220+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:24:03.244+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:24:03.287+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:24:03.287+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:24:03.308+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:24:03.308+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:24:03.321+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-07-29T17:24:33.817+0000] {processor.py:157} INFO - Started process (PID=43816) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:24:33.822+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:24:33.825+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:24:33.825+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:24:33.844+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:24:33.874+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:24:33.874+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:24:33.886+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:24:33.886+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:24:33.895+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-07-29T17:25:04.301+0000] {processor.py:157} INFO - Started process (PID=43841) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:25:04.303+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:25:04.305+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:25:04.305+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:25:04.318+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:25:04.334+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:25:04.334+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:25:04.346+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:25:04.346+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:25:04.357+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-29T17:25:34.774+0000] {processor.py:157} INFO - Started process (PID=43866) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:25:34.775+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:25:34.777+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:25:34.777+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:25:34.796+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:25:34.830+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:25:34.829+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:25:34.843+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:25:34.843+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:25:34.853+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-07-29T17:26:05.240+0000] {processor.py:157} INFO - Started process (PID=43891) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:26:05.241+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:26:05.244+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:26:05.244+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:26:05.262+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:26:05.287+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:26:05.287+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:26:05.303+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:26:05.303+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:26:05.314+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-07-29T17:26:35.646+0000] {processor.py:157} INFO - Started process (PID=43916) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:26:35.647+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:26:35.649+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:26:35.649+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:26:35.658+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:26:35.674+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:26:35.674+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:26:35.687+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:26:35.686+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:26:35.696+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-29T17:27:06.090+0000] {processor.py:157} INFO - Started process (PID=43941) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:27:06.091+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:27:06.095+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:27:06.094+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:27:06.106+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:27:06.129+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:27:06.129+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:27:06.141+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:27:06.141+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:27:06.151+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-29T17:27:36.603+0000] {processor.py:157} INFO - Started process (PID=43966) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:27:36.604+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:27:36.606+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:27:36.606+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:27:36.617+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:27:36.633+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:27:36.633+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:27:36.646+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:27:36.646+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:27:36.653+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-29T17:28:07.091+0000] {processor.py:157} INFO - Started process (PID=43991) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:28:07.093+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:28:07.096+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:28:07.096+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:28:07.113+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:28:07.143+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:28:07.143+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:28:07.156+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:28:07.156+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:28:07.167+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-07-29T17:28:37.582+0000] {processor.py:157} INFO - Started process (PID=44016) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:28:37.583+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:28:37.588+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:28:37.588+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:28:37.600+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:28:37.615+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:28:37.615+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:28:37.626+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:28:37.626+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:28:37.638+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-29T17:29:08.091+0000] {processor.py:157} INFO - Started process (PID=44040) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:29:08.092+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:29:08.108+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:29:08.106+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:29:08.130+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:29:08.156+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:29:08.156+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:29:08.174+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:29:08.174+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:29:08.193+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-07-29T17:29:38.670+0000] {processor.py:157} INFO - Started process (PID=44066) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:29:38.671+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:29:38.679+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:29:38.678+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:29:38.691+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:29:38.705+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:29:38.705+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:29:38.716+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:29:38.716+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:29:38.726+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-29T17:30:09.299+0000] {processor.py:157} INFO - Started process (PID=44091) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:30:09.300+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:30:09.304+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:30:09.304+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:30:09.323+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:30:09.355+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:30:09.355+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:30:09.371+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:30:09.371+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:30:09.381+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-07-29T17:30:39.811+0000] {processor.py:157} INFO - Started process (PID=44116) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:30:39.817+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:30:39.819+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:30:39.819+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:30:39.827+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:30:39.840+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:30:39.840+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:30:39.849+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:30:39.849+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:30:39.858+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-29T17:31:10.253+0000] {processor.py:157} INFO - Started process (PID=44141) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:31:10.254+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:31:10.259+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:31:10.258+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:31:10.283+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:31:10.309+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:31:10.309+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:31:10.323+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:31:10.323+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:31:10.334+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-07-29T17:31:40.773+0000] {processor.py:157} INFO - Started process (PID=44166) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:31:40.774+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:31:40.780+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:31:40.780+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:31:40.793+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:31:40.807+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:31:40.807+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:31:40.816+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:31:40.816+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:31:40.827+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-29T17:32:11.202+0000] {processor.py:157} INFO - Started process (PID=44191) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:32:11.206+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:32:11.209+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:32:11.208+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:32:11.228+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:32:11.258+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:32:11.258+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:32:11.279+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:32:11.279+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:32:11.292+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-07-29T17:32:41.793+0000] {processor.py:157} INFO - Started process (PID=44216) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:32:41.797+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:32:41.801+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:32:41.801+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:32:41.810+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:32:41.825+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:32:41.825+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:32:41.839+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:32:41.839+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:32:41.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-29T17:33:12.213+0000] {processor.py:157} INFO - Started process (PID=44241) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:33:12.214+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:33:12.216+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:33:12.216+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:33:12.233+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:33:12.258+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:33:12.257+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:33:12.282+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:33:12.282+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:33:12.291+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-07-29T17:33:42.781+0000] {processor.py:157} INFO - Started process (PID=44266) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:33:42.786+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:33:42.790+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:33:42.789+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:33:42.800+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:33:42.813+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:33:42.813+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:33:42.822+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:33:42.822+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:33:42.832+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-29T17:34:13.194+0000] {processor.py:157} INFO - Started process (PID=44291) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:34:13.195+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:34:13.206+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:34:13.206+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:34:13.225+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:34:13.250+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:34:13.250+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:34:13.265+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:34:13.265+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:34:13.279+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-07-29T17:34:43.755+0000] {processor.py:157} INFO - Started process (PID=44316) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:34:43.756+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:34:43.759+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:34:43.759+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:34:43.776+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:34:43.799+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:34:43.799+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:34:43.813+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:34:43.813+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:34:43.823+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-29T17:35:14.163+0000] {processor.py:157} INFO - Started process (PID=44341) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:35:14.163+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:35:14.166+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:35:14.166+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:35:14.174+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:35:14.192+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:35:14.192+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:35:14.202+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:35:14.202+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:35:14.210+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-29T17:35:44.614+0000] {processor.py:157} INFO - Started process (PID=44366) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:35:44.615+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:35:44.618+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:35:44.617+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:35:44.636+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:35:44.663+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:35:44.663+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:35:44.680+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:35:44.680+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:35:44.690+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-07-29T17:36:15.109+0000] {processor.py:157} INFO - Started process (PID=44390) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:36:15.109+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:36:15.112+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:36:15.111+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:36:15.129+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:36:15.157+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:36:15.157+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:36:15.166+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:36:15.166+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:36:15.178+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-29T17:36:45.725+0000] {processor.py:157} INFO - Started process (PID=44416) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:36:45.732+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:36:45.735+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:36:45.735+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:36:45.748+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:36:45.763+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:36:45.763+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:36:45.774+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:36:45.774+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:36:45.782+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-29T17:37:16.230+0000] {processor.py:157} INFO - Started process (PID=44440) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:37:16.230+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:37:16.233+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:37:16.232+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:37:16.251+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:37:16.271+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:37:16.271+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:37:16.281+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:37:16.281+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:37:16.292+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-29T17:37:46.752+0000] {processor.py:157} INFO - Started process (PID=44466) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:37:46.758+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:37:46.762+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:37:46.761+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:37:46.790+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:37:46.863+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:37:46.862+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:37:46.885+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:37:46.884+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:37:46.897+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.147 seconds
[2024-07-29T17:38:17.285+0000] {processor.py:157} INFO - Started process (PID=44491) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:38:17.285+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:38:17.287+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:38:17.287+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:38:17.299+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:38:17.314+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:38:17.314+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:38:17.325+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:38:17.324+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:38:17.333+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-29T17:38:47.738+0000] {processor.py:157} INFO - Started process (PID=44516) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:38:47.739+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:38:47.748+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:38:47.747+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:38:47.764+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:38:47.793+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:38:47.793+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:38:47.820+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:38:47.820+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:38:47.830+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-07-29T17:39:18.239+0000] {processor.py:157} INFO - Started process (PID=44541) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:39:18.239+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:39:18.241+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:39:18.241+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:39:18.276+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:39:18.295+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:39:18.294+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:39:18.308+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:39:18.308+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:39:18.317+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-07-29T17:39:48.835+0000] {processor.py:157} INFO - Started process (PID=44566) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:39:48.837+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:39:48.841+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:39:48.841+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:39:48.871+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:39:48.897+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:39:48.896+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:39:48.911+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:39:48.911+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:39:48.923+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-07-29T17:40:19.303+0000] {processor.py:157} INFO - Started process (PID=44591) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:40:19.304+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:40:19.307+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:40:19.306+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:40:19.328+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:40:19.347+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:40:19.347+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:40:19.361+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:40:19.361+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:40:19.372+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-29T17:40:49.824+0000] {processor.py:157} INFO - Started process (PID=44616) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:40:49.824+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:40:49.826+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:40:49.826+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:40:49.842+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:40:49.859+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:40:49.859+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:40:49.871+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:40:49.871+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:40:49.879+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-29T17:41:20.288+0000] {processor.py:157} INFO - Started process (PID=44641) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:41:20.288+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:41:20.290+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:41:20.289+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:41:20.298+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:41:20.315+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:41:20.314+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:41:20.324+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:41:20.324+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:41:20.332+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-29T17:41:50.770+0000] {processor.py:157} INFO - Started process (PID=44666) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:41:50.771+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:41:50.775+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:41:50.775+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:41:50.790+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:41:50.813+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:41:50.813+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:41:50.826+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:41:50.825+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:41:50.834+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-29T17:42:21.328+0000] {processor.py:157} INFO - Started process (PID=44691) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:42:21.329+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:42:21.335+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:42:21.334+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:42:21.346+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:42:21.360+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:42:21.360+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:42:21.371+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:42:21.371+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:42:21.383+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-29T17:42:51.748+0000] {processor.py:157} INFO - Started process (PID=44716) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:42:51.749+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:42:51.751+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:42:51.751+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:42:51.775+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:42:51.790+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:42:51.789+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:42:51.799+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:42:51.799+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:42:51.806+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-29T17:43:22.284+0000] {processor.py:157} INFO - Started process (PID=44741) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:43:22.285+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:43:22.287+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:43:22.287+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:43:22.306+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:43:22.322+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:43:22.322+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:43:22.337+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:43:22.337+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:43:22.348+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-29T17:43:52.744+0000] {processor.py:157} INFO - Started process (PID=44766) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:43:52.744+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:43:52.746+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:43:52.746+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:43:52.757+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:43:52.773+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:43:52.773+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:43:52.784+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:43:52.784+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:43:52.794+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-29T17:44:23.210+0000] {processor.py:157} INFO - Started process (PID=44791) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:44:23.211+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:44:23.213+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:44:23.212+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:44:23.229+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:44:23.252+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:44:23.252+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:44:23.266+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:44:23.266+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:44:23.274+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-29T17:44:53.820+0000] {processor.py:157} INFO - Started process (PID=44816) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:44:53.821+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:44:53.830+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:44:53.830+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:44:53.838+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:44:53.852+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:44:53.852+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:44:53.863+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:44:53.863+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:44:53.873+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-29T17:45:24.365+0000] {processor.py:157} INFO - Started process (PID=44841) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:45:24.366+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:45:24.368+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:45:24.367+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:45:24.380+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:45:24.396+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:45:24.396+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:45:24.407+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:45:24.407+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:45:24.417+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-29T17:45:54.767+0000] {processor.py:157} INFO - Started process (PID=44866) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:45:54.768+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:45:54.771+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:45:54.771+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:45:54.786+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:45:54.808+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:45:54.808+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:45:54.820+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:45:54.820+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:45:54.835+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-29T17:46:25.303+0000] {processor.py:157} INFO - Started process (PID=44891) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:46:25.304+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:46:25.311+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:46:25.311+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:46:25.320+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:46:25.337+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:46:25.337+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:46:25.349+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:46:25.349+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:46:25.358+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-29T17:46:55.775+0000] {processor.py:157} INFO - Started process (PID=44916) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:46:55.775+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:46:55.778+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:46:55.778+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:46:55.791+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:46:55.808+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:46:55.808+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:46:55.818+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:46:55.818+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:46:55.826+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-29T17:47:26.267+0000] {processor.py:157} INFO - Started process (PID=44941) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:47:26.267+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:47:26.270+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:47:26.270+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:47:26.288+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:47:26.307+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:47:26.307+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:47:26.318+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:47:26.318+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:47:26.328+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-29T17:47:56.694+0000] {processor.py:157} INFO - Started process (PID=44966) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:47:56.694+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:47:56.695+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:47:56.695+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:47:56.704+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:47:56.722+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:47:56.722+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:47:56.735+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:47:56.735+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:47:56.744+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-29T17:48:27.199+0000] {processor.py:157} INFO - Started process (PID=44991) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:48:27.199+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:48:27.202+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:48:27.202+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:48:27.223+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:48:27.247+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:48:27.247+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:48:27.262+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:48:27.262+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:48:27.273+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-07-29T17:48:57.695+0000] {processor.py:157} INFO - Started process (PID=45016) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:48:57.696+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:48:57.698+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:48:57.698+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:48:57.713+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:48:57.728+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:48:57.728+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:48:57.739+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:48:57.739+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:48:57.748+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-29T17:49:28.210+0000] {processor.py:157} INFO - Started process (PID=45041) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:49:28.211+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:49:28.217+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:49:28.217+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:49:28.228+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:49:28.244+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:49:28.244+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:49:28.255+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:49:28.255+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:49:28.266+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-29T17:49:58.692+0000] {processor.py:157} INFO - Started process (PID=45066) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:49:58.693+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:49:58.696+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:49:58.696+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:49:58.711+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:49:58.732+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:49:58.732+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:49:58.742+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:49:58.742+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:49:58.750+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-29T17:50:29.184+0000] {processor.py:157} INFO - Started process (PID=45091) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:50:29.185+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:50:29.187+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:50:29.187+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:50:29.201+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:50:29.223+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:50:29.223+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:50:29.236+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:50:29.236+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:50:29.246+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-29T17:50:59.650+0000] {processor.py:157} INFO - Started process (PID=45116) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:50:59.650+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:50:59.653+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:50:59.653+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:50:59.670+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:50:59.689+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:50:59.689+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:50:59.700+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:50:59.700+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:50:59.710+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-29T17:51:30.075+0000] {processor.py:157} INFO - Started process (PID=45141) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:51:30.076+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:51:30.077+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:51:30.077+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:51:30.087+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:51:30.103+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:51:30.103+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:51:30.115+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:51:30.115+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:51:30.124+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-29T17:52:00.551+0000] {processor.py:157} INFO - Started process (PID=45166) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:52:00.552+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:52:00.561+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:52:00.560+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:52:00.570+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:52:00.585+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:52:00.585+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:52:00.596+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:52:00.596+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:52:00.606+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-29T17:52:30.974+0000] {processor.py:157} INFO - Started process (PID=45191) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:52:30.975+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:52:30.977+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:52:30.976+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:52:30.986+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:52:31.005+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:52:31.005+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:52:31.017+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:52:31.017+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:52:31.024+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-29T17:53:01.412+0000] {processor.py:157} INFO - Started process (PID=45216) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:53:01.416+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:53:01.419+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:53:01.419+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:53:01.433+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:53:01.452+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:53:01.452+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:53:01.465+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:53:01.465+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:53:01.474+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-29T17:53:31.966+0000] {processor.py:157} INFO - Started process (PID=45241) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:53:31.966+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:53:31.969+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:53:31.968+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:53:31.984+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:53:32.002+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:53:32.002+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:53:32.011+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:53:32.011+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:53:32.019+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-29T17:54:02.392+0000] {processor.py:157} INFO - Started process (PID=45266) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:54:02.393+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:54:02.395+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:54:02.395+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:54:02.409+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:54:02.424+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:54:02.424+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:54:02.435+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:54:02.435+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:54:02.445+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-29T17:54:32.839+0000] {processor.py:157} INFO - Started process (PID=45291) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:54:32.839+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:54:32.841+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:54:32.841+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:54:32.853+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:54:32.877+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:54:32.876+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:54:32.889+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:54:32.889+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:54:32.901+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-29T17:55:03.320+0000] {processor.py:157} INFO - Started process (PID=45316) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:55:03.323+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:55:03.326+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:55:03.325+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:55:03.343+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:55:03.359+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:55:03.359+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:55:03.370+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:55:03.370+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:55:03.378+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-29T17:55:33.864+0000] {processor.py:157} INFO - Started process (PID=45341) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:55:33.864+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:55:33.867+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:55:33.866+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:55:33.879+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:55:33.900+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:55:33.900+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:55:33.913+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:55:33.913+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:55:33.923+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-29T17:56:04.344+0000] {processor.py:157} INFO - Started process (PID=45366) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:56:04.348+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:56:04.353+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:56:04.352+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:56:04.363+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:56:04.376+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:56:04.376+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:56:04.386+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:56:04.386+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:56:04.395+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-29T17:56:34.818+0000] {processor.py:157} INFO - Started process (PID=45391) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:56:34.819+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:56:34.826+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:56:34.826+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:56:34.840+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:56:34.856+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:56:34.855+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:56:34.866+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:56:34.866+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:56:34.875+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-29T17:57:05.301+0000] {processor.py:157} INFO - Started process (PID=45416) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:57:05.301+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:57:05.309+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:57:05.309+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:57:05.321+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:57:05.335+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:57:05.335+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:57:05.346+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:57:05.346+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:57:05.356+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-29T17:57:35.724+0000] {processor.py:157} INFO - Started process (PID=45441) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:57:35.725+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:57:35.727+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:57:35.727+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:57:35.737+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:57:35.755+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:57:35.755+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:57:35.768+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:57:35.768+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:57:35.777+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-29T17:58:06.182+0000] {processor.py:157} INFO - Started process (PID=45466) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:58:06.182+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:58:06.184+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:58:06.183+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:58:06.197+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:58:06.218+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:58:06.218+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:58:06.229+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:58:06.228+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:58:06.238+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-29T17:58:36.703+0000] {processor.py:157} INFO - Started process (PID=45491) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:58:36.704+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:58:36.706+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:58:36.705+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:58:36.716+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:58:36.737+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:58:36.737+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:58:36.749+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:58:36.749+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:58:36.758+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-29T17:59:07.290+0000] {processor.py:157} INFO - Started process (PID=45516) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:59:07.291+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:59:07.294+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:59:07.294+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:59:07.306+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:59:07.327+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:59:07.327+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:59:07.338+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:59:07.338+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:59:07.347+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-29T17:59:37.774+0000] {processor.py:157} INFO - Started process (PID=45541) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:59:37.782+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T17:59:37.785+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:59:37.785+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:59:37.795+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T17:59:37.816+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:59:37.816+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T17:59:37.827+0000] {logging_mixin.py:151} INFO - [2024-07-29T17:59:37.827+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T17:59:37.837+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-29T18:00:08.297+0000] {processor.py:157} INFO - Started process (PID=45566) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:00:08.298+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:00:08.301+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:00:08.300+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:00:08.311+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:00:08.331+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:00:08.331+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:00:08.343+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:00:08.343+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:00:08.353+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-29T18:00:38.887+0000] {processor.py:157} INFO - Started process (PID=45591) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:00:38.889+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:00:38.891+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:00:38.891+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:00:38.904+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:00:38.931+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:00:38.931+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:00:38.943+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:00:38.943+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:00:38.954+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-29T18:01:09.365+0000] {processor.py:157} INFO - Started process (PID=45616) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:01:09.368+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:01:09.370+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:01:09.369+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:01:09.379+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:01:09.391+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:01:09.391+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:01:09.400+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:01:09.400+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:01:09.410+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-29T18:01:39.889+0000] {processor.py:157} INFO - Started process (PID=45641) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:01:39.890+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:01:39.892+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:01:39.892+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:01:39.905+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:01:39.928+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:01:39.928+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:01:39.938+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:01:39.938+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:01:39.948+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-29T18:02:10.397+0000] {processor.py:157} INFO - Started process (PID=45666) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:02:10.397+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:02:10.400+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:02:10.399+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:02:10.413+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:02:10.433+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:02:10.433+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:02:10.447+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:02:10.447+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:02:10.455+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-29T18:02:40.953+0000] {processor.py:157} INFO - Started process (PID=45691) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:02:40.954+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:02:40.957+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:02:40.957+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:02:40.974+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:02:40.993+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:02:40.993+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:02:41.003+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:02:41.003+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:02:41.012+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-29T18:03:11.478+0000] {processor.py:157} INFO - Started process (PID=45716) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:03:11.478+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:03:11.486+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:03:11.486+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:03:11.498+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:03:11.514+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:03:11.514+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:03:11.524+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:03:11.524+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:03:11.535+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-29T18:03:42.002+0000] {processor.py:157} INFO - Started process (PID=45741) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:03:42.003+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:03:42.010+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:03:42.009+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:03:42.019+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:03:42.033+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:03:42.033+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:03:42.044+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:03:42.044+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:03:42.053+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-29T18:04:12.533+0000] {processor.py:157} INFO - Started process (PID=45766) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:04:12.538+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:04:12.541+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:04:12.541+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:04:12.550+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:04:12.563+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:04:12.563+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:04:12.571+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:04:12.571+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:04:12.582+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-29T18:04:43.077+0000] {processor.py:157} INFO - Started process (PID=45791) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:04:43.078+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:04:43.086+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:04:43.086+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:04:43.097+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:04:43.110+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:04:43.109+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:04:43.119+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:04:43.119+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:04:43.128+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-29T18:05:13.542+0000] {processor.py:157} INFO - Started process (PID=45816) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:05:13.544+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:05:13.546+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:05:13.546+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:05:13.563+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:05:13.585+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:05:13.585+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:05:13.598+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:05:13.598+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:05:13.608+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-29T18:05:44.040+0000] {processor.py:157} INFO - Started process (PID=45841) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:05:44.041+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:05:44.043+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:05:44.043+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:05:44.052+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:05:44.071+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:05:44.071+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:05:44.082+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:05:44.082+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:05:44.092+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-29T18:06:14.541+0000] {processor.py:157} INFO - Started process (PID=45866) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:06:14.545+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:06:14.547+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:06:14.547+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:06:14.566+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:06:14.587+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:06:14.587+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:06:14.600+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:06:14.600+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:06:14.610+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-29T18:06:45.052+0000] {processor.py:157} INFO - Started process (PID=45891) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:06:45.053+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:06:45.055+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:06:45.055+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:06:45.083+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:06:45.100+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:06:45.100+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:06:45.113+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:06:45.113+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:06:45.123+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-29T18:07:15.584+0000] {processor.py:157} INFO - Started process (PID=45916) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:07:15.585+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:07:15.589+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:07:15.589+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:07:15.604+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:07:15.625+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:07:15.625+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:07:15.643+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:07:15.642+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:07:15.652+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-29T18:07:46.144+0000] {processor.py:157} INFO - Started process (PID=45941) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:07:46.151+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:07:46.153+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:07:46.153+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:07:46.163+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:07:46.185+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:07:46.185+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:07:46.197+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:07:46.197+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:07:46.206+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-29T18:08:16.739+0000] {processor.py:157} INFO - Started process (PID=45966) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:08:16.739+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:08:16.742+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:08:16.742+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:08:16.754+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:08:16.771+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:08:16.771+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:08:16.781+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:08:16.780+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:08:16.791+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-29T18:08:47.212+0000] {processor.py:157} INFO - Started process (PID=45991) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:08:47.213+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:08:47.226+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:08:47.226+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:08:47.245+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:08:47.266+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:08:47.266+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:08:47.279+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:08:47.279+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:08:47.292+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-07-29T18:09:17.746+0000] {processor.py:157} INFO - Started process (PID=46016) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:09:17.747+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:09:17.750+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:09:17.750+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:09:17.768+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:09:17.799+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:09:17.799+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:09:17.812+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:09:17.812+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:09:17.823+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-07-29T18:09:48.295+0000] {processor.py:157} INFO - Started process (PID=46041) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:09:48.299+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:09:48.303+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:09:48.303+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:09:48.319+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:09:48.346+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:09:48.346+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:09:48.363+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:09:48.363+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:09:48.373+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-07-29T18:10:18.885+0000] {processor.py:157} INFO - Started process (PID=46066) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:10:18.885+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:10:18.893+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:10:18.892+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:10:18.903+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:10:18.917+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:10:18.917+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:10:18.929+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:10:18.929+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:10:18.940+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-29T18:10:49.229+0000] {processor.py:157} INFO - Started process (PID=46091) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:10:49.230+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:10:49.233+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:10:49.233+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:10:49.247+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:10:49.285+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:10:49.285+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:10:49.298+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:10:49.298+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:10:49.308+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-07-29T18:11:19.729+0000] {processor.py:157} INFO - Started process (PID=46116) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:11:19.732+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:11:19.747+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:11:19.746+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:11:19.760+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:11:19.779+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:11:19.779+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:11:19.788+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:11:19.788+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:11:19.799+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-29T18:11:50.310+0000] {processor.py:157} INFO - Started process (PID=46141) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:11:50.313+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:11:50.315+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:11:50.315+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:11:50.331+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:11:50.350+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:11:50.350+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:11:50.363+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:11:50.363+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:11:50.375+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-29T18:12:20.860+0000] {processor.py:157} INFO - Started process (PID=46166) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:12:20.861+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:12:20.867+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:12:20.866+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:12:20.885+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:12:20.898+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:12:20.898+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:12:20.908+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:12:20.908+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:12:20.918+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-29T18:12:51.285+0000] {processor.py:157} INFO - Started process (PID=46191) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:12:51.285+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:12:51.288+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:12:51.287+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:12:51.303+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:12:51.323+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:12:51.323+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:12:51.335+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:12:51.335+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:12:51.345+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-29T18:13:21.811+0000] {processor.py:157} INFO - Started process (PID=46216) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:13:21.812+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:13:21.816+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:13:21.815+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:13:21.837+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:13:21.859+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:13:21.859+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:13:21.869+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:13:21.869+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:13:21.881+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-29T18:13:52.189+0000] {processor.py:157} INFO - Started process (PID=46241) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:13:52.189+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:13:52.194+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:13:52.193+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:13:52.208+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:13:52.227+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:13:52.227+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:13:52.238+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:13:52.238+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:13:52.247+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-29T18:14:22.786+0000] {processor.py:157} INFO - Started process (PID=46266) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:14:22.787+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:14:22.790+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:14:22.789+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:14:22.802+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:14:22.850+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:14:22.850+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:14:22.861+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:14:22.861+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:14:22.870+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-07-29T18:14:53.319+0000] {processor.py:157} INFO - Started process (PID=46291) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:14:53.320+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:14:53.323+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:14:53.323+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:14:53.343+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:14:53.367+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:14:53.367+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:14:53.380+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:14:53.380+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:14:53.389+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-29T18:15:23.832+0000] {processor.py:157} INFO - Started process (PID=46316) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:15:23.833+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:15:23.836+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:15:23.836+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:15:23.848+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:15:23.868+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:15:23.868+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:15:23.879+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:15:23.879+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:15:23.887+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-29T18:15:54.366+0000] {processor.py:157} INFO - Started process (PID=46341) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:15:54.367+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:15:54.371+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:15:54.371+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:15:54.390+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:15:54.411+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:15:54.411+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:15:54.422+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:15:54.422+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:15:54.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-29T18:16:24.857+0000] {processor.py:157} INFO - Started process (PID=46366) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:16:24.858+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:16:24.860+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:16:24.859+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:16:24.874+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:16:24.896+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:16:24.896+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:16:24.907+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:16:24.906+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:16:24.915+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-29T18:16:55.306+0000] {processor.py:157} INFO - Started process (PID=46391) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:16:55.306+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:16:55.308+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:16:55.308+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:16:55.322+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:16:55.339+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:16:55.339+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:16:55.350+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:16:55.350+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:16:55.361+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-29T18:17:25.744+0000] {processor.py:157} INFO - Started process (PID=46416) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:17:25.744+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:17:25.750+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:17:25.749+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:17:25.767+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:17:25.784+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:17:25.784+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:17:25.795+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:17:25.795+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:17:25.806+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-29T18:17:56.212+0000] {processor.py:157} INFO - Started process (PID=46441) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:17:56.213+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:17:56.221+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:17:56.221+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:17:56.231+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:17:56.244+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:17:56.244+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:17:56.256+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:17:56.255+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:17:56.266+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-29T18:18:26.814+0000] {processor.py:157} INFO - Started process (PID=46466) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:18:26.814+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:18:26.818+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:18:26.818+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:18:26.835+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:18:26.861+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:18:26.861+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:18:26.874+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:18:26.874+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:18:26.885+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-29T18:18:57.279+0000] {processor.py:157} INFO - Started process (PID=46491) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:18:57.279+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:18:57.281+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:18:57.281+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:18:57.291+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:18:57.310+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:18:57.310+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:18:57.320+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:18:57.320+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:18:57.330+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-29T18:19:27.813+0000] {processor.py:157} INFO - Started process (PID=46516) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:19:27.814+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:19:27.817+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:19:27.816+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:19:27.829+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:19:27.851+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:19:27.851+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:19:27.863+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:19:27.863+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:19:27.872+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-29T18:19:58.258+0000] {processor.py:157} INFO - Started process (PID=46541) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:19:58.262+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:19:58.265+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:19:58.265+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:19:58.276+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:19:58.293+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:19:58.293+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:19:58.306+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:19:58.305+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:19:58.317+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-29T18:20:28.728+0000] {processor.py:157} INFO - Started process (PID=46566) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:20:28.734+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:20:28.738+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:20:28.737+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:20:28.751+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:20:28.765+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:20:28.765+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:20:28.775+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:20:28.775+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:20:28.782+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-29T18:20:59.274+0000] {processor.py:157} INFO - Started process (PID=46591) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:20:59.276+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:20:59.278+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:20:59.278+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:20:59.298+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:20:59.319+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:20:59.319+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:20:59.332+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:20:59.332+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:20:59.341+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-29T18:21:29.803+0000] {processor.py:157} INFO - Started process (PID=46616) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:21:29.804+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:21:29.807+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:21:29.807+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:21:29.823+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:21:29.871+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:21:29.871+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:21:29.883+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:21:29.883+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:21:29.894+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-07-29T18:22:00.394+0000] {processor.py:157} INFO - Started process (PID=46641) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:22:00.398+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:22:00.401+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:22:00.401+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:22:00.413+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:22:00.434+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:22:00.434+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:22:00.446+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:22:00.446+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:22:00.455+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-29T18:22:30.936+0000] {processor.py:157} INFO - Started process (PID=46666) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:22:30.942+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:22:30.945+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:22:30.944+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:22:30.954+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:22:30.966+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:22:30.966+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:22:30.975+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:22:30.975+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:22:30.985+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-29T18:23:01.343+0000] {processor.py:157} INFO - Started process (PID=46691) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:23:01.345+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:23:01.347+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:23:01.347+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:23:01.365+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:23:01.382+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:23:01.382+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:23:01.395+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:23:01.395+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:23:01.405+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-29T18:23:31.875+0000] {processor.py:157} INFO - Started process (PID=46716) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:23:31.876+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:23:31.878+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:23:31.878+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:23:31.893+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:23:31.912+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:23:31.912+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:23:31.926+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:23:31.926+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:23:31.936+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-29T18:24:02.430+0000] {processor.py:157} INFO - Started process (PID=46741) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:24:02.431+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:24:02.435+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:24:02.435+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:24:02.453+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:24:02.476+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:24:02.476+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:24:02.486+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:24:02.486+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:24:02.495+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-29T18:24:32.951+0000] {processor.py:157} INFO - Started process (PID=46766) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:24:32.952+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:24:32.954+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:24:32.954+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:24:32.973+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:24:32.997+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:24:32.997+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:24:33.009+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:24:33.009+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:24:33.019+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-29T18:25:03.484+0000] {processor.py:157} INFO - Started process (PID=46791) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:25:03.485+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:25:03.488+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:25:03.488+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:25:03.503+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:25:03.522+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:25:03.522+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:25:03.535+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:25:03.535+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:25:03.543+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-29T18:25:33.857+0000] {processor.py:157} INFO - Started process (PID=46816) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:25:33.858+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:25:33.862+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:25:33.861+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:25:33.877+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:25:33.898+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:25:33.898+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:25:33.913+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:25:33.913+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:25:33.922+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-29T18:26:04.399+0000] {processor.py:157} INFO - Started process (PID=46841) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:26:04.400+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:26:04.403+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:26:04.403+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:26:04.421+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:26:04.443+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:26:04.443+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:26:04.453+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:26:04.453+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:26:04.463+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-29T18:26:34.864+0000] {processor.py:157} INFO - Started process (PID=46866) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:26:34.864+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:26:34.867+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:26:34.867+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:26:34.881+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:26:34.900+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:26:34.900+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:26:34.916+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:26:34.916+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:26:34.925+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-29T18:27:05.463+0000] {processor.py:157} INFO - Started process (PID=46891) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:27:05.464+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:27:05.467+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:27:05.466+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:27:05.482+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:27:05.506+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:27:05.506+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:27:05.516+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:27:05.516+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:27:05.525+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-29T18:27:35.924+0000] {processor.py:157} INFO - Started process (PID=46916) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:27:35.924+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:27:35.926+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:27:35.926+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:27:35.937+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:27:35.960+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:27:35.960+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:27:35.971+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:27:35.971+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:27:35.982+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-29T18:28:06.545+0000] {processor.py:157} INFO - Started process (PID=46941) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:28:06.546+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:28:06.551+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:28:06.551+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:28:06.570+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:28:06.584+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:28:06.584+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:28:06.595+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:28:06.594+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:28:06.603+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-29T18:28:37.106+0000] {processor.py:157} INFO - Started process (PID=46966) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:28:37.107+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:28:37.109+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:28:37.108+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:28:37.128+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:28:37.143+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:28:37.143+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:28:37.153+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:28:37.153+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:28:37.163+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-29T18:29:07.642+0000] {processor.py:157} INFO - Started process (PID=46991) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:29:07.643+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:29:07.650+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:29:07.650+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:29:07.662+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:29:07.674+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:29:07.674+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:29:07.684+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:29:07.684+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:29:07.693+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-29T18:29:38.111+0000] {processor.py:157} INFO - Started process (PID=47016) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:29:38.114+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:29:38.118+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:29:38.118+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:29:38.139+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:29:38.171+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:29:38.171+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:29:38.185+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:29:38.185+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:29:38.196+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-07-29T18:30:08.691+0000] {processor.py:157} INFO - Started process (PID=47041) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:30:08.691+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:30:08.693+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:30:08.693+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:30:08.705+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:30:08.733+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:30:08.733+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:30:08.743+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:30:08.743+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:30:08.754+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-29T18:30:39.249+0000] {processor.py:157} INFO - Started process (PID=47066) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:30:39.251+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:30:39.252+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:30:39.252+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:30:39.273+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:30:39.297+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:30:39.297+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:30:39.309+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:30:39.309+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:30:39.320+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-29T18:31:09.783+0000] {processor.py:157} INFO - Started process (PID=47091) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:31:09.784+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:31:09.786+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:31:09.786+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:31:09.799+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:31:09.819+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:31:09.819+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:31:09.832+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:31:09.832+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:31:09.840+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-29T18:31:40.284+0000] {processor.py:157} INFO - Started process (PID=47116) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:31:40.285+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:31:40.287+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:31:40.287+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:31:40.307+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:31:40.328+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:31:40.328+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:31:40.342+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:31:40.342+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:31:40.353+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-29T18:32:10.788+0000] {processor.py:157} INFO - Started process (PID=47141) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:32:10.788+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:32:10.790+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:32:10.790+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:32:10.801+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:32:10.817+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:32:10.817+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:32:10.832+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:32:10.831+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:32:10.840+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-29T18:32:41.302+0000] {processor.py:157} INFO - Started process (PID=47166) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:32:41.303+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:32:41.306+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:32:41.305+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:32:41.325+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:32:41.352+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:32:41.352+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:32:41.366+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:32:41.366+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:32:41.375+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-29T18:33:11.835+0000] {processor.py:157} INFO - Started process (PID=47191) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:33:11.837+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:33:11.840+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:33:11.839+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:33:11.851+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:33:11.867+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:33:11.867+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:33:11.877+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:33:11.877+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:33:11.889+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-29T18:33:42.355+0000] {processor.py:157} INFO - Started process (PID=47216) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:33:42.356+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:33:42.363+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:33:42.363+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:33:42.379+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:33:42.404+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:33:42.403+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:33:42.417+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:33:42.416+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:33:42.428+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-07-29T18:34:12.907+0000] {processor.py:157} INFO - Started process (PID=47241) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:34:12.909+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:34:12.915+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:34:12.914+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:34:12.946+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:34:12.988+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:34:12.988+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:34:13.007+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:34:13.007+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:34:13.022+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-07-29T18:34:43.554+0000] {processor.py:157} INFO - Started process (PID=47266) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:34:43.555+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:34:43.558+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:34:43.558+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:34:43.575+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:34:43.598+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:34:43.598+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:34:43.611+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:34:43.611+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:34:43.623+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-29T18:35:14.123+0000] {processor.py:157} INFO - Started process (PID=47291) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:35:14.124+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:35:14.127+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:35:14.127+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:35:14.148+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:35:14.168+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:35:14.168+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:35:14.182+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:35:14.182+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:35:14.195+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-29T18:35:44.608+0000] {processor.py:157} INFO - Started process (PID=47316) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:35:44.610+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:35:44.611+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:35:44.611+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:35:44.622+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:35:44.637+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:35:44.637+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:35:44.647+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:35:44.647+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:35:44.655+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-29T18:36:15.166+0000] {processor.py:157} INFO - Started process (PID=47341) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:36:15.167+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:36:15.175+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:36:15.175+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:36:15.193+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:36:15.212+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:36:15.212+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:36:15.225+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:36:15.225+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:36:15.235+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-29T18:36:45.697+0000] {processor.py:157} INFO - Started process (PID=47366) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:36:45.697+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:36:45.701+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:36:45.701+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:36:45.721+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:36:45.741+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:36:45.741+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:36:45.753+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:36:45.753+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:36:45.761+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-29T18:37:16.217+0000] {processor.py:157} INFO - Started process (PID=47391) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:37:16.219+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:37:16.221+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:37:16.221+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:37:16.231+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:37:16.248+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:37:16.248+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:37:16.259+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:37:16.259+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:37:16.268+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-29T18:37:46.804+0000] {processor.py:157} INFO - Started process (PID=47416) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:37:46.805+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:37:46.808+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:37:46.808+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:37:46.828+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:37:46.855+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:37:46.855+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:37:46.868+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:37:46.868+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:37:46.878+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-07-29T18:38:17.311+0000] {processor.py:157} INFO - Started process (PID=47441) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:38:17.313+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:38:17.320+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:38:17.320+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:38:17.331+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:38:17.347+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:38:17.347+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:38:17.361+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:38:17.361+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:38:17.370+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-29T18:38:47.823+0000] {processor.py:157} INFO - Started process (PID=47466) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:38:47.823+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:38:47.827+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:38:47.827+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:38:47.846+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:38:47.867+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:38:47.867+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:38:47.879+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:38:47.879+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:38:47.888+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-29T18:39:18.417+0000] {processor.py:157} INFO - Started process (PID=47491) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:39:18.418+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:39:18.421+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:39:18.420+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:39:18.443+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:39:18.475+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:39:18.475+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:39:18.491+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:39:18.491+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:39:18.501+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-07-29T18:39:49.004+0000] {processor.py:157} INFO - Started process (PID=47516) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:39:49.005+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:39:49.009+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:39:49.008+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:39:49.024+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:39:49.047+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:39:49.047+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:39:49.063+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:39:49.063+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:39:49.072+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-29T18:40:19.524+0000] {processor.py:157} INFO - Started process (PID=47541) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:40:19.525+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:40:19.530+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:40:19.530+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:40:19.548+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:40:19.591+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:40:19.591+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:40:19.607+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:40:19.607+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:40:19.617+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-07-29T18:40:50.072+0000] {processor.py:157} INFO - Started process (PID=47566) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:40:50.072+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:40:50.077+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:40:50.077+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:40:50.090+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:40:50.104+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:40:50.104+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:40:50.115+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:40:50.114+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:40:50.123+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-29T18:41:20.556+0000] {processor.py:157} INFO - Started process (PID=47590) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:41:20.557+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:41:20.562+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:41:20.561+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:41:20.580+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:41:20.607+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:41:20.607+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:41:20.621+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:41:20.621+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:41:20.631+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-07-29T18:41:51.029+0000] {processor.py:157} INFO - Started process (PID=47616) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:41:51.029+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:41:51.036+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:41:51.035+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:41:51.045+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:41:51.058+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:41:51.058+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:41:51.068+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:41:51.068+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:41:51.079+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-29T18:42:21.537+0000] {processor.py:157} INFO - Started process (PID=47640) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:42:21.538+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:42:21.542+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:42:21.542+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:42:21.560+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:42:21.585+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:42:21.585+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:42:21.597+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:42:21.597+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:42:21.606+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-29T18:42:52.067+0000] {processor.py:157} INFO - Started process (PID=47666) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:42:52.067+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:42:52.074+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:42:52.074+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:42:52.084+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:42:52.097+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:42:52.097+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:42:52.107+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:42:52.107+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:42:52.115+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-29T18:43:22.565+0000] {processor.py:157} INFO - Started process (PID=47691) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:43:22.565+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:43:22.568+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:43:22.568+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:43:22.587+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:43:22.609+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:43:22.609+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:43:22.621+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:43:22.621+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:43:22.630+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-29T18:43:53.062+0000] {processor.py:157} INFO - Started process (PID=47716) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:43:53.063+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:43:53.070+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:43:53.070+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:43:53.079+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:43:53.092+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:43:53.092+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:43:53.108+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:43:53.107+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:43:53.117+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-29T18:44:23.529+0000] {processor.py:157} INFO - Started process (PID=47741) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:44:23.530+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:44:23.534+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:44:23.534+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:44:23.551+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:44:23.576+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:44:23.576+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:44:23.589+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:44:23.588+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:44:23.599+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-29T18:44:54.158+0000] {processor.py:157} INFO - Started process (PID=47766) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:44:54.159+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:44:54.165+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:44:54.165+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:44:54.177+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:44:54.190+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:44:54.190+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:44:54.202+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:44:54.202+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:44:54.211+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-29T18:45:24.596+0000] {processor.py:157} INFO - Started process (PID=47791) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:45:24.596+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:45:24.599+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:45:24.599+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:45:24.616+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:45:24.640+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:45:24.640+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:45:24.652+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:45:24.652+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:45:24.663+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-29T18:45:55.119+0000] {processor.py:157} INFO - Started process (PID=47816) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:45:55.120+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:45:55.126+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:45:55.126+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:45:55.139+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:45:55.153+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:45:55.153+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:45:55.163+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:45:55.163+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:45:55.174+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-29T18:46:25.670+0000] {processor.py:157} INFO - Started process (PID=47841) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:46:25.672+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:46:25.674+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:46:25.674+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:46:25.689+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:46:25.710+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:46:25.710+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:46:25.722+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:46:25.722+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:46:25.734+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-29T18:46:56.241+0000] {processor.py:157} INFO - Started process (PID=47866) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:46:56.242+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:46:56.251+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:46:56.250+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:46:56.262+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:46:56.277+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:46:56.277+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:46:56.287+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:46:56.287+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:46:56.297+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-29T18:47:26.748+0000] {processor.py:157} INFO - Started process (PID=47890) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:47:26.748+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:47:26.753+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:47:26.753+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:47:26.772+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:47:26.799+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:47:26.799+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:47:26.813+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:47:26.813+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:47:26.826+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-07-29T18:47:57.267+0000] {processor.py:157} INFO - Started process (PID=47916) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:47:57.268+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:47:57.274+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:47:57.274+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:47:57.285+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:47:57.299+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:47:57.299+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:47:57.308+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:47:57.308+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:47:57.319+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-29T18:48:27.738+0000] {processor.py:157} INFO - Started process (PID=47941) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:48:27.739+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:48:27.743+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:48:27.743+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:48:27.763+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:48:27.788+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:48:27.788+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:48:27.800+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:48:27.800+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:48:27.809+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-29T18:48:58.195+0000] {processor.py:157} INFO - Started process (PID=47966) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:48:58.196+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:48:58.199+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:48:58.198+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:48:58.215+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:48:58.230+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:48:58.230+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:48:58.242+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:48:58.242+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:48:58.250+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-29T18:49:28.733+0000] {processor.py:157} INFO - Started process (PID=47991) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:49:28.735+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:49:28.738+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:49:28.737+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:49:28.756+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:49:28.781+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:49:28.781+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:49:28.794+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:49:28.793+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:49:28.803+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-29T18:49:59.296+0000] {processor.py:157} INFO - Started process (PID=48016) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:49:59.297+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:49:59.303+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:49:59.302+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:49:59.325+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:49:59.350+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:49:59.350+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:49:59.365+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:49:59.365+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:49:59.375+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-07-29T18:50:29.815+0000] {processor.py:157} INFO - Started process (PID=48041) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:50:29.817+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:50:29.820+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:50:29.820+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:50:29.841+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:50:29.886+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:50:29.886+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:50:29.905+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:50:29.904+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:50:29.917+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-07-29T18:51:00.363+0000] {processor.py:157} INFO - Started process (PID=48066) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:51:00.366+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:51:00.374+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:51:00.374+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:51:00.429+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:51:00.471+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:51:00.471+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:51:00.492+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:51:00.492+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:51:00.505+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.143 seconds
[2024-07-29T18:51:30.954+0000] {processor.py:157} INFO - Started process (PID=48091) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:51:30.955+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:51:30.960+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:51:30.960+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:51:30.987+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:51:31.040+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:51:31.040+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:51:31.062+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:51:31.062+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:51:31.092+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.145 seconds
[2024-07-29T18:52:01.507+0000] {processor.py:157} INFO - Started process (PID=48116) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:52:01.508+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:52:01.516+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:52:01.515+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:52:01.544+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:52:01.584+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:52:01.584+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:52:01.605+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:52:01.605+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:52:01.619+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-07-29T18:52:32.056+0000] {processor.py:157} INFO - Started process (PID=48141) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:52:32.057+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:52:32.061+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:52:32.061+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:52:32.088+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:52:32.117+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:52:32.116+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:52:32.134+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:52:32.134+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:52:32.148+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-07-29T18:53:02.644+0000] {processor.py:157} INFO - Started process (PID=48166) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:53:02.645+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:53:02.650+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:53:02.649+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:53:02.683+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:53:02.739+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:53:02.739+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:53:02.761+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:53:02.761+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:53:02.776+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.141 seconds
[2024-07-29T18:53:33.149+0000] {processor.py:157} INFO - Started process (PID=48191) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:53:33.150+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:53:33.153+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:53:33.153+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:53:33.174+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:53:33.195+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:53:33.195+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:53:33.211+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:53:33.211+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:53:33.229+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-07-29T18:54:03.700+0000] {processor.py:157} INFO - Started process (PID=48216) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:54:03.701+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:54:03.703+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:54:03.703+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:54:03.714+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:54:03.730+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:54:03.730+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:54:03.740+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:54:03.740+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:54:03.748+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-29T18:54:34.167+0000] {processor.py:157} INFO - Started process (PID=48241) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:54:34.168+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:54:34.177+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:54:34.176+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:54:34.202+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:54:34.229+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:54:34.228+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:54:34.254+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:54:34.253+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:54:34.265+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-07-29T18:55:04.754+0000] {processor.py:157} INFO - Started process (PID=48266) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:55:04.755+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:55:04.759+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:55:04.759+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:55:04.784+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:55:04.808+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:55:04.808+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:55:04.823+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:55:04.823+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:55:04.834+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-07-29T18:55:35.222+0000] {processor.py:157} INFO - Started process (PID=48291) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:55:35.223+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:55:35.228+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:55:35.227+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:55:35.256+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:55:35.296+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:55:35.296+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:55:35.310+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:55:35.310+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:55:35.322+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-07-29T18:56:05.801+0000] {processor.py:157} INFO - Started process (PID=48316) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:56:05.803+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:56:05.806+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:56:05.806+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:56:05.819+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:56:05.842+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:56:05.842+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:56:05.855+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:56:05.854+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:56:05.862+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-29T18:56:36.207+0000] {processor.py:157} INFO - Started process (PID=48341) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:56:36.212+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:56:36.215+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:56:36.214+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:56:36.220+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:56:36.233+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:56:36.233+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:56:36.244+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:56:36.244+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:56:36.253+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-29T18:57:06.691+0000] {processor.py:157} INFO - Started process (PID=48365) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:57:06.696+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:57:06.700+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:57:06.699+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:57:06.728+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:57:06.802+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:57:06.802+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:57:06.822+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:57:06.822+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:57:06.836+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.151 seconds
[2024-07-29T18:57:37.286+0000] {processor.py:157} INFO - Started process (PID=48391) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:57:37.288+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:57:37.295+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:57:37.295+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:57:37.327+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:57:37.391+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:57:37.391+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:57:37.411+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:57:37.410+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:57:37.425+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.146 seconds
[2024-07-29T18:58:07.815+0000] {processor.py:157} INFO - Started process (PID=48416) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:58:07.817+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:58:07.823+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:58:07.823+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:58:07.857+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:58:07.893+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:58:07.893+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:58:07.914+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:58:07.913+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:58:07.927+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-07-29T18:58:38.311+0000] {processor.py:157} INFO - Started process (PID=48441) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:58:38.313+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:58:38.318+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:58:38.318+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:58:38.348+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:58:38.375+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:58:38.375+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:58:38.395+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:58:38.395+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:58:38.411+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-07-29T18:59:08.851+0000] {processor.py:157} INFO - Started process (PID=48466) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:59:08.853+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:59:08.856+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:59:08.856+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:59:08.874+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:59:08.905+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:59:08.905+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:59:08.922+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:59:08.922+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:59:08.939+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-07-29T18:59:39.334+0000] {processor.py:157} INFO - Started process (PID=48491) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:59:39.337+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T18:59:39.354+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:59:39.353+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:59:39.373+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T18:59:39.401+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:59:39.401+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T18:59:39.418+0000] {logging_mixin.py:151} INFO - [2024-07-29T18:59:39.418+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T18:59:39.430+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-07-29T19:00:09.846+0000] {processor.py:157} INFO - Started process (PID=48516) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:00:09.847+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T19:00:09.853+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:00:09.853+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:00:09.880+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:00:09.916+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:00:09.916+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T19:00:09.936+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:00:09.936+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T19:00:09.954+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-07-29T19:00:40.320+0000] {processor.py:157} INFO - Started process (PID=48541) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:00:40.323+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T19:00:40.328+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:00:40.328+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:00:40.354+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:00:40.393+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:00:40.393+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T19:00:40.416+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:00:40.416+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T19:00:40.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-07-29T19:01:10.977+0000] {processor.py:157} INFO - Started process (PID=48565) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:01:10.979+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T19:01:10.984+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:01:10.984+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:01:11.004+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:01:11.058+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:01:11.058+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T19:01:11.077+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:01:11.077+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T19:01:11.089+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-07-29T19:01:41.786+0000] {processor.py:157} INFO - Started process (PID=48591) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:01:41.790+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T19:01:41.793+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:01:41.793+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:01:41.815+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:01:41.851+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:01:41.851+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T19:01:41.866+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:01:41.866+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T19:01:41.882+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-07-29T19:13:56.374+0000] {processor.py:157} INFO - Started process (PID=48617) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:13:56.376+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T19:13:56.384+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:13:56.384+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:13:56.427+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:13:56.483+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:13:56.483+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T19:13:56.513+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:13:56.513+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T19:13:56.530+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.166 seconds
[2024-07-29T19:14:26.956+0000] {processor.py:157} INFO - Started process (PID=48642) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:14:26.957+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T19:14:26.958+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:14:26.958+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:14:26.970+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:14:26.982+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:14:26.982+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T19:14:26.991+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:14:26.991+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T19:14:27.000+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-29T19:14:57.421+0000] {processor.py:157} INFO - Started process (PID=48668) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:14:57.422+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T19:14:57.423+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:14:57.423+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:14:57.435+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:14:57.452+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:14:57.451+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T19:14:57.461+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:14:57.461+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T19:14:57.470+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-29T19:15:27.922+0000] {processor.py:157} INFO - Started process (PID=48693) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:15:27.925+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T19:15:27.927+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:15:27.927+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:15:27.943+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:15:27.960+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:15:27.959+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T19:15:27.969+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:15:27.969+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T19:15:27.979+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-29T19:15:58.363+0000] {processor.py:157} INFO - Started process (PID=48718) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:15:58.366+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T19:15:58.370+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:15:58.369+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:15:58.384+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:15:58.407+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:15:58.407+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T19:15:58.420+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:15:58.420+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T19:15:58.430+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-29T19:16:28.814+0000] {processor.py:157} INFO - Started process (PID=48743) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:16:28.815+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T19:16:28.817+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:16:28.817+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:16:28.829+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:16:28.847+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:16:28.846+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T19:16:28.857+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:16:28.857+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T19:16:28.868+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-29T19:32:05.461+0000] {processor.py:157} INFO - Started process (PID=48767) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:32:05.467+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T19:32:05.473+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:32:05.473+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:32:05.492+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:32:05.537+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:32:05.537+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T19:32:05.557+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:32:05.556+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T19:32:05.575+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-07-29T19:32:36.174+0000] {processor.py:157} INFO - Started process (PID=48793) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:32:36.174+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T19:32:36.178+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:32:36.177+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:32:36.194+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:32:36.224+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:32:36.224+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T19:32:36.250+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:32:36.250+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T19:32:36.264+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-07-29T19:33:06.613+0000] {processor.py:157} INFO - Started process (PID=48818) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:33:06.614+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T19:33:06.617+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:33:06.616+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:33:06.634+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:33:06.658+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:33:06.658+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T19:33:06.672+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:33:06.672+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T19:33:06.683+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-29T19:33:37.151+0000] {processor.py:157} INFO - Started process (PID=48843) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:33:37.152+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T19:33:37.155+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:33:37.155+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:33:37.167+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:33:37.184+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:33:37.184+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T19:33:37.196+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:33:37.196+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T19:33:37.205+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-29T19:34:07.617+0000] {processor.py:157} INFO - Started process (PID=48868) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:34:07.619+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T19:34:07.621+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:34:07.621+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:34:07.638+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:34:07.652+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:34:07.652+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T19:34:07.664+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:34:07.664+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T19:34:07.672+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-29T19:34:38.076+0000] {processor.py:157} INFO - Started process (PID=48892) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:34:38.077+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T19:34:38.081+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:34:38.081+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:34:38.102+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:34:38.135+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:34:38.135+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T19:34:38.148+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:34:38.148+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T19:34:38.159+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-07-29T19:35:08.540+0000] {processor.py:157} INFO - Started process (PID=48918) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:35:08.540+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T19:35:08.544+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:35:08.543+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:35:08.555+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:35:08.575+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:35:08.575+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T19:35:08.585+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:35:08.585+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T19:35:08.594+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-29T19:35:39.024+0000] {processor.py:157} INFO - Started process (PID=48943) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:35:39.025+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T19:35:39.029+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:35:39.028+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:35:39.039+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:35:39.056+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:35:39.056+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T19:35:39.066+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:35:39.065+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T19:35:39.074+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-29T19:36:09.502+0000] {processor.py:157} INFO - Started process (PID=48968) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:36:09.503+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T19:36:09.507+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:36:09.507+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:36:09.520+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:36:09.543+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:36:09.543+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T19:36:09.555+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:36:09.555+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T19:36:09.565+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-29T19:36:39.938+0000] {processor.py:157} INFO - Started process (PID=48993) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:36:39.941+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T19:36:39.943+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:36:39.943+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:36:39.957+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:36:39.978+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:36:39.978+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T19:36:39.991+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:36:39.991+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T19:36:40.001+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-29T19:37:10.456+0000] {processor.py:157} INFO - Started process (PID=49018) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:37:10.457+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T19:37:10.462+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:37:10.461+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:37:10.502+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:37:10.531+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:37:10.531+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T19:37:10.550+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:37:10.549+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T19:37:10.559+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-07-29T19:37:40.994+0000] {processor.py:157} INFO - Started process (PID=49043) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:37:40.995+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T19:37:40.996+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:37:40.996+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:37:41.010+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:37:41.028+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:37:41.028+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T19:37:41.041+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:37:41.041+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T19:37:41.051+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-29T19:38:11.478+0000] {processor.py:157} INFO - Started process (PID=49068) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:38:11.479+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T19:38:11.480+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:38:11.480+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:38:11.492+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:38:11.508+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:38:11.508+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T19:38:11.518+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:38:11.518+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T19:38:11.527+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-29T19:38:41.918+0000] {processor.py:157} INFO - Started process (PID=49093) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:38:41.923+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T19:38:41.926+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:38:41.926+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:38:41.936+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:38:41.949+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:38:41.949+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T19:38:41.958+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:38:41.958+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T19:38:41.967+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-29T19:39:12.411+0000] {processor.py:157} INFO - Started process (PID=49118) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:39:12.411+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T19:39:12.413+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:39:12.413+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:39:12.424+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:39:12.441+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:39:12.441+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T19:39:12.453+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:39:12.453+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T19:39:12.461+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-29T19:39:42.819+0000] {processor.py:157} INFO - Started process (PID=49143) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:39:42.820+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T19:39:42.823+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:39:42.823+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:39:42.836+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:39:42.859+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:39:42.859+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T19:39:42.870+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:39:42.870+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T19:39:42.880+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-29T19:40:13.284+0000] {processor.py:157} INFO - Started process (PID=49168) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:40:13.285+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T19:40:13.288+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:40:13.288+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:40:13.301+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:40:13.317+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:40:13.317+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T19:40:13.328+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:40:13.328+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T19:40:13.337+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-29T19:40:43.751+0000] {processor.py:157} INFO - Started process (PID=49193) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:40:43.752+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T19:40:43.753+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:40:43.753+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:40:43.767+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:40:43.782+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:40:43.782+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T19:40:43.791+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:40:43.791+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T19:40:43.800+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-29T19:41:14.195+0000] {processor.py:157} INFO - Started process (PID=49218) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:41:14.197+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T19:41:14.199+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:41:14.199+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:41:14.210+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:41:14.226+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:41:14.226+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T19:41:14.238+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:41:14.238+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T19:41:14.248+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-29T19:41:44.671+0000] {processor.py:157} INFO - Started process (PID=49243) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:41:44.672+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T19:41:44.674+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:41:44.673+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:41:44.689+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:41:44.705+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:41:44.705+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T19:41:44.719+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:41:44.719+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T19:41:44.729+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-29T19:42:15.137+0000] {processor.py:157} INFO - Started process (PID=49268) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:42:15.140+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T19:42:15.142+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:42:15.142+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:42:15.155+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:42:15.172+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:42:15.172+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T19:42:15.185+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:42:15.185+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T19:42:15.194+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-29T19:42:45.617+0000] {processor.py:157} INFO - Started process (PID=49293) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:42:45.618+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T19:42:45.620+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:42:45.620+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:42:45.631+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:42:45.648+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:42:45.648+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T19:42:45.661+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:42:45.661+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T19:42:45.670+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-29T19:43:16.031+0000] {processor.py:157} INFO - Started process (PID=49318) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:43:16.033+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T19:43:16.036+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:43:16.036+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:43:16.050+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:43:16.073+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:43:16.073+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T19:43:16.083+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:43:16.083+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T19:43:16.090+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-29T19:43:46.524+0000] {processor.py:157} INFO - Started process (PID=49343) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:43:46.525+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T19:43:46.527+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:43:46.527+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:43:46.539+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:43:46.556+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:43:46.556+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T19:43:46.569+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:43:46.568+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T19:43:46.579+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-29T19:44:16.994+0000] {processor.py:157} INFO - Started process (PID=49367) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:44:16.995+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T19:44:16.996+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:44:16.996+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:44:17.008+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:44:17.026+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:44:17.026+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T19:44:17.035+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:44:17.035+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T19:44:17.043+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-29T19:44:47.423+0000] {processor.py:157} INFO - Started process (PID=49393) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:44:47.424+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T19:44:47.426+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:44:47.426+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:44:47.442+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:44:47.456+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:44:47.456+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T19:44:47.468+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:44:47.468+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T19:44:47.477+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-29T19:45:17.886+0000] {processor.py:157} INFO - Started process (PID=49418) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:45:17.888+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T19:45:17.890+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:45:17.889+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:45:17.905+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:45:17.921+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:45:17.921+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T19:45:17.932+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:45:17.932+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T19:45:17.940+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-29T19:45:48.419+0000] {processor.py:157} INFO - Started process (PID=49443) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:45:48.422+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T19:45:48.425+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:45:48.424+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:45:48.440+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T19:45:48.455+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:45:48.454+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T19:45:48.468+0000] {logging_mixin.py:151} INFO - [2024-07-29T19:45:48.468+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T19:45:48.482+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-29T20:03:42.563+0000] {processor.py:157} INFO - Started process (PID=49469) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T20:03:42.565+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T20:03:42.569+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:03:42.569+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T20:03:42.589+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T20:03:42.632+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:03:42.632+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T20:03:42.656+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:03:42.656+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T20:03:42.672+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-07-29T20:04:13.071+0000] {processor.py:157} INFO - Started process (PID=49495) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T20:04:13.073+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T20:04:13.075+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:04:13.075+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T20:04:13.090+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T20:04:13.108+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:04:13.108+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T20:04:13.119+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:04:13.119+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T20:04:13.129+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-29T20:04:43.526+0000] {processor.py:157} INFO - Started process (PID=49520) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T20:04:43.526+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T20:04:43.529+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:04:43.528+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T20:04:43.546+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T20:04:43.560+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:04:43.560+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T20:04:43.573+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:04:43.573+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T20:04:43.584+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-29T20:05:13.889+0000] {processor.py:157} INFO - Started process (PID=49545) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T20:05:13.890+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T20:05:13.893+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:05:13.893+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T20:05:13.906+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T20:05:13.928+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:05:13.928+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T20:05:13.941+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:05:13.941+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T20:05:13.950+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-29T20:05:44.376+0000] {processor.py:157} INFO - Started process (PID=49570) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T20:05:44.377+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T20:05:44.379+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:05:44.379+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T20:05:44.390+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T20:05:44.404+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:05:44.404+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T20:05:44.414+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:05:44.414+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T20:05:44.423+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-29T20:22:05.075+0000] {processor.py:157} INFO - Started process (PID=49595) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T20:22:05.076+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T20:22:05.078+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:22:05.078+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T20:22:05.092+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T20:22:05.113+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:22:05.113+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T20:22:05.127+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:22:05.127+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T20:22:05.140+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-29T20:22:35.697+0000] {processor.py:157} INFO - Started process (PID=49622) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T20:22:35.699+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T20:22:35.703+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:22:35.703+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T20:22:35.724+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T20:22:35.744+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:22:35.744+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T20:22:35.759+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:22:35.759+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T20:22:35.767+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-29T20:23:06.245+0000] {processor.py:157} INFO - Started process (PID=49647) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T20:23:06.245+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T20:23:06.247+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:23:06.247+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T20:23:06.262+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T20:23:06.275+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:23:06.275+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T20:23:06.287+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:23:06.287+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T20:23:06.297+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-29T20:23:36.830+0000] {processor.py:157} INFO - Started process (PID=49672) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T20:23:36.831+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T20:23:36.833+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:23:36.833+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T20:23:36.845+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T20:23:36.862+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:23:36.862+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T20:23:36.872+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:23:36.872+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T20:23:36.881+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-29T20:24:07.271+0000] {processor.py:157} INFO - Started process (PID=49697) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T20:24:07.272+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T20:24:07.273+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:24:07.273+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T20:24:07.279+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T20:24:07.292+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:24:07.292+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T20:24:07.302+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:24:07.302+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T20:24:07.310+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.041 seconds
[2024-07-29T20:24:37.622+0000] {processor.py:157} INFO - Started process (PID=49722) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T20:24:37.624+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T20:24:37.625+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:24:37.625+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T20:24:37.642+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T20:24:37.656+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:24:37.656+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T20:24:37.665+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:24:37.665+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T20:24:37.672+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-29T20:25:08.092+0000] {processor.py:157} INFO - Started process (PID=49747) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T20:25:08.094+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T20:25:08.095+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:25:08.095+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T20:25:08.113+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T20:25:08.126+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:25:08.126+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T20:25:08.137+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:25:08.137+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T20:25:08.145+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-29T20:25:38.547+0000] {processor.py:157} INFO - Started process (PID=49772) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T20:25:38.548+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T20:25:38.550+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:25:38.550+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T20:25:38.568+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T20:25:38.586+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:25:38.586+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T20:25:38.597+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:25:38.597+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T20:25:38.606+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-29T20:26:09.036+0000] {processor.py:157} INFO - Started process (PID=49797) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T20:26:09.038+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T20:26:09.041+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:26:09.041+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T20:26:09.058+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T20:26:09.080+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:26:09.080+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T20:26:09.092+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:26:09.092+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T20:26:09.103+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-29T20:26:39.476+0000] {processor.py:157} INFO - Started process (PID=49822) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T20:26:39.478+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T20:26:39.480+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:26:39.480+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T20:26:39.497+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T20:26:39.510+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:26:39.510+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T20:26:39.522+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:26:39.522+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T20:26:39.529+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-29T20:43:17.287+0000] {processor.py:157} INFO - Started process (PID=49847) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T20:43:17.288+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T20:43:17.292+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:43:17.292+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T20:43:17.313+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T20:43:17.331+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:43:17.331+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T20:43:17.342+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:43:17.342+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T20:43:17.351+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-29T20:43:47.719+0000] {processor.py:157} INFO - Started process (PID=49874) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T20:43:47.719+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T20:43:47.724+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:43:47.723+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T20:43:47.742+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T20:43:47.768+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:43:47.768+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T20:43:47.781+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:43:47.781+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T20:43:47.793+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-29T20:44:18.255+0000] {processor.py:157} INFO - Started process (PID=49899) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T20:44:18.256+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T20:44:18.257+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:44:18.257+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T20:44:18.268+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T20:44:18.284+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:44:18.284+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T20:44:18.293+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:44:18.293+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T20:44:18.302+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-29T20:44:48.674+0000] {processor.py:157} INFO - Started process (PID=49924) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T20:44:48.675+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T20:44:48.677+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:44:48.676+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T20:44:48.687+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T20:44:48.704+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:44:48.704+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T20:44:48.715+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:44:48.715+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T20:44:48.724+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-29T20:45:19.054+0000] {processor.py:157} INFO - Started process (PID=49949) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T20:45:19.055+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T20:45:19.057+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:45:19.056+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T20:45:19.072+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T20:45:19.087+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:45:19.087+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T20:45:19.104+0000] {logging_mixin.py:151} INFO - [2024-07-29T20:45:19.104+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T20:45:19.115+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-29T21:02:55.646+0000] {processor.py:157} INFO - Started process (PID=49973) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T21:02:55.648+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T21:02:55.650+0000] {logging_mixin.py:151} INFO - [2024-07-29T21:02:55.650+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T21:02:55.677+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T21:02:55.695+0000] {logging_mixin.py:151} INFO - [2024-07-29T21:02:55.695+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T21:02:55.710+0000] {logging_mixin.py:151} INFO - [2024-07-29T21:02:55.709+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T21:02:55.724+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-07-29T21:03:26.116+0000] {processor.py:157} INFO - Started process (PID=50001) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T21:03:26.118+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T21:03:26.122+0000] {logging_mixin.py:151} INFO - [2024-07-29T21:03:26.121+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T21:03:26.137+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T21:03:26.160+0000] {logging_mixin.py:151} INFO - [2024-07-29T21:03:26.160+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T21:03:26.172+0000] {logging_mixin.py:151} INFO - [2024-07-29T21:03:26.172+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T21:03:26.183+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-29T21:03:56.607+0000] {processor.py:157} INFO - Started process (PID=50026) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T21:03:56.608+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T21:03:56.611+0000] {logging_mixin.py:151} INFO - [2024-07-29T21:03:56.611+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T21:03:56.623+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T21:03:56.639+0000] {logging_mixin.py:151} INFO - [2024-07-29T21:03:56.638+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T21:03:56.648+0000] {logging_mixin.py:151} INFO - [2024-07-29T21:03:56.648+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T21:03:56.658+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-29T21:04:27.016+0000] {processor.py:157} INFO - Started process (PID=50051) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T21:04:27.018+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T21:04:27.020+0000] {logging_mixin.py:151} INFO - [2024-07-29T21:04:27.020+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T21:04:27.034+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T21:04:27.051+0000] {logging_mixin.py:151} INFO - [2024-07-29T21:04:27.051+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T21:04:27.062+0000] {logging_mixin.py:151} INFO - [2024-07-29T21:04:27.062+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T21:04:27.070+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-29T21:04:57.344+0000] {processor.py:157} INFO - Started process (PID=50076) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T21:04:57.346+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T21:04:57.347+0000] {logging_mixin.py:151} INFO - [2024-07-29T21:04:57.347+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T21:04:57.356+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T21:04:57.371+0000] {logging_mixin.py:151} INFO - [2024-07-29T21:04:57.371+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T21:04:57.381+0000] {logging_mixin.py:151} INFO - [2024-07-29T21:04:57.381+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T21:04:57.390+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-29T21:05:27.813+0000] {processor.py:157} INFO - Started process (PID=50101) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T21:05:27.815+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T21:05:27.816+0000] {logging_mixin.py:151} INFO - [2024-07-29T21:05:27.816+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T21:05:27.827+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T21:05:27.844+0000] {logging_mixin.py:151} INFO - [2024-07-29T21:05:27.844+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T21:05:27.857+0000] {logging_mixin.py:151} INFO - [2024-07-29T21:05:27.857+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T21:05:27.865+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-29T21:21:17.344+0000] {processor.py:157} INFO - Started process (PID=50125) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T21:21:17.347+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T21:21:17.350+0000] {logging_mixin.py:151} INFO - [2024-07-29T21:21:17.350+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T21:21:17.389+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T21:21:17.432+0000] {logging_mixin.py:151} INFO - [2024-07-29T21:21:17.431+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T21:21:17.464+0000] {logging_mixin.py:151} INFO - [2024-07-29T21:21:17.464+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T21:21:17.487+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.147 seconds
[2024-07-29T21:37:14.091+0000] {processor.py:157} INFO - Started process (PID=50153) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T21:37:14.093+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T21:37:14.096+0000] {logging_mixin.py:151} INFO - [2024-07-29T21:37:14.096+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T21:37:14.118+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T21:37:14.158+0000] {logging_mixin.py:151} INFO - [2024-07-29T21:37:14.157+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T21:37:14.176+0000] {logging_mixin.py:151} INFO - [2024-07-29T21:37:14.176+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T21:37:14.196+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-07-29T21:37:44.620+0000] {processor.py:157} INFO - Started process (PID=50178) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T21:37:44.623+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T21:37:44.627+0000] {logging_mixin.py:151} INFO - [2024-07-29T21:37:44.627+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T21:37:44.647+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T21:37:44.673+0000] {logging_mixin.py:151} INFO - [2024-07-29T21:37:44.673+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T21:37:44.690+0000] {logging_mixin.py:151} INFO - [2024-07-29T21:37:44.689+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T21:37:44.701+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-07-29T21:38:15.095+0000] {processor.py:157} INFO - Started process (PID=50203) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T21:38:15.096+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T21:38:15.099+0000] {logging_mixin.py:151} INFO - [2024-07-29T21:38:15.099+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T21:38:15.114+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T21:38:15.133+0000] {logging_mixin.py:151} INFO - [2024-07-29T21:38:15.133+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T21:38:15.146+0000] {logging_mixin.py:151} INFO - [2024-07-29T21:38:15.145+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T21:38:15.162+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-29T21:38:45.549+0000] {processor.py:157} INFO - Started process (PID=50228) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T21:38:45.550+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T21:38:45.552+0000] {logging_mixin.py:151} INFO - [2024-07-29T21:38:45.551+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T21:38:45.566+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T21:38:45.585+0000] {logging_mixin.py:151} INFO - [2024-07-29T21:38:45.585+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T21:38:45.596+0000] {logging_mixin.py:151} INFO - [2024-07-29T21:38:45.596+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T21:38:45.605+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-29T21:39:15.991+0000] {processor.py:157} INFO - Started process (PID=50253) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T21:39:15.991+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T21:39:15.993+0000] {logging_mixin.py:151} INFO - [2024-07-29T21:39:15.992+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T21:39:16.000+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T21:39:16.015+0000] {logging_mixin.py:151} INFO - [2024-07-29T21:39:16.015+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T21:39:16.026+0000] {logging_mixin.py:151} INFO - [2024-07-29T21:39:16.026+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T21:39:16.035+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-29T21:55:51.160+0000] {processor.py:157} INFO - Started process (PID=50280) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T21:55:51.163+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T21:55:51.166+0000] {logging_mixin.py:151} INFO - [2024-07-29T21:55:51.165+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T21:55:51.180+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T21:55:51.201+0000] {logging_mixin.py:151} INFO - [2024-07-29T21:55:51.201+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T21:55:51.213+0000] {logging_mixin.py:151} INFO - [2024-07-29T21:55:51.213+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T21:55:51.224+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-29T21:56:21.701+0000] {processor.py:157} INFO - Started process (PID=50304) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T21:56:21.703+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T21:56:21.706+0000] {logging_mixin.py:151} INFO - [2024-07-29T21:56:21.706+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T21:56:21.740+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T21:56:21.768+0000] {logging_mixin.py:151} INFO - [2024-07-29T21:56:21.768+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T21:56:21.792+0000] {logging_mixin.py:151} INFO - [2024-07-29T21:56:21.792+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T21:56:21.804+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-07-29T22:03:44.359+0000] {processor.py:157} INFO - Started process (PID=50330) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T22:03:44.361+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T22:03:44.366+0000] {logging_mixin.py:151} INFO - [2024-07-29T22:03:44.365+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T22:03:44.399+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T22:03:44.432+0000] {logging_mixin.py:151} INFO - [2024-07-29T22:03:44.431+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T22:03:44.458+0000] {logging_mixin.py:151} INFO - [2024-07-29T22:03:44.458+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T22:03:44.480+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-07-29T22:04:15.024+0000] {processor.py:157} INFO - Started process (PID=50355) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T22:04:15.025+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T22:04:15.027+0000] {logging_mixin.py:151} INFO - [2024-07-29T22:04:15.027+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T22:04:15.052+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T22:04:15.068+0000] {logging_mixin.py:151} INFO - [2024-07-29T22:04:15.068+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T22:04:15.078+0000] {logging_mixin.py:151} INFO - [2024-07-29T22:04:15.078+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T22:04:15.086+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-29T22:21:37.430+0000] {processor.py:157} INFO - Started process (PID=50381) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T22:21:37.431+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T22:21:37.438+0000] {logging_mixin.py:151} INFO - [2024-07-29T22:21:37.437+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T22:21:37.457+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T22:21:37.495+0000] {logging_mixin.py:151} INFO - [2024-07-29T22:21:37.494+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T22:21:37.515+0000] {logging_mixin.py:151} INFO - [2024-07-29T22:21:37.515+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T22:21:37.530+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-07-29T22:22:08.020+0000] {processor.py:157} INFO - Started process (PID=50407) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T22:22:08.021+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T22:22:08.023+0000] {logging_mixin.py:151} INFO - [2024-07-29T22:22:08.023+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T22:22:08.044+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T22:22:08.067+0000] {logging_mixin.py:151} INFO - [2024-07-29T22:22:08.066+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T22:22:08.077+0000] {logging_mixin.py:151} INFO - [2024-07-29T22:22:08.077+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T22:22:08.083+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-29T22:22:38.456+0000] {processor.py:157} INFO - Started process (PID=50432) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T22:22:38.458+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T22:22:38.461+0000] {logging_mixin.py:151} INFO - [2024-07-29T22:22:38.461+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T22:22:38.474+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T22:22:38.494+0000] {logging_mixin.py:151} INFO - [2024-07-29T22:22:38.493+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T22:22:38.505+0000] {logging_mixin.py:151} INFO - [2024-07-29T22:22:38.505+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T22:22:38.513+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-29T22:23:08.940+0000] {processor.py:157} INFO - Started process (PID=50457) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T22:23:08.941+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T22:23:08.943+0000] {logging_mixin.py:151} INFO - [2024-07-29T22:23:08.943+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T22:23:08.956+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T22:23:08.972+0000] {logging_mixin.py:151} INFO - [2024-07-29T22:23:08.972+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T22:23:08.983+0000] {logging_mixin.py:151} INFO - [2024-07-29T22:23:08.983+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T22:23:08.991+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-29T22:23:39.335+0000] {processor.py:157} INFO - Started process (PID=50482) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T22:23:39.337+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T22:23:39.339+0000] {logging_mixin.py:151} INFO - [2024-07-29T22:23:39.339+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T22:23:39.362+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T22:23:39.378+0000] {logging_mixin.py:151} INFO - [2024-07-29T22:23:39.378+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T22:23:39.391+0000] {logging_mixin.py:151} INFO - [2024-07-29T22:23:39.391+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T22:23:39.400+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-29T22:39:34.542+0000] {processor.py:157} INFO - Started process (PID=50508) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T22:39:34.549+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T22:39:34.551+0000] {logging_mixin.py:151} INFO - [2024-07-29T22:39:34.551+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T22:39:34.570+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T22:39:34.602+0000] {logging_mixin.py:151} INFO - [2024-07-29T22:39:34.602+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T22:39:34.631+0000] {logging_mixin.py:151} INFO - [2024-07-29T22:39:34.631+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T22:39:34.650+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-07-29T22:57:13.139+0000] {processor.py:157} INFO - Started process (PID=50533) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T22:57:13.143+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T22:57:13.148+0000] {logging_mixin.py:151} INFO - [2024-07-29T22:57:13.148+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T22:57:13.175+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T22:57:13.219+0000] {logging_mixin.py:151} INFO - [2024-07-29T22:57:13.219+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T22:57:13.235+0000] {logging_mixin.py:151} INFO - [2024-07-29T22:57:13.234+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T22:57:13.246+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-07-29T22:57:43.700+0000] {processor.py:157} INFO - Started process (PID=50558) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T22:57:43.703+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T22:57:43.709+0000] {logging_mixin.py:151} INFO - [2024-07-29T22:57:43.708+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T22:57:43.748+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T22:57:43.775+0000] {logging_mixin.py:151} INFO - [2024-07-29T22:57:43.775+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T22:57:43.788+0000] {logging_mixin.py:151} INFO - [2024-07-29T22:57:43.788+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T22:57:43.798+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-07-29T22:58:14.265+0000] {processor.py:157} INFO - Started process (PID=50583) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T22:58:14.267+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T22:58:14.271+0000] {logging_mixin.py:151} INFO - [2024-07-29T22:58:14.271+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T22:58:14.287+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T22:58:14.308+0000] {logging_mixin.py:151} INFO - [2024-07-29T22:58:14.308+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T22:58:14.331+0000] {logging_mixin.py:151} INFO - [2024-07-29T22:58:14.331+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T22:58:14.345+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-07-29T22:58:44.792+0000] {processor.py:157} INFO - Started process (PID=50608) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T22:58:44.793+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T22:58:44.795+0000] {logging_mixin.py:151} INFO - [2024-07-29T22:58:44.794+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T22:58:44.806+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T22:58:44.824+0000] {logging_mixin.py:151} INFO - [2024-07-29T22:58:44.824+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T22:58:44.835+0000] {logging_mixin.py:151} INFO - [2024-07-29T22:58:44.835+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T22:58:44.843+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-29T22:59:15.192+0000] {processor.py:157} INFO - Started process (PID=50633) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T22:59:15.193+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T22:59:15.194+0000] {logging_mixin.py:151} INFO - [2024-07-29T22:59:15.194+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T22:59:15.204+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T22:59:15.219+0000] {logging_mixin.py:151} INFO - [2024-07-29T22:59:15.219+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T22:59:15.229+0000] {logging_mixin.py:151} INFO - [2024-07-29T22:59:15.229+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T22:59:15.237+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-29T23:04:52.256+0000] {processor.py:157} INFO - Started process (PID=50658) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T23:04:52.261+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T23:04:52.266+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:04:52.266+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T23:04:52.300+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T23:04:52.353+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:04:52.353+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T23:04:52.388+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:04:52.388+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T23:04:52.412+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.161 seconds
[2024-07-29T23:05:22.996+0000] {processor.py:157} INFO - Started process (PID=50684) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T23:05:22.998+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T23:05:23.001+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:05:23.001+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T23:05:23.022+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T23:05:23.062+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:05:23.062+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T23:05:23.076+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:05:23.076+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T23:05:23.088+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-07-29T23:05:53.498+0000] {processor.py:157} INFO - Started process (PID=50710) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T23:05:53.501+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T23:05:53.503+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:05:53.503+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T23:05:53.516+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T23:05:53.532+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:05:53.532+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T23:05:53.541+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:05:53.541+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T23:05:53.550+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-29T23:06:23.950+0000] {processor.py:157} INFO - Started process (PID=50735) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T23:06:23.951+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T23:06:23.954+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:06:23.954+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T23:06:23.965+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T23:06:23.981+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:06:23.981+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T23:06:23.991+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:06:23.991+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T23:06:23.999+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-29T23:06:54.418+0000] {processor.py:157} INFO - Started process (PID=50760) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T23:06:54.420+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T23:06:54.423+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:06:54.423+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T23:06:54.442+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T23:06:54.465+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:06:54.464+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T23:06:54.478+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:06:54.478+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T23:06:54.487+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-29T23:22:54.579+0000] {processor.py:157} INFO - Started process (PID=50785) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T23:22:54.582+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T23:22:54.584+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:22:54.584+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T23:22:54.609+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T23:22:54.639+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:22:54.639+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T23:22:54.660+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:22:54.660+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T23:22:54.685+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-07-29T23:23:25.176+0000] {processor.py:157} INFO - Started process (PID=50810) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T23:23:25.178+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T23:23:25.181+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:23:25.181+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T23:23:25.198+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T23:23:25.220+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:23:25.220+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T23:23:25.235+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:23:25.235+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T23:23:25.243+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-29T23:23:55.687+0000] {processor.py:157} INFO - Started process (PID=50835) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T23:23:55.688+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T23:23:55.690+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:23:55.690+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T23:23:55.706+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T23:23:55.722+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:23:55.722+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T23:23:55.733+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:23:55.733+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T23:23:55.743+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-29T23:24:26.200+0000] {processor.py:157} INFO - Started process (PID=50860) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T23:24:26.202+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T23:24:26.204+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:24:26.204+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T23:24:26.219+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T23:24:26.234+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:24:26.234+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T23:24:26.244+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:24:26.244+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T23:24:26.253+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-29T23:41:16.193+0000] {processor.py:157} INFO - Started process (PID=50886) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T23:41:16.201+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T23:41:16.205+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:41:16.205+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T23:41:16.224+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T23:41:16.256+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:41:16.256+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T23:41:16.275+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:41:16.275+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T23:41:16.298+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-07-29T23:41:46.720+0000] {processor.py:157} INFO - Started process (PID=50912) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T23:41:46.723+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T23:41:46.727+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:41:46.727+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T23:41:46.747+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T23:41:46.771+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:41:46.771+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T23:41:46.783+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:41:46.783+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T23:41:46.793+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-07-29T23:57:49.301+0000] {processor.py:157} INFO - Started process (PID=50937) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T23:57:49.308+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T23:57:49.319+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:57:49.319+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T23:57:49.344+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T23:57:49.383+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:57:49.383+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T23:57:49.412+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:57:49.412+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T23:57:49.439+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.142 seconds
[2024-07-29T23:58:19.847+0000] {processor.py:157} INFO - Started process (PID=50962) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T23:58:19.849+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T23:58:19.851+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:58:19.851+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T23:58:19.865+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T23:58:19.886+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:58:19.886+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T23:58:19.899+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:58:19.899+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T23:58:19.909+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-29T23:58:50.355+0000] {processor.py:157} INFO - Started process (PID=50987) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T23:58:50.356+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T23:58:50.359+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:58:50.359+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T23:58:50.369+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T23:58:50.388+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:58:50.388+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T23:58:50.400+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:58:50.400+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T23:58:50.407+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-29T23:59:20.854+0000] {processor.py:157} INFO - Started process (PID=51012) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T23:59:20.856+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T23:59:20.858+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:59:20.858+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T23:59:20.876+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T23:59:20.889+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:59:20.889+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T23:59:20.899+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:59:20.899+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T23:59:20.908+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-29T23:59:51.368+0000] {processor.py:157} INFO - Started process (PID=51037) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-29T23:59:51.369+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-29T23:59:51.371+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:59:51.371+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T23:59:51.382+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-29T23:59:51.397+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:59:51.397+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-29T23:59:51.409+0000] {logging_mixin.py:151} INFO - [2024-07-29T23:59:51.409+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-29T01:00:00+00:00, run_after=2024-07-30T01:00:00+00:00
[2024-07-29T23:59:51.418+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
