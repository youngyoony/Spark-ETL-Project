[2024-08-20T00:00:07.845+0000] {processor.py:157} INFO - Started process (PID=75911) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:00:07.849+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T00:00:07.851+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:00:07.850+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:00:07.872+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:00:07.896+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:00:07.896+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T00:00:07.910+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:00:07.910+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-20T00:00:07.921+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-08-20T00:00:38.224+0000] {processor.py:157} INFO - Started process (PID=75922) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:00:38.225+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T00:00:38.227+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:00:38.227+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:00:38.235+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:00:38.252+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:00:38.251+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T00:00:38.262+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:00:38.262+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-20T00:00:38.270+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-20T00:01:08.613+0000] {processor.py:157} INFO - Started process (PID=75931) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:01:08.615+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T00:01:08.620+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:01:08.619+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:01:08.639+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:01:08.677+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:01:08.677+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T00:01:08.691+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:01:08.691+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-20T00:01:08.704+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-08-20T00:01:38.946+0000] {processor.py:157} INFO - Started process (PID=75942) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:01:38.948+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T00:01:38.959+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:01:38.954+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:01:38.982+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:01:39.013+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:01:39.013+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T00:01:39.031+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:01:39.031+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-20T00:01:39.041+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-08-20T00:02:09.271+0000] {processor.py:157} INFO - Started process (PID=75952) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:02:09.274+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T00:02:09.278+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:02:09.277+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:02:09.297+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:02:09.323+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:02:09.323+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T00:02:09.335+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:02:09.335+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-20T00:02:09.344+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-08-20T00:02:39.574+0000] {processor.py:157} INFO - Started process (PID=75962) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:02:39.578+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T00:02:39.582+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:02:39.582+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:02:39.598+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:02:39.621+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:02:39.621+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T00:02:39.635+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:02:39.635+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-20T00:02:39.645+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-08-20T00:03:09.873+0000] {processor.py:157} INFO - Started process (PID=75972) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:03:09.876+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T00:03:09.879+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:03:09.879+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:03:09.888+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:03:09.905+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:03:09.905+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T00:03:09.919+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:03:09.918+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-20T00:03:09.928+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-20T00:03:40.294+0000] {processor.py:157} INFO - Started process (PID=75982) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:03:40.295+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T00:03:40.300+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:03:40.299+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:03:40.320+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:03:40.344+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:03:40.344+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T00:03:40.357+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:03:40.357+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-20T00:03:40.367+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-20T00:04:10.565+0000] {processor.py:157} INFO - Started process (PID=75992) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:04:10.566+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T00:04:10.571+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:04:10.570+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:04:10.588+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:04:10.611+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:04:10.611+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T00:04:10.624+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:04:10.624+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-20T00:04:10.635+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-08-20T00:04:40.867+0000] {processor.py:157} INFO - Started process (PID=76002) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:04:40.868+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T00:04:40.873+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:04:40.872+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:04:40.883+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:04:40.898+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:04:40.898+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T00:04:40.907+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:04:40.907+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-20T00:04:40.916+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-20T00:05:11.216+0000] {processor.py:157} INFO - Started process (PID=76012) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:05:11.219+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T00:05:11.222+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:05:11.222+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:05:11.237+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:05:11.259+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:05:11.259+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T00:05:11.276+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:05:11.276+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-20T00:05:11.285+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-20T00:05:41.623+0000] {processor.py:157} INFO - Started process (PID=76021) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:05:41.624+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T00:05:41.628+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:05:41.628+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:05:41.656+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:05:41.675+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:05:41.674+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T00:05:41.685+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:05:41.685+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-20T00:05:41.693+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-08-20T00:06:11.958+0000] {processor.py:157} INFO - Started process (PID=76032) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:06:11.959+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T00:06:11.963+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:06:11.962+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:06:11.973+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:06:11.996+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:06:11.996+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T00:06:12.009+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:06:12.009+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-20T00:06:12.020+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-20T00:06:42.350+0000] {processor.py:157} INFO - Started process (PID=76041) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:06:42.352+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T00:06:42.355+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:06:42.355+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:06:42.372+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:06:42.392+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:06:42.392+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T00:06:42.410+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:06:42.410+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-20T00:06:42.422+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-08-20T00:07:12.638+0000] {processor.py:157} INFO - Started process (PID=76052) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:07:12.641+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T00:07:12.643+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:07:12.643+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:07:12.657+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:07:12.696+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:07:12.696+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T00:07:12.708+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:07:12.708+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-20T00:07:12.717+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-08-20T00:07:42.943+0000] {processor.py:157} INFO - Started process (PID=76061) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:07:42.944+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T00:07:42.947+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:07:42.947+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:07:42.980+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:07:43.005+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:07:43.005+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T00:07:43.019+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:07:43.019+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-20T00:07:43.029+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-08-20T00:08:13.231+0000] {processor.py:157} INFO - Started process (PID=76072) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:08:13.232+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T00:08:13.235+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:08:13.234+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:08:13.247+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:08:13.265+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:08:13.265+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T00:08:13.281+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:08:13.281+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-20T00:08:13.292+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-20T00:08:43.556+0000] {processor.py:157} INFO - Started process (PID=76082) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:08:43.557+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T00:08:43.561+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:08:43.561+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:08:43.579+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:08:43.609+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:08:43.609+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T00:08:43.624+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:08:43.624+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-20T00:08:43.634+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-08-20T00:09:13.895+0000] {processor.py:157} INFO - Started process (PID=76092) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:09:13.897+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T00:09:13.901+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:09:13.900+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:09:13.920+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:09:13.945+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:09:13.944+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T00:09:13.975+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:09:13.975+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-20T00:09:13.986+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-08-20T00:09:44.221+0000] {processor.py:157} INFO - Started process (PID=76102) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:09:44.223+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T00:09:44.227+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:09:44.227+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:09:44.248+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:09:44.263+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:09:44.262+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T00:09:44.276+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:09:44.276+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-20T00:09:44.286+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-20T00:10:14.605+0000] {processor.py:157} INFO - Started process (PID=76112) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:10:14.608+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T00:10:14.609+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:10:14.609+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:10:14.624+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:10:14.646+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:10:14.646+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T00:10:14.670+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:10:14.670+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-20T00:10:14.680+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-08-20T00:10:44.915+0000] {processor.py:157} INFO - Started process (PID=76122) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:10:44.917+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T00:10:44.919+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:10:44.919+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:10:44.930+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:10:44.946+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:10:44.946+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T00:10:44.956+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:10:44.955+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-20T00:10:44.964+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-20T00:11:15.329+0000] {processor.py:157} INFO - Started process (PID=76131) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:11:15.331+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T00:11:15.336+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:11:15.336+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:11:15.366+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:11:15.391+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:11:15.391+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T00:11:15.415+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:11:15.415+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-20T00:11:15.425+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-08-20T00:11:45.681+0000] {processor.py:157} INFO - Started process (PID=76141) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:11:45.686+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T00:11:45.690+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:11:45.690+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:11:45.709+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:11:45.735+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:11:45.735+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T00:11:45.749+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:11:45.748+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-20T00:11:45.758+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-08-20T00:12:15.985+0000] {processor.py:157} INFO - Started process (PID=76152) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:12:15.987+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T00:12:15.990+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:12:15.990+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:12:15.999+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:12:16.015+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:12:16.015+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T00:12:16.024+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:12:16.024+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-20T00:12:16.036+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-20T00:12:46.406+0000] {processor.py:157} INFO - Started process (PID=76162) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:12:46.416+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T00:12:46.421+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:12:46.421+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:12:46.457+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:12:46.488+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:12:46.488+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T00:12:46.505+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:12:46.505+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-20T00:12:46.535+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.144 seconds
[2024-08-20T00:13:16.699+0000] {processor.py:157} INFO - Started process (PID=76172) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:13:16.701+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T00:13:16.703+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:13:16.703+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:13:16.717+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:13:16.733+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:13:16.733+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T00:13:16.743+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:13:16.743+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-20T00:13:16.754+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-20T00:13:47.096+0000] {processor.py:157} INFO - Started process (PID=76182) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:13:47.098+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T00:13:47.103+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:13:47.103+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:13:47.121+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:13:47.147+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:13:47.147+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T00:13:47.163+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:13:47.163+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-20T00:13:47.175+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-08-20T00:14:17.389+0000] {processor.py:157} INFO - Started process (PID=76192) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:14:17.391+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T00:14:17.397+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:14:17.397+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:14:17.416+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:14:17.447+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:14:17.447+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T00:14:17.461+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:14:17.461+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-20T00:14:17.473+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-08-20T00:14:47.690+0000] {processor.py:157} INFO - Started process (PID=76202) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:14:47.695+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T00:14:47.699+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:14:47.698+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:14:47.716+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:14:47.739+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:14:47.738+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T00:14:47.754+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:14:47.753+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-20T00:14:47.764+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-08-20T00:15:18.071+0000] {processor.py:157} INFO - Started process (PID=76212) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:15:18.072+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T00:15:18.077+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:15:18.076+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:15:18.097+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:15:18.124+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:15:18.124+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T00:15:18.137+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:15:18.137+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-20T00:15:18.154+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-08-20T00:15:48.433+0000] {processor.py:157} INFO - Started process (PID=76222) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:15:48.435+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T00:15:48.440+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:15:48.439+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:15:48.459+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:15:48.486+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:15:48.486+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T00:15:48.500+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:15:48.500+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-20T00:15:48.512+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-08-20T00:16:18.718+0000] {processor.py:157} INFO - Started process (PID=76232) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:16:18.719+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T00:16:18.721+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:16:18.721+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:16:18.736+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:16:18.748+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:16:18.748+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T00:16:18.757+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:16:18.757+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-20T00:16:18.764+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-20T00:16:49.014+0000] {processor.py:157} INFO - Started process (PID=76242) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:16:49.015+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T00:16:49.018+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:16:49.018+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:16:49.053+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:16:49.089+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:16:49.089+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T00:16:49.102+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:16:49.102+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-20T00:16:49.113+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-08-20T00:17:19.309+0000] {processor.py:157} INFO - Started process (PID=76252) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:17:19.311+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T00:17:19.313+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:17:19.313+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:17:19.332+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:17:19.354+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:17:19.354+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T00:17:19.367+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:17:19.367+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-20T00:17:19.376+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-20T00:17:49.689+0000] {processor.py:157} INFO - Started process (PID=76262) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:17:49.690+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T00:17:49.692+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:17:49.691+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:17:49.708+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:17:49.728+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:17:49.728+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T00:17:49.740+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:17:49.740+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-20T00:17:49.750+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-20T00:18:20.029+0000] {processor.py:157} INFO - Started process (PID=76272) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:18:20.034+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T00:18:20.037+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:18:20.037+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:18:20.056+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:18:20.081+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:18:20.081+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T00:18:20.094+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:18:20.094+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-20T00:18:20.104+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-08-20T00:18:50.315+0000] {processor.py:157} INFO - Started process (PID=76282) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:18:50.317+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T00:18:50.320+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:18:50.319+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:18:50.330+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:18:50.349+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:18:50.349+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T00:18:50.361+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:18:50.361+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-20T00:18:50.371+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-20T00:19:20.716+0000] {processor.py:157} INFO - Started process (PID=76292) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:19:20.717+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T00:19:20.721+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:19:20.721+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:19:20.738+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:19:20.786+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:19:20.786+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T00:19:20.800+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:19:20.800+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-20T00:19:20.811+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-08-20T00:19:51.113+0000] {processor.py:157} INFO - Started process (PID=76302) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:19:51.115+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T00:19:51.117+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:19:51.116+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:19:51.126+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:19:51.144+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:19:51.144+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T00:19:51.154+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:19:51.154+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-20T00:19:51.165+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-20T00:20:21.534+0000] {processor.py:157} INFO - Started process (PID=76312) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:20:21.538+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T00:20:21.541+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:20:21.541+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:20:21.564+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:20:21.592+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:20:21.592+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T00:20:21.606+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:20:21.606+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-20T00:20:21.620+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-08-20T00:20:51.816+0000] {processor.py:157} INFO - Started process (PID=76322) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:20:51.821+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T00:20:51.824+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:20:51.823+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:20:51.851+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:20:51.869+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:20:51.869+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T00:20:51.884+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:20:51.884+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-20T00:20:51.893+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-08-20T00:21:22.152+0000] {processor.py:157} INFO - Started process (PID=76332) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:21:22.153+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T00:21:22.156+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:21:22.156+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:21:22.167+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:21:22.184+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:21:22.184+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T00:21:22.196+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:21:22.196+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-20T00:21:22.206+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-20T00:21:52.544+0000] {processor.py:157} INFO - Started process (PID=76342) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:21:52.547+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T00:21:52.548+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:21:52.548+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:21:52.588+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:21:52.618+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:21:52.618+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T00:21:52.641+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:21:52.641+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-20T00:21:52.652+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-08-20T00:22:22.882+0000] {processor.py:157} INFO - Started process (PID=76352) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:22:22.883+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T00:22:22.886+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:22:22.886+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:22:22.899+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:22:22.922+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:22:22.922+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T00:22:22.933+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:22:22.933+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-20T00:22:22.943+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-20T00:22:53.301+0000] {processor.py:157} INFO - Started process (PID=76362) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:22:53.302+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T00:22:53.306+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:22:53.306+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:22:53.331+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:22:53.354+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:22:53.354+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T00:22:53.368+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:22:53.368+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-20T00:22:53.378+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-08-20T00:23:23.604+0000] {processor.py:157} INFO - Started process (PID=76372) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:23:23.605+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T00:23:23.608+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:23:23.608+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:23:23.623+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:23:23.647+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:23:23.647+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T00:23:23.660+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:23:23.660+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-20T00:23:23.671+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-20T00:23:53.928+0000] {processor.py:157} INFO - Started process (PID=76382) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:23:53.929+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T00:23:53.931+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:23:53.931+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:23:53.942+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:23:53.959+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:23:53.959+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T00:23:53.972+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:23:53.972+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-20T00:23:53.980+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-20T00:24:24.313+0000] {processor.py:157} INFO - Started process (PID=76391) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:24:24.316+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T00:24:24.322+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:24:24.321+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:24:24.340+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:24:24.368+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:24:24.368+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T00:24:24.382+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:24:24.382+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-20T00:24:24.392+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-08-20T00:24:55.211+0000] {processor.py:157} INFO - Started process (PID=76402) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:24:55.218+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T00:24:55.224+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:24:55.223+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:24:55.245+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:24:55.283+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:24:55.283+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T00:24:55.301+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:24:55.301+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-20T00:24:55.313+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-08-20T00:41:05.178+0000] {processor.py:157} INFO - Started process (PID=76412) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:41:05.178+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T00:41:05.179+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:41:05.179+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:41:05.194+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:41:05.213+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:41:05.213+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T00:41:05.228+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:41:05.228+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-20T00:41:05.242+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-20T00:41:35.598+0000] {processor.py:157} INFO - Started process (PID=77027) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:41:35.600+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T00:41:35.606+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:41:35.605+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:41:35.624+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:41:35.675+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:41:35.674+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T00:41:35.692+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:41:35.692+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-20T00:41:35.712+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-08-20T00:42:05.929+0000] {processor.py:157} INFO - Started process (PID=77038) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:42:05.933+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T00:42:05.939+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:42:05.938+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:42:05.968+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:42:05.997+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:42:05.996+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T00:42:06.010+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:42:06.009+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-20T00:42:06.021+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-08-20T00:42:36.393+0000] {processor.py:157} INFO - Started process (PID=77047) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:42:36.394+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T00:42:36.397+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:42:36.396+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:42:36.415+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:42:36.440+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:42:36.440+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T00:42:36.453+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:42:36.453+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-20T00:42:36.465+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-08-20T00:43:06.795+0000] {processor.py:157} INFO - Started process (PID=77058) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:43:06.795+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T00:43:06.798+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:43:06.797+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:43:06.808+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:43:06.828+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:43:06.828+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T00:43:06.840+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:43:06.840+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-20T00:43:06.849+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-20T00:43:37.297+0000] {processor.py:157} INFO - Started process (PID=77297) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:43:37.302+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T00:43:37.315+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:43:37.315+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:43:37.341+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:43:37.394+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:43:37.394+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T00:43:37.414+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:43:37.414+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-20T00:43:37.428+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.141 seconds
[2024-08-20T00:44:07.930+0000] {processor.py:157} INFO - Started process (PID=77307) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:44:07.935+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T00:44:07.939+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:44:07.939+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:44:07.967+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:44:08.017+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:44:08.017+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T00:44:08.046+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:44:08.046+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-20T00:44:08.066+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.144 seconds
[2024-08-20T00:44:38.270+0000] {processor.py:157} INFO - Started process (PID=77317) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:44:38.273+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T00:44:38.280+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:44:38.280+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:44:38.308+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:44:38.377+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:44:38.376+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T00:44:38.397+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:44:38.397+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-20T00:44:38.411+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.148 seconds
[2024-08-20T00:45:08.708+0000] {processor.py:157} INFO - Started process (PID=77327) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:45:08.712+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T00:45:08.716+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:45:08.716+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:45:08.741+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:45:08.790+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:45:08.790+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T00:45:08.807+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:45:08.806+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-20T00:45:08.823+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-08-20T00:45:39.167+0000] {processor.py:157} INFO - Started process (PID=77337) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:45:39.171+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T00:45:39.185+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:45:39.183+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:45:39.245+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:45:39.308+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:45:39.308+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T00:45:39.333+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:45:39.332+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-20T00:45:39.348+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.190 seconds
[2024-08-20T00:46:09.565+0000] {processor.py:157} INFO - Started process (PID=77347) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:46:09.568+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T00:46:09.572+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:46:09.572+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:46:09.597+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:46:09.632+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:46:09.632+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T00:46:09.664+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:46:09.664+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-20T00:46:09.681+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-08-20T00:46:40.134+0000] {processor.py:157} INFO - Started process (PID=77357) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:46:40.137+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T00:46:40.149+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:46:40.148+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:46:40.183+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:46:40.262+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:46:40.261+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T00:46:40.287+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:46:40.287+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-20T00:46:40.312+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.183 seconds
[2024-08-20T00:47:10.524+0000] {processor.py:157} INFO - Started process (PID=77367) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:47:10.528+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T00:47:10.553+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:47:10.553+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:47:10.574+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:47:10.622+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:47:10.622+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T00:47:10.646+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:47:10.646+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-20T00:47:10.660+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.149 seconds
[2024-08-20T00:47:40.874+0000] {processor.py:157} INFO - Started process (PID=77377) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:47:40.876+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T00:47:40.882+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:47:40.881+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:47:40.903+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:47:40.936+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:47:40.936+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T00:47:40.951+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:47:40.951+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-20T00:47:40.962+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-08-20T00:48:11.362+0000] {processor.py:157} INFO - Started process (PID=77387) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:48:11.371+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T00:48:11.380+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:48:11.379+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:48:11.415+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:48:11.449+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:48:11.449+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T00:48:11.467+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:48:11.467+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-20T00:48:11.481+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-08-20T00:48:41.666+0000] {processor.py:157} INFO - Started process (PID=77397) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:48:41.667+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T00:48:41.671+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:48:41.671+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:48:41.703+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:48:41.732+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:48:41.732+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T00:48:41.760+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:48:41.760+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-20T00:48:41.781+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-08-20T00:49:12.131+0000] {processor.py:157} INFO - Started process (PID=77407) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:49:12.133+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T00:49:12.141+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:49:12.140+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:49:12.181+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:49:12.239+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:49:12.239+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T00:49:12.258+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:49:12.258+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-20T00:49:12.270+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.145 seconds
[2024-08-20T00:49:42.459+0000] {processor.py:157} INFO - Started process (PID=77417) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:49:42.463+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T00:49:42.473+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:49:42.473+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:49:42.496+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:49:42.529+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:49:42.529+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T00:49:42.558+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:49:42.558+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-20T00:49:42.570+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-08-20T00:50:12.853+0000] {processor.py:157} INFO - Started process (PID=77427) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:50:12.854+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T00:50:12.859+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:50:12.859+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:50:12.881+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:50:12.936+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:50:12.935+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T00:50:12.954+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:50:12.954+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-20T00:50:12.964+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-08-20T00:50:43.232+0000] {processor.py:157} INFO - Started process (PID=77437) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:50:43.236+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T00:50:43.241+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:50:43.240+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:50:43.259+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:50:43.298+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:50:43.298+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T00:50:43.311+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:50:43.311+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-20T00:50:43.319+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-08-20T00:51:13.734+0000] {processor.py:157} INFO - Started process (PID=77447) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:51:13.741+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T00:51:13.745+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:51:13.744+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:51:13.764+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:51:13.797+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:51:13.797+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T00:51:13.810+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:51:13.810+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-20T00:51:13.820+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-08-20T00:51:44.248+0000] {processor.py:157} INFO - Started process (PID=77457) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:51:44.250+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T00:51:44.259+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:51:44.258+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:51:44.285+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:51:44.333+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:51:44.333+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T00:51:44.365+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:51:44.364+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-20T00:51:44.378+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-08-20T00:52:14.703+0000] {processor.py:157} INFO - Started process (PID=77467) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:52:14.704+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T00:52:14.707+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:52:14.707+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:52:14.740+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:52:14.769+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:52:14.769+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T00:52:14.796+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:52:14.796+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-20T00:52:14.816+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-08-20T00:52:45.025+0000] {processor.py:157} INFO - Started process (PID=77476) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:52:45.033+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T00:52:45.042+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:52:45.042+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:52:45.063+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:52:45.107+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:52:45.106+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T00:52:45.126+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:52:45.126+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-20T00:52:45.137+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-08-20T00:53:15.318+0000] {processor.py:157} INFO - Started process (PID=77487) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:53:15.320+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T00:53:15.328+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:53:15.327+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:53:15.360+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:53:15.403+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:53:15.403+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T00:53:15.430+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:53:15.430+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-20T00:53:15.442+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-08-20T00:53:45.766+0000] {processor.py:157} INFO - Started process (PID=77497) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:53:45.769+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T00:53:45.776+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:53:45.775+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:53:45.801+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:53:45.843+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:53:45.843+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T00:53:45.859+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:53:45.859+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-20T00:53:45.873+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-08-20T00:54:16.129+0000] {processor.py:157} INFO - Started process (PID=77507) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:54:16.131+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T00:54:16.134+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:54:16.134+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:54:16.155+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:54:16.191+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:54:16.190+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T00:54:16.208+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:54:16.208+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-20T00:54:16.221+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-08-20T00:54:46.510+0000] {processor.py:157} INFO - Started process (PID=77517) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:54:46.514+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T00:54:46.518+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:54:46.517+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:54:46.537+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:54:46.576+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:54:46.576+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T00:54:46.591+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:54:46.591+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-20T00:54:46.602+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-08-20T00:55:16.912+0000] {processor.py:157} INFO - Started process (PID=77527) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:55:16.916+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T00:55:16.919+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:55:16.918+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:55:16.938+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:55:16.986+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:55:16.986+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T00:55:17.004+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:55:17.004+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-20T00:55:17.015+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-08-20T00:55:47.385+0000] {processor.py:157} INFO - Started process (PID=77537) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:55:47.398+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T00:55:47.408+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:55:47.408+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:55:47.432+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:55:47.470+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:55:47.470+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T00:55:47.486+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:55:47.486+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-20T00:55:47.498+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-08-20T00:56:17.738+0000] {processor.py:157} INFO - Started process (PID=77547) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:56:17.742+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T00:56:17.745+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:56:17.744+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:56:17.766+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:56:17.811+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:56:17.811+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T00:56:17.829+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:56:17.829+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-20T00:56:17.839+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-08-20T00:56:48.059+0000] {processor.py:157} INFO - Started process (PID=77557) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:56:48.062+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T00:56:48.069+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:56:48.068+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:56:48.119+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:56:48.187+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:56:48.187+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T00:56:48.206+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:56:48.206+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-20T00:56:48.220+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.168 seconds
[2024-08-20T00:57:18.386+0000] {processor.py:157} INFO - Started process (PID=77567) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:57:18.390+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T00:57:18.393+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:57:18.393+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:57:18.425+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:57:18.461+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:57:18.461+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T00:57:18.478+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:57:18.478+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-20T00:57:18.488+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-08-20T00:57:48.874+0000] {processor.py:157} INFO - Started process (PID=77577) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:57:48.879+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T00:57:48.884+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:57:48.883+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:57:48.911+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:57:48.957+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:57:48.957+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T00:57:48.975+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:57:48.975+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-20T00:57:48.987+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-08-20T00:58:19.207+0000] {processor.py:157} INFO - Started process (PID=77587) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:58:19.209+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T00:58:19.215+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:58:19.214+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:58:19.260+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:58:19.313+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:58:19.313+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T00:58:19.337+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:58:19.337+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-20T00:58:19.352+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.154 seconds
[2024-08-20T00:58:49.535+0000] {processor.py:157} INFO - Started process (PID=77597) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:58:49.539+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T00:58:49.542+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:58:49.541+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:58:49.567+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:58:49.610+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:58:49.610+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T00:58:49.626+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:58:49.626+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-20T00:58:49.638+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-08-20T00:59:20.101+0000] {processor.py:157} INFO - Started process (PID=77606) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:59:20.103+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T00:59:20.109+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:59:20.108+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:59:20.131+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:59:20.170+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:59:20.170+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T00:59:20.196+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:59:20.196+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-20T00:59:20.211+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-08-20T00:59:50.555+0000] {processor.py:157} INFO - Started process (PID=77617) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:59:50.557+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T00:59:50.563+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:59:50.563+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:59:50.583+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T00:59:50.627+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:59:50.627+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T00:59:50.646+0000] {logging_mixin.py:151} INFO - [2024-08-20T00:59:50.646+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-20T00:59:50.657+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-08-20T01:00:20.877+0000] {processor.py:157} INFO - Started process (PID=77626) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:00:20.880+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:00:20.886+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:00:20.885+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:00:20.923+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:00:20.964+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:00:20.964+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:00:20.985+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:00:20.985+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:00:20.996+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-08-20T01:00:51.202+0000] {processor.py:157} INFO - Started process (PID=77637) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:00:51.207+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:00:51.212+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:00:51.212+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:00:51.234+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:00:51.291+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:00:51.291+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:00:51.320+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:00:51.320+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:00:51.331+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-08-20T01:01:21.689+0000] {processor.py:157} INFO - Started process (PID=77647) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:01:21.691+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:01:21.702+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:01:21.701+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:01:21.722+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:01:21.762+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:01:21.762+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:01:21.780+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:01:21.780+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:01:21.789+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-08-20T01:01:52.169+0000] {processor.py:157} INFO - Started process (PID=77655) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:01:52.171+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:01:52.178+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:01:52.178+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:01:52.201+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:01:52.250+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:01:52.249+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:01:52.271+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:01:52.271+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:01:52.286+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-08-20T01:02:22.563+0000] {processor.py:157} INFO - Started process (PID=77666) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:02:22.565+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:02:22.573+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:02:22.572+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:02:22.598+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:02:22.643+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:02:22.643+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:02:22.664+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:02:22.664+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:02:22.676+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-08-20T01:02:52.896+0000] {processor.py:157} INFO - Started process (PID=77677) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:02:52.898+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:02:52.903+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:02:52.902+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:02:52.936+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:02:52.980+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:02:52.980+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:02:53.005+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:02:53.004+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:02:53.017+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-08-20T01:03:23.223+0000] {processor.py:157} INFO - Started process (PID=77687) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:03:23.225+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:03:23.228+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:03:23.228+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:03:23.249+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:03:23.299+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:03:23.299+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:03:23.313+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:03:23.313+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:03:23.324+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-08-20T01:03:53.583+0000] {processor.py:157} INFO - Started process (PID=77697) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:03:53.586+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:03:53.598+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:03:53.598+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:03:53.619+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:03:53.719+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:03:53.718+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:03:53.747+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:03:53.747+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:03:53.759+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.185 seconds
[2024-08-20T01:04:24.177+0000] {processor.py:157} INFO - Started process (PID=77707) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:04:24.179+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:04:24.187+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:04:24.186+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:04:24.224+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:04:24.273+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:04:24.273+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:04:24.304+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:04:24.304+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:04:24.319+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.152 seconds
[2024-08-20T01:04:54.724+0000] {processor.py:157} INFO - Started process (PID=77716) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:04:54.727+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:04:54.733+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:04:54.732+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:04:54.759+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:04:54.810+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:04:54.810+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:04:54.826+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:04:54.826+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:04:54.839+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-08-20T01:05:25.117+0000] {processor.py:157} INFO - Started process (PID=77727) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:05:25.119+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:05:25.128+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:05:25.127+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:05:25.154+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:05:25.184+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:05:25.184+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:05:25.198+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:05:25.198+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:05:25.209+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-08-20T01:05:55.381+0000] {processor.py:157} INFO - Started process (PID=77737) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:05:55.382+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:05:55.384+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:05:55.384+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:05:55.398+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:05:55.414+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:05:55.414+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:05:55.424+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:05:55.424+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:05:55.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-20T01:06:25.774+0000] {processor.py:157} INFO - Started process (PID=77747) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:06:25.775+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:06:25.778+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:06:25.778+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:06:25.794+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:06:25.817+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:06:25.817+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:06:25.829+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:06:25.829+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:06:25.840+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-20T01:06:56.147+0000] {processor.py:157} INFO - Started process (PID=77757) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:06:56.148+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:06:56.150+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:06:56.150+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:06:56.162+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:06:56.181+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:06:56.181+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:06:56.192+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:06:56.192+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:06:56.203+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-20T01:07:26.470+0000] {processor.py:157} INFO - Started process (PID=77767) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:07:26.472+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:07:26.477+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:07:26.477+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:07:26.499+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:07:26.549+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:07:26.549+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:07:26.563+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:07:26.563+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:07:26.573+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-08-20T01:07:56.916+0000] {processor.py:157} INFO - Started process (PID=77777) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:07:56.917+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:07:56.919+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:07:56.919+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:07:56.940+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:07:56.965+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:07:56.965+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:07:56.981+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:07:56.981+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:07:56.992+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-08-20T01:08:27.189+0000] {processor.py:157} INFO - Started process (PID=77787) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:08:27.190+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:08:27.192+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:08:27.192+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:08:27.209+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:08:27.229+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:08:27.229+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:08:27.247+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:08:27.247+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:08:27.261+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-20T01:08:57.556+0000] {processor.py:157} INFO - Started process (PID=77797) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:08:57.558+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:08:57.562+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:08:57.562+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:08:57.583+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:08:57.615+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:08:57.615+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:08:57.638+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:08:57.638+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:08:57.650+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-08-20T01:09:27.874+0000] {processor.py:157} INFO - Started process (PID=77807) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:09:27.877+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:09:27.880+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:09:27.880+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:09:27.896+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:09:27.922+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:09:27.922+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:09:27.934+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:09:27.934+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:09:27.945+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-08-20T01:09:58.259+0000] {processor.py:157} INFO - Started process (PID=77817) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:09:58.261+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:09:58.263+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:09:58.263+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:09:58.278+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:09:58.324+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:09:58.324+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:09:58.340+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:09:58.340+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:09:58.352+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-08-20T01:10:28.661+0000] {processor.py:157} INFO - Started process (PID=77827) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:10:28.664+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:10:28.677+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:10:28.677+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:10:28.710+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:10:28.784+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:10:28.784+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:10:28.807+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:10:28.807+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:10:28.832+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.178 seconds
[2024-08-20T01:10:58.995+0000] {processor.py:157} INFO - Started process (PID=77837) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:10:58.999+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:10:59.014+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:10:59.013+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:10:59.042+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:10:59.088+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:10:59.088+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:10:59.111+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:10:59.111+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:10:59.121+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-08-20T01:11:29.531+0000] {processor.py:157} INFO - Started process (PID=77847) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:11:29.535+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:11:29.538+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:11:29.538+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:11:29.554+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:11:29.588+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:11:29.587+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:11:29.609+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:11:29.609+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:11:29.620+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-08-20T01:11:59.906+0000] {processor.py:157} INFO - Started process (PID=77857) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:11:59.907+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:11:59.912+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:11:59.911+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:11:59.929+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:11:59.955+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:11:59.955+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:11:59.969+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:11:59.969+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:11:59.980+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-08-20T01:12:30.220+0000] {processor.py:157} INFO - Started process (PID=77866) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:12:30.226+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:12:30.234+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:12:30.233+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:12:30.256+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:12:30.307+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:12:30.307+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:12:30.331+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:12:30.331+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:12:30.343+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.153 seconds
[2024-08-20T01:13:00.736+0000] {processor.py:157} INFO - Started process (PID=77877) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:13:00.740+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:13:00.748+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:13:00.748+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:13:00.771+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:13:00.816+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:13:00.816+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:13:00.836+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:13:00.836+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:13:00.847+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-08-20T01:13:31.085+0000] {processor.py:157} INFO - Started process (PID=77886) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:13:31.088+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:13:31.103+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:13:31.102+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:13:31.125+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:13:31.170+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:13:31.170+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:13:31.184+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:13:31.184+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:13:31.195+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-08-20T01:14:01.426+0000] {processor.py:157} INFO - Started process (PID=77897) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:14:01.428+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:14:01.432+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:14:01.431+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:14:01.452+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:14:01.497+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:14:01.497+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:14:01.511+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:14:01.511+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:14:01.522+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-08-20T01:14:31.775+0000] {processor.py:157} INFO - Started process (PID=77907) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:14:31.777+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:14:31.782+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:14:31.782+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:14:31.807+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:14:31.845+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:14:31.845+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:14:31.862+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:14:31.862+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:14:31.876+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-08-20T01:15:02.089+0000] {processor.py:157} INFO - Started process (PID=77917) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:15:02.092+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:15:02.095+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:15:02.095+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:15:02.127+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:15:02.160+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:15:02.160+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:15:02.175+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:15:02.175+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:15:02.184+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-08-20T01:15:32.661+0000] {processor.py:157} INFO - Started process (PID=77926) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:15:32.664+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:15:32.669+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:15:32.668+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:15:32.699+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:15:32.778+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:15:32.778+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:15:32.813+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:15:32.813+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:15:32.840+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.186 seconds
[2024-08-20T01:16:02.988+0000] {processor.py:157} INFO - Started process (PID=77937) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:16:02.993+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:16:02.995+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:16:02.995+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:16:03.015+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:16:03.057+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:16:03.056+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:16:03.071+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:16:03.071+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:16:03.081+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-08-20T01:16:33.433+0000] {processor.py:157} INFO - Started process (PID=77947) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:16:33.437+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:16:33.441+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:16:33.441+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:16:33.475+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:16:33.502+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:16:33.502+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:16:33.519+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:16:33.519+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:16:33.533+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-08-20T01:17:03.904+0000] {processor.py:157} INFO - Started process (PID=77956) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:17:03.908+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:17:03.923+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:17:03.916+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:17:03.953+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:17:03.996+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:17:03.996+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:17:04.011+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:17:04.011+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:17:04.021+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-08-20T01:17:34.255+0000] {processor.py:157} INFO - Started process (PID=77967) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:17:34.260+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:17:34.266+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:17:34.266+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:17:34.288+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:17:34.320+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:17:34.320+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:17:34.335+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:17:34.335+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:17:34.343+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-08-20T01:18:04.592+0000] {processor.py:157} INFO - Started process (PID=77976) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:18:04.597+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:18:04.610+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:18:04.609+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:18:04.647+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:18:04.692+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:18:04.692+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:18:04.725+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:18:04.724+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:18:04.737+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.162 seconds
[2024-08-20T01:18:35.131+0000] {processor.py:157} INFO - Started process (PID=77987) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:18:35.133+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:18:35.136+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:18:35.135+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:18:35.166+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:18:35.199+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:18:35.199+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:18:35.214+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:18:35.214+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:18:35.225+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-08-20T01:19:05.444+0000] {processor.py:157} INFO - Started process (PID=77997) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:19:05.446+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:19:05.448+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:19:05.448+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:19:05.462+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:19:05.479+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:19:05.479+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:19:05.492+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:19:05.492+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:19:05.503+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-20T01:19:35.793+0000] {processor.py:157} INFO - Started process (PID=78006) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:19:35.797+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:19:35.800+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:19:35.799+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:19:35.821+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:19:35.860+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:19:35.860+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:19:35.874+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:19:35.874+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:19:35.884+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-08-20T01:20:06.125+0000] {processor.py:157} INFO - Started process (PID=78016) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:20:06.127+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:20:06.131+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:20:06.130+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:20:06.152+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:20:06.196+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:20:06.196+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:20:06.211+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:20:06.211+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:20:06.222+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-08-20T01:20:36.501+0000] {processor.py:157} INFO - Started process (PID=78027) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:20:36.503+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:20:36.507+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:20:36.507+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:20:36.552+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:20:36.597+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:20:36.597+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:20:36.615+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:20:36.615+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:20:36.626+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-08-20T01:21:06.866+0000] {processor.py:157} INFO - Started process (PID=78036) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:21:06.869+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:21:06.873+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:21:06.873+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:21:06.895+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:21:06.933+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:21:06.933+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:21:06.950+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:21:06.950+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:21:06.960+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-08-20T01:21:37.204+0000] {processor.py:157} INFO - Started process (PID=78047) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:21:37.208+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:21:37.212+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:21:37.212+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:21:37.230+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:21:37.250+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:21:37.250+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:21:37.263+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:21:37.263+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:21:37.274+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-20T01:22:07.573+0000] {processor.py:157} INFO - Started process (PID=78057) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:22:07.579+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:22:07.583+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:22:07.582+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:22:07.603+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:22:07.651+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:22:07.651+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:22:07.665+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:22:07.665+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:22:07.675+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-08-20T01:22:37.868+0000] {processor.py:157} INFO - Started process (PID=78067) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:22:37.871+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:22:37.875+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:22:37.875+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:22:37.890+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:22:37.915+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:22:37.915+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:22:37.930+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:22:37.929+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:22:37.940+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-08-20T01:23:08.225+0000] {processor.py:157} INFO - Started process (PID=78077) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:23:08.232+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:23:08.249+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:23:08.248+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:23:08.271+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:23:08.298+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:23:08.298+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:23:08.313+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:23:08.313+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:23:08.323+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-08-20T01:23:38.538+0000] {processor.py:157} INFO - Started process (PID=78087) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:23:38.540+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:23:38.543+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:23:38.543+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:23:38.553+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:23:38.572+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:23:38.572+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:23:38.581+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:23:38.581+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:23:38.590+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-20T01:24:08.887+0000] {processor.py:157} INFO - Started process (PID=78097) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:24:08.889+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:24:08.893+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:24:08.893+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:24:08.911+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:24:08.935+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:24:08.935+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:24:08.947+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:24:08.947+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:24:08.957+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-20T01:24:39.261+0000] {processor.py:157} INFO - Started process (PID=78107) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:24:39.262+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:24:39.264+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:24:39.264+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:24:39.278+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:24:39.293+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:24:39.293+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:24:39.305+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:24:39.305+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:24:39.315+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-20T01:25:09.693+0000] {processor.py:157} INFO - Started process (PID=78117) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:25:09.695+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:25:09.715+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:25:09.713+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:25:09.737+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:25:09.775+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:25:09.775+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:25:09.791+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:25:09.790+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:25:09.803+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-08-20T01:25:40.095+0000] {processor.py:157} INFO - Started process (PID=78127) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:25:40.098+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:25:40.105+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:25:40.104+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:25:40.134+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:25:40.177+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:25:40.177+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:25:40.267+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:25:40.266+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:25:40.292+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.207 seconds
[2024-08-20T01:26:10.527+0000] {processor.py:157} INFO - Started process (PID=78137) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:26:10.529+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:26:10.533+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:26:10.533+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:26:10.555+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:26:10.608+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:26:10.608+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:26:10.626+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:26:10.625+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:26:10.636+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-08-20T01:26:40.870+0000] {processor.py:157} INFO - Started process (PID=78147) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:26:40.871+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:26:40.874+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:26:40.874+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:26:40.895+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:26:40.937+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:26:40.937+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:26:40.952+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:26:40.952+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:26:40.962+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-08-20T01:27:11.219+0000] {processor.py:157} INFO - Started process (PID=78157) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:27:11.223+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:27:11.225+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:27:11.225+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:27:11.245+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:27:11.282+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:27:11.281+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:27:11.295+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:27:11.294+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:27:11.304+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-08-20T01:27:41.609+0000] {processor.py:157} INFO - Started process (PID=78167) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:27:41.612+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:27:41.617+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:27:41.617+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:27:41.639+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:27:41.681+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:27:41.681+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:27:41.694+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:27:41.694+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:27:41.705+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-08-20T01:28:11.951+0000] {processor.py:157} INFO - Started process (PID=78177) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:28:11.954+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:28:11.958+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:28:11.958+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:28:11.996+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:28:12.033+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:28:12.033+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:28:12.054+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:28:12.054+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:28:12.067+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-08-20T01:28:42.284+0000] {processor.py:157} INFO - Started process (PID=78187) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:28:42.286+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:28:42.293+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:28:42.292+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:28:42.325+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:28:42.384+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:28:42.384+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:28:42.407+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:28:42.407+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:28:42.420+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.145 seconds
[2024-08-20T01:29:12.704+0000] {processor.py:157} INFO - Started process (PID=78197) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:29:12.709+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:29:12.715+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:29:12.714+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:29:12.780+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:29:12.859+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:29:12.859+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:29:12.883+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:29:12.883+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:29:12.900+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.203 seconds
[2024-08-20T01:29:43.058+0000] {processor.py:157} INFO - Started process (PID=78207) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:29:43.064+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:29:43.068+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:29:43.068+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:29:43.093+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:29:43.155+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:29:43.155+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:29:43.170+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:29:43.170+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:29:43.179+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-08-20T01:30:13.487+0000] {processor.py:157} INFO - Started process (PID=78217) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:30:13.488+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:30:13.493+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:30:13.492+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:30:13.517+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:30:13.561+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:30:13.561+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:30:13.575+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:30:13.574+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:30:13.585+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-08-20T01:30:43.924+0000] {processor.py:157} INFO - Started process (PID=78227) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:30:43.931+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:30:43.937+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:30:43.936+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:30:43.962+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:30:44.012+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:30:44.012+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:30:44.028+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:30:44.028+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:30:44.041+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-08-20T01:31:14.318+0000] {processor.py:157} INFO - Started process (PID=78237) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:31:14.321+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:31:14.325+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:31:14.324+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:31:14.348+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:31:14.392+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:31:14.392+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:31:14.406+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:31:14.406+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:31:14.417+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-08-20T01:31:44.765+0000] {processor.py:157} INFO - Started process (PID=78247) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:31:44.770+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:31:44.774+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:31:44.774+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:31:44.804+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:31:44.855+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:31:44.855+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:31:44.881+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:31:44.881+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:31:44.895+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.155 seconds
[2024-08-20T01:32:15.141+0000] {processor.py:157} INFO - Started process (PID=78257) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:32:15.149+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:32:15.156+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:32:15.155+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:32:15.189+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:32:15.244+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:32:15.243+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:32:15.261+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:32:15.261+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:32:15.273+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-08-20T01:32:45.513+0000] {processor.py:157} INFO - Started process (PID=78267) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:32:45.519+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:32:45.527+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:32:45.526+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:32:45.549+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:32:45.598+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:32:45.598+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:32:45.613+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:32:45.613+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:32:45.625+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-08-20T01:33:15.900+0000] {processor.py:157} INFO - Started process (PID=78277) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:33:15.903+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:33:15.920+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:33:15.917+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:33:15.951+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:33:16.006+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:33:16.006+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:33:16.021+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:33:16.020+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:33:16.034+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.143 seconds
[2024-08-20T01:33:46.262+0000] {processor.py:157} INFO - Started process (PID=78287) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:33:46.264+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:33:46.273+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:33:46.272+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:33:46.318+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:33:46.369+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:33:46.369+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:33:46.390+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:33:46.389+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:33:46.402+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.148 seconds
[2024-08-20T01:34:16.879+0000] {processor.py:157} INFO - Started process (PID=78296) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:34:16.881+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:34:16.888+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:34:16.887+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:34:16.909+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:34:16.959+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:34:16.958+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:34:16.973+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:34:16.973+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:34:16.985+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-08-20T01:34:47.399+0000] {processor.py:157} INFO - Started process (PID=78307) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:34:47.410+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:34:47.418+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:34:47.418+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:34:47.450+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:34:47.523+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:34:47.523+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:34:47.550+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:34:47.549+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:34:47.563+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.190 seconds
[2024-08-20T01:35:17.770+0000] {processor.py:157} INFO - Started process (PID=78317) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:35:17.778+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:35:17.783+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:35:17.782+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:35:17.810+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:35:17.865+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:35:17.865+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:35:17.884+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:35:17.884+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:35:17.899+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-08-20T01:35:48.189+0000] {processor.py:157} INFO - Started process (PID=78327) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:35:48.192+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:35:48.198+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:35:48.198+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:35:48.247+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:35:48.307+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:35:48.307+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:35:48.326+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:35:48.326+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:35:48.339+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.157 seconds
[2024-08-20T01:36:18.525+0000] {processor.py:157} INFO - Started process (PID=78337) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:36:18.528+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:36:18.531+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:36:18.530+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:36:18.550+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:36:18.599+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:36:18.599+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:36:18.613+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:36:18.613+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:36:18.627+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-08-20T01:36:48.924+0000] {processor.py:157} INFO - Started process (PID=78347) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:36:48.926+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:36:48.953+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:36:48.953+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:36:48.971+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:36:49.002+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:36:49.002+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:36:49.020+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:36:49.020+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:36:49.030+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-08-20T01:37:19.406+0000] {processor.py:157} INFO - Started process (PID=78357) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:37:19.408+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:37:19.415+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:37:19.414+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:37:19.441+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:37:19.489+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:37:19.489+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:37:19.509+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:37:19.509+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:37:19.518+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-08-20T01:37:49.950+0000] {processor.py:157} INFO - Started process (PID=78367) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:37:49.953+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:37:49.957+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:37:49.957+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:37:49.979+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:37:50.023+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:37:50.022+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:37:50.039+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:37:50.039+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:37:50.050+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-08-20T01:38:20.292+0000] {processor.py:157} INFO - Started process (PID=78377) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:38:20.296+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:38:20.300+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:38:20.299+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:38:20.332+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:38:20.367+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:38:20.367+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:38:20.383+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:38:20.383+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:38:20.395+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-08-20T01:38:50.687+0000] {processor.py:157} INFO - Started process (PID=78387) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:38:50.689+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:38:50.692+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:38:50.691+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:38:50.712+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:38:50.738+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:38:50.738+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:38:50.752+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:38:50.752+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:38:50.763+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-08-20T01:39:21.015+0000] {processor.py:157} INFO - Started process (PID=78396) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:39:21.018+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:39:21.022+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:39:21.021+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:39:21.044+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:39:21.087+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:39:21.087+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:39:21.101+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:39:21.101+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:39:21.111+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-08-20T01:39:51.363+0000] {processor.py:157} INFO - Started process (PID=78406) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:39:51.365+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:39:51.370+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:39:51.369+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:39:51.390+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:39:51.433+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:39:51.433+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:39:51.449+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:39:51.449+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:39:51.457+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-08-20T01:40:21.752+0000] {processor.py:157} INFO - Started process (PID=78417) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:40:21.754+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:40:21.766+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:40:21.765+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:40:21.794+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:40:21.833+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:40:21.832+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:40:21.864+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:40:21.864+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:40:21.876+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.153 seconds
[2024-08-20T01:40:52.208+0000] {processor.py:157} INFO - Started process (PID=78427) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:40:52.210+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:40:52.214+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:40:52.213+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:40:52.234+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:40:52.279+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:40:52.279+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:40:52.294+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:40:52.294+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:40:52.305+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-08-20T01:41:22.617+0000] {processor.py:157} INFO - Started process (PID=78437) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:41:22.620+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:41:22.625+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:41:22.624+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:41:22.658+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:41:22.738+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:41:22.738+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:41:22.766+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:41:22.766+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:41:22.780+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.171 seconds
[2024-08-20T01:41:52.984+0000] {processor.py:157} INFO - Started process (PID=78447) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:41:52.986+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:41:52.989+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:41:52.989+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:41:53.009+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:41:53.051+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:41:53.051+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:41:53.068+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:41:53.068+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:41:53.078+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-08-20T01:42:23.426+0000] {processor.py:157} INFO - Started process (PID=78457) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:42:23.431+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:42:23.434+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:42:23.434+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:42:23.457+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:42:23.526+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:42:23.526+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:42:23.541+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:42:23.541+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:42:23.552+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.137 seconds
[2024-08-20T01:42:53.737+0000] {processor.py:157} INFO - Started process (PID=78467) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:42:53.748+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:42:53.776+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:42:53.775+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:42:53.808+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:42:53.871+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:42:53.871+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:42:53.910+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:42:53.910+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:42:53.928+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.201 seconds
[2024-08-20T01:43:24.157+0000] {processor.py:157} INFO - Started process (PID=78477) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:43:24.159+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:43:24.164+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:43:24.163+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:43:24.189+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:43:24.237+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:43:24.237+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:43:24.254+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:43:24.254+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:43:24.265+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-08-20T01:43:54.582+0000] {processor.py:157} INFO - Started process (PID=78487) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:43:54.583+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:43:54.587+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:43:54.587+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:43:54.625+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:43:54.657+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:43:54.657+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:43:54.684+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:43:54.684+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:43:54.694+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-08-20T01:44:24.955+0000] {processor.py:157} INFO - Started process (PID=78496) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:44:24.961+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:44:24.966+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:44:24.965+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:44:24.989+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:44:25.032+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:44:25.032+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:44:25.049+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:44:25.049+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:44:25.076+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-08-20T01:44:55.389+0000] {processor.py:157} INFO - Started process (PID=78506) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:44:55.394+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:44:55.397+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:44:55.397+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:44:55.423+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:44:55.469+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:44:55.469+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:44:55.485+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:44:55.485+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:44:55.495+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-08-20T01:45:25.944+0000] {processor.py:157} INFO - Started process (PID=78517) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:45:25.948+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:45:25.955+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:45:25.955+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:45:25.987+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:45:26.023+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:45:26.023+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:45:26.038+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:45:26.038+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:45:26.060+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-08-20T01:45:56.334+0000] {processor.py:157} INFO - Started process (PID=78527) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:45:56.340+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:45:56.348+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:45:56.347+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:45:56.390+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:45:56.466+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:45:56.466+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:45:56.486+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:45:56.486+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:45:56.506+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.179 seconds
[2024-08-20T01:46:26.846+0000] {processor.py:157} INFO - Started process (PID=78537) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:46:26.849+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:46:26.859+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:46:26.858+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:46:26.901+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:46:26.958+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:46:26.958+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:46:26.991+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:46:26.990+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:46:27.004+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.173 seconds
[2024-08-20T01:46:57.218+0000] {processor.py:157} INFO - Started process (PID=78546) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:46:57.226+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:46:57.234+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:46:57.233+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:46:57.259+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:46:57.328+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:46:57.327+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:46:57.350+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:46:57.350+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:46:57.360+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.149 seconds
[2024-08-20T01:47:27.540+0000] {processor.py:157} INFO - Started process (PID=78557) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:47:27.541+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:47:27.555+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:47:27.555+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:47:27.574+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:47:27.601+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:47:27.601+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:47:27.615+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:47:27.615+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:47:27.627+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-08-20T01:47:57.958+0000] {processor.py:157} INFO - Started process (PID=78567) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:47:57.960+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:47:57.967+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:47:57.967+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:47:57.990+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:47:58.025+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:47:58.025+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:47:58.041+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:47:58.041+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:47:58.051+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-08-20T01:48:28.301+0000] {processor.py:157} INFO - Started process (PID=78576) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:48:28.302+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:48:28.308+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:48:28.307+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:48:28.328+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:48:28.369+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:48:28.369+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:48:28.382+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:48:28.382+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:48:28.393+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-08-20T01:48:58.726+0000] {processor.py:157} INFO - Started process (PID=78587) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:48:58.732+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:48:58.735+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:48:58.735+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:48:58.754+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:48:58.785+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:48:58.785+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:48:58.801+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:48:58.801+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:48:58.821+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-08-20T01:49:29.131+0000] {processor.py:157} INFO - Started process (PID=78597) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:49:29.132+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:49:29.139+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:49:29.138+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:49:29.155+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:49:29.182+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:49:29.182+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:49:29.197+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:49:29.197+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:49:29.207+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-08-20T01:49:59.370+0000] {processor.py:157} INFO - Started process (PID=78607) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:49:59.372+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:49:59.374+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:49:59.374+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:49:59.385+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:49:59.410+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:49:59.409+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:49:59.423+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:49:59.423+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:49:59.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-20T01:50:29.719+0000] {processor.py:157} INFO - Started process (PID=78616) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:50:29.720+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:50:29.723+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:50:29.723+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:50:29.741+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:50:29.772+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:50:29.772+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:50:29.787+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:50:29.787+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:50:29.797+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-08-20T01:51:00.045+0000] {processor.py:157} INFO - Started process (PID=78627) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:51:00.046+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:51:00.050+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:51:00.050+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:51:00.071+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:51:00.097+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:51:00.097+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:51:00.110+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:51:00.110+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:51:00.121+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-08-20T01:51:30.383+0000] {processor.py:157} INFO - Started process (PID=78637) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:51:30.385+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:51:30.387+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:51:30.386+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:51:30.397+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:51:30.415+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:51:30.415+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:51:30.425+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:51:30.425+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:51:30.434+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-20T01:52:00.710+0000] {processor.py:157} INFO - Started process (PID=78647) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:52:00.712+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:52:00.715+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:52:00.715+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:52:00.731+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:52:00.750+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:52:00.750+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:52:00.760+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:52:00.760+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:52:00.769+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-20T01:52:31.101+0000] {processor.py:157} INFO - Started process (PID=78657) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:52:31.102+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:52:31.108+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:52:31.107+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:52:31.138+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:52:31.167+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:52:31.167+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:52:31.182+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:52:31.182+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:52:31.192+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-08-20T01:53:01.525+0000] {processor.py:157} INFO - Started process (PID=78667) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:53:01.527+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:53:01.528+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:53:01.528+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:53:01.539+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:53:01.557+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:53:01.557+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:53:01.567+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:53:01.567+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:53:01.575+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-20T01:53:31.912+0000] {processor.py:157} INFO - Started process (PID=78677) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:53:31.916+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:53:31.919+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:53:31.919+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:53:31.938+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:53:31.970+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:53:31.970+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:53:31.983+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:53:31.983+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:53:31.996+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-20T01:54:02.392+0000] {processor.py:157} INFO - Started process (PID=78687) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:54:02.394+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:54:02.396+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:54:02.396+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:54:02.415+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:54:02.440+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:54:02.440+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:54:02.453+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:54:02.453+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:54:02.464+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-08-20T01:54:32.735+0000] {processor.py:157} INFO - Started process (PID=78697) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:54:32.736+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:54:32.737+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:54:32.737+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:54:32.764+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:54:32.792+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:54:32.792+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:54:32.807+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:54:32.807+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:54:32.827+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-08-20T01:55:03.037+0000] {processor.py:157} INFO - Started process (PID=78707) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:55:03.040+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:55:03.043+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:55:03.043+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:55:03.060+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:55:03.079+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:55:03.079+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:55:03.088+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:55:03.088+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:55:03.097+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-20T01:55:33.461+0000] {processor.py:157} INFO - Started process (PID=78717) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:55:33.468+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:55:33.472+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:55:33.471+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:55:33.485+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:55:33.504+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:55:33.504+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:55:33.515+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:55:33.515+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:55:33.525+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-20T01:56:03.793+0000] {processor.py:157} INFO - Started process (PID=78727) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:56:03.794+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:56:03.798+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:56:03.798+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:56:03.814+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:56:03.833+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:56:03.833+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:56:03.845+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:56:03.845+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:56:03.853+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-20T01:56:34.207+0000] {processor.py:157} INFO - Started process (PID=78737) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:56:34.208+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:56:34.212+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:56:34.212+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:56:34.231+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:56:34.282+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:56:34.282+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:56:34.307+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:56:34.307+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:56:34.319+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-08-20T01:57:04.572+0000] {processor.py:157} INFO - Started process (PID=78747) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:57:04.574+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:57:04.579+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:57:04.579+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:57:04.598+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:57:04.628+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:57:04.628+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:57:04.648+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:57:04.648+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:57:04.657+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-08-20T01:57:34.913+0000] {processor.py:157} INFO - Started process (PID=78755) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:57:34.923+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:57:34.949+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:57:34.948+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:57:35.044+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:57:35.121+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:57:35.121+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:57:35.180+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:57:35.180+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:57:35.206+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.316 seconds
[2024-08-20T01:58:05.476+0000] {processor.py:157} INFO - Started process (PID=78767) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:58:05.479+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:58:05.483+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:58:05.482+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:58:05.508+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:58:05.532+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:58:05.532+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:58:05.546+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:58:05.546+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:58:05.557+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-08-20T01:58:35.890+0000] {processor.py:157} INFO - Started process (PID=78775) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:58:35.892+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:58:35.896+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:58:35.896+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:58:35.911+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:58:35.943+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:58:35.943+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:58:35.959+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:58:35.958+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:58:35.971+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-08-20T01:59:06.222+0000] {processor.py:157} INFO - Started process (PID=78786) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:59:06.223+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:59:06.229+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:59:06.229+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:59:06.273+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:59:06.304+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:59:06.304+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:59:06.317+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:59:06.317+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:59:06.328+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-08-20T01:59:36.531+0000] {processor.py:157} INFO - Started process (PID=78797) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:59:36.536+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T01:59:36.539+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:59:36.539+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:59:36.555+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T01:59:36.577+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:59:36.576+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T01:59:36.589+0000] {logging_mixin.py:151} INFO - [2024-08-20T01:59:36.589+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T01:59:36.597+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-20T02:00:06.891+0000] {processor.py:157} INFO - Started process (PID=78807) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:00:06.894+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:00:06.903+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:00:06.901+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:00:06.922+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:00:06.950+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:00:06.950+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:00:06.966+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:00:06.966+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:00:06.976+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-08-20T02:00:37.170+0000] {processor.py:157} INFO - Started process (PID=78817) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:00:37.172+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:00:37.173+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:00:37.173+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:00:37.185+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:00:37.205+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:00:37.205+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:00:37.219+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:00:37.219+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:00:37.230+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-20T02:01:07.609+0000] {processor.py:157} INFO - Started process (PID=78827) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:01:07.613+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:01:07.616+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:01:07.615+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:01:07.633+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:01:07.666+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:01:07.666+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:01:07.681+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:01:07.681+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:01:07.692+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-20T02:01:37.940+0000] {processor.py:157} INFO - Started process (PID=78837) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:01:37.941+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:01:37.944+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:01:37.943+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:01:37.955+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:01:37.983+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:01:37.982+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:01:37.997+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:01:37.997+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:01:38.006+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-20T02:02:08.338+0000] {processor.py:157} INFO - Started process (PID=78847) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:02:08.339+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:02:08.342+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:02:08.341+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:02:08.381+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:02:08.420+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:02:08.420+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:02:08.436+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:02:08.436+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:02:08.445+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-08-20T02:02:38.886+0000] {processor.py:157} INFO - Started process (PID=78857) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:02:38.905+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:02:38.916+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:02:38.913+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:02:38.942+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:02:38.988+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:02:38.987+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:02:39.003+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:02:39.003+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:02:39.013+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-08-20T02:03:09.161+0000] {processor.py:157} INFO - Started process (PID=78867) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:03:09.163+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:03:09.168+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:03:09.167+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:03:09.189+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:03:09.219+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:03:09.219+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:03:09.233+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:03:09.232+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:03:09.242+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-08-20T02:03:39.522+0000] {processor.py:157} INFO - Started process (PID=78877) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:03:39.523+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:03:39.525+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:03:39.525+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:03:39.543+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:03:39.562+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:03:39.562+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:03:39.576+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:03:39.576+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:03:39.591+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-20T02:04:09.834+0000] {processor.py:157} INFO - Started process (PID=78887) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:04:09.835+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:04:09.837+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:04:09.836+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:04:09.850+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:04:09.872+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:04:09.872+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:04:09.885+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:04:09.885+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:04:09.896+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-20T02:04:40.179+0000] {processor.py:157} INFO - Started process (PID=78897) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:04:40.180+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:04:40.200+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:04:40.196+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:04:40.225+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:04:40.260+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:04:40.259+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:04:40.287+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:04:40.287+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:04:40.297+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-08-20T02:05:10.496+0000] {processor.py:157} INFO - Started process (PID=78907) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:05:10.498+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:05:10.501+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:05:10.501+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:05:10.520+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:05:10.541+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:05:10.541+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:05:10.551+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:05:10.551+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:05:10.561+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-20T02:05:40.802+0000] {processor.py:157} INFO - Started process (PID=78917) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:05:40.805+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:05:40.809+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:05:40.808+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:05:40.819+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:05:40.838+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:05:40.838+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:05:40.851+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:05:40.851+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:05:40.861+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-20T02:06:11.089+0000] {processor.py:157} INFO - Started process (PID=78927) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:06:11.090+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:06:11.092+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:06:11.092+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:06:11.103+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:06:11.119+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:06:11.119+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:06:11.131+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:06:11.131+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:06:11.141+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-20T02:06:41.446+0000] {processor.py:157} INFO - Started process (PID=78937) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:06:41.449+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:06:41.452+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:06:41.452+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:06:41.466+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:06:41.481+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:06:41.481+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:06:41.491+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:06:41.491+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:06:41.500+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-20T02:07:11.770+0000] {processor.py:157} INFO - Started process (PID=78946) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:07:11.775+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:07:11.778+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:07:11.778+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:07:11.802+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:07:11.826+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:07:11.826+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:07:11.844+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:07:11.844+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:07:11.851+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-08-20T02:07:42.143+0000] {processor.py:157} INFO - Started process (PID=78957) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:07:42.145+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:07:42.148+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:07:42.148+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:07:42.158+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:07:42.177+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:07:42.177+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:07:42.190+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:07:42.190+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:07:42.199+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-20T02:08:12.497+0000] {processor.py:157} INFO - Started process (PID=78967) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:08:12.498+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:08:12.501+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:08:12.501+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:08:12.516+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:08:12.532+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:08:12.531+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:08:12.544+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:08:12.544+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:08:12.554+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-20T02:08:42.798+0000] {processor.py:157} INFO - Started process (PID=78977) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:08:42.800+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:08:42.803+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:08:42.802+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:08:42.816+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:08:42.839+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:08:42.839+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:08:42.851+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:08:42.851+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:08:42.861+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-20T02:09:13.054+0000] {processor.py:157} INFO - Started process (PID=78987) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:09:13.056+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:09:13.058+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:09:13.058+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:09:13.070+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:09:13.088+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:09:13.088+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:09:13.099+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:09:13.099+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:09:13.110+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-20T02:09:43.365+0000] {processor.py:157} INFO - Started process (PID=78997) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:09:43.368+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:09:43.370+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:09:43.370+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:09:43.380+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:09:43.398+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:09:43.398+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:09:43.410+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:09:43.410+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:09:43.419+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-20T02:10:13.746+0000] {processor.py:157} INFO - Started process (PID=79007) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:10:13.747+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:10:13.749+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:10:13.749+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:10:13.765+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:10:13.781+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:10:13.781+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:10:13.791+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:10:13.790+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:10:13.799+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-20T02:10:44.113+0000] {processor.py:157} INFO - Started process (PID=79017) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:10:44.115+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:10:44.118+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:10:44.118+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:10:44.136+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:10:44.158+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:10:44.158+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:10:44.170+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:10:44.170+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:10:44.180+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-20T02:11:14.481+0000] {processor.py:157} INFO - Started process (PID=79027) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:11:14.483+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:11:14.485+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:11:14.485+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:11:14.501+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:11:14.515+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:11:14.515+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:11:14.529+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:11:14.529+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:11:14.539+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-20T02:11:44.871+0000] {processor.py:157} INFO - Started process (PID=79037) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:11:44.873+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:11:44.877+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:11:44.876+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:11:44.893+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:11:44.915+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:11:44.914+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:11:44.927+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:11:44.927+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:11:44.937+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-20T02:12:15.187+0000] {processor.py:157} INFO - Started process (PID=79047) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:12:15.188+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:12:15.190+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:12:15.190+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:12:15.202+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:12:15.221+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:12:15.220+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:12:15.232+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:12:15.232+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:12:15.240+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-20T02:12:45.520+0000] {processor.py:157} INFO - Started process (PID=79057) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:12:45.521+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:12:45.523+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:12:45.523+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:12:45.535+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:12:45.551+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:12:45.551+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:12:45.561+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:12:45.561+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:12:45.571+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-20T02:13:15.972+0000] {processor.py:157} INFO - Started process (PID=79067) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:13:15.973+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:13:15.975+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:13:15.975+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:13:15.991+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:13:16.016+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:13:16.016+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:13:16.032+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:13:16.032+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:13:16.042+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-20T02:13:46.283+0000] {processor.py:157} INFO - Started process (PID=79077) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:13:46.286+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:13:46.288+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:13:46.288+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:13:46.300+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:13:46.314+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:13:46.314+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:13:46.323+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:13:46.323+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:13:46.332+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-20T02:14:16.574+0000] {processor.py:157} INFO - Started process (PID=79087) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:14:16.575+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:14:16.576+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:14:16.576+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:14:16.586+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:14:16.603+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:14:16.603+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:14:16.613+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:14:16.612+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:14:16.620+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-20T02:14:46.951+0000] {processor.py:157} INFO - Started process (PID=79097) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:14:46.953+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:14:46.955+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:14:46.955+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:14:46.966+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:14:46.985+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:14:46.985+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:14:46.998+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:14:46.998+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:14:47.009+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-20T02:15:17.372+0000] {processor.py:157} INFO - Started process (PID=79107) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:15:17.373+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:15:17.377+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:15:17.376+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:15:17.395+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:15:17.415+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:15:17.415+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:15:17.428+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:15:17.428+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:15:17.440+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-20T02:15:47.668+0000] {processor.py:157} INFO - Started process (PID=79117) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:15:47.669+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:15:47.672+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:15:47.672+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:15:47.688+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:15:47.705+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:15:47.705+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:15:47.719+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:15:47.719+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:15:47.734+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-20T02:16:18.038+0000] {processor.py:157} INFO - Started process (PID=79127) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:16:18.040+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:16:18.044+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:16:18.044+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:16:18.059+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:16:18.080+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:16:18.080+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:16:18.093+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:16:18.093+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:16:18.103+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-20T02:16:48.494+0000] {processor.py:157} INFO - Started process (PID=79137) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:16:48.496+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:16:48.499+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:16:48.499+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:16:48.511+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:16:48.529+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:16:48.529+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:16:48.540+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:16:48.540+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:16:48.548+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-20T02:17:18.843+0000] {processor.py:157} INFO - Started process (PID=79147) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:17:18.847+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:17:18.851+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:17:18.851+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:17:18.869+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:17:18.892+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:17:18.892+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:17:18.908+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:17:18.908+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:17:18.916+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-08-20T02:17:49.214+0000] {processor.py:157} INFO - Started process (PID=79157) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:17:49.215+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:17:49.217+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:17:49.217+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:17:49.228+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:17:49.247+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:17:49.247+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:17:49.260+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:17:49.260+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:17:49.271+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-20T02:18:19.685+0000] {processor.py:157} INFO - Started process (PID=79167) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:18:19.697+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:18:19.703+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:18:19.702+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:18:19.729+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:18:19.801+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:18:19.801+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:18:19.820+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:18:19.820+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:18:19.832+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.160 seconds
[2024-08-20T02:18:50.036+0000] {processor.py:157} INFO - Started process (PID=79177) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:18:50.038+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:18:50.041+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:18:50.040+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:18:50.060+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:18:50.088+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:18:50.088+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:18:50.103+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:18:50.103+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:18:50.118+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-20T02:19:20.328+0000] {processor.py:157} INFO - Started process (PID=79187) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:19:20.329+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:19:20.331+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:19:20.330+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:19:20.345+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:19:20.362+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:19:20.362+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:19:20.374+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:19:20.374+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:19:20.381+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-20T02:19:50.667+0000] {processor.py:157} INFO - Started process (PID=79197) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:19:50.670+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:19:50.672+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:19:50.672+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:19:50.691+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:19:50.710+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:19:50.710+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:19:50.723+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:19:50.723+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:19:50.733+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-20T02:20:21.056+0000] {processor.py:157} INFO - Started process (PID=79207) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:20:21.058+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:20:21.060+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:20:21.060+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:20:21.071+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:20:21.087+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:20:21.087+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:20:21.098+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:20:21.098+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:20:21.107+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-20T02:20:51.440+0000] {processor.py:157} INFO - Started process (PID=79217) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:20:51.442+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:20:51.444+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:20:51.444+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:20:51.460+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:20:51.483+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:20:51.483+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:20:51.497+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:20:51.497+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:20:51.507+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-20T02:21:21.774+0000] {processor.py:157} INFO - Started process (PID=79227) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:21:21.776+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:21:21.777+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:21:21.777+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:21:21.794+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:21:21.811+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:21:21.811+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:21:21.825+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:21:21.825+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:21:21.837+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-20T02:21:52.207+0000] {processor.py:157} INFO - Started process (PID=79237) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:21:52.209+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:21:52.213+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:21:52.212+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:21:52.242+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:21:52.282+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:21:52.282+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:21:52.297+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:21:52.297+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:21:52.309+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-08-20T02:22:22.517+0000] {processor.py:157} INFO - Started process (PID=79247) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:22:22.518+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:22:22.521+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:22:22.521+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:22:22.539+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:22:22.562+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:22:22.561+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:22:22.573+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:22:22.573+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:22:22.582+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-20T02:22:52.885+0000] {processor.py:157} INFO - Started process (PID=79257) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:22:52.885+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:22:52.888+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:22:52.887+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:22:52.897+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:22:52.916+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:22:52.916+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:22:52.929+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:22:52.929+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:22:52.938+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-20T02:23:23.268+0000] {processor.py:157} INFO - Started process (PID=79267) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:23:23.269+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:23:23.273+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:23:23.273+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:23:23.289+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:23:23.323+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:23:23.323+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:23:23.337+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:23:23.337+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:23:23.345+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-08-20T02:23:53.646+0000] {processor.py:157} INFO - Started process (PID=79277) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:23:53.646+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:23:53.649+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:23:53.649+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:23:53.661+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:23:53.681+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:23:53.681+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:23:53.695+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:23:53.695+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:23:53.705+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-20T02:24:23.972+0000] {processor.py:157} INFO - Started process (PID=79287) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:24:23.973+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:24:23.975+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:24:23.975+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:24:23.986+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:24:24.002+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:24:24.002+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:24:24.012+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:24:24.012+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:24:24.021+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-20T02:24:54.363+0000] {processor.py:157} INFO - Started process (PID=79297) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:24:54.365+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:24:54.369+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:24:54.369+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:24:54.384+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:24:54.406+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:24:54.406+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:24:54.416+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:24:54.416+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:24:54.425+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-20T02:25:24.689+0000] {processor.py:157} INFO - Started process (PID=79307) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:25:24.690+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:25:24.692+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:25:24.692+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:25:24.703+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:25:24.723+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:25:24.723+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:25:24.737+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:25:24.737+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:25:24.746+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-20T02:25:55.038+0000] {processor.py:157} INFO - Started process (PID=79317) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:25:55.040+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:25:55.042+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:25:55.042+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:25:55.052+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:25:55.069+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:25:55.068+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:25:55.078+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:25:55.078+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:25:55.085+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-20T02:26:25.424+0000] {processor.py:157} INFO - Started process (PID=79327) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:26:25.426+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:26:25.429+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:26:25.429+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:26:25.447+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:26:25.470+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:26:25.470+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:26:25.484+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:26:25.484+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:26:25.494+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-20T02:26:55.747+0000] {processor.py:157} INFO - Started process (PID=79337) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:26:55.749+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:26:55.751+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:26:55.751+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:26:55.762+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:26:55.779+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:26:55.779+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:26:55.788+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:26:55.788+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:26:55.797+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-20T02:27:26.111+0000] {processor.py:157} INFO - Started process (PID=79346) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:27:26.125+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:27:26.135+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:27:26.134+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:27:26.152+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:27:26.180+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:27:26.179+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:27:26.193+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:27:26.193+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:27:26.205+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-08-20T02:27:56.422+0000] {processor.py:157} INFO - Started process (PID=79357) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:27:56.423+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:27:56.425+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:27:56.425+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:27:56.440+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:27:56.455+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:27:56.455+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:27:56.466+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:27:56.466+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:27:56.475+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-20T02:28:26.793+0000] {processor.py:157} INFO - Started process (PID=79366) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:28:26.800+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:28:26.807+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:28:26.806+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:28:26.832+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:28:26.874+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:28:26.874+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:28:26.889+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:28:26.889+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:28:26.900+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-08-20T02:28:57.042+0000] {processor.py:157} INFO - Started process (PID=79377) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:28:57.047+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:28:57.050+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:28:57.050+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:28:57.058+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:28:57.071+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:28:57.071+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:28:57.080+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:28:57.080+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:28:57.088+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-08-20T02:29:27.394+0000] {processor.py:157} INFO - Started process (PID=79387) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:29:27.396+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:29:27.399+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:29:27.399+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:29:27.418+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:29:27.449+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:29:27.449+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:29:27.469+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:29:27.469+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:29:27.481+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-08-20T02:29:57.800+0000] {processor.py:157} INFO - Started process (PID=79397) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:29:57.802+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:29:57.805+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:29:57.805+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:29:57.828+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:29:57.846+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:29:57.846+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:29:57.858+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:29:57.857+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:29:57.868+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-20T02:30:28.172+0000] {processor.py:157} INFO - Started process (PID=79406) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:30:28.174+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:30:28.178+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:30:28.177+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:30:28.210+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:30:28.276+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:30:28.276+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:30:28.295+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:30:28.294+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:30:28.310+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.143 seconds
[2024-08-20T02:30:58.635+0000] {processor.py:157} INFO - Started process (PID=79417) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:30:58.636+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:30:58.639+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:30:58.639+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:30:58.656+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:30:58.681+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:30:58.681+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:30:58.694+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:30:58.694+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:30:58.705+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-08-20T02:31:28.940+0000] {processor.py:157} INFO - Started process (PID=79427) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:31:28.941+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:31:28.943+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:31:28.943+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:31:28.957+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:31:28.975+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:31:28.975+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:31:28.988+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:31:28.988+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:31:28.995+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-20T02:31:59.198+0000] {processor.py:157} INFO - Started process (PID=79437) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:31:59.199+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:31:59.202+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:31:59.201+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:31:59.213+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:31:59.231+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:31:59.231+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:31:59.243+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:31:59.243+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:31:59.251+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-20T02:32:29.630+0000] {processor.py:157} INFO - Started process (PID=79447) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:32:29.631+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:32:29.635+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:32:29.635+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:32:29.654+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:32:29.705+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:32:29.705+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:32:29.718+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:32:29.718+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:32:29.728+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-08-20T02:33:00.001+0000] {processor.py:157} INFO - Started process (PID=79457) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:33:00.002+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:33:00.005+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:33:00.005+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:33:00.017+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:33:00.035+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:33:00.035+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:33:00.045+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:33:00.045+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:33:00.055+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-20T02:33:30.287+0000] {processor.py:157} INFO - Started process (PID=79467) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:33:30.295+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:33:30.301+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:33:30.300+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:33:30.328+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:33:30.374+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:33:30.374+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:33:30.392+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:33:30.392+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:33:30.412+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-08-20T02:34:00.647+0000] {processor.py:157} INFO - Started process (PID=79477) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:34:00.653+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:34:00.658+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:34:00.657+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:34:00.677+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:34:00.706+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:34:00.706+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:34:00.728+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:34:00.728+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:34:00.736+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-08-20T02:34:31.068+0000] {processor.py:157} INFO - Started process (PID=79487) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:34:31.071+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:34:31.075+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:34:31.074+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:34:31.093+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:34:31.123+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:34:31.123+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:34:31.140+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:34:31.139+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:34:31.152+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-08-20T02:35:01.358+0000] {processor.py:157} INFO - Started process (PID=79497) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:35:01.361+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:35:01.363+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:35:01.363+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:35:01.374+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:35:01.391+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:35:01.391+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:35:01.403+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:35:01.403+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:35:01.411+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-20T02:35:31.759+0000] {processor.py:157} INFO - Started process (PID=79507) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:35:31.763+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:35:31.767+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:35:31.767+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:35:31.784+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:35:31.820+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:35:31.820+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:35:31.838+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:35:31.838+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:35:31.849+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-08-20T02:36:02.119+0000] {processor.py:157} INFO - Started process (PID=79517) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:36:02.123+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:36:02.137+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:36:02.136+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:36:02.153+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:36:02.171+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:36:02.171+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:36:02.182+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:36:02.182+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:36:02.191+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-08-20T02:36:32.526+0000] {processor.py:157} INFO - Started process (PID=79527) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:36:32.527+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:36:32.530+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:36:32.530+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:36:32.547+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:36:32.577+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:36:32.577+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:36:32.593+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:36:32.593+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:36:32.603+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-08-20T02:37:02.914+0000] {processor.py:157} INFO - Started process (PID=79537) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:37:02.915+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:37:02.916+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:37:02.916+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:37:02.930+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:37:02.946+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:37:02.946+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:37:02.956+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:37:02.956+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:37:02.966+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-20T02:37:33.303+0000] {processor.py:157} INFO - Started process (PID=79547) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:37:33.305+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:37:33.309+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:37:33.309+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:37:33.345+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:37:33.393+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:37:33.393+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:37:33.407+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:37:33.407+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:37:33.419+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-08-20T02:38:03.592+0000] {processor.py:157} INFO - Started process (PID=79556) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:38:03.596+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:38:03.599+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:38:03.599+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:38:03.628+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:38:03.669+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:38:03.669+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:38:03.686+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:38:03.686+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:38:03.697+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-08-20T02:38:34.010+0000] {processor.py:157} INFO - Started process (PID=79567) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:38:34.011+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:38:34.014+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:38:34.014+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:38:34.026+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:38:34.043+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:38:34.043+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:38:34.056+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:38:34.056+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:38:34.065+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-20T02:39:04.356+0000] {processor.py:157} INFO - Started process (PID=79577) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:39:04.360+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:39:04.362+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:39:04.362+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:39:04.379+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:39:04.402+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:39:04.402+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:39:04.415+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:39:04.415+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:39:04.426+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-20T02:39:34.730+0000] {processor.py:157} INFO - Started process (PID=79587) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:39:34.737+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:39:34.740+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:39:34.740+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:39:34.749+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:39:34.762+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:39:34.762+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:39:34.771+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:39:34.771+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:39:34.780+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-20T02:40:05.076+0000] {processor.py:157} INFO - Started process (PID=79597) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:40:05.078+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:40:05.079+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:40:05.079+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:40:05.093+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:40:05.108+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:40:05.108+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:40:05.119+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:40:05.119+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:40:05.127+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-20T02:40:35.456+0000] {processor.py:157} INFO - Started process (PID=79607) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:40:35.459+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:40:35.469+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:40:35.466+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:40:35.499+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:40:35.552+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:40:35.552+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:40:35.575+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:40:35.575+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:40:35.587+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.148 seconds
[2024-08-20T02:41:05.777+0000] {processor.py:157} INFO - Started process (PID=79617) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:41:05.780+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:41:05.784+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:41:05.783+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:41:05.817+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:41:05.848+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:41:05.848+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:41:05.867+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:41:05.867+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:41:05.884+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-08-20T02:41:36.203+0000] {processor.py:157} INFO - Started process (PID=79627) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:41:36.203+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:41:36.206+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:41:36.206+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:41:36.225+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:41:36.247+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:41:36.247+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:41:36.260+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:41:36.260+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:41:36.271+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-20T02:42:06.603+0000] {processor.py:157} INFO - Started process (PID=79637) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:42:06.607+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:42:06.610+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:42:06.610+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:42:06.626+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:42:06.661+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:42:06.661+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:42:06.674+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:42:06.674+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:42:06.685+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-08-20T02:42:36.997+0000] {processor.py:157} INFO - Started process (PID=79647) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:42:36.998+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:42:37.001+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:42:37.001+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:42:37.012+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:42:37.030+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:42:37.030+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:42:37.041+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:42:37.041+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:42:37.052+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-20T02:43:07.363+0000] {processor.py:157} INFO - Started process (PID=79657) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:43:07.364+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:43:07.367+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:43:07.367+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:43:07.384+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:43:07.405+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:43:07.405+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:43:07.419+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:43:07.419+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:43:07.428+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-20T02:43:37.659+0000] {processor.py:157} INFO - Started process (PID=79667) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:43:37.660+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:43:37.663+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:43:37.663+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:43:37.673+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:43:37.692+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:43:37.692+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:43:37.705+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:43:37.704+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:43:37.712+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-20T02:44:08.094+0000] {processor.py:157} INFO - Started process (PID=79677) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:44:08.100+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:44:08.120+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:44:08.120+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:44:08.143+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:44:08.169+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:44:08.169+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:44:08.181+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:44:08.181+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:44:08.192+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-08-20T02:44:38.412+0000] {processor.py:157} INFO - Started process (PID=79687) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:44:38.414+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:44:38.416+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:44:38.416+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:44:38.428+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:44:38.445+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:44:38.445+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:44:38.457+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:44:38.457+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:44:38.468+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-20T02:45:08.700+0000] {processor.py:157} INFO - Started process (PID=79697) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:45:08.702+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:45:08.705+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:45:08.704+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:45:08.724+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:45:08.741+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:45:08.740+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:45:08.755+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:45:08.755+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:45:08.766+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-20T02:45:39.134+0000] {processor.py:157} INFO - Started process (PID=79707) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:45:39.139+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:45:39.163+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:45:39.162+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:45:39.187+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:45:39.228+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:45:39.228+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:45:39.252+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:45:39.252+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:45:39.264+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.142 seconds
[2024-08-20T02:46:09.453+0000] {processor.py:157} INFO - Started process (PID=79717) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:46:09.455+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:46:09.458+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:46:09.457+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:46:09.474+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:46:09.495+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:46:09.495+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:46:09.506+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:46:09.505+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:46:09.514+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-20T02:46:39.732+0000] {processor.py:157} INFO - Started process (PID=79727) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:46:39.733+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:46:39.735+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:46:39.734+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:46:39.743+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:46:39.774+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:46:39.773+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:46:39.793+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:46:39.792+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:46:39.805+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-20T02:47:10.052+0000] {processor.py:157} INFO - Started process (PID=79737) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:47:10.056+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:47:10.058+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:47:10.058+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:47:10.081+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:47:10.124+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:47:10.124+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:47:10.140+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:47:10.139+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:47:10.151+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-08-20T02:47:40.442+0000] {processor.py:157} INFO - Started process (PID=79747) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:47:40.444+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:47:40.446+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:47:40.446+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:47:40.457+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:47:40.477+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:47:40.477+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:47:40.489+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:47:40.489+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:47:40.501+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-20T02:48:10.834+0000] {processor.py:157} INFO - Started process (PID=79757) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:48:10.837+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:48:10.840+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:48:10.840+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:48:10.866+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:48:10.896+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:48:10.896+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:48:10.918+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:48:10.918+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:48:10.929+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-08-20T02:48:41.141+0000] {processor.py:157} INFO - Started process (PID=79767) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:48:41.142+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:48:41.146+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:48:41.146+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:48:41.165+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:48:41.189+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:48:41.189+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:48:41.203+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:48:41.203+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:48:41.215+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-08-20T02:49:11.500+0000] {processor.py:157} INFO - Started process (PID=79777) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:49:11.503+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:49:11.507+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:49:11.507+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:49:11.526+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:49:11.550+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:49:11.550+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:49:11.563+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:49:11.563+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:49:11.573+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-08-20T02:49:41.791+0000] {processor.py:157} INFO - Started process (PID=79787) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:49:41.794+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:49:41.797+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:49:41.797+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:49:41.820+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:49:41.842+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:49:41.842+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:49:41.852+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:49:41.852+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:49:41.859+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-20T02:50:12.165+0000] {processor.py:157} INFO - Started process (PID=79797) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:50:12.166+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:50:12.168+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:50:12.168+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:50:12.184+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:50:12.201+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:50:12.201+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:50:12.213+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:50:12.213+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:50:12.222+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-20T02:50:42.549+0000] {processor.py:157} INFO - Started process (PID=79807) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:50:42.550+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:50:42.553+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:50:42.553+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:50:42.566+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:50:42.586+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:50:42.586+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:50:42.597+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:50:42.597+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:50:42.606+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-20T02:51:12.948+0000] {processor.py:157} INFO - Started process (PID=79816) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:51:12.950+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:51:12.956+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:51:12.956+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:51:12.988+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:51:13.050+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:51:13.050+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:51:13.065+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:51:13.065+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:51:13.086+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.149 seconds
[2024-08-20T02:51:43.264+0000] {processor.py:157} INFO - Started process (PID=79827) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:51:43.267+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:51:43.271+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:51:43.270+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:51:43.288+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:51:43.311+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:51:43.311+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:51:43.322+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:51:43.322+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:51:43.331+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-20T02:52:13.567+0000] {processor.py:157} INFO - Started process (PID=79837) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:52:13.568+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:52:13.572+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:52:13.572+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:52:13.595+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:52:13.616+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:52:13.616+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:52:13.646+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:52:13.646+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:52:13.656+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-08-20T02:52:43.810+0000] {processor.py:157} INFO - Started process (PID=79847) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:52:43.814+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:52:43.818+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:52:43.818+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:52:43.839+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:52:43.868+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:52:43.867+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:52:43.883+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:52:43.883+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:52:43.893+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-08-20T02:53:14.079+0000] {processor.py:157} INFO - Started process (PID=79857) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:53:14.081+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:53:14.085+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:53:14.085+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:53:14.101+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:53:14.123+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:53:14.122+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:53:14.133+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:53:14.133+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:53:14.142+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-08-20T02:53:44.475+0000] {processor.py:157} INFO - Started process (PID=79867) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:53:44.478+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:53:44.482+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:53:44.482+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:53:44.505+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:53:44.537+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:53:44.537+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:53:44.561+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:53:44.561+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:53:44.573+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-08-20T02:54:14.779+0000] {processor.py:157} INFO - Started process (PID=79877) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:54:14.781+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:54:14.784+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:54:14.783+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:54:14.799+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:54:14.823+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:54:14.823+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:54:14.836+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:54:14.836+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:54:14.846+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-20T02:54:45.063+0000] {processor.py:157} INFO - Started process (PID=79887) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:54:45.065+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:54:45.067+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:54:45.067+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:54:45.078+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:54:45.094+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:54:45.094+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:54:45.104+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:54:45.104+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:54:45.114+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-20T02:55:15.450+0000] {processor.py:157} INFO - Started process (PID=79896) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:55:15.455+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:55:15.459+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:55:15.459+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:55:15.495+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:55:15.525+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:55:15.525+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:55:15.538+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:55:15.538+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:55:15.548+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-08-20T02:55:45.871+0000] {processor.py:157} INFO - Started process (PID=79907) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:55:45.878+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:55:45.883+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:55:45.883+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:55:45.901+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:55:45.944+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:55:45.944+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:55:45.959+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:55:45.959+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:55:45.969+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-08-20T02:56:16.278+0000] {processor.py:157} INFO - Started process (PID=79915) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:56:16.280+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:56:16.285+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:56:16.285+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:56:16.306+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:56:16.341+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:56:16.341+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:56:16.360+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:56:16.360+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:56:16.375+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-08-20T02:56:46.585+0000] {processor.py:157} INFO - Started process (PID=79927) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:56:46.587+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:56:46.590+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:56:46.589+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:56:46.609+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:56:46.640+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:56:46.640+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:56:46.667+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:56:46.667+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:56:46.683+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-08-20T02:57:16.892+0000] {processor.py:157} INFO - Started process (PID=79937) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:57:16.893+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:57:16.895+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:57:16.894+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:57:16.904+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:57:16.923+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:57:16.923+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:57:16.940+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:57:16.940+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:57:16.950+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-20T02:57:47.296+0000] {processor.py:157} INFO - Started process (PID=79946) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:57:47.304+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:57:47.322+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:57:47.321+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:57:47.344+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:57:47.376+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:57:47.375+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:57:47.407+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:57:47.407+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:57:47.417+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-08-20T02:58:17.769+0000] {processor.py:157} INFO - Started process (PID=79956) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:58:17.772+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:58:17.776+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:58:17.776+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:58:17.796+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:58:17.837+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:58:17.837+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:58:17.853+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:58:17.853+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:58:17.862+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-08-20T02:58:48.033+0000] {processor.py:157} INFO - Started process (PID=79967) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:58:48.034+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:58:48.036+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:58:48.036+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:58:48.049+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:58:48.066+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:58:48.066+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:58:48.079+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:58:48.079+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:58:48.088+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-20T02:59:18.398+0000] {processor.py:157} INFO - Started process (PID=79977) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:59:18.399+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:59:18.406+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:59:18.403+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:59:18.445+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:59:18.477+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:59:18.477+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:59:18.491+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:59:18.491+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:59:18.501+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-08-20T02:59:48.717+0000] {processor.py:157} INFO - Started process (PID=79987) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:59:48.720+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T02:59:48.723+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:59:48.723+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:59:48.741+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T02:59:48.766+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:59:48.766+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T02:59:48.778+0000] {logging_mixin.py:151} INFO - [2024-08-20T02:59:48.778+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T02:59:48.789+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-08-20T03:00:19.135+0000] {processor.py:157} INFO - Started process (PID=79997) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T03:00:19.137+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T03:00:19.142+0000] {logging_mixin.py:151} INFO - [2024-08-20T03:00:19.142+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T03:00:19.168+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T03:00:19.234+0000] {logging_mixin.py:151} INFO - [2024-08-20T03:00:19.234+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T03:00:19.253+0000] {logging_mixin.py:151} INFO - [2024-08-20T03:00:19.253+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T03:00:19.265+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-08-20T03:00:49.471+0000] {processor.py:157} INFO - Started process (PID=80007) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T03:00:49.472+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T03:00:49.476+0000] {logging_mixin.py:151} INFO - [2024-08-20T03:00:49.475+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T03:00:49.499+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T03:00:49.521+0000] {logging_mixin.py:151} INFO - [2024-08-20T03:00:49.521+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T03:00:49.537+0000] {logging_mixin.py:151} INFO - [2024-08-20T03:00:49.537+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T03:00:49.548+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-08-20T03:01:19.896+0000] {processor.py:157} INFO - Started process (PID=80017) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T03:01:19.901+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T03:01:19.905+0000] {logging_mixin.py:151} INFO - [2024-08-20T03:01:19.905+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T03:01:19.928+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T03:01:19.947+0000] {logging_mixin.py:151} INFO - [2024-08-20T03:01:19.947+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T03:01:19.963+0000] {logging_mixin.py:151} INFO - [2024-08-20T03:01:19.963+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T03:01:19.980+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-20T03:01:50.273+0000] {processor.py:157} INFO - Started process (PID=80027) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T03:01:50.276+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T03:01:50.279+0000] {logging_mixin.py:151} INFO - [2024-08-20T03:01:50.279+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T03:01:50.290+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T03:01:50.308+0000] {logging_mixin.py:151} INFO - [2024-08-20T03:01:50.308+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T03:01:50.320+0000] {logging_mixin.py:151} INFO - [2024-08-20T03:01:50.320+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T03:01:50.331+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-20T03:02:20.668+0000] {processor.py:157} INFO - Started process (PID=80037) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T03:02:20.670+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T03:02:20.696+0000] {logging_mixin.py:151} INFO - [2024-08-20T03:02:20.695+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T03:02:20.724+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T03:02:20.777+0000] {logging_mixin.py:151} INFO - [2024-08-20T03:02:20.776+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T03:02:20.798+0000] {logging_mixin.py:151} INFO - [2024-08-20T03:02:20.798+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T03:02:20.814+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.155 seconds
[2024-08-20T03:02:51.012+0000] {processor.py:157} INFO - Started process (PID=80047) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T03:02:51.013+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T03:02:51.017+0000] {logging_mixin.py:151} INFO - [2024-08-20T03:02:51.017+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T03:02:51.036+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T03:02:51.059+0000] {logging_mixin.py:151} INFO - [2024-08-20T03:02:51.059+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T03:02:51.071+0000] {logging_mixin.py:151} INFO - [2024-08-20T03:02:51.071+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T03:02:51.085+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-08-20T03:03:21.417+0000] {processor.py:157} INFO - Started process (PID=80057) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T03:03:21.422+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T03:03:21.437+0000] {logging_mixin.py:151} INFO - [2024-08-20T03:03:21.436+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T03:03:21.462+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T03:03:21.497+0000] {logging_mixin.py:151} INFO - [2024-08-20T03:03:21.497+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T03:03:21.523+0000] {logging_mixin.py:151} INFO - [2024-08-20T03:03:21.522+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T03:03:21.536+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-08-20T03:03:51.761+0000] {processor.py:157} INFO - Started process (PID=80067) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T03:03:51.765+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T03:03:51.769+0000] {logging_mixin.py:151} INFO - [2024-08-20T03:03:51.769+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T03:03:51.792+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T03:03:51.815+0000] {logging_mixin.py:151} INFO - [2024-08-20T03:03:51.815+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T03:03:51.829+0000] {logging_mixin.py:151} INFO - [2024-08-20T03:03:51.829+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T03:03:51.838+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-08-20T03:04:22.133+0000] {processor.py:157} INFO - Started process (PID=80077) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T03:04:22.138+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T03:04:22.141+0000] {logging_mixin.py:151} INFO - [2024-08-20T03:04:22.141+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T03:04:22.158+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T03:04:22.184+0000] {logging_mixin.py:151} INFO - [2024-08-20T03:04:22.184+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T03:04:22.197+0000] {logging_mixin.py:151} INFO - [2024-08-20T03:04:22.197+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T03:04:22.208+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-08-20T03:04:52.405+0000] {processor.py:157} INFO - Started process (PID=80087) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T03:04:52.407+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T03:04:52.409+0000] {logging_mixin.py:151} INFO - [2024-08-20T03:04:52.409+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T03:04:52.419+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T03:04:52.438+0000] {logging_mixin.py:151} INFO - [2024-08-20T03:04:52.438+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T03:04:52.449+0000] {logging_mixin.py:151} INFO - [2024-08-20T03:04:52.449+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T03:04:52.457+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-20T03:05:22.648+0000] {processor.py:157} INFO - Started process (PID=80097) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T03:05:22.653+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T03:05:22.658+0000] {logging_mixin.py:151} INFO - [2024-08-20T03:05:22.658+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T03:05:22.683+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T03:05:22.716+0000] {logging_mixin.py:151} INFO - [2024-08-20T03:05:22.716+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T03:05:22.737+0000] {logging_mixin.py:151} INFO - [2024-08-20T03:05:22.737+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T03:05:22.748+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-08-20T03:21:53.158+0000] {processor.py:157} INFO - Started process (PID=80108) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T03:21:53.162+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T03:21:53.167+0000] {logging_mixin.py:151} INFO - [2024-08-20T03:21:53.167+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T03:21:53.201+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T03:21:53.257+0000] {logging_mixin.py:151} INFO - [2024-08-20T03:21:53.257+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T03:21:53.304+0000] {logging_mixin.py:151} INFO - [2024-08-20T03:21:53.304+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T03:21:53.321+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.181 seconds
[2024-08-20T03:38:35.455+0000] {processor.py:157} INFO - Started process (PID=80119) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T03:38:35.461+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T03:38:35.465+0000] {logging_mixin.py:151} INFO - [2024-08-20T03:38:35.464+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T03:38:35.488+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T03:38:35.525+0000] {logging_mixin.py:151} INFO - [2024-08-20T03:38:35.525+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T03:38:35.540+0000] {logging_mixin.py:151} INFO - [2024-08-20T03:38:35.540+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T03:38:35.550+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-08-20T03:39:05.748+0000] {processor.py:157} INFO - Started process (PID=80129) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T03:39:05.751+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T03:39:05.758+0000] {logging_mixin.py:151} INFO - [2024-08-20T03:39:05.756+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T03:39:05.780+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T03:39:05.820+0000] {logging_mixin.py:151} INFO - [2024-08-20T03:39:05.820+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T03:39:05.837+0000] {logging_mixin.py:151} INFO - [2024-08-20T03:39:05.837+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T03:39:05.845+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-08-20T03:55:34.009+0000] {processor.py:157} INFO - Started process (PID=80141) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T03:55:34.012+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T03:55:34.024+0000] {logging_mixin.py:151} INFO - [2024-08-20T03:55:34.023+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T03:55:34.089+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T03:55:34.178+0000] {logging_mixin.py:151} INFO - [2024-08-20T03:55:34.178+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T03:55:34.215+0000] {logging_mixin.py:151} INFO - [2024-08-20T03:55:34.215+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T03:55:34.248+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.253 seconds
[2024-08-20T03:56:04.557+0000] {processor.py:157} INFO - Started process (PID=80151) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T03:56:04.560+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T03:56:04.563+0000] {logging_mixin.py:151} INFO - [2024-08-20T03:56:04.563+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T03:56:04.591+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T03:56:04.630+0000] {logging_mixin.py:151} INFO - [2024-08-20T03:56:04.629+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T03:56:04.643+0000] {logging_mixin.py:151} INFO - [2024-08-20T03:56:04.643+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T03:56:04.655+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-08-20T04:12:39.728+0000] {processor.py:157} INFO - Started process (PID=80161) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T04:12:39.732+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T04:12:39.736+0000] {logging_mixin.py:151} INFO - [2024-08-20T04:12:39.736+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T04:12:39.755+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T04:12:39.787+0000] {logging_mixin.py:151} INFO - [2024-08-20T04:12:39.787+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T04:12:39.818+0000] {logging_mixin.py:151} INFO - [2024-08-20T04:12:39.817+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T04:12:39.832+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-08-20T04:28:35.010+0000] {processor.py:157} INFO - Started process (PID=80171) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T04:28:35.014+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T04:28:35.020+0000] {logging_mixin.py:151} INFO - [2024-08-20T04:28:35.020+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T04:28:35.040+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T04:28:35.077+0000] {logging_mixin.py:151} INFO - [2024-08-20T04:28:35.077+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T04:28:35.094+0000] {logging_mixin.py:151} INFO - [2024-08-20T04:28:35.094+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T04:28:35.104+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-08-20T04:29:05.436+0000] {processor.py:157} INFO - Started process (PID=80180) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T04:29:05.441+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T04:29:05.460+0000] {logging_mixin.py:151} INFO - [2024-08-20T04:29:05.459+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T04:29:05.480+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T04:29:05.515+0000] {logging_mixin.py:151} INFO - [2024-08-20T04:29:05.515+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T04:29:05.540+0000] {logging_mixin.py:151} INFO - [2024-08-20T04:29:05.540+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T04:29:05.551+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-08-20T04:45:26.628+0000] {processor.py:157} INFO - Started process (PID=80192) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T04:45:26.632+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T04:45:26.635+0000] {logging_mixin.py:151} INFO - [2024-08-20T04:45:26.635+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T04:45:26.681+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T04:45:26.763+0000] {logging_mixin.py:151} INFO - [2024-08-20T04:45:26.762+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T04:45:26.818+0000] {logging_mixin.py:151} INFO - [2024-08-20T04:45:26.817+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T04:45:26.847+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.222 seconds
[2024-08-20T04:45:57.160+0000] {processor.py:157} INFO - Started process (PID=80202) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T04:45:57.171+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T04:45:57.181+0000] {logging_mixin.py:151} INFO - [2024-08-20T04:45:57.180+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T04:45:57.201+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T04:45:57.229+0000] {logging_mixin.py:151} INFO - [2024-08-20T04:45:57.229+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T04:45:57.242+0000] {logging_mixin.py:151} INFO - [2024-08-20T04:45:57.242+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T04:45:57.251+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-08-20T04:46:27.499+0000] {processor.py:157} INFO - Started process (PID=80213) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T04:46:27.500+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T04:46:27.502+0000] {logging_mixin.py:151} INFO - [2024-08-20T04:46:27.502+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T04:46:27.522+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T04:46:27.544+0000] {logging_mixin.py:151} INFO - [2024-08-20T04:46:27.544+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T04:46:27.561+0000] {logging_mixin.py:151} INFO - [2024-08-20T04:46:27.561+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T04:46:27.570+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-08-20T04:46:57.867+0000] {processor.py:157} INFO - Started process (PID=80223) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T04:46:57.869+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T04:46:57.872+0000] {logging_mixin.py:151} INFO - [2024-08-20T04:46:57.872+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T04:46:57.887+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T04:46:57.907+0000] {logging_mixin.py:151} INFO - [2024-08-20T04:46:57.907+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T04:46:57.918+0000] {logging_mixin.py:151} INFO - [2024-08-20T04:46:57.918+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T04:46:57.929+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-20T05:03:16.312+0000] {processor.py:157} INFO - Started process (PID=80234) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T05:03:16.316+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T05:03:16.319+0000] {logging_mixin.py:151} INFO - [2024-08-20T05:03:16.318+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T05:03:16.351+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T05:03:16.375+0000] {logging_mixin.py:151} INFO - [2024-08-20T05:03:16.375+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T05:03:16.395+0000] {logging_mixin.py:151} INFO - [2024-08-20T05:03:16.395+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T05:03:16.409+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-08-20T05:03:46.601+0000] {processor.py:157} INFO - Started process (PID=80245) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T05:03:46.605+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T05:03:46.608+0000] {logging_mixin.py:151} INFO - [2024-08-20T05:03:46.608+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T05:03:46.627+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T05:03:46.664+0000] {logging_mixin.py:151} INFO - [2024-08-20T05:03:46.664+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T05:03:46.679+0000] {logging_mixin.py:151} INFO - [2024-08-20T05:03:46.679+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T05:03:46.690+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-08-20T05:04:16.942+0000] {processor.py:157} INFO - Started process (PID=80255) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T05:04:16.944+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T05:04:16.946+0000] {logging_mixin.py:151} INFO - [2024-08-20T05:04:16.946+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T05:04:16.955+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T05:04:16.972+0000] {logging_mixin.py:151} INFO - [2024-08-20T05:04:16.972+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T05:04:16.982+0000] {logging_mixin.py:151} INFO - [2024-08-20T05:04:16.982+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T05:04:16.995+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-20T05:04:47.334+0000] {processor.py:157} INFO - Started process (PID=80265) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T05:04:47.338+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T05:04:47.341+0000] {logging_mixin.py:151} INFO - [2024-08-20T05:04:47.341+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T05:04:47.356+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T05:04:47.374+0000] {logging_mixin.py:151} INFO - [2024-08-20T05:04:47.374+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T05:04:47.385+0000] {logging_mixin.py:151} INFO - [2024-08-20T05:04:47.385+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T05:04:47.395+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-20T05:05:17.728+0000] {processor.py:157} INFO - Started process (PID=80275) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T05:05:17.730+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T05:05:17.733+0000] {logging_mixin.py:151} INFO - [2024-08-20T05:05:17.733+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T05:05:17.751+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T05:05:17.778+0000] {logging_mixin.py:151} INFO - [2024-08-20T05:05:17.778+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T05:05:17.790+0000] {logging_mixin.py:151} INFO - [2024-08-20T05:05:17.790+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T05:05:17.801+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-08-20T05:21:23.004+0000] {processor.py:157} INFO - Started process (PID=80286) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T05:21:23.005+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T05:21:23.007+0000] {logging_mixin.py:151} INFO - [2024-08-20T05:21:23.007+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T05:21:23.023+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T05:21:23.054+0000] {logging_mixin.py:151} INFO - [2024-08-20T05:21:23.054+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T05:21:23.067+0000] {logging_mixin.py:151} INFO - [2024-08-20T05:21:23.067+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T05:21:23.077+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-08-20T05:21:53.373+0000] {processor.py:157} INFO - Started process (PID=80297) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T05:21:53.375+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T05:21:53.377+0000] {logging_mixin.py:151} INFO - [2024-08-20T05:21:53.377+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T05:21:53.395+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T05:21:53.420+0000] {logging_mixin.py:151} INFO - [2024-08-20T05:21:53.419+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T05:21:53.436+0000] {logging_mixin.py:151} INFO - [2024-08-20T05:21:53.436+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T05:21:53.447+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-08-20T05:22:23.779+0000] {processor.py:157} INFO - Started process (PID=80307) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T05:22:23.780+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T05:22:23.781+0000] {logging_mixin.py:151} INFO - [2024-08-20T05:22:23.781+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T05:22:23.791+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T05:22:23.806+0000] {logging_mixin.py:151} INFO - [2024-08-20T05:22:23.806+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T05:22:23.817+0000] {logging_mixin.py:151} INFO - [2024-08-20T05:22:23.816+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T05:22:23.825+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-20T05:22:54.124+0000] {processor.py:157} INFO - Started process (PID=80316) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T05:22:54.125+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T05:22:54.130+0000] {logging_mixin.py:151} INFO - [2024-08-20T05:22:54.130+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T05:22:54.172+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T05:22:54.197+0000] {logging_mixin.py:151} INFO - [2024-08-20T05:22:54.197+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T05:22:54.210+0000] {logging_mixin.py:151} INFO - [2024-08-20T05:22:54.210+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T05:22:54.219+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-08-20T05:23:24.387+0000] {processor.py:157} INFO - Started process (PID=80327) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T05:23:24.387+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T05:23:24.389+0000] {logging_mixin.py:151} INFO - [2024-08-20T05:23:24.389+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T05:23:24.404+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T05:23:24.418+0000] {logging_mixin.py:151} INFO - [2024-08-20T05:23:24.418+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T05:23:24.428+0000] {logging_mixin.py:151} INFO - [2024-08-20T05:23:24.428+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T05:23:24.438+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-20T05:39:01.356+0000] {processor.py:157} INFO - Started process (PID=80338) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T05:39:01.360+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T05:39:01.363+0000] {logging_mixin.py:151} INFO - [2024-08-20T05:39:01.363+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T05:39:01.386+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T05:39:01.412+0000] {logging_mixin.py:151} INFO - [2024-08-20T05:39:01.412+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T05:39:01.433+0000] {logging_mixin.py:151} INFO - [2024-08-20T05:39:01.433+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T05:39:01.455+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-08-20T05:39:31.812+0000] {processor.py:157} INFO - Started process (PID=80349) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T05:39:31.814+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T05:39:31.830+0000] {logging_mixin.py:151} INFO - [2024-08-20T05:39:31.829+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T05:39:31.861+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T05:39:31.901+0000] {logging_mixin.py:151} INFO - [2024-08-20T05:39:31.901+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T05:39:31.915+0000] {logging_mixin.py:151} INFO - [2024-08-20T05:39:31.915+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T05:39:31.926+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-08-20T05:40:02.153+0000] {processor.py:157} INFO - Started process (PID=80359) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T05:40:02.155+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T05:40:02.157+0000] {logging_mixin.py:151} INFO - [2024-08-20T05:40:02.157+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T05:40:02.169+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T05:40:02.184+0000] {logging_mixin.py:151} INFO - [2024-08-20T05:40:02.183+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T05:40:02.195+0000] {logging_mixin.py:151} INFO - [2024-08-20T05:40:02.194+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T05:40:02.205+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-20T05:40:32.506+0000] {processor.py:157} INFO - Started process (PID=80369) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T05:40:32.508+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T05:40:32.511+0000] {logging_mixin.py:151} INFO - [2024-08-20T05:40:32.511+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T05:40:32.528+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T05:40:32.549+0000] {logging_mixin.py:151} INFO - [2024-08-20T05:40:32.549+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T05:40:32.562+0000] {logging_mixin.py:151} INFO - [2024-08-20T05:40:32.562+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T05:40:32.570+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-20T05:41:02.815+0000] {processor.py:157} INFO - Started process (PID=80379) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T05:41:02.817+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T05:41:02.820+0000] {logging_mixin.py:151} INFO - [2024-08-20T05:41:02.820+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T05:41:02.834+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T05:41:02.863+0000] {logging_mixin.py:151} INFO - [2024-08-20T05:41:02.862+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T05:41:02.883+0000] {logging_mixin.py:151} INFO - [2024-08-20T05:41:02.883+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T05:41:02.892+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-08-20T05:41:33.078+0000] {processor.py:157} INFO - Started process (PID=80388) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T05:41:33.081+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T05:41:33.085+0000] {logging_mixin.py:151} INFO - [2024-08-20T05:41:33.085+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T05:41:33.104+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T05:41:33.127+0000] {logging_mixin.py:151} INFO - [2024-08-20T05:41:33.127+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T05:41:33.140+0000] {logging_mixin.py:151} INFO - [2024-08-20T05:41:33.140+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T05:41:33.150+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-08-20T05:57:21.145+0000] {processor.py:157} INFO - Started process (PID=80399) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T05:57:21.148+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T05:57:21.151+0000] {logging_mixin.py:151} INFO - [2024-08-20T05:57:21.151+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T05:57:21.187+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T05:57:21.217+0000] {logging_mixin.py:151} INFO - [2024-08-20T05:57:21.217+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T05:57:21.239+0000] {logging_mixin.py:151} INFO - [2024-08-20T05:57:21.239+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T05:57:21.262+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-08-20T06:13:34.369+0000] {processor.py:157} INFO - Started process (PID=80409) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T06:13:34.375+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T06:13:34.380+0000] {logging_mixin.py:151} INFO - [2024-08-20T06:13:34.379+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T06:13:34.407+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T06:13:34.458+0000] {logging_mixin.py:151} INFO - [2024-08-20T06:13:34.458+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T06:13:34.482+0000] {logging_mixin.py:151} INFO - [2024-08-20T06:13:34.482+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T06:13:34.501+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-08-20T06:14:04.669+0000] {processor.py:157} INFO - Started process (PID=80420) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T06:14:04.673+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T06:14:04.682+0000] {logging_mixin.py:151} INFO - [2024-08-20T06:14:04.681+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T06:14:04.716+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T06:14:04.745+0000] {logging_mixin.py:151} INFO - [2024-08-20T06:14:04.745+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T06:14:04.760+0000] {logging_mixin.py:151} INFO - [2024-08-20T06:14:04.760+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T06:14:04.770+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-08-20T06:30:19.269+0000] {processor.py:157} INFO - Started process (PID=80430) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T06:30:19.270+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T06:30:19.274+0000] {logging_mixin.py:151} INFO - [2024-08-20T06:30:19.274+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T06:30:19.290+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T06:30:19.311+0000] {logging_mixin.py:151} INFO - [2024-08-20T06:30:19.311+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T06:30:19.323+0000] {logging_mixin.py:151} INFO - [2024-08-20T06:30:19.323+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T06:30:19.331+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-20T06:30:49.638+0000] {processor.py:157} INFO - Started process (PID=80440) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T06:30:49.640+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T06:30:49.643+0000] {logging_mixin.py:151} INFO - [2024-08-20T06:30:49.643+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T06:30:49.661+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T06:30:49.686+0000] {logging_mixin.py:151} INFO - [2024-08-20T06:30:49.686+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T06:30:49.700+0000] {logging_mixin.py:151} INFO - [2024-08-20T06:30:49.700+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T06:30:49.710+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-08-20T06:48:53.033+0000] {processor.py:157} INFO - Started process (PID=80450) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T06:48:53.036+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T06:48:53.039+0000] {logging_mixin.py:151} INFO - [2024-08-20T06:48:53.038+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T06:48:53.059+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T06:48:53.086+0000] {logging_mixin.py:151} INFO - [2024-08-20T06:48:53.086+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T06:48:53.098+0000] {logging_mixin.py:151} INFO - [2024-08-20T06:48:53.098+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T06:48:53.107+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-08-20T06:49:23.450+0000] {processor.py:157} INFO - Started process (PID=80462) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T06:49:23.481+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T06:49:23.500+0000] {logging_mixin.py:151} INFO - [2024-08-20T06:49:23.500+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T06:49:23.521+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T06:49:23.566+0000] {logging_mixin.py:151} INFO - [2024-08-20T06:49:23.566+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T06:49:23.581+0000] {logging_mixin.py:151} INFO - [2024-08-20T06:49:23.581+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T06:49:23.591+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.147 seconds
[2024-08-20T07:06:32.784+0000] {processor.py:157} INFO - Started process (PID=80472) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T07:06:32.785+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T07:06:32.788+0000] {logging_mixin.py:151} INFO - [2024-08-20T07:06:32.788+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T07:06:32.802+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T07:06:32.837+0000] {logging_mixin.py:151} INFO - [2024-08-20T07:06:32.837+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T07:06:32.848+0000] {logging_mixin.py:151} INFO - [2024-08-20T07:06:32.848+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T07:06:32.857+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-08-20T07:07:03.124+0000] {processor.py:157} INFO - Started process (PID=80482) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T07:07:03.125+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T07:07:03.128+0000] {logging_mixin.py:151} INFO - [2024-08-20T07:07:03.128+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T07:07:03.148+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T07:07:03.178+0000] {logging_mixin.py:151} INFO - [2024-08-20T07:07:03.178+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T07:07:03.194+0000] {logging_mixin.py:151} INFO - [2024-08-20T07:07:03.193+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T07:07:03.205+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-08-20T07:07:33.469+0000] {processor.py:157} INFO - Started process (PID=80492) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T07:07:33.470+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T07:07:33.471+0000] {logging_mixin.py:151} INFO - [2024-08-20T07:07:33.471+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T07:07:33.481+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T07:07:33.494+0000] {logging_mixin.py:151} INFO - [2024-08-20T07:07:33.493+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T07:07:33.506+0000] {logging_mixin.py:151} INFO - [2024-08-20T07:07:33.506+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T07:07:33.515+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-08-20T07:08:03.928+0000] {processor.py:157} INFO - Started process (PID=80502) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T07:08:03.939+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T07:08:03.944+0000] {logging_mixin.py:151} INFO - [2024-08-20T07:08:03.944+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T07:08:03.961+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T07:08:03.984+0000] {logging_mixin.py:151} INFO - [2024-08-20T07:08:03.984+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T07:08:03.998+0000] {logging_mixin.py:151} INFO - [2024-08-20T07:08:03.998+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T07:08:04.008+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-08-20T07:08:34.354+0000] {processor.py:157} INFO - Started process (PID=80512) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T07:08:34.359+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T07:08:34.362+0000] {logging_mixin.py:151} INFO - [2024-08-20T07:08:34.362+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T07:08:34.379+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T07:08:34.400+0000] {logging_mixin.py:151} INFO - [2024-08-20T07:08:34.400+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T07:08:34.414+0000] {logging_mixin.py:151} INFO - [2024-08-20T07:08:34.414+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T07:08:34.424+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-20T07:26:51.988+0000] {processor.py:157} INFO - Started process (PID=80522) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T07:26:51.989+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T07:26:51.992+0000] {logging_mixin.py:151} INFO - [2024-08-20T07:26:51.992+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T07:26:52.003+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T07:26:52.033+0000] {logging_mixin.py:151} INFO - [2024-08-20T07:26:52.033+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T07:26:52.067+0000] {logging_mixin.py:151} INFO - [2024-08-20T07:26:52.066+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T07:26:52.093+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-08-20T07:43:28.568+0000] {processor.py:157} INFO - Started process (PID=80532) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T07:43:28.571+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T07:43:28.578+0000] {logging_mixin.py:151} INFO - [2024-08-20T07:43:28.577+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T07:43:28.624+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T07:43:28.681+0000] {logging_mixin.py:151} INFO - [2024-08-20T07:43:28.681+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T07:43:28.717+0000] {logging_mixin.py:151} INFO - [2024-08-20T07:43:28.717+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T07:43:28.732+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.168 seconds
[2024-08-20T07:43:58.895+0000] {processor.py:157} INFO - Started process (PID=80541) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T07:43:58.900+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T07:43:58.906+0000] {logging_mixin.py:151} INFO - [2024-08-20T07:43:58.905+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T07:43:58.930+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T07:43:58.950+0000] {logging_mixin.py:151} INFO - [2024-08-20T07:43:58.950+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T07:43:58.968+0000] {logging_mixin.py:151} INFO - [2024-08-20T07:43:58.968+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T07:43:58.978+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-08-20T08:00:31.420+0000] {processor.py:157} INFO - Started process (PID=80553) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T08:00:31.423+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T08:00:31.426+0000] {logging_mixin.py:151} INFO - [2024-08-20T08:00:31.426+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T08:00:31.450+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T08:00:31.472+0000] {logging_mixin.py:151} INFO - [2024-08-20T08:00:31.472+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T08:00:31.487+0000] {logging_mixin.py:151} INFO - [2024-08-20T08:00:31.487+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T08:00:31.498+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-08-20T08:01:01.819+0000] {processor.py:157} INFO - Started process (PID=80564) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T08:01:01.820+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T08:01:01.825+0000] {logging_mixin.py:151} INFO - [2024-08-20T08:01:01.824+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T08:01:01.843+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T08:01:01.863+0000] {logging_mixin.py:151} INFO - [2024-08-20T08:01:01.863+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T08:01:01.876+0000] {logging_mixin.py:151} INFO - [2024-08-20T08:01:01.876+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T08:01:01.885+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-20T08:01:32.227+0000] {processor.py:157} INFO - Started process (PID=80574) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T08:01:32.228+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T08:01:32.230+0000] {logging_mixin.py:151} INFO - [2024-08-20T08:01:32.229+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T08:01:32.241+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T08:01:32.257+0000] {logging_mixin.py:151} INFO - [2024-08-20T08:01:32.257+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T08:01:32.268+0000] {logging_mixin.py:151} INFO - [2024-08-20T08:01:32.268+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T08:01:32.277+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-20T08:02:02.575+0000] {processor.py:157} INFO - Started process (PID=80584) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T08:02:02.577+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T08:02:02.579+0000] {logging_mixin.py:151} INFO - [2024-08-20T08:02:02.579+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T08:02:02.589+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T08:02:02.605+0000] {logging_mixin.py:151} INFO - [2024-08-20T08:02:02.605+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T08:02:02.615+0000] {logging_mixin.py:151} INFO - [2024-08-20T08:02:02.615+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T08:02:02.623+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-20T08:17:46.941+0000] {processor.py:157} INFO - Started process (PID=80596) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T08:17:46.943+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T08:17:46.945+0000] {logging_mixin.py:151} INFO - [2024-08-20T08:17:46.945+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T08:17:46.966+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T08:17:47.000+0000] {logging_mixin.py:151} INFO - [2024-08-20T08:17:47.000+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T08:17:47.028+0000] {logging_mixin.py:151} INFO - [2024-08-20T08:17:47.028+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T08:17:47.048+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-08-20T08:18:17.302+0000] {processor.py:157} INFO - Started process (PID=80605) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T08:18:17.304+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T08:18:17.307+0000] {logging_mixin.py:151} INFO - [2024-08-20T08:18:17.306+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T08:18:17.332+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T08:18:17.351+0000] {logging_mixin.py:151} INFO - [2024-08-20T08:18:17.351+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T08:18:17.365+0000] {logging_mixin.py:151} INFO - [2024-08-20T08:18:17.365+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T08:18:17.376+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-08-20T08:34:18.657+0000] {processor.py:157} INFO - Started process (PID=80616) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T08:34:18.657+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T08:34:18.660+0000] {logging_mixin.py:151} INFO - [2024-08-20T08:34:18.659+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T08:34:18.672+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T08:34:18.693+0000] {logging_mixin.py:151} INFO - [2024-08-20T08:34:18.692+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T08:34:18.705+0000] {logging_mixin.py:151} INFO - [2024-08-20T08:34:18.705+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T08:34:18.716+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-20T08:34:49.044+0000] {processor.py:157} INFO - Started process (PID=80626) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T08:34:49.045+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T08:34:49.062+0000] {logging_mixin.py:151} INFO - [2024-08-20T08:34:49.061+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T08:34:49.077+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T08:34:49.098+0000] {logging_mixin.py:151} INFO - [2024-08-20T08:34:49.098+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T08:34:49.110+0000] {logging_mixin.py:151} INFO - [2024-08-20T08:34:49.110+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T08:34:49.119+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-08-20T08:35:19.472+0000] {processor.py:157} INFO - Started process (PID=80636) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T08:35:19.477+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T08:35:19.482+0000] {logging_mixin.py:151} INFO - [2024-08-20T08:35:19.482+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T08:35:19.504+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T08:35:19.525+0000] {logging_mixin.py:151} INFO - [2024-08-20T08:35:19.525+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T08:35:19.538+0000] {logging_mixin.py:151} INFO - [2024-08-20T08:35:19.538+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T08:35:19.550+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-08-20T08:35:49.820+0000] {processor.py:157} INFO - Started process (PID=80646) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T08:35:49.821+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T08:35:49.823+0000] {logging_mixin.py:151} INFO - [2024-08-20T08:35:49.823+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T08:35:49.834+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T08:35:49.851+0000] {logging_mixin.py:151} INFO - [2024-08-20T08:35:49.851+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T08:35:49.862+0000] {logging_mixin.py:151} INFO - [2024-08-20T08:35:49.862+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T08:35:49.871+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-20T08:36:20.169+0000] {processor.py:157} INFO - Started process (PID=80656) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T08:36:20.171+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T08:36:20.173+0000] {logging_mixin.py:151} INFO - [2024-08-20T08:36:20.172+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T08:36:20.181+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T08:36:20.197+0000] {logging_mixin.py:151} INFO - [2024-08-20T08:36:20.197+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T08:36:20.207+0000] {logging_mixin.py:151} INFO - [2024-08-20T08:36:20.207+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T08:36:20.216+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-20T08:52:19.587+0000] {processor.py:157} INFO - Started process (PID=80665) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T08:52:19.588+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T08:52:19.593+0000] {logging_mixin.py:151} INFO - [2024-08-20T08:52:19.593+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T08:52:19.612+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T08:52:19.637+0000] {logging_mixin.py:151} INFO - [2024-08-20T08:52:19.637+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T08:52:19.651+0000] {logging_mixin.py:151} INFO - [2024-08-20T08:52:19.650+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T08:52:19.661+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-08-20T08:52:49.995+0000] {processor.py:157} INFO - Started process (PID=80675) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T08:52:50.004+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T08:52:50.007+0000] {logging_mixin.py:151} INFO - [2024-08-20T08:52:50.007+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T08:52:50.025+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T08:52:50.061+0000] {logging_mixin.py:151} INFO - [2024-08-20T08:52:50.060+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T08:52:50.075+0000] {logging_mixin.py:151} INFO - [2024-08-20T08:52:50.075+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T08:52:50.086+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-08-20T09:09:09.840+0000] {processor.py:157} INFO - Started process (PID=80686) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T09:09:09.842+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T09:09:09.844+0000] {logging_mixin.py:151} INFO - [2024-08-20T09:09:09.843+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T09:09:09.851+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T09:09:09.865+0000] {logging_mixin.py:151} INFO - [2024-08-20T09:09:09.865+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T09:09:09.873+0000] {logging_mixin.py:151} INFO - [2024-08-20T09:09:09.873+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T09:09:09.881+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.044 seconds
[2024-08-20T09:24:47.393+0000] {processor.py:157} INFO - Started process (PID=80697) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T09:24:47.394+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T09:24:47.398+0000] {logging_mixin.py:151} INFO - [2024-08-20T09:24:47.397+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T09:24:47.418+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T09:24:47.614+0000] {logging_mixin.py:151} INFO - [2024-08-20T09:24:47.614+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T09:24:47.644+0000] {logging_mixin.py:151} INFO - [2024-08-20T09:24:47.643+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T09:24:47.665+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.289 seconds
[2024-08-20T09:25:18.049+0000] {processor.py:157} INFO - Started process (PID=80708) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T09:25:18.050+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T09:25:18.054+0000] {logging_mixin.py:151} INFO - [2024-08-20T09:25:18.054+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T09:25:18.079+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T09:25:18.116+0000] {logging_mixin.py:151} INFO - [2024-08-20T09:25:18.116+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T09:25:18.133+0000] {logging_mixin.py:151} INFO - [2024-08-20T09:25:18.133+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T09:25:18.143+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-08-20T09:25:48.579+0000] {processor.py:157} INFO - Started process (PID=80718) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T09:25:48.581+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T09:25:48.583+0000] {logging_mixin.py:151} INFO - [2024-08-20T09:25:48.582+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T09:25:48.593+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T09:25:48.613+0000] {logging_mixin.py:151} INFO - [2024-08-20T09:25:48.612+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T09:25:48.623+0000] {logging_mixin.py:151} INFO - [2024-08-20T09:25:48.623+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T09:25:48.631+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-20T09:26:18.970+0000] {processor.py:157} INFO - Started process (PID=80728) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T09:26:18.972+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T09:26:18.976+0000] {logging_mixin.py:151} INFO - [2024-08-20T09:26:18.976+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T09:26:19.023+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T09:26:19.064+0000] {logging_mixin.py:151} INFO - [2024-08-20T09:26:19.064+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T09:26:19.081+0000] {logging_mixin.py:151} INFO - [2024-08-20T09:26:19.081+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T09:26:19.090+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-08-20T09:43:16.393+0000] {processor.py:157} INFO - Started process (PID=80738) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T09:43:16.396+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T09:43:16.409+0000] {logging_mixin.py:151} INFO - [2024-08-20T09:43:16.408+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T09:43:16.435+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T09:43:16.486+0000] {logging_mixin.py:151} INFO - [2024-08-20T09:43:16.486+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T09:43:16.499+0000] {logging_mixin.py:151} INFO - [2024-08-20T09:43:16.499+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T09:43:16.509+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-08-20T09:43:46.820+0000] {processor.py:157} INFO - Started process (PID=80748) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T09:43:46.824+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T09:43:46.827+0000] {logging_mixin.py:151} INFO - [2024-08-20T09:43:46.827+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T09:43:46.845+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T09:43:46.893+0000] {logging_mixin.py:151} INFO - [2024-08-20T09:43:46.893+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T09:43:46.905+0000] {logging_mixin.py:151} INFO - [2024-08-20T09:43:46.905+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T09:43:46.915+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-08-20T09:59:38.424+0000] {processor.py:157} INFO - Started process (PID=80758) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T09:59:38.429+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T09:59:38.432+0000] {logging_mixin.py:151} INFO - [2024-08-20T09:59:38.432+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T09:59:38.449+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T09:59:38.489+0000] {logging_mixin.py:151} INFO - [2024-08-20T09:59:38.489+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T09:59:38.514+0000] {logging_mixin.py:151} INFO - [2024-08-20T09:59:38.514+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T09:59:38.527+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-08-20T10:00:08.815+0000] {processor.py:157} INFO - Started process (PID=80767) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T10:00:08.817+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T10:00:08.820+0000] {logging_mixin.py:151} INFO - [2024-08-20T10:00:08.820+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T10:00:08.834+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T10:00:08.902+0000] {logging_mixin.py:151} INFO - [2024-08-20T10:00:08.902+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T10:00:08.913+0000] {logging_mixin.py:151} INFO - [2024-08-20T10:00:08.913+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T10:00:08.923+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-08-20T10:00:39.114+0000] {processor.py:157} INFO - Started process (PID=80778) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T10:00:39.115+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T10:00:39.119+0000] {logging_mixin.py:151} INFO - [2024-08-20T10:00:39.119+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T10:00:39.141+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T10:00:39.158+0000] {logging_mixin.py:151} INFO - [2024-08-20T10:00:39.158+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T10:00:39.174+0000] {logging_mixin.py:151} INFO - [2024-08-20T10:00:39.174+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T10:00:39.183+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-20T10:01:09.552+0000] {processor.py:157} INFO - Started process (PID=80788) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T10:01:09.554+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T10:01:09.556+0000] {logging_mixin.py:151} INFO - [2024-08-20T10:01:09.556+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T10:01:09.581+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T10:01:09.600+0000] {logging_mixin.py:151} INFO - [2024-08-20T10:01:09.600+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T10:01:09.611+0000] {logging_mixin.py:151} INFO - [2024-08-20T10:01:09.611+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T10:01:09.620+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-20T10:01:39.964+0000] {processor.py:157} INFO - Started process (PID=80798) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T10:01:39.965+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T10:01:39.967+0000] {logging_mixin.py:151} INFO - [2024-08-20T10:01:39.967+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T10:01:39.985+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T10:01:40.002+0000] {logging_mixin.py:151} INFO - [2024-08-20T10:01:40.002+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T10:01:40.012+0000] {logging_mixin.py:151} INFO - [2024-08-20T10:01:40.012+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T10:01:40.020+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-20T10:18:47.568+0000] {processor.py:157} INFO - Started process (PID=80810) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T10:18:47.569+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T10:18:47.572+0000] {logging_mixin.py:151} INFO - [2024-08-20T10:18:47.572+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T10:18:47.597+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T10:18:47.615+0000] {logging_mixin.py:151} INFO - [2024-08-20T10:18:47.615+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T10:18:47.628+0000] {logging_mixin.py:151} INFO - [2024-08-20T10:18:47.628+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T10:18:47.637+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-20T10:19:18.008+0000] {processor.py:157} INFO - Started process (PID=80820) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T10:19:18.009+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T10:19:18.014+0000] {logging_mixin.py:151} INFO - [2024-08-20T10:19:18.013+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T10:19:18.070+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T10:19:18.091+0000] {logging_mixin.py:151} INFO - [2024-08-20T10:19:18.091+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T10:19:18.106+0000] {logging_mixin.py:151} INFO - [2024-08-20T10:19:18.106+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T10:19:18.117+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-08-20T10:19:48.344+0000] {processor.py:157} INFO - Started process (PID=80830) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T10:19:48.345+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T10:19:48.348+0000] {logging_mixin.py:151} INFO - [2024-08-20T10:19:48.347+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T10:19:48.363+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T10:19:48.379+0000] {logging_mixin.py:151} INFO - [2024-08-20T10:19:48.379+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T10:19:48.388+0000] {logging_mixin.py:151} INFO - [2024-08-20T10:19:48.388+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T10:19:48.399+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-20T10:20:18.736+0000] {processor.py:157} INFO - Started process (PID=80840) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T10:20:18.743+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T10:20:18.750+0000] {logging_mixin.py:151} INFO - [2024-08-20T10:20:18.750+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T10:20:18.761+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T10:20:18.777+0000] {logging_mixin.py:151} INFO - [2024-08-20T10:20:18.777+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T10:20:18.789+0000] {logging_mixin.py:151} INFO - [2024-08-20T10:20:18.789+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T10:20:18.799+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-20T10:20:49.188+0000] {processor.py:157} INFO - Started process (PID=80850) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T10:20:49.191+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T10:20:49.193+0000] {logging_mixin.py:151} INFO - [2024-08-20T10:20:49.193+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T10:20:49.209+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T10:20:49.225+0000] {logging_mixin.py:151} INFO - [2024-08-20T10:20:49.225+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T10:20:49.237+0000] {logging_mixin.py:151} INFO - [2024-08-20T10:20:49.237+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T10:20:49.246+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-20T10:21:19.734+0000] {processor.py:157} INFO - Started process (PID=80860) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T10:21:19.734+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T10:21:19.738+0000] {logging_mixin.py:151} INFO - [2024-08-20T10:21:19.738+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T10:21:19.769+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T10:21:19.832+0000] {logging_mixin.py:151} INFO - [2024-08-20T10:21:19.832+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T10:21:19.841+0000] {logging_mixin.py:151} INFO - [2024-08-20T10:21:19.841+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T10:21:19.850+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-08-20T10:37:54.759+0000] {processor.py:157} INFO - Started process (PID=80869) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T10:37:54.761+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T10:37:54.764+0000] {logging_mixin.py:151} INFO - [2024-08-20T10:37:54.764+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T10:37:54.793+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T10:37:54.817+0000] {logging_mixin.py:151} INFO - [2024-08-20T10:37:54.817+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T10:37:54.828+0000] {logging_mixin.py:151} INFO - [2024-08-20T10:37:54.827+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T10:37:54.836+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-08-20T10:54:21.790+0000] {processor.py:157} INFO - Started process (PID=80879) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T10:54:21.792+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T10:54:21.795+0000] {logging_mixin.py:151} INFO - [2024-08-20T10:54:21.795+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T10:54:21.812+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T10:54:21.832+0000] {logging_mixin.py:151} INFO - [2024-08-20T10:54:21.832+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T10:54:21.847+0000] {logging_mixin.py:151} INFO - [2024-08-20T10:54:21.847+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T10:54:21.856+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-20T10:54:52.232+0000] {processor.py:157} INFO - Started process (PID=80890) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T10:54:52.235+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T10:54:52.248+0000] {logging_mixin.py:151} INFO - [2024-08-20T10:54:52.247+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T10:54:52.265+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T10:54:52.290+0000] {logging_mixin.py:151} INFO - [2024-08-20T10:54:52.290+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T10:54:52.304+0000] {logging_mixin.py:151} INFO - [2024-08-20T10:54:52.304+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T10:54:52.316+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-08-20T11:10:43.844+0000] {processor.py:157} INFO - Started process (PID=80900) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T11:10:43.846+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T11:10:43.847+0000] {logging_mixin.py:151} INFO - [2024-08-20T11:10:43.847+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T11:10:43.857+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T11:10:43.871+0000] {logging_mixin.py:151} INFO - [2024-08-20T11:10:43.870+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T11:10:43.880+0000] {logging_mixin.py:151} INFO - [2024-08-20T11:10:43.880+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T11:10:43.889+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-08-20T11:11:14.187+0000] {processor.py:157} INFO - Started process (PID=80912) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T11:11:14.188+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T11:11:14.192+0000] {logging_mixin.py:151} INFO - [2024-08-20T11:11:14.192+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T11:11:14.208+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T11:11:14.229+0000] {logging_mixin.py:151} INFO - [2024-08-20T11:11:14.229+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T11:11:14.245+0000] {logging_mixin.py:151} INFO - [2024-08-20T11:11:14.245+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T11:11:14.255+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-08-20T11:11:44.446+0000] {processor.py:157} INFO - Started process (PID=80922) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T11:11:44.448+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T11:11:44.452+0000] {logging_mixin.py:151} INFO - [2024-08-20T11:11:44.451+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T11:11:44.466+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T11:11:44.485+0000] {logging_mixin.py:151} INFO - [2024-08-20T11:11:44.485+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T11:11:44.499+0000] {logging_mixin.py:151} INFO - [2024-08-20T11:11:44.499+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T11:11:44.508+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-20T11:12:14.836+0000] {processor.py:157} INFO - Started process (PID=80932) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T11:12:14.837+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T11:12:14.839+0000] {logging_mixin.py:151} INFO - [2024-08-20T11:12:14.839+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T11:12:14.854+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T11:12:14.869+0000] {logging_mixin.py:151} INFO - [2024-08-20T11:12:14.869+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T11:12:14.879+0000] {logging_mixin.py:151} INFO - [2024-08-20T11:12:14.879+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T11:12:14.887+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-20T11:12:45.314+0000] {processor.py:157} INFO - Started process (PID=80941) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T11:12:45.317+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T11:12:45.322+0000] {logging_mixin.py:151} INFO - [2024-08-20T11:12:45.321+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T11:12:45.360+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T11:12:45.400+0000] {logging_mixin.py:151} INFO - [2024-08-20T11:12:45.400+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T11:12:45.416+0000] {logging_mixin.py:151} INFO - [2024-08-20T11:12:45.416+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T11:12:45.442+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-08-20T11:28:16.641+0000] {processor.py:157} INFO - Started process (PID=80953) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T11:28:16.642+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T11:28:16.645+0000] {logging_mixin.py:151} INFO - [2024-08-20T11:28:16.645+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T11:28:16.669+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T11:28:16.702+0000] {logging_mixin.py:151} INFO - [2024-08-20T11:28:16.702+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T11:28:16.725+0000] {logging_mixin.py:151} INFO - [2024-08-20T11:28:16.725+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T11:28:16.740+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-08-20T11:28:47.126+0000] {processor.py:157} INFO - Started process (PID=80964) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T11:28:47.131+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T11:28:47.135+0000] {logging_mixin.py:151} INFO - [2024-08-20T11:28:47.135+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T11:28:47.167+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T11:28:47.214+0000] {logging_mixin.py:151} INFO - [2024-08-20T11:28:47.214+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T11:28:47.229+0000] {logging_mixin.py:151} INFO - [2024-08-20T11:28:47.229+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T11:28:47.240+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-08-20T11:29:17.417+0000] {processor.py:157} INFO - Started process (PID=80974) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T11:29:17.419+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T11:29:17.421+0000] {logging_mixin.py:151} INFO - [2024-08-20T11:29:17.421+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T11:29:17.430+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T11:29:17.446+0000] {logging_mixin.py:151} INFO - [2024-08-20T11:29:17.446+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T11:29:17.455+0000] {logging_mixin.py:151} INFO - [2024-08-20T11:29:17.455+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T11:29:17.466+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-20T11:29:47.798+0000] {processor.py:157} INFO - Started process (PID=80984) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T11:29:47.802+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T11:29:47.806+0000] {logging_mixin.py:151} INFO - [2024-08-20T11:29:47.806+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T11:29:47.822+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T11:29:47.846+0000] {logging_mixin.py:151} INFO - [2024-08-20T11:29:47.845+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T11:29:47.860+0000] {logging_mixin.py:151} INFO - [2024-08-20T11:29:47.860+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T11:29:47.869+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-08-20T11:39:38.564+0000] {processor.py:157} INFO - Started process (PID=80996) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T11:39:38.565+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T11:39:38.570+0000] {logging_mixin.py:151} INFO - [2024-08-20T11:39:38.569+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T11:39:38.586+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T11:39:38.607+0000] {logging_mixin.py:151} INFO - [2024-08-20T11:39:38.607+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T11:39:38.623+0000] {logging_mixin.py:151} INFO - [2024-08-20T11:39:38.623+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T11:39:38.634+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-20T11:56:49.843+0000] {processor.py:157} INFO - Started process (PID=81006) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T11:56:49.851+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T11:56:49.854+0000] {logging_mixin.py:151} INFO - [2024-08-20T11:56:49.854+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T11:56:49.872+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T11:56:49.894+0000] {logging_mixin.py:151} INFO - [2024-08-20T11:56:49.894+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T11:56:49.907+0000] {logging_mixin.py:151} INFO - [2024-08-20T11:56:49.907+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T11:56:49.918+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-08-20T13:19:44.925+0000] {processor.py:157} INFO - Started process (PID=81016) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T13:19:44.929+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T13:19:44.932+0000] {logging_mixin.py:151} INFO - [2024-08-20T13:19:44.931+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T13:19:44.947+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T13:19:44.974+0000] {logging_mixin.py:151} INFO - [2024-08-20T13:19:44.973+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T13:19:44.989+0000] {logging_mixin.py:151} INFO - [2024-08-20T13:19:44.989+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T13:19:45.003+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-08-20T13:31:29.126+0000] {processor.py:157} INFO - Started process (PID=81026) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T13:31:29.132+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T13:31:29.153+0000] {logging_mixin.py:151} INFO - [2024-08-20T13:31:29.153+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T13:31:29.171+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T13:31:29.226+0000] {logging_mixin.py:151} INFO - [2024-08-20T13:31:29.226+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T13:31:29.256+0000] {logging_mixin.py:151} INFO - [2024-08-20T13:31:29.256+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T13:31:29.276+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.162 seconds
[2024-08-20T14:21:47.152+0000] {processor.py:157} INFO - Started process (PID=81036) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T14:21:47.154+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T14:21:47.159+0000] {logging_mixin.py:151} INFO - [2024-08-20T14:21:47.158+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T14:21:47.184+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T14:21:47.228+0000] {logging_mixin.py:151} INFO - [2024-08-20T14:21:47.228+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T14:21:47.256+0000] {logging_mixin.py:151} INFO - [2024-08-20T14:21:47.256+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T14:21:47.275+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-08-20T14:32:29.214+0000] {processor.py:157} INFO - Started process (PID=81048) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T14:32:29.216+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T14:32:29.221+0000] {logging_mixin.py:151} INFO - [2024-08-20T14:32:29.221+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T14:32:29.249+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T14:32:29.313+0000] {logging_mixin.py:151} INFO - [2024-08-20T14:32:29.313+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T14:32:29.338+0000] {logging_mixin.py:151} INFO - [2024-08-20T14:32:29.338+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T14:32:29.355+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.147 seconds
[2024-08-20T15:06:31.426+0000] {processor.py:157} INFO - Started process (PID=81058) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T15:06:31.429+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T15:06:31.443+0000] {logging_mixin.py:151} INFO - [2024-08-20T15:06:31.441+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T15:06:31.475+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T15:06:31.504+0000] {logging_mixin.py:151} INFO - [2024-08-20T15:06:31.503+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T15:06:31.517+0000] {logging_mixin.py:151} INFO - [2024-08-20T15:06:31.517+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T15:06:31.531+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-08-20T15:33:29.414+0000] {processor.py:157} INFO - Started process (PID=81068) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T15:33:29.418+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T15:33:29.420+0000] {logging_mixin.py:151} INFO - [2024-08-20T15:33:29.420+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T15:33:29.439+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T15:33:29.471+0000] {logging_mixin.py:151} INFO - [2024-08-20T15:33:29.471+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T15:33:29.488+0000] {logging_mixin.py:151} INFO - [2024-08-20T15:33:29.488+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T15:33:29.507+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-08-20T16:07:12.535+0000] {processor.py:157} INFO - Started process (PID=81078) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T16:07:12.537+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T16:07:12.546+0000] {logging_mixin.py:151} INFO - [2024-08-20T16:07:12.545+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T16:07:12.568+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T16:07:12.597+0000] {logging_mixin.py:151} INFO - [2024-08-20T16:07:12.597+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T16:07:12.616+0000] {logging_mixin.py:151} INFO - [2024-08-20T16:07:12.616+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T16:07:12.632+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-08-20T16:34:29.402+0000] {processor.py:157} INFO - Started process (PID=81089) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T16:34:29.410+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T16:34:29.421+0000] {logging_mixin.py:151} INFO - [2024-08-20T16:34:29.420+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T16:34:29.458+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T16:34:29.514+0000] {logging_mixin.py:151} INFO - [2024-08-20T16:34:29.514+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T16:34:29.556+0000] {logging_mixin.py:151} INFO - [2024-08-20T16:34:29.556+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T16:34:29.575+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.180 seconds
[2024-08-20T16:51:22.908+0000] {processor.py:157} INFO - Started process (PID=81100) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T16:51:22.910+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T16:51:22.924+0000] {logging_mixin.py:151} INFO - [2024-08-20T16:51:22.923+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T16:51:22.959+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T16:51:23.013+0000] {logging_mixin.py:151} INFO - [2024-08-20T16:51:23.013+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T16:51:23.047+0000] {logging_mixin.py:151} INFO - [2024-08-20T16:51:23.047+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T16:51:23.068+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.172 seconds
[2024-08-20T17:35:29.349+0000] {processor.py:157} INFO - Started process (PID=81110) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T17:35:29.353+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T17:35:29.358+0000] {logging_mixin.py:151} INFO - [2024-08-20T17:35:29.357+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T17:35:29.390+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T17:35:29.432+0000] {logging_mixin.py:151} INFO - [2024-08-20T17:35:29.432+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T17:35:29.457+0000] {logging_mixin.py:151} INFO - [2024-08-20T17:35:29.457+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T17:35:29.472+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.137 seconds
[2024-08-20T17:53:00.846+0000] {processor.py:157} INFO - Started process (PID=81120) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T17:53:00.847+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T17:53:00.851+0000] {logging_mixin.py:151} INFO - [2024-08-20T17:53:00.850+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T17:53:00.871+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T17:53:00.908+0000] {logging_mixin.py:151} INFO - [2024-08-20T17:53:00.908+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T17:53:00.924+0000] {logging_mixin.py:151} INFO - [2024-08-20T17:53:00.924+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T17:53:00.937+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-08-20T18:12:54.736+0000] {processor.py:157} INFO - Started process (PID=81131) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T18:12:54.741+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T18:12:54.750+0000] {logging_mixin.py:151} INFO - [2024-08-20T18:12:54.750+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T18:12:54.783+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T18:12:54.838+0000] {logging_mixin.py:151} INFO - [2024-08-20T18:12:54.838+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T18:12:54.872+0000] {logging_mixin.py:151} INFO - [2024-08-20T18:12:54.872+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T18:12:54.893+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.167 seconds
[2024-08-20T18:36:17.780+0000] {processor.py:157} INFO - Started process (PID=81142) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T18:36:17.785+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T18:36:17.797+0000] {logging_mixin.py:151} INFO - [2024-08-20T18:36:17.792+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T18:36:17.845+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T18:36:17.896+0000] {logging_mixin.py:151} INFO - [2024-08-20T18:36:17.896+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T18:36:17.928+0000] {logging_mixin.py:151} INFO - [2024-08-20T18:36:17.928+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T18:36:17.958+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.190 seconds
[2024-08-20T18:36:48.082+0000] {processor.py:157} INFO - Started process (PID=81152) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T18:36:48.091+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T18:36:48.098+0000] {logging_mixin.py:151} INFO - [2024-08-20T18:36:48.097+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T18:36:48.117+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T18:36:48.156+0000] {logging_mixin.py:151} INFO - [2024-08-20T18:36:48.155+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T18:36:48.171+0000] {logging_mixin.py:151} INFO - [2024-08-20T18:36:48.171+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T18:36:48.180+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-08-20T19:21:01.455+0000] {processor.py:157} INFO - Started process (PID=81164) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T19:21:01.464+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T19:21:01.471+0000] {logging_mixin.py:151} INFO - [2024-08-20T19:21:01.471+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T19:21:01.507+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T19:21:01.566+0000] {logging_mixin.py:151} INFO - [2024-08-20T19:21:01.566+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T19:21:01.598+0000] {logging_mixin.py:151} INFO - [2024-08-20T19:21:01.598+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T19:21:01.623+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.177 seconds
[2024-08-20T19:21:31.736+0000] {processor.py:157} INFO - Started process (PID=81174) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T19:21:31.739+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T19:21:31.744+0000] {logging_mixin.py:151} INFO - [2024-08-20T19:21:31.744+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T19:21:31.773+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T19:21:31.801+0000] {logging_mixin.py:151} INFO - [2024-08-20T19:21:31.801+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T19:21:31.825+0000] {logging_mixin.py:151} INFO - [2024-08-20T19:21:31.825+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T19:21:31.837+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-08-20T19:22:02.178+0000] {processor.py:157} INFO - Started process (PID=81184) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T19:22:02.181+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T19:22:02.188+0000] {logging_mixin.py:151} INFO - [2024-08-20T19:22:02.187+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T19:22:02.229+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T19:22:02.269+0000] {logging_mixin.py:151} INFO - [2024-08-20T19:22:02.269+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T19:22:02.286+0000] {logging_mixin.py:151} INFO - [2024-08-20T19:22:02.286+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T19:22:02.302+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-08-20T19:22:32.656+0000] {processor.py:157} INFO - Started process (PID=81193) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T19:22:32.658+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T19:22:32.663+0000] {logging_mixin.py:151} INFO - [2024-08-20T19:22:32.662+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T19:22:32.683+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T19:22:32.719+0000] {logging_mixin.py:151} INFO - [2024-08-20T19:22:32.719+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T19:22:32.734+0000] {logging_mixin.py:151} INFO - [2024-08-20T19:22:32.734+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T19:22:32.744+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-08-20T19:23:03.248+0000] {processor.py:157} INFO - Started process (PID=81204) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T19:23:03.253+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T19:23:03.268+0000] {logging_mixin.py:151} INFO - [2024-08-20T19:23:03.266+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T19:23:03.349+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T19:23:03.479+0000] {logging_mixin.py:151} INFO - [2024-08-20T19:23:03.479+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T19:23:03.574+0000] {logging_mixin.py:151} INFO - [2024-08-20T19:23:03.573+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T19:23:03.606+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.367 seconds
[2024-08-20T19:23:34.321+0000] {processor.py:157} INFO - Started process (PID=81214) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T19:23:34.323+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T19:23:34.328+0000] {logging_mixin.py:151} INFO - [2024-08-20T19:23:34.327+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T19:23:34.349+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T19:23:34.397+0000] {logging_mixin.py:151} INFO - [2024-08-20T19:23:34.397+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T19:23:34.413+0000] {logging_mixin.py:151} INFO - [2024-08-20T19:23:34.413+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T19:23:34.426+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-08-20T19:24:04.639+0000] {processor.py:157} INFO - Started process (PID=81222) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T19:24:04.643+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T19:24:04.650+0000] {logging_mixin.py:151} INFO - [2024-08-20T19:24:04.649+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T19:24:04.694+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T19:24:04.728+0000] {logging_mixin.py:151} INFO - [2024-08-20T19:24:04.728+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T19:24:04.761+0000] {logging_mixin.py:151} INFO - [2024-08-20T19:24:04.761+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T19:24:04.776+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.143 seconds
[2024-08-20T19:24:34.936+0000] {processor.py:157} INFO - Started process (PID=81234) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T19:24:34.938+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T19:24:34.942+0000] {logging_mixin.py:151} INFO - [2024-08-20T19:24:34.942+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T19:24:34.959+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T19:24:34.984+0000] {logging_mixin.py:151} INFO - [2024-08-20T19:24:34.983+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T19:24:34.997+0000] {logging_mixin.py:151} INFO - [2024-08-20T19:24:34.997+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T19:24:35.008+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-08-20T19:25:05.370+0000] {processor.py:157} INFO - Started process (PID=81244) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T19:25:05.372+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T19:25:05.377+0000] {logging_mixin.py:151} INFO - [2024-08-20T19:25:05.376+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T19:25:05.395+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T19:25:05.420+0000] {logging_mixin.py:151} INFO - [2024-08-20T19:25:05.419+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T19:25:05.434+0000] {logging_mixin.py:151} INFO - [2024-08-20T19:25:05.434+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T19:25:05.444+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-08-20T19:25:35.690+0000] {processor.py:157} INFO - Started process (PID=81254) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T19:25:35.692+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T19:25:35.697+0000] {logging_mixin.py:151} INFO - [2024-08-20T19:25:35.697+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T19:25:35.733+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T19:25:35.760+0000] {logging_mixin.py:151} INFO - [2024-08-20T19:25:35.760+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T19:25:35.774+0000] {logging_mixin.py:151} INFO - [2024-08-20T19:25:35.774+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T19:25:35.784+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-08-20T19:26:06.057+0000] {processor.py:157} INFO - Started process (PID=81264) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T19:26:06.063+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T19:26:06.071+0000] {logging_mixin.py:151} INFO - [2024-08-20T19:26:06.070+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T19:26:06.096+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T19:26:06.135+0000] {logging_mixin.py:151} INFO - [2024-08-20T19:26:06.135+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T19:26:06.151+0000] {logging_mixin.py:151} INFO - [2024-08-20T19:26:06.151+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T19:26:06.161+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-08-20T19:26:36.400+0000] {processor.py:157} INFO - Started process (PID=81273) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T19:26:36.406+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T19:26:36.409+0000] {logging_mixin.py:151} INFO - [2024-08-20T19:26:36.409+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T19:26:36.439+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T19:26:36.478+0000] {logging_mixin.py:151} INFO - [2024-08-20T19:26:36.478+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T19:26:36.496+0000] {logging_mixin.py:151} INFO - [2024-08-20T19:26:36.496+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T19:26:36.508+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-08-20T19:27:06.822+0000] {processor.py:157} INFO - Started process (PID=81284) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T19:27:06.825+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T19:27:06.829+0000] {logging_mixin.py:151} INFO - [2024-08-20T19:27:06.829+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T19:27:06.849+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T19:27:06.874+0000] {logging_mixin.py:151} INFO - [2024-08-20T19:27:06.874+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T19:27:06.888+0000] {logging_mixin.py:151} INFO - [2024-08-20T19:27:06.887+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T19:27:06.897+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-08-20T19:27:37.278+0000] {processor.py:157} INFO - Started process (PID=81294) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T19:27:37.279+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T19:27:37.283+0000] {logging_mixin.py:151} INFO - [2024-08-20T19:27:37.282+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T19:27:37.305+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T19:27:37.339+0000] {logging_mixin.py:151} INFO - [2024-08-20T19:27:37.339+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T19:27:37.357+0000] {logging_mixin.py:151} INFO - [2024-08-20T19:27:37.357+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T19:27:37.368+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-08-20T19:28:46.900+0000] {processor.py:157} INFO - Started process (PID=81305) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T19:28:46.903+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T19:28:46.931+0000] {logging_mixin.py:151} INFO - [2024-08-20T19:28:46.931+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T19:28:46.949+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T19:28:46.984+0000] {logging_mixin.py:151} INFO - [2024-08-20T19:28:46.983+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T19:28:46.998+0000] {logging_mixin.py:151} INFO - [2024-08-20T19:28:46.998+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T19:28:47.010+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-08-20T19:29:26.249+0000] {processor.py:157} INFO - Started process (PID=81316) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T19:29:26.252+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T19:29:26.256+0000] {logging_mixin.py:151} INFO - [2024-08-20T19:29:26.256+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T19:29:26.268+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T19:29:26.290+0000] {logging_mixin.py:151} INFO - [2024-08-20T19:29:26.290+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T19:29:26.304+0000] {logging_mixin.py:151} INFO - [2024-08-20T19:29:26.304+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T19:29:26.315+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-20T19:29:56.605+0000] {processor.py:157} INFO - Started process (PID=81326) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T19:29:56.607+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T19:29:56.612+0000] {logging_mixin.py:151} INFO - [2024-08-20T19:29:56.611+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T19:29:56.628+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T19:29:56.652+0000] {logging_mixin.py:151} INFO - [2024-08-20T19:29:56.652+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T19:29:56.666+0000] {logging_mixin.py:151} INFO - [2024-08-20T19:29:56.666+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T19:29:56.678+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-08-20T19:41:39.087+0000] {processor.py:157} INFO - Started process (PID=81335) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T19:41:39.090+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T19:41:39.113+0000] {logging_mixin.py:151} INFO - [2024-08-20T19:41:39.112+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T19:41:39.139+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T19:41:39.180+0000] {logging_mixin.py:151} INFO - [2024-08-20T19:41:39.180+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T19:41:39.204+0000] {logging_mixin.py:151} INFO - [2024-08-20T19:41:39.203+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T19:41:39.239+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.156 seconds
[2024-08-20T19:59:53.728+0000] {processor.py:157} INFO - Started process (PID=81347) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T19:59:53.736+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T19:59:53.744+0000] {logging_mixin.py:151} INFO - [2024-08-20T19:59:53.743+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T19:59:53.781+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T19:59:53.837+0000] {logging_mixin.py:151} INFO - [2024-08-20T19:59:53.836+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T19:59:53.869+0000] {logging_mixin.py:151} INFO - [2024-08-20T19:59:53.869+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T19:59:53.886+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.163 seconds
[2024-08-20T21:23:31.795+0000] {processor.py:157} INFO - Started process (PID=81357) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T21:23:31.797+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T21:23:31.802+0000] {logging_mixin.py:151} INFO - [2024-08-20T21:23:31.801+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T21:23:31.837+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T21:23:31.876+0000] {logging_mixin.py:151} INFO - [2024-08-20T21:23:31.876+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T21:23:31.920+0000] {logging_mixin.py:151} INFO - [2024-08-20T21:23:31.920+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T21:23:31.939+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.147 seconds
[2024-08-20T21:29:04.851+0000] {processor.py:157} INFO - Started process (PID=81367) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T21:29:04.853+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T21:29:04.857+0000] {logging_mixin.py:151} INFO - [2024-08-20T21:29:04.857+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T21:29:04.879+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T21:29:04.916+0000] {logging_mixin.py:151} INFO - [2024-08-20T21:29:04.916+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T21:29:04.928+0000] {logging_mixin.py:151} INFO - [2024-08-20T21:29:04.928+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T21:29:04.939+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-08-20T22:20:17.629+0000] {processor.py:157} INFO - Started process (PID=81377) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T22:20:17.631+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T22:20:17.637+0000] {logging_mixin.py:151} INFO - [2024-08-20T22:20:17.636+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T22:20:17.666+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T22:20:17.704+0000] {logging_mixin.py:151} INFO - [2024-08-20T22:20:17.704+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T22:20:17.729+0000] {logging_mixin.py:151} INFO - [2024-08-20T22:20:17.729+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T22:20:17.745+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-08-20T22:30:04.779+0000] {processor.py:157} INFO - Started process (PID=81389) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T22:30:04.782+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T22:30:04.796+0000] {logging_mixin.py:151} INFO - [2024-08-20T22:30:04.795+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T22:30:04.834+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T22:30:04.901+0000] {logging_mixin.py:151} INFO - [2024-08-20T22:30:04.901+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T22:30:04.943+0000] {logging_mixin.py:151} INFO - [2024-08-20T22:30:04.943+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T22:30:04.962+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.197 seconds
[2024-08-20T23:01:53.924+0000] {processor.py:157} INFO - Started process (PID=81399) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T23:01:53.927+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T23:01:53.929+0000] {logging_mixin.py:151} INFO - [2024-08-20T23:01:53.929+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T23:01:53.946+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T23:01:53.972+0000] {logging_mixin.py:151} INFO - [2024-08-20T23:01:53.972+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T23:01:53.989+0000] {logging_mixin.py:151} INFO - [2024-08-20T23:01:53.989+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T23:01:54.000+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-08-20T23:31:04.810+0000] {processor.py:157} INFO - Started process (PID=81410) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T23:31:04.813+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T23:31:04.816+0000] {logging_mixin.py:151} INFO - [2024-08-20T23:31:04.816+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T23:31:04.832+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T23:31:04.857+0000] {logging_mixin.py:151} INFO - [2024-08-20T23:31:04.857+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T23:31:04.872+0000] {logging_mixin.py:151} INFO - [2024-08-20T23:31:04.872+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T23:31:04.883+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-08-20T23:49:37.988+0000] {processor.py:157} INFO - Started process (PID=81419) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T23:49:37.990+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T23:49:37.999+0000] {logging_mixin.py:151} INFO - [2024-08-20T23:49:37.998+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T23:49:38.100+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T23:49:38.184+0000] {logging_mixin.py:151} INFO - [2024-08-20T23:49:38.183+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T23:49:38.226+0000] {logging_mixin.py:151} INFO - [2024-08-20T23:49:38.225+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T23:49:38.296+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.317 seconds
[2024-08-20T23:50:08.945+0000] {processor.py:157} INFO - Started process (PID=81430) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T23:50:08.947+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T23:50:08.953+0000] {logging_mixin.py:151} INFO - [2024-08-20T23:50:08.952+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T23:50:08.976+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T23:50:09.009+0000] {logging_mixin.py:151} INFO - [2024-08-20T23:50:09.009+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T23:50:09.024+0000] {logging_mixin.py:151} INFO - [2024-08-20T23:50:09.024+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T23:50:09.036+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-08-20T23:50:39.295+0000] {processor.py:157} INFO - Started process (PID=81440) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T23:50:39.298+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T23:50:39.301+0000] {logging_mixin.py:151} INFO - [2024-08-20T23:50:39.300+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T23:50:39.325+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T23:50:39.354+0000] {logging_mixin.py:151} INFO - [2024-08-20T23:50:39.354+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T23:50:39.369+0000] {logging_mixin.py:151} INFO - [2024-08-20T23:50:39.369+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T23:50:39.380+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-08-20T23:51:09.825+0000] {processor.py:157} INFO - Started process (PID=81450) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T23:51:09.828+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T23:51:09.832+0000] {logging_mixin.py:151} INFO - [2024-08-20T23:51:09.832+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T23:51:09.862+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T23:51:09.901+0000] {logging_mixin.py:151} INFO - [2024-08-20T23:51:09.901+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T23:51:09.920+0000] {logging_mixin.py:151} INFO - [2024-08-20T23:51:09.920+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T23:51:09.933+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-08-20T23:51:40.254+0000] {processor.py:157} INFO - Started process (PID=81460) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T23:51:40.255+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T23:51:40.260+0000] {logging_mixin.py:151} INFO - [2024-08-20T23:51:40.259+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T23:51:40.289+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T23:51:40.331+0000] {logging_mixin.py:151} INFO - [2024-08-20T23:51:40.330+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T23:51:40.346+0000] {logging_mixin.py:151} INFO - [2024-08-20T23:51:40.346+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T23:51:40.362+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-08-20T23:52:10.652+0000] {processor.py:157} INFO - Started process (PID=81470) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T23:52:10.657+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T23:52:10.666+0000] {logging_mixin.py:151} INFO - [2024-08-20T23:52:10.665+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T23:52:10.691+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T23:52:10.748+0000] {logging_mixin.py:151} INFO - [2024-08-20T23:52:10.748+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T23:52:10.769+0000] {logging_mixin.py:151} INFO - [2024-08-20T23:52:10.769+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T23:52:10.783+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-08-20T23:52:41.299+0000] {processor.py:157} INFO - Started process (PID=81480) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T23:52:41.318+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T23:52:41.328+0000] {logging_mixin.py:151} INFO - [2024-08-20T23:52:41.324+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T23:52:41.424+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T23:52:41.555+0000] {logging_mixin.py:151} INFO - [2024-08-20T23:52:41.553+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T23:52:41.575+0000] {logging_mixin.py:151} INFO - [2024-08-20T23:52:41.575+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T23:52:41.592+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.409 seconds
[2024-08-20T23:53:11.994+0000] {processor.py:157} INFO - Started process (PID=81490) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T23:53:12.007+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T23:53:12.021+0000] {logging_mixin.py:151} INFO - [2024-08-20T23:53:12.018+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T23:53:12.071+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T23:53:12.126+0000] {logging_mixin.py:151} INFO - [2024-08-20T23:53:12.125+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T23:53:12.143+0000] {logging_mixin.py:151} INFO - [2024-08-20T23:53:12.143+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T23:53:12.160+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.177 seconds
[2024-08-20T23:53:42.425+0000] {processor.py:157} INFO - Started process (PID=81500) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T23:53:42.428+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T23:53:42.431+0000] {logging_mixin.py:151} INFO - [2024-08-20T23:53:42.430+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T23:53:42.457+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T23:53:42.487+0000] {logging_mixin.py:151} INFO - [2024-08-20T23:53:42.487+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T23:53:42.501+0000] {logging_mixin.py:151} INFO - [2024-08-20T23:53:42.501+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T23:53:42.513+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-08-20T23:54:12.864+0000] {processor.py:157} INFO - Started process (PID=81510) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T23:54:12.866+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T23:54:12.870+0000] {logging_mixin.py:151} INFO - [2024-08-20T23:54:12.870+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T23:54:12.888+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T23:54:12.922+0000] {logging_mixin.py:151} INFO - [2024-08-20T23:54:12.921+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T23:54:12.935+0000] {logging_mixin.py:151} INFO - [2024-08-20T23:54:12.935+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T23:54:12.950+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-08-20T23:54:43.314+0000] {processor.py:157} INFO - Started process (PID=81520) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T23:54:43.318+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T23:54:43.328+0000] {logging_mixin.py:151} INFO - [2024-08-20T23:54:43.327+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T23:54:43.347+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T23:54:43.376+0000] {logging_mixin.py:151} INFO - [2024-08-20T23:54:43.376+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T23:54:43.393+0000] {logging_mixin.py:151} INFO - [2024-08-20T23:54:43.393+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T23:54:43.407+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-08-20T23:55:13.803+0000] {processor.py:157} INFO - Started process (PID=81530) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T23:55:13.809+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T23:55:13.814+0000] {logging_mixin.py:151} INFO - [2024-08-20T23:55:13.813+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T23:55:13.834+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T23:55:13.855+0000] {logging_mixin.py:151} INFO - [2024-08-20T23:55:13.855+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T23:55:13.868+0000] {logging_mixin.py:151} INFO - [2024-08-20T23:55:13.867+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T23:55:13.888+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-08-20T23:55:44.107+0000] {processor.py:157} INFO - Started process (PID=81540) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T23:55:44.108+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T23:55:44.110+0000] {logging_mixin.py:151} INFO - [2024-08-20T23:55:44.110+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T23:55:44.121+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T23:55:44.136+0000] {logging_mixin.py:151} INFO - [2024-08-20T23:55:44.135+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T23:55:44.148+0000] {logging_mixin.py:151} INFO - [2024-08-20T23:55:44.148+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T23:55:44.158+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-20T23:56:14.540+0000] {processor.py:157} INFO - Started process (PID=81550) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T23:56:14.543+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T23:56:14.546+0000] {logging_mixin.py:151} INFO - [2024-08-20T23:56:14.546+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T23:56:14.578+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T23:56:14.603+0000] {logging_mixin.py:151} INFO - [2024-08-20T23:56:14.603+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T23:56:14.616+0000] {logging_mixin.py:151} INFO - [2024-08-20T23:56:14.616+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T23:56:14.627+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-08-20T23:56:44.913+0000] {processor.py:157} INFO - Started process (PID=81559) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T23:56:44.915+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T23:56:44.921+0000] {logging_mixin.py:151} INFO - [2024-08-20T23:56:44.921+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T23:56:44.952+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T23:56:44.986+0000] {logging_mixin.py:151} INFO - [2024-08-20T23:56:44.986+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T23:56:45.000+0000] {logging_mixin.py:151} INFO - [2024-08-20T23:56:44.999+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T23:56:45.012+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-08-20T23:57:15.263+0000] {processor.py:157} INFO - Started process (PID=81569) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T23:57:15.272+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T23:57:15.282+0000] {logging_mixin.py:151} INFO - [2024-08-20T23:57:15.281+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T23:57:15.299+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T23:57:15.329+0000] {logging_mixin.py:151} INFO - [2024-08-20T23:57:15.329+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T23:57:15.354+0000] {logging_mixin.py:151} INFO - [2024-08-20T23:57:15.354+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T23:57:15.364+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-08-20T23:57:45.557+0000] {processor.py:157} INFO - Started process (PID=81580) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T23:57:45.559+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T23:57:45.561+0000] {logging_mixin.py:151} INFO - [2024-08-20T23:57:45.561+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T23:57:45.573+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T23:57:45.590+0000] {logging_mixin.py:151} INFO - [2024-08-20T23:57:45.590+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T23:57:45.601+0000] {logging_mixin.py:151} INFO - [2024-08-20T23:57:45.601+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T23:57:45.610+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-20T23:58:15.958+0000] {processor.py:157} INFO - Started process (PID=81590) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T23:58:15.959+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T23:58:15.965+0000] {logging_mixin.py:151} INFO - [2024-08-20T23:58:15.964+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T23:58:15.981+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T23:58:16.007+0000] {logging_mixin.py:151} INFO - [2024-08-20T23:58:16.006+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T23:58:16.019+0000] {logging_mixin.py:151} INFO - [2024-08-20T23:58:16.019+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T23:58:16.031+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-08-20T23:58:46.371+0000] {processor.py:157} INFO - Started process (PID=81600) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T23:58:46.372+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T23:58:46.384+0000] {logging_mixin.py:151} INFO - [2024-08-20T23:58:46.384+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T23:58:46.403+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T23:58:46.429+0000] {logging_mixin.py:151} INFO - [2024-08-20T23:58:46.429+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T23:58:46.444+0000] {logging_mixin.py:151} INFO - [2024-08-20T23:58:46.444+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T23:58:46.455+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-20T23:59:16.695+0000] {processor.py:157} INFO - Started process (PID=81610) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T23:59:16.696+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T23:59:16.699+0000] {logging_mixin.py:151} INFO - [2024-08-20T23:59:16.699+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T23:59:16.713+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T23:59:16.734+0000] {logging_mixin.py:151} INFO - [2024-08-20T23:59:16.734+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T23:59:16.748+0000] {logging_mixin.py:151} INFO - [2024-08-20T23:59:16.748+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T23:59:16.759+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-20T23:59:47.025+0000] {processor.py:157} INFO - Started process (PID=81620) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-20T23:59:47.028+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-20T23:59:47.030+0000] {logging_mixin.py:151} INFO - [2024-08-20T23:59:47.030+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T23:59:47.051+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-20T23:59:47.074+0000] {logging_mixin.py:151} INFO - [2024-08-20T23:59:47.074+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-20T23:59:47.089+0000] {logging_mixin.py:151} INFO - [2024-08-20T23:59:47.089+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-20T23:59:47.098+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
