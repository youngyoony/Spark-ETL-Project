[2024-08-01T00:03:40.733+0000] {processor.py:157} INFO - Started process (PID=14999) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T00:03:40.734+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T00:03:40.745+0000] {logging_mixin.py:151} INFO - [2024-08-01T00:03:40.744+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T00:03:40.784+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T00:03:40.825+0000] {logging_mixin.py:151} INFO - [2024-08-01T00:03:40.825+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T00:03:40.858+0000] {logging_mixin.py:151} INFO - [2024-08-01T00:03:40.858+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-31T01:00:00+00:00, run_after=2024-08-01T01:00:00+00:00
[2024-08-01T00:03:40.876+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.147 seconds
[2024-08-01T00:04:11.615+0000] {processor.py:157} INFO - Started process (PID=15024) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T00:04:11.616+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T00:04:11.626+0000] {logging_mixin.py:151} INFO - [2024-08-01T00:04:11.625+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T00:04:11.644+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T00:04:11.673+0000] {logging_mixin.py:151} INFO - [2024-08-01T00:04:11.673+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T00:04:11.688+0000] {logging_mixin.py:151} INFO - [2024-08-01T00:04:11.687+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-31T01:00:00+00:00, run_after=2024-08-01T01:00:00+00:00
[2024-08-01T00:04:11.700+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-08-01T00:04:42.129+0000] {processor.py:157} INFO - Started process (PID=15050) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T00:04:42.130+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T00:04:42.132+0000] {logging_mixin.py:151} INFO - [2024-08-01T00:04:42.132+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T00:04:42.147+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T00:04:42.162+0000] {logging_mixin.py:151} INFO - [2024-08-01T00:04:42.161+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T00:04:42.174+0000] {logging_mixin.py:151} INFO - [2024-08-01T00:04:42.174+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-31T01:00:00+00:00, run_after=2024-08-01T01:00:00+00:00
[2024-08-01T00:04:42.183+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-01T00:05:12.609+0000] {processor.py:157} INFO - Started process (PID=15075) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T00:05:12.610+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T00:05:12.614+0000] {logging_mixin.py:151} INFO - [2024-08-01T00:05:12.613+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T00:05:12.631+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T00:05:12.653+0000] {logging_mixin.py:151} INFO - [2024-08-01T00:05:12.653+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T00:05:12.665+0000] {logging_mixin.py:151} INFO - [2024-08-01T00:05:12.665+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-31T01:00:00+00:00, run_after=2024-08-01T01:00:00+00:00
[2024-08-01T00:05:12.674+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-01T00:19:25.257+0000] {processor.py:157} INFO - Started process (PID=15100) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T00:19:25.258+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T00:19:25.263+0000] {logging_mixin.py:151} INFO - [2024-08-01T00:19:25.262+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T00:19:25.285+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T00:19:25.335+0000] {logging_mixin.py:151} INFO - [2024-08-01T00:19:25.335+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T00:19:25.363+0000] {logging_mixin.py:151} INFO - [2024-08-01T00:19:25.363+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-31T01:00:00+00:00, run_after=2024-08-01T01:00:00+00:00
[2024-08-01T00:19:25.395+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.145 seconds
[2024-08-01T00:19:56.082+0000] {processor.py:157} INFO - Started process (PID=15124) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T00:19:56.084+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T00:19:56.087+0000] {logging_mixin.py:151} INFO - [2024-08-01T00:19:56.087+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T00:19:56.106+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T00:19:56.130+0000] {logging_mixin.py:151} INFO - [2024-08-01T00:19:56.130+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T00:19:56.143+0000] {logging_mixin.py:151} INFO - [2024-08-01T00:19:56.142+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-31T01:00:00+00:00, run_after=2024-08-01T01:00:00+00:00
[2024-08-01T00:19:56.155+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-08-01T00:20:26.637+0000] {processor.py:157} INFO - Started process (PID=15150) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T00:20:26.638+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T00:20:26.641+0000] {logging_mixin.py:151} INFO - [2024-08-01T00:20:26.641+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T00:20:26.652+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T00:20:26.669+0000] {logging_mixin.py:151} INFO - [2024-08-01T00:20:26.669+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T00:20:26.679+0000] {logging_mixin.py:151} INFO - [2024-08-01T00:20:26.679+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-31T01:00:00+00:00, run_after=2024-08-01T01:00:00+00:00
[2024-08-01T00:20:26.689+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-01T00:20:57.129+0000] {processor.py:157} INFO - Started process (PID=15175) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T00:20:57.133+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T00:20:57.136+0000] {logging_mixin.py:151} INFO - [2024-08-01T00:20:57.136+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T00:20:57.153+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T00:20:57.169+0000] {logging_mixin.py:151} INFO - [2024-08-01T00:20:57.169+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T00:20:57.179+0000] {logging_mixin.py:151} INFO - [2024-08-01T00:20:57.179+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-31T01:00:00+00:00, run_after=2024-08-01T01:00:00+00:00
[2024-08-01T00:20:57.188+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-01T00:21:27.625+0000] {processor.py:157} INFO - Started process (PID=15200) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T00:21:27.625+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T00:21:27.627+0000] {logging_mixin.py:151} INFO - [2024-08-01T00:21:27.627+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T00:21:27.643+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T00:21:27.658+0000] {logging_mixin.py:151} INFO - [2024-08-01T00:21:27.658+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T00:21:27.670+0000] {logging_mixin.py:151} INFO - [2024-08-01T00:21:27.670+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-31T01:00:00+00:00, run_after=2024-08-01T01:00:00+00:00
[2024-08-01T00:21:27.679+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-01T00:38:27.284+0000] {processor.py:157} INFO - Started process (PID=15225) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T00:38:27.287+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T00:38:27.298+0000] {logging_mixin.py:151} INFO - [2024-08-01T00:38:27.297+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T00:38:27.343+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T00:38:27.392+0000] {logging_mixin.py:151} INFO - [2024-08-01T00:38:27.392+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T00:38:27.430+0000] {logging_mixin.py:151} INFO - [2024-08-01T00:38:27.430+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-31T01:00:00+00:00, run_after=2024-08-01T01:00:00+00:00
[2024-08-01T00:38:27.466+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.188 seconds
[2024-08-01T00:38:57.922+0000] {processor.py:157} INFO - Started process (PID=15643) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T00:38:57.927+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T00:38:57.943+0000] {logging_mixin.py:151} INFO - [2024-08-01T00:38:57.943+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T00:38:57.960+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T00:38:57.988+0000] {logging_mixin.py:151} INFO - [2024-08-01T00:38:57.988+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T00:38:58.000+0000] {logging_mixin.py:151} INFO - [2024-08-01T00:38:58.000+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-31T01:00:00+00:00, run_after=2024-08-01T01:00:00+00:00
[2024-08-01T00:38:58.009+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-08-01T00:39:28.527+0000] {processor.py:157} INFO - Started process (PID=15668) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T00:39:28.528+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T00:39:28.530+0000] {logging_mixin.py:151} INFO - [2024-08-01T00:39:28.530+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T00:39:28.554+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T00:39:28.589+0000] {logging_mixin.py:151} INFO - [2024-08-01T00:39:28.589+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T00:39:28.604+0000] {logging_mixin.py:151} INFO - [2024-08-01T00:39:28.604+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-31T01:00:00+00:00, run_after=2024-08-01T01:00:00+00:00
[2024-08-01T00:39:28.614+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-08-01T00:39:59.013+0000] {processor.py:157} INFO - Started process (PID=15693) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T00:39:59.015+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T00:39:59.017+0000] {logging_mixin.py:151} INFO - [2024-08-01T00:39:59.016+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T00:39:59.054+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T00:39:59.078+0000] {logging_mixin.py:151} INFO - [2024-08-01T00:39:59.078+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T00:39:59.090+0000] {logging_mixin.py:151} INFO - [2024-08-01T00:39:59.090+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-31T01:00:00+00:00, run_after=2024-08-01T01:00:00+00:00
[2024-08-01T00:39:59.098+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-01T00:40:29.570+0000] {processor.py:157} INFO - Started process (PID=15718) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T00:40:29.573+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T00:40:29.575+0000] {logging_mixin.py:151} INFO - [2024-08-01T00:40:29.575+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T00:40:29.590+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T00:40:29.610+0000] {logging_mixin.py:151} INFO - [2024-08-01T00:40:29.610+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T00:40:29.625+0000] {logging_mixin.py:151} INFO - [2024-08-01T00:40:29.625+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-31T01:00:00+00:00, run_after=2024-08-01T01:00:00+00:00
[2024-08-01T00:40:29.639+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-01T00:57:49.903+0000] {processor.py:157} INFO - Started process (PID=15746) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T00:57:49.904+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T00:57:49.905+0000] {logging_mixin.py:151} INFO - [2024-08-01T00:57:49.905+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T00:57:49.933+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T00:57:49.956+0000] {logging_mixin.py:151} INFO - [2024-08-01T00:57:49.956+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T00:57:49.967+0000] {logging_mixin.py:151} INFO - [2024-08-01T00:57:49.967+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-31T01:00:00+00:00, run_after=2024-08-01T01:00:00+00:00
[2024-08-01T00:57:49.977+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-08-01T00:58:20.408+0000] {processor.py:157} INFO - Started process (PID=15770) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T00:58:20.410+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T00:58:20.417+0000] {logging_mixin.py:151} INFO - [2024-08-01T00:58:20.416+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T00:58:20.438+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T00:58:20.464+0000] {logging_mixin.py:151} INFO - [2024-08-01T00:58:20.464+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T00:58:20.480+0000] {logging_mixin.py:151} INFO - [2024-08-01T00:58:20.480+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-31T01:00:00+00:00, run_after=2024-08-01T01:00:00+00:00
[2024-08-01T00:58:20.495+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-08-01T00:58:50.960+0000] {processor.py:157} INFO - Started process (PID=15796) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T00:58:50.961+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T00:58:50.963+0000] {logging_mixin.py:151} INFO - [2024-08-01T00:58:50.963+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T00:58:50.974+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T00:58:50.990+0000] {logging_mixin.py:151} INFO - [2024-08-01T00:58:50.990+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T00:58:51.001+0000] {logging_mixin.py:151} INFO - [2024-08-01T00:58:51.001+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-31T01:00:00+00:00, run_after=2024-08-01T01:00:00+00:00
[2024-08-01T00:58:51.010+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-01T00:59:21.469+0000] {processor.py:157} INFO - Started process (PID=15821) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T00:59:21.473+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T00:59:21.476+0000] {logging_mixin.py:151} INFO - [2024-08-01T00:59:21.476+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T00:59:21.514+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T00:59:21.541+0000] {logging_mixin.py:151} INFO - [2024-08-01T00:59:21.541+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T00:59:21.554+0000] {logging_mixin.py:151} INFO - [2024-08-01T00:59:21.553+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-31T01:00:00+00:00, run_after=2024-08-01T01:00:00+00:00
[2024-08-01T00:59:21.564+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-08-01T00:59:52.062+0000] {processor.py:157} INFO - Started process (PID=15846) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T00:59:52.064+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T00:59:52.066+0000] {logging_mixin.py:151} INFO - [2024-08-01T00:59:52.066+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T00:59:52.077+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T00:59:52.093+0000] {logging_mixin.py:151} INFO - [2024-08-01T00:59:52.093+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T00:59:52.104+0000] {logging_mixin.py:151} INFO - [2024-08-01T00:59:52.104+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-31T01:00:00+00:00, run_after=2024-08-01T01:00:00+00:00
[2024-08-01T00:59:52.114+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-01T01:16:54.197+0000] {processor.py:157} INFO - Started process (PID=16264) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T01:16:54.203+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T01:16:54.209+0000] {logging_mixin.py:151} INFO - [2024-08-01T01:16:54.209+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T01:16:54.235+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T01:16:54.275+0000] {logging_mixin.py:151} INFO - [2024-08-01T01:16:54.275+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T01:16:54.307+0000] {logging_mixin.py:151} INFO - [2024-08-01T01:16:54.306+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T01:16:54.329+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-08-01T01:17:24.842+0000] {processor.py:157} INFO - Started process (PID=16291) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T01:17:24.845+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T01:17:24.848+0000] {logging_mixin.py:151} INFO - [2024-08-01T01:17:24.847+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T01:17:24.870+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T01:17:24.917+0000] {logging_mixin.py:151} INFO - [2024-08-01T01:17:24.917+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T01:17:24.933+0000] {logging_mixin.py:151} INFO - [2024-08-01T01:17:24.933+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T01:17:24.945+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-08-01T01:17:55.339+0000] {processor.py:157} INFO - Started process (PID=16316) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T01:17:55.340+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T01:17:55.342+0000] {logging_mixin.py:151} INFO - [2024-08-01T01:17:55.342+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T01:17:55.359+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T01:17:55.375+0000] {logging_mixin.py:151} INFO - [2024-08-01T01:17:55.375+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T01:17:55.386+0000] {logging_mixin.py:151} INFO - [2024-08-01T01:17:55.386+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T01:17:55.395+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-01T01:18:25.822+0000] {processor.py:157} INFO - Started process (PID=16341) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T01:18:25.823+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T01:18:25.827+0000] {logging_mixin.py:151} INFO - [2024-08-01T01:18:25.827+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T01:18:25.844+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T01:18:25.861+0000] {logging_mixin.py:151} INFO - [2024-08-01T01:18:25.861+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T01:18:25.873+0000] {logging_mixin.py:151} INFO - [2024-08-01T01:18:25.873+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T01:18:25.882+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-01T01:35:57.965+0000] {processor.py:157} INFO - Started process (PID=16368) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T01:35:57.967+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T01:35:57.973+0000] {logging_mixin.py:151} INFO - [2024-08-01T01:35:57.972+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T01:35:58.013+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T01:35:58.057+0000] {logging_mixin.py:151} INFO - [2024-08-01T01:35:58.056+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T01:35:58.090+0000] {logging_mixin.py:151} INFO - [2024-08-01T01:35:58.090+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T01:35:58.115+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.153 seconds
[2024-08-01T01:36:28.658+0000] {processor.py:157} INFO - Started process (PID=16393) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T01:36:28.660+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T01:36:28.665+0000] {logging_mixin.py:151} INFO - [2024-08-01T01:36:28.664+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T01:36:28.704+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T01:36:28.734+0000] {logging_mixin.py:151} INFO - [2024-08-01T01:36:28.734+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T01:36:28.748+0000] {logging_mixin.py:151} INFO - [2024-08-01T01:36:28.748+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T01:36:28.761+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-08-01T01:36:59.178+0000] {processor.py:157} INFO - Started process (PID=16418) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T01:36:59.179+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T01:36:59.182+0000] {logging_mixin.py:151} INFO - [2024-08-01T01:36:59.182+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T01:36:59.198+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T01:36:59.215+0000] {logging_mixin.py:151} INFO - [2024-08-01T01:36:59.214+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T01:36:59.225+0000] {logging_mixin.py:151} INFO - [2024-08-01T01:36:59.225+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T01:36:59.233+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-01T01:37:29.598+0000] {processor.py:157} INFO - Started process (PID=16443) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T01:37:29.600+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T01:37:29.602+0000] {logging_mixin.py:151} INFO - [2024-08-01T01:37:29.602+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T01:37:29.618+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T01:37:29.638+0000] {logging_mixin.py:151} INFO - [2024-08-01T01:37:29.638+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T01:37:29.649+0000] {logging_mixin.py:151} INFO - [2024-08-01T01:37:29.649+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T01:37:29.659+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-01T01:52:16.358+0000] {processor.py:157} INFO - Started process (PID=16470) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T01:52:16.360+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T01:52:16.363+0000] {logging_mixin.py:151} INFO - [2024-08-01T01:52:16.363+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T01:52:16.388+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T01:52:16.421+0000] {logging_mixin.py:151} INFO - [2024-08-01T01:52:16.421+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T01:52:16.438+0000] {logging_mixin.py:151} INFO - [2024-08-01T01:52:16.438+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T01:52:16.449+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-08-01T01:52:47.157+0000] {processor.py:157} INFO - Started process (PID=16495) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T01:52:47.158+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T01:52:47.163+0000] {logging_mixin.py:151} INFO - [2024-08-01T01:52:47.162+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T01:52:47.191+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T01:52:47.216+0000] {logging_mixin.py:151} INFO - [2024-08-01T01:52:47.216+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T01:52:47.230+0000] {logging_mixin.py:151} INFO - [2024-08-01T01:52:47.230+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T01:52:47.242+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-08-01T01:53:17.658+0000] {processor.py:157} INFO - Started process (PID=16520) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T01:53:17.667+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T01:53:17.668+0000] {logging_mixin.py:151} INFO - [2024-08-01T01:53:17.668+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T01:53:17.679+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T01:53:17.693+0000] {logging_mixin.py:151} INFO - [2024-08-01T01:53:17.693+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T01:53:17.701+0000] {logging_mixin.py:151} INFO - [2024-08-01T01:53:17.701+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T01:53:17.709+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-01T01:53:48.159+0000] {processor.py:157} INFO - Started process (PID=16545) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T01:53:48.161+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T01:53:48.163+0000] {logging_mixin.py:151} INFO - [2024-08-01T01:53:48.163+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T01:53:48.176+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T01:53:48.193+0000] {logging_mixin.py:151} INFO - [2024-08-01T01:53:48.193+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T01:53:48.203+0000] {logging_mixin.py:151} INFO - [2024-08-01T01:53:48.203+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T01:53:48.213+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-01T01:54:18.588+0000] {processor.py:157} INFO - Started process (PID=16570) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T01:54:18.592+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T01:54:18.595+0000] {logging_mixin.py:151} INFO - [2024-08-01T01:54:18.595+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T01:54:18.610+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T01:54:18.631+0000] {logging_mixin.py:151} INFO - [2024-08-01T01:54:18.631+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T01:54:18.643+0000] {logging_mixin.py:151} INFO - [2024-08-01T01:54:18.643+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T01:54:18.653+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-01T01:54:48.823+0000] {processor.py:157} INFO - Started process (PID=16595) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T01:54:48.825+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T01:54:48.827+0000] {logging_mixin.py:151} INFO - [2024-08-01T01:54:48.827+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T01:54:48.838+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T01:54:48.853+0000] {logging_mixin.py:151} INFO - [2024-08-01T01:54:48.853+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T01:54:48.863+0000] {logging_mixin.py:151} INFO - [2024-08-01T01:54:48.863+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T01:54:48.871+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-01T01:55:19.315+0000] {processor.py:157} INFO - Started process (PID=16620) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T01:55:19.317+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T01:55:19.319+0000] {logging_mixin.py:151} INFO - [2024-08-01T01:55:19.319+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T01:55:19.336+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T01:55:19.349+0000] {logging_mixin.py:151} INFO - [2024-08-01T01:55:19.349+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T01:55:19.359+0000] {logging_mixin.py:151} INFO - [2024-08-01T01:55:19.359+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T01:55:19.369+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-01T02:13:22.857+0000] {processor.py:157} INFO - Started process (PID=16645) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T02:13:22.858+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T02:13:22.861+0000] {logging_mixin.py:151} INFO - [2024-08-01T02:13:22.861+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T02:13:22.872+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T02:13:22.889+0000] {logging_mixin.py:151} INFO - [2024-08-01T02:13:22.888+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T02:13:22.898+0000] {logging_mixin.py:151} INFO - [2024-08-01T02:13:22.898+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T02:13:22.906+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-01T02:13:53.332+0000] {processor.py:157} INFO - Started process (PID=16670) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T02:13:53.335+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T02:13:53.337+0000] {logging_mixin.py:151} INFO - [2024-08-01T02:13:53.337+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T02:13:53.350+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T02:13:53.369+0000] {logging_mixin.py:151} INFO - [2024-08-01T02:13:53.368+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T02:13:53.381+0000] {logging_mixin.py:151} INFO - [2024-08-01T02:13:53.381+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T02:13:53.391+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-01T02:14:23.709+0000] {processor.py:157} INFO - Started process (PID=16695) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T02:14:23.710+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T02:14:23.712+0000] {logging_mixin.py:151} INFO - [2024-08-01T02:14:23.712+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T02:14:23.727+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T02:14:23.739+0000] {logging_mixin.py:151} INFO - [2024-08-01T02:14:23.739+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T02:14:23.748+0000] {logging_mixin.py:151} INFO - [2024-08-01T02:14:23.748+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T02:14:23.757+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-01T02:14:54.168+0000] {processor.py:157} INFO - Started process (PID=16720) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T02:14:54.170+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T02:14:54.171+0000] {logging_mixin.py:151} INFO - [2024-08-01T02:14:54.171+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T02:14:54.186+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T02:14:54.200+0000] {logging_mixin.py:151} INFO - [2024-08-01T02:14:54.200+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T02:14:54.211+0000] {logging_mixin.py:151} INFO - [2024-08-01T02:14:54.210+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T02:14:54.218+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-01T02:31:41.933+0000] {processor.py:157} INFO - Started process (PID=16747) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T02:31:41.934+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T02:31:41.944+0000] {logging_mixin.py:151} INFO - [2024-08-01T02:31:41.942+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T02:31:41.979+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T02:31:42.019+0000] {logging_mixin.py:151} INFO - [2024-08-01T02:31:42.019+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T02:31:42.053+0000] {logging_mixin.py:151} INFO - [2024-08-01T02:31:42.053+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T02:31:42.076+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.152 seconds
[2024-08-01T02:45:53.583+0000] {processor.py:157} INFO - Started process (PID=16774) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T02:45:53.584+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T02:45:53.586+0000] {logging_mixin.py:151} INFO - [2024-08-01T02:45:53.585+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T02:45:53.595+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T02:45:53.617+0000] {logging_mixin.py:151} INFO - [2024-08-01T02:45:53.617+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T02:45:53.638+0000] {logging_mixin.py:151} INFO - [2024-08-01T02:45:53.638+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T02:45:53.651+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-01T02:46:24.163+0000] {processor.py:157} INFO - Started process (PID=16799) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T02:46:24.165+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T02:46:24.171+0000] {logging_mixin.py:151} INFO - [2024-08-01T02:46:24.171+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T02:46:24.196+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T02:46:24.236+0000] {logging_mixin.py:151} INFO - [2024-08-01T02:46:24.236+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T02:46:24.253+0000] {logging_mixin.py:151} INFO - [2024-08-01T02:46:24.252+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T02:46:24.264+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-08-01T02:46:54.674+0000] {processor.py:157} INFO - Started process (PID=16824) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T02:46:54.675+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T02:46:54.677+0000] {logging_mixin.py:151} INFO - [2024-08-01T02:46:54.677+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T02:46:54.687+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T02:46:54.704+0000] {logging_mixin.py:151} INFO - [2024-08-01T02:46:54.704+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T02:46:54.714+0000] {logging_mixin.py:151} INFO - [2024-08-01T02:46:54.714+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T02:46:54.726+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-01T02:47:25.076+0000] {processor.py:157} INFO - Started process (PID=16849) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T02:47:25.077+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T02:47:25.079+0000] {logging_mixin.py:151} INFO - [2024-08-01T02:47:25.078+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T02:47:25.089+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T02:47:25.105+0000] {logging_mixin.py:151} INFO - [2024-08-01T02:47:25.105+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T02:47:25.115+0000] {logging_mixin.py:151} INFO - [2024-08-01T02:47:25.115+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T02:47:25.123+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-01T02:47:55.527+0000] {processor.py:157} INFO - Started process (PID=16874) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T02:47:55.529+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T02:47:55.531+0000] {logging_mixin.py:151} INFO - [2024-08-01T02:47:55.530+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T02:47:55.545+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T02:47:55.561+0000] {logging_mixin.py:151} INFO - [2024-08-01T02:47:55.560+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T02:47:55.569+0000] {logging_mixin.py:151} INFO - [2024-08-01T02:47:55.569+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T02:47:55.580+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-01T02:48:26.067+0000] {processor.py:157} INFO - Started process (PID=16899) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T02:48:26.068+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T02:48:26.070+0000] {logging_mixin.py:151} INFO - [2024-08-01T02:48:26.070+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T02:48:26.081+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T02:48:26.097+0000] {logging_mixin.py:151} INFO - [2024-08-01T02:48:26.097+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T02:48:26.107+0000] {logging_mixin.py:151} INFO - [2024-08-01T02:48:26.107+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T02:48:26.117+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-01T03:04:24.757+0000] {processor.py:157} INFO - Started process (PID=16925) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T03:04:24.759+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T03:04:24.762+0000] {logging_mixin.py:151} INFO - [2024-08-01T03:04:24.762+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T03:04:24.788+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T03:04:24.819+0000] {logging_mixin.py:151} INFO - [2024-08-01T03:04:24.819+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T03:04:24.841+0000] {logging_mixin.py:151} INFO - [2024-08-01T03:04:24.841+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T03:04:24.862+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-08-01T03:04:55.430+0000] {processor.py:157} INFO - Started process (PID=16951) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T03:04:55.432+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T03:04:55.434+0000] {logging_mixin.py:151} INFO - [2024-08-01T03:04:55.433+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T03:04:55.449+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T03:04:55.468+0000] {logging_mixin.py:151} INFO - [2024-08-01T03:04:55.468+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T03:04:55.478+0000] {logging_mixin.py:151} INFO - [2024-08-01T03:04:55.478+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T03:04:55.490+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-01T03:05:25.820+0000] {processor.py:157} INFO - Started process (PID=16976) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T03:05:25.823+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T03:05:25.825+0000] {logging_mixin.py:151} INFO - [2024-08-01T03:05:25.825+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T03:05:25.838+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T03:05:25.855+0000] {logging_mixin.py:151} INFO - [2024-08-01T03:05:25.855+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T03:05:25.867+0000] {logging_mixin.py:151} INFO - [2024-08-01T03:05:25.867+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T03:05:25.878+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-01T03:05:56.320+0000] {processor.py:157} INFO - Started process (PID=17001) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T03:05:56.320+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T03:05:56.323+0000] {logging_mixin.py:151} INFO - [2024-08-01T03:05:56.323+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T03:05:56.337+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T03:05:56.358+0000] {logging_mixin.py:151} INFO - [2024-08-01T03:05:56.358+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T03:05:56.369+0000] {logging_mixin.py:151} INFO - [2024-08-01T03:05:56.369+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T03:05:56.377+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-01T03:06:26.725+0000] {processor.py:157} INFO - Started process (PID=17026) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T03:06:26.726+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T03:06:26.728+0000] {logging_mixin.py:151} INFO - [2024-08-01T03:06:26.728+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T03:06:26.738+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T03:06:26.754+0000] {logging_mixin.py:151} INFO - [2024-08-01T03:06:26.754+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T03:06:26.764+0000] {logging_mixin.py:151} INFO - [2024-08-01T03:06:26.764+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T03:06:26.773+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-01T03:06:57.059+0000] {processor.py:157} INFO - Started process (PID=17051) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T03:06:57.060+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T03:06:57.062+0000] {logging_mixin.py:151} INFO - [2024-08-01T03:06:57.062+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T03:06:57.071+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T03:06:57.086+0000] {logging_mixin.py:151} INFO - [2024-08-01T03:06:57.086+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T03:06:57.096+0000] {logging_mixin.py:151} INFO - [2024-08-01T03:06:57.096+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T03:06:57.105+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-08-01T03:08:55.308+0000] {processor.py:157} INFO - Started process (PID=17076) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T03:08:55.310+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T03:08:55.314+0000] {logging_mixin.py:151} INFO - [2024-08-01T03:08:55.314+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T03:08:55.334+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T03:08:55.360+0000] {logging_mixin.py:151} INFO - [2024-08-01T03:08:55.360+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T03:08:55.373+0000] {logging_mixin.py:151} INFO - [2024-08-01T03:08:55.373+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T03:08:55.385+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-08-01T03:09:25.841+0000] {processor.py:157} INFO - Started process (PID=17101) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T03:09:25.843+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T03:09:25.845+0000] {logging_mixin.py:151} INFO - [2024-08-01T03:09:25.844+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T03:09:25.856+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T03:09:25.873+0000] {logging_mixin.py:151} INFO - [2024-08-01T03:09:25.872+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T03:09:25.882+0000] {logging_mixin.py:151} INFO - [2024-08-01T03:09:25.882+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T03:09:25.891+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-01T03:14:50.544+0000] {processor.py:157} INFO - Started process (PID=17125) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T03:14:50.551+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T03:14:50.557+0000] {logging_mixin.py:151} INFO - [2024-08-01T03:14:50.557+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T03:14:50.588+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T03:14:50.631+0000] {logging_mixin.py:151} INFO - [2024-08-01T03:14:50.631+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T03:14:50.648+0000] {logging_mixin.py:151} INFO - [2024-08-01T03:14:50.648+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T03:14:50.673+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-08-01T03:25:31.113+0000] {processor.py:157} INFO - Started process (PID=17153) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T03:25:31.117+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T03:25:31.121+0000] {logging_mixin.py:151} INFO - [2024-08-01T03:25:31.121+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T03:25:31.139+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T03:25:31.164+0000] {logging_mixin.py:151} INFO - [2024-08-01T03:25:31.163+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T03:25:31.183+0000] {logging_mixin.py:151} INFO - [2024-08-01T03:25:31.183+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T03:25:31.199+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-08-01T03:26:01.736+0000] {processor.py:157} INFO - Started process (PID=17178) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T03:26:01.739+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T03:26:01.742+0000] {logging_mixin.py:151} INFO - [2024-08-01T03:26:01.742+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T03:26:01.760+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T03:26:01.775+0000] {logging_mixin.py:151} INFO - [2024-08-01T03:26:01.775+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T03:26:01.785+0000] {logging_mixin.py:151} INFO - [2024-08-01T03:26:01.785+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T03:26:01.793+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-01T03:42:14.101+0000] {processor.py:157} INFO - Started process (PID=17202) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T03:42:14.103+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T03:42:14.106+0000] {logging_mixin.py:151} INFO - [2024-08-01T03:42:14.105+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T03:42:14.129+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T03:42:14.152+0000] {logging_mixin.py:151} INFO - [2024-08-01T03:42:14.152+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T03:42:14.170+0000] {logging_mixin.py:151} INFO - [2024-08-01T03:42:14.170+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T03:42:14.182+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-08-01T03:42:44.943+0000] {processor.py:157} INFO - Started process (PID=17228) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T03:42:44.945+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T03:42:44.951+0000] {logging_mixin.py:151} INFO - [2024-08-01T03:42:44.951+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T03:42:44.980+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T03:42:45.020+0000] {logging_mixin.py:151} INFO - [2024-08-01T03:42:45.020+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T03:42:45.043+0000] {logging_mixin.py:151} INFO - [2024-08-01T03:42:45.043+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T03:42:45.069+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.371 seconds
[2024-08-01T03:59:30.338+0000] {processor.py:157} INFO - Started process (PID=17253) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T03:59:30.339+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T03:59:30.341+0000] {logging_mixin.py:151} INFO - [2024-08-01T03:59:30.341+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T03:59:30.356+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T03:59:30.369+0000] {logging_mixin.py:151} INFO - [2024-08-01T03:59:30.369+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T03:59:30.378+0000] {logging_mixin.py:151} INFO - [2024-08-01T03:59:30.378+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T03:59:30.387+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-01T04:00:00.763+0000] {processor.py:157} INFO - Started process (PID=17278) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T04:00:00.765+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T04:00:00.769+0000] {logging_mixin.py:151} INFO - [2024-08-01T04:00:00.769+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T04:00:00.812+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T04:00:00.839+0000] {logging_mixin.py:151} INFO - [2024-08-01T04:00:00.839+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T04:00:00.852+0000] {logging_mixin.py:151} INFO - [2024-08-01T04:00:00.852+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T04:00:00.861+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-08-01T04:00:31.281+0000] {processor.py:157} INFO - Started process (PID=17303) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T04:00:31.282+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T04:00:31.284+0000] {logging_mixin.py:151} INFO - [2024-08-01T04:00:31.284+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T04:00:31.298+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T04:00:31.312+0000] {logging_mixin.py:151} INFO - [2024-08-01T04:00:31.312+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T04:00:31.327+0000] {logging_mixin.py:151} INFO - [2024-08-01T04:00:31.327+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T04:00:31.337+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-01T04:01:01.779+0000] {processor.py:157} INFO - Started process (PID=17328) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T04:01:01.780+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T04:01:01.782+0000] {logging_mixin.py:151} INFO - [2024-08-01T04:01:01.782+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T04:01:01.795+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T04:01:01.808+0000] {logging_mixin.py:151} INFO - [2024-08-01T04:01:01.808+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T04:01:01.818+0000] {logging_mixin.py:151} INFO - [2024-08-01T04:01:01.818+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T04:01:01.827+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-01T04:01:32.250+0000] {processor.py:157} INFO - Started process (PID=17353) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T04:01:32.253+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T04:01:32.255+0000] {logging_mixin.py:151} INFO - [2024-08-01T04:01:32.254+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T04:01:32.264+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T04:01:32.279+0000] {logging_mixin.py:151} INFO - [2024-08-01T04:01:32.279+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T04:01:32.289+0000] {logging_mixin.py:151} INFO - [2024-08-01T04:01:32.289+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T04:01:32.297+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-01T04:17:42.815+0000] {processor.py:157} INFO - Started process (PID=17378) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T04:17:42.816+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T04:17:42.818+0000] {logging_mixin.py:151} INFO - [2024-08-01T04:17:42.818+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T04:17:42.836+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T04:17:42.862+0000] {logging_mixin.py:151} INFO - [2024-08-01T04:17:42.862+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T04:17:42.891+0000] {logging_mixin.py:151} INFO - [2024-08-01T04:17:42.891+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T04:17:42.912+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-08-01T04:18:13.424+0000] {processor.py:157} INFO - Started process (PID=17403) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T04:18:13.425+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T04:18:13.427+0000] {logging_mixin.py:151} INFO - [2024-08-01T04:18:13.427+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T04:18:13.445+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T04:18:13.462+0000] {logging_mixin.py:151} INFO - [2024-08-01T04:18:13.462+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T04:18:13.472+0000] {logging_mixin.py:151} INFO - [2024-08-01T04:18:13.472+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T04:18:13.482+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-01T04:34:38.257+0000] {processor.py:157} INFO - Started process (PID=17430) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T04:34:38.261+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T04:34:38.268+0000] {logging_mixin.py:151} INFO - [2024-08-01T04:34:38.267+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T04:34:38.295+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T04:34:38.341+0000] {logging_mixin.py:151} INFO - [2024-08-01T04:34:38.341+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T04:34:38.373+0000] {logging_mixin.py:151} INFO - [2024-08-01T04:34:38.373+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T04:34:38.389+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-08-01T04:35:08.833+0000] {processor.py:157} INFO - Started process (PID=17455) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T04:35:08.836+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T04:35:08.840+0000] {logging_mixin.py:151} INFO - [2024-08-01T04:35:08.840+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T04:35:08.858+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T04:35:08.873+0000] {logging_mixin.py:151} INFO - [2024-08-01T04:35:08.873+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T04:35:08.883+0000] {logging_mixin.py:151} INFO - [2024-08-01T04:35:08.883+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T04:35:08.892+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-01T04:35:39.302+0000] {processor.py:157} INFO - Started process (PID=17480) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T04:35:39.305+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T04:35:39.307+0000] {logging_mixin.py:151} INFO - [2024-08-01T04:35:39.306+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T04:35:39.318+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T04:35:39.339+0000] {logging_mixin.py:151} INFO - [2024-08-01T04:35:39.339+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T04:35:39.351+0000] {logging_mixin.py:151} INFO - [2024-08-01T04:35:39.351+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T04:35:39.360+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-01T04:36:09.747+0000] {processor.py:157} INFO - Started process (PID=17505) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T04:36:09.748+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T04:36:09.751+0000] {logging_mixin.py:151} INFO - [2024-08-01T04:36:09.750+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T04:36:09.765+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T04:36:09.780+0000] {logging_mixin.py:151} INFO - [2024-08-01T04:36:09.780+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T04:36:09.789+0000] {logging_mixin.py:151} INFO - [2024-08-01T04:36:09.789+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T04:36:09.797+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-01T04:36:40.808+0000] {processor.py:157} INFO - Started process (PID=17530) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T04:36:40.809+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T04:36:40.810+0000] {logging_mixin.py:151} INFO - [2024-08-01T04:36:40.810+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T04:36:40.823+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T04:36:40.836+0000] {logging_mixin.py:151} INFO - [2024-08-01T04:36:40.836+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T04:36:40.846+0000] {logging_mixin.py:151} INFO - [2024-08-01T04:36:40.846+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T04:36:40.856+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-01T04:37:11.208+0000] {processor.py:157} INFO - Started process (PID=17555) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T04:37:11.209+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T04:37:11.211+0000] {logging_mixin.py:151} INFO - [2024-08-01T04:37:11.211+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T04:37:11.228+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T04:37:11.241+0000] {logging_mixin.py:151} INFO - [2024-08-01T04:37:11.241+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T04:37:11.252+0000] {logging_mixin.py:151} INFO - [2024-08-01T04:37:11.252+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T04:37:11.261+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-01T04:37:41.764+0000] {processor.py:157} INFO - Started process (PID=17580) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T04:37:41.767+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T04:37:41.769+0000] {logging_mixin.py:151} INFO - [2024-08-01T04:37:41.768+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T04:37:41.779+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T04:37:41.796+0000] {logging_mixin.py:151} INFO - [2024-08-01T04:37:41.796+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T04:37:41.806+0000] {logging_mixin.py:151} INFO - [2024-08-01T04:37:41.805+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T04:37:41.816+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-01T04:38:12.261+0000] {processor.py:157} INFO - Started process (PID=17605) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T04:38:12.262+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T04:38:12.264+0000] {logging_mixin.py:151} INFO - [2024-08-01T04:38:12.263+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T04:38:12.274+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T04:38:12.290+0000] {logging_mixin.py:151} INFO - [2024-08-01T04:38:12.290+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T04:38:12.300+0000] {logging_mixin.py:151} INFO - [2024-08-01T04:38:12.300+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T04:38:12.308+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-01T04:38:42.753+0000] {processor.py:157} INFO - Started process (PID=17630) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T04:38:42.756+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T04:38:42.758+0000] {logging_mixin.py:151} INFO - [2024-08-01T04:38:42.758+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T04:38:42.776+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T04:38:42.790+0000] {logging_mixin.py:151} INFO - [2024-08-01T04:38:42.790+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T04:38:42.800+0000] {logging_mixin.py:151} INFO - [2024-08-01T04:38:42.800+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T04:38:42.810+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-01T04:39:13.108+0000] {processor.py:157} INFO - Started process (PID=17655) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T04:39:13.109+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T04:39:13.110+0000] {logging_mixin.py:151} INFO - [2024-08-01T04:39:13.110+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T04:39:13.118+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T04:39:13.133+0000] {logging_mixin.py:151} INFO - [2024-08-01T04:39:13.132+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T04:39:13.141+0000] {logging_mixin.py:151} INFO - [2024-08-01T04:39:13.141+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T04:39:13.151+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.044 seconds
[2024-08-01T04:39:43.579+0000] {processor.py:157} INFO - Started process (PID=17680) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T04:39:43.580+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T04:39:43.581+0000] {logging_mixin.py:151} INFO - [2024-08-01T04:39:43.581+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T04:39:43.593+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T04:39:43.607+0000] {logging_mixin.py:151} INFO - [2024-08-01T04:39:43.606+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T04:39:43.617+0000] {logging_mixin.py:151} INFO - [2024-08-01T04:39:43.617+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T04:39:43.626+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-01T04:40:14.040+0000] {processor.py:157} INFO - Started process (PID=17705) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T04:40:14.041+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T04:40:14.043+0000] {logging_mixin.py:151} INFO - [2024-08-01T04:40:14.043+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T04:40:14.057+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T04:40:14.071+0000] {logging_mixin.py:151} INFO - [2024-08-01T04:40:14.071+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T04:40:14.081+0000] {logging_mixin.py:151} INFO - [2024-08-01T04:40:14.081+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T04:40:14.091+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-01T04:40:44.513+0000] {processor.py:157} INFO - Started process (PID=17730) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T04:40:44.515+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T04:40:44.517+0000] {logging_mixin.py:151} INFO - [2024-08-01T04:40:44.517+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T04:40:44.532+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T04:40:44.548+0000] {logging_mixin.py:151} INFO - [2024-08-01T04:40:44.548+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T04:40:44.558+0000] {logging_mixin.py:151} INFO - [2024-08-01T04:40:44.558+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T04:40:44.566+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-01T04:51:17.256+0000] {processor.py:157} INFO - Started process (PID=17755) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T04:51:17.259+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T04:51:17.261+0000] {logging_mixin.py:151} INFO - [2024-08-01T04:51:17.261+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T04:51:17.276+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T04:51:17.336+0000] {logging_mixin.py:151} INFO - [2024-08-01T04:51:17.336+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T04:51:17.365+0000] {logging_mixin.py:151} INFO - [2024-08-01T04:51:17.365+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T04:51:17.394+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.149 seconds
[2024-08-01T04:51:48.221+0000] {processor.py:157} INFO - Started process (PID=17782) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T04:51:48.224+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T04:51:48.230+0000] {logging_mixin.py:151} INFO - [2024-08-01T04:51:48.229+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T04:51:48.258+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T04:51:48.311+0000] {logging_mixin.py:151} INFO - [2024-08-01T04:51:48.311+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T04:51:48.328+0000] {logging_mixin.py:151} INFO - [2024-08-01T04:51:48.328+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T04:51:48.341+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-08-01T04:52:46.491+0000] {processor.py:157} INFO - Started process (PID=17807) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T04:52:46.492+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T04:52:46.494+0000] {logging_mixin.py:151} INFO - [2024-08-01T04:52:46.493+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T04:52:46.506+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T04:52:46.523+0000] {logging_mixin.py:151} INFO - [2024-08-01T04:52:46.523+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T04:52:46.534+0000] {logging_mixin.py:151} INFO - [2024-08-01T04:52:46.534+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T04:52:46.545+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-01T04:53:16.915+0000] {processor.py:157} INFO - Started process (PID=17832) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T04:53:16.917+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T04:53:16.919+0000] {logging_mixin.py:151} INFO - [2024-08-01T04:53:16.918+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T04:53:16.934+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T04:53:16.949+0000] {logging_mixin.py:151} INFO - [2024-08-01T04:53:16.949+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T04:53:16.959+0000] {logging_mixin.py:151} INFO - [2024-08-01T04:53:16.959+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T04:53:16.969+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-01T04:57:26.034+0000] {processor.py:157} INFO - Started process (PID=17858) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T04:57:26.038+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T04:57:26.043+0000] {logging_mixin.py:151} INFO - [2024-08-01T04:57:26.043+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T04:57:26.062+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T04:57:26.094+0000] {logging_mixin.py:151} INFO - [2024-08-01T04:57:26.094+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T04:57:26.116+0000] {logging_mixin.py:151} INFO - [2024-08-01T04:57:26.115+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T04:57:26.137+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-08-01T04:57:56.914+0000] {processor.py:157} INFO - Started process (PID=17884) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T04:57:57.035+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T04:57:57.043+0000] {logging_mixin.py:151} INFO - [2024-08-01T04:57:57.043+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T04:57:57.063+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T04:57:57.083+0000] {logging_mixin.py:151} INFO - [2024-08-01T04:57:57.083+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T04:57:57.095+0000] {logging_mixin.py:151} INFO - [2024-08-01T04:57:57.095+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T04:57:57.105+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.194 seconds
[2024-08-01T04:58:27.754+0000] {processor.py:157} INFO - Started process (PID=17909) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T04:58:27.759+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T04:58:27.762+0000] {logging_mixin.py:151} INFO - [2024-08-01T04:58:27.762+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T04:58:27.791+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T04:58:27.825+0000] {logging_mixin.py:151} INFO - [2024-08-01T04:58:27.825+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T04:58:27.839+0000] {logging_mixin.py:151} INFO - [2024-08-01T04:58:27.839+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T04:58:27.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-08-01T05:06:46.621+0000] {processor.py:157} INFO - Started process (PID=17933) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:06:46.626+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:06:46.628+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:06:46.628+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:06:46.651+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:06:46.698+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:06:46.698+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:06:46.719+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:06:46.719+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:06:46.737+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-08-01T05:07:17.254+0000] {processor.py:157} INFO - Started process (PID=17959) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:07:17.256+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:07:17.265+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:07:17.264+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:07:17.295+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:07:17.341+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:07:17.340+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:07:17.365+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:07:17.365+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:07:17.381+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-08-01T05:07:47.756+0000] {processor.py:157} INFO - Started process (PID=17984) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:07:47.761+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:07:47.764+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:07:47.764+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:07:47.777+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:07:47.796+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:07:47.796+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:07:47.805+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:07:47.805+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:07:47.815+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-01T05:08:18.138+0000] {processor.py:157} INFO - Started process (PID=18009) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:08:18.143+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:08:18.145+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:08:18.145+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:08:18.166+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:08:18.194+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:08:18.194+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:08:18.209+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:08:18.209+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:08:18.221+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-08-01T05:08:48.557+0000] {processor.py:157} INFO - Started process (PID=18034) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:08:48.558+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:08:48.559+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:08:48.559+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:08:48.572+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:08:48.585+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:08:48.585+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:08:48.598+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:08:48.598+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:08:48.610+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-01T05:09:18.918+0000] {processor.py:157} INFO - Started process (PID=18059) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:09:18.919+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:09:18.921+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:09:18.921+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:09:18.934+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:09:18.952+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:09:18.952+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:09:18.963+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:09:18.963+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:09:18.972+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-01T05:09:49.427+0000] {processor.py:157} INFO - Started process (PID=18084) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:09:49.429+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:09:49.433+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:09:49.433+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:09:49.453+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:09:49.484+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:09:49.484+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:09:49.497+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:09:49.497+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:09:49.507+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-08-01T05:10:19.891+0000] {processor.py:157} INFO - Started process (PID=18109) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:10:19.893+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:10:19.896+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:10:19.896+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:10:19.908+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:10:19.926+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:10:19.926+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:10:19.936+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:10:19.936+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:10:19.946+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-01T05:10:50.342+0000] {processor.py:157} INFO - Started process (PID=18134) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:10:50.345+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:10:50.348+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:10:50.347+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:10:50.369+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:10:50.385+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:10:50.385+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:10:50.400+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:10:50.400+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:10:50.408+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-01T05:11:20.778+0000] {processor.py:157} INFO - Started process (PID=18159) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:11:20.780+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:11:20.782+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:11:20.781+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:11:20.792+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:11:20.808+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:11:20.808+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:11:20.818+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:11:20.818+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:11:20.829+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-01T05:11:51.195+0000] {processor.py:157} INFO - Started process (PID=18184) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:11:51.197+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:11:51.199+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:11:51.199+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:11:51.211+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:11:51.227+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:11:51.227+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:11:51.238+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:11:51.238+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:11:51.246+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-01T05:12:21.625+0000] {processor.py:157} INFO - Started process (PID=18209) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:12:21.627+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:12:21.629+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:12:21.628+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:12:21.643+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:12:21.657+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:12:21.657+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:12:21.668+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:12:21.668+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:12:21.677+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-01T05:12:52.033+0000] {processor.py:157} INFO - Started process (PID=18234) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:12:52.035+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:12:52.038+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:12:52.038+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:12:52.051+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:12:52.066+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:12:52.065+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:12:52.077+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:12:52.077+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:12:52.085+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-01T05:13:22.461+0000] {processor.py:157} INFO - Started process (PID=18259) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:13:22.462+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:13:22.463+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:13:22.463+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:13:22.470+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:13:22.482+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:13:22.482+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:13:22.491+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:13:22.491+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:13:22.500+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.041 seconds
[2024-08-01T05:13:52.828+0000] {processor.py:157} INFO - Started process (PID=18284) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:13:52.829+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:13:52.831+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:13:52.831+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:13:52.843+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:13:52.857+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:13:52.857+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:13:52.867+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:13:52.867+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:13:52.876+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-01T05:14:23.176+0000] {processor.py:157} INFO - Started process (PID=18309) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:14:23.176+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:14:23.178+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:14:23.177+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:14:23.185+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:14:23.199+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:14:23.199+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:14:23.209+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:14:23.209+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:14:23.217+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.043 seconds
[2024-08-01T05:14:53.577+0000] {processor.py:157} INFO - Started process (PID=18334) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:14:53.579+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:14:53.581+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:14:53.581+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:14:53.595+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:14:53.609+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:14:53.609+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:14:53.618+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:14:53.618+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:14:53.627+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-01T05:15:24.060+0000] {processor.py:157} INFO - Started process (PID=18359) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:15:24.063+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:15:24.067+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:15:24.067+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:15:24.082+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:15:24.096+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:15:24.096+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:15:24.107+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:15:24.107+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:15:24.113+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-01T05:15:54.545+0000] {processor.py:157} INFO - Started process (PID=18384) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:15:54.546+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:15:54.549+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:15:54.548+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:15:54.561+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:15:54.600+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:15:54.599+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:15:54.620+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:15:54.620+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:15:54.630+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-01T05:16:25.070+0000] {processor.py:157} INFO - Started process (PID=18409) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:16:25.072+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:16:25.075+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:16:25.075+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:16:25.089+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:16:25.107+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:16:25.107+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:16:25.116+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:16:25.116+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:16:25.124+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-01T05:16:55.491+0000] {processor.py:157} INFO - Started process (PID=18434) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:16:55.493+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:16:55.495+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:16:55.495+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:16:55.507+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:16:55.524+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:16:55.524+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:16:55.535+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:16:55.535+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:16:55.546+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-01T05:17:25.913+0000] {processor.py:157} INFO - Started process (PID=18459) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:17:25.914+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:17:25.916+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:17:25.916+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:17:25.927+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:17:25.943+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:17:25.943+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:17:25.953+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:17:25.953+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:17:25.962+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-01T05:17:56.386+0000] {processor.py:157} INFO - Started process (PID=18484) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:17:56.387+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:17:56.388+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:17:56.388+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:17:56.400+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:17:56.416+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:17:56.415+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:17:56.426+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:17:56.426+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:17:56.436+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-01T05:18:26.765+0000] {processor.py:157} INFO - Started process (PID=18509) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:18:26.766+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:18:26.769+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:18:26.768+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:18:26.788+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:18:26.801+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:18:26.801+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:18:26.812+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:18:26.812+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:18:26.818+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-01T05:18:57.151+0000] {processor.py:157} INFO - Started process (PID=18534) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:18:57.151+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:18:57.153+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:18:57.153+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:18:57.165+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:18:57.179+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:18:57.179+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:18:57.190+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:18:57.190+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:18:57.200+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-01T05:19:27.498+0000] {processor.py:157} INFO - Started process (PID=18559) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:19:27.499+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:19:27.501+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:19:27.501+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:19:27.509+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:19:27.526+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:19:27.526+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:19:27.535+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:19:27.535+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:19:27.545+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-08-01T05:19:57.859+0000] {processor.py:157} INFO - Started process (PID=18584) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:19:57.861+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:19:57.864+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:19:57.864+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:19:57.878+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:19:57.898+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:19:57.898+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:19:57.913+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:19:57.913+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:19:57.926+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-01T05:20:28.309+0000] {processor.py:157} INFO - Started process (PID=18609) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:20:28.312+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:20:28.315+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:20:28.314+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:20:28.329+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:20:28.342+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:20:28.342+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:20:28.353+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:20:28.353+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:20:28.361+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-01T05:20:58.732+0000] {processor.py:157} INFO - Started process (PID=18634) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:20:58.733+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:20:58.734+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:20:58.734+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:20:58.743+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:20:58.757+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:20:58.756+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:20:58.767+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:20:58.767+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:20:58.777+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-08-01T05:21:29.128+0000] {processor.py:157} INFO - Started process (PID=18659) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:21:29.129+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:21:29.130+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:21:29.130+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:21:29.142+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:21:29.158+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:21:29.158+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:21:29.168+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:21:29.167+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:21:29.176+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-01T05:21:59.532+0000] {processor.py:157} INFO - Started process (PID=18684) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:21:59.533+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:21:59.535+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:21:59.535+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:21:59.552+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:21:59.566+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:21:59.565+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:21:59.575+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:21:59.575+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:21:59.584+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-01T05:22:29.848+0000] {processor.py:157} INFO - Started process (PID=18709) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:22:29.849+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:22:29.850+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:22:29.850+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:22:29.864+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:22:29.881+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:22:29.881+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:22:29.891+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:22:29.890+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:22:29.899+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-01T05:23:00.299+0000] {processor.py:157} INFO - Started process (PID=18734) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:23:00.301+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:23:00.304+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:23:00.303+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:23:00.316+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:23:00.331+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:23:00.331+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:23:00.341+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:23:00.341+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:23:00.351+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-01T05:23:30.701+0000] {processor.py:157} INFO - Started process (PID=18759) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:23:30.702+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:23:30.704+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:23:30.704+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:23:30.715+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:23:30.732+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:23:30.732+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:23:30.743+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:23:30.743+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:23:30.750+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-01T05:24:01.115+0000] {processor.py:157} INFO - Started process (PID=18784) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:24:01.116+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:24:01.118+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:24:01.118+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:24:01.132+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:24:01.145+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:24:01.144+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:24:01.156+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:24:01.156+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:24:01.165+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-01T05:24:31.521+0000] {processor.py:157} INFO - Started process (PID=18809) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:24:31.522+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:24:31.524+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:24:31.524+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:24:31.534+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:24:31.549+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:24:31.549+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:24:31.560+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:24:31.560+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:24:31.569+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-01T05:25:01.894+0000] {processor.py:157} INFO - Started process (PID=18834) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:25:01.894+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:25:01.895+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:25:01.895+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:25:01.902+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:25:01.914+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:25:01.914+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:25:01.923+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:25:01.923+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:25:01.932+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.040 seconds
[2024-08-01T05:25:32.244+0000] {processor.py:157} INFO - Started process (PID=18859) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:25:32.244+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:25:32.246+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:25:32.246+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:25:32.262+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:25:32.278+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:25:32.278+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:25:32.288+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:25:32.288+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:25:32.298+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-01T05:26:02.641+0000] {processor.py:157} INFO - Started process (PID=18884) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:26:02.642+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:26:02.644+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:26:02.644+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:26:02.660+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:26:02.673+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:26:02.673+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:26:02.685+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:26:02.685+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:26:02.695+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-01T05:26:33.009+0000] {processor.py:157} INFO - Started process (PID=18909) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:26:33.010+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:26:33.012+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:26:33.012+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:26:33.028+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:26:33.044+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:26:33.044+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:26:33.052+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:26:33.052+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:26:33.063+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-01T05:27:03.426+0000] {processor.py:157} INFO - Started process (PID=18934) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:27:03.428+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:27:03.430+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:27:03.430+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:27:03.442+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:27:03.457+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:27:03.457+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:27:03.467+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:27:03.466+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:27:03.473+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-01T05:27:33.861+0000] {processor.py:157} INFO - Started process (PID=18959) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:27:33.862+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:27:33.864+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:27:33.864+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:27:33.876+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:27:33.894+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:27:33.894+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:27:33.905+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:27:33.905+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:27:33.916+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-01T05:28:04.301+0000] {processor.py:157} INFO - Started process (PID=18984) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:28:04.302+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:28:04.303+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:28:04.303+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:28:04.319+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:28:04.335+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:28:04.335+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:28:04.345+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:28:04.345+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:28:04.355+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-01T05:28:34.759+0000] {processor.py:157} INFO - Started process (PID=19009) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:28:34.760+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:28:34.764+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:28:34.763+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:28:34.780+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:28:34.797+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:28:34.797+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:28:34.807+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:28:34.807+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:28:34.816+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-01T05:29:05.168+0000] {processor.py:157} INFO - Started process (PID=19034) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:29:05.169+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:29:05.170+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:29:05.170+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:29:05.178+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:29:05.192+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:29:05.192+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:29:05.202+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:29:05.202+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:29:05.211+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-08-01T05:29:35.568+0000] {processor.py:157} INFO - Started process (PID=19059) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:29:35.569+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:29:35.571+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:29:35.571+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:29:35.585+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:29:35.600+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:29:35.600+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:29:35.609+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:29:35.609+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:29:35.618+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-01T05:30:05.987+0000] {processor.py:157} INFO - Started process (PID=19084) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:30:05.990+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:30:05.992+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:30:05.992+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:30:06.004+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:30:06.020+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:30:06.020+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:30:06.031+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:30:06.031+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:30:06.038+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-01T05:30:36.422+0000] {processor.py:157} INFO - Started process (PID=19109) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:30:36.424+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:30:36.426+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:30:36.426+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:30:36.439+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:30:36.454+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:30:36.454+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:30:36.466+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:30:36.466+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:30:36.475+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-01T05:31:06.908+0000] {processor.py:157} INFO - Started process (PID=19134) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:31:06.909+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:31:06.911+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:31:06.911+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:31:06.925+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:31:06.941+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:31:06.941+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:31:06.951+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:31:06.951+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:31:06.960+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-01T05:31:37.336+0000] {processor.py:157} INFO - Started process (PID=19159) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:31:37.337+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:31:37.339+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:31:37.338+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:31:37.349+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:31:37.365+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:31:37.365+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:31:37.375+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:31:37.375+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:31:37.385+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-01T05:32:07.811+0000] {processor.py:157} INFO - Started process (PID=19184) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:32:07.813+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:32:07.814+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:32:07.814+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:32:07.829+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:32:07.843+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:32:07.843+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:32:07.855+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:32:07.855+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:32:07.864+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-01T05:32:38.249+0000] {processor.py:157} INFO - Started process (PID=19209) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:32:38.249+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:32:38.251+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:32:38.251+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:32:38.258+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:32:38.277+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:32:38.277+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:32:38.289+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:32:38.289+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:32:38.298+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-01T05:33:08.720+0000] {processor.py:157} INFO - Started process (PID=19234) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:33:08.723+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:33:08.725+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:33:08.725+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:33:08.735+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:33:08.750+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:33:08.750+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:33:08.762+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:33:08.762+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:33:08.772+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-01T05:33:39.140+0000] {processor.py:157} INFO - Started process (PID=19259) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:33:39.141+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:33:39.143+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:33:39.143+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:33:39.155+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:33:39.171+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:33:39.171+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:33:39.181+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:33:39.181+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:33:39.190+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-01T05:34:09.535+0000] {processor.py:157} INFO - Started process (PID=19284) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:34:09.536+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:34:09.538+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:34:09.538+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:34:09.553+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:34:09.567+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:34:09.567+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:34:09.577+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:34:09.577+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:34:09.585+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-01T05:34:39.955+0000] {processor.py:157} INFO - Started process (PID=19309) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:34:39.957+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:34:39.959+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:34:39.959+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:34:39.973+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:34:39.987+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:34:39.987+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:34:39.999+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:34:39.999+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:34:40.006+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-01T05:35:10.396+0000] {processor.py:157} INFO - Started process (PID=19334) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:35:10.397+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:35:10.399+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:35:10.398+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:35:10.409+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:35:10.425+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:35:10.425+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:35:10.434+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:35:10.434+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:35:10.443+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-01T05:35:40.802+0000] {processor.py:157} INFO - Started process (PID=19359) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:35:40.803+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:35:40.805+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:35:40.805+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:35:40.818+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:35:40.833+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:35:40.833+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:35:40.843+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:35:40.843+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:35:40.850+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-01T05:36:11.293+0000] {processor.py:157} INFO - Started process (PID=19384) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:36:11.295+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:36:11.297+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:36:11.296+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:36:11.309+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:36:11.324+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:36:11.324+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:36:11.334+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:36:11.334+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:36:11.342+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-01T05:36:41.739+0000] {processor.py:157} INFO - Started process (PID=19409) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:36:41.740+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:36:41.742+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:36:41.742+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:36:41.758+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:36:41.772+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:36:41.772+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:36:41.783+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:36:41.783+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:36:41.794+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-01T05:37:12.185+0000] {processor.py:157} INFO - Started process (PID=19434) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:37:12.186+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:37:12.188+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:37:12.188+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:37:12.200+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:37:12.215+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:37:12.215+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:37:12.227+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:37:12.227+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:37:12.235+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-01T05:37:42.537+0000] {processor.py:157} INFO - Started process (PID=19459) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:37:42.540+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:37:42.543+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:37:42.543+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:37:42.558+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:37:42.578+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:37:42.578+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:37:42.591+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:37:42.591+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:37:42.601+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-01T05:38:13.037+0000] {processor.py:157} INFO - Started process (PID=19484) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:38:13.037+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:38:13.039+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:38:13.039+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:38:13.050+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:38:13.065+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:38:13.065+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:38:13.075+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:38:13.075+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:38:13.084+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-01T05:38:43.467+0000] {processor.py:157} INFO - Started process (PID=19509) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:38:43.468+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:38:43.470+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:38:43.470+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:38:43.485+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:38:43.500+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:38:43.500+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:38:43.511+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:38:43.511+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:38:43.520+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-01T05:39:13.901+0000] {processor.py:157} INFO - Started process (PID=19534) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:39:13.902+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:39:13.904+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:39:13.904+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:39:13.919+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:39:13.934+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:39:13.933+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:39:13.943+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:39:13.943+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:39:13.953+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-01T05:39:44.311+0000] {processor.py:157} INFO - Started process (PID=19559) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:39:44.312+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:39:44.314+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:39:44.314+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:39:44.326+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:39:44.341+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:39:44.341+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:39:44.353+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:39:44.353+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:39:44.364+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-01T05:40:14.691+0000] {processor.py:157} INFO - Started process (PID=19584) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:40:14.692+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:40:14.693+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:40:14.693+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:40:14.699+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:40:14.712+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:40:14.712+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:40:14.722+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:40:14.722+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:40:14.730+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.041 seconds
[2024-08-01T05:40:45.080+0000] {processor.py:157} INFO - Started process (PID=19609) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:40:45.083+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:40:45.087+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:40:45.086+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:40:45.095+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:40:45.109+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:40:45.108+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:40:45.121+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:40:45.121+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:40:45.130+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-01T05:41:15.543+0000] {processor.py:157} INFO - Started process (PID=19634) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:41:15.544+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:41:15.546+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:41:15.546+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:41:15.558+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:41:15.573+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:41:15.573+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:41:15.582+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:41:15.582+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:41:15.592+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-01T05:41:45.945+0000] {processor.py:157} INFO - Started process (PID=19659) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:41:45.946+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:41:45.948+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:41:45.948+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:41:45.960+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:41:45.976+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:41:45.976+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:41:45.985+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:41:45.985+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:41:45.994+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-01T05:42:16.390+0000] {processor.py:157} INFO - Started process (PID=19684) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:42:16.391+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:42:16.393+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:42:16.393+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:42:16.404+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:42:16.420+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:42:16.420+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:42:16.431+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:42:16.431+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:42:16.439+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-01T05:42:46.826+0000] {processor.py:157} INFO - Started process (PID=19709) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:42:46.828+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:42:46.830+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:42:46.830+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:42:46.843+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:42:46.859+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:42:46.859+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:42:46.871+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:42:46.871+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:42:46.879+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-01T05:43:17.312+0000] {processor.py:157} INFO - Started process (PID=19734) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:43:17.313+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:43:17.315+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:43:17.314+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:43:17.326+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:43:17.342+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:43:17.341+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:43:17.351+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:43:17.351+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:43:17.361+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-01T05:43:47.679+0000] {processor.py:157} INFO - Started process (PID=19759) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:43:47.681+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:43:47.683+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:43:47.683+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:43:47.692+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:43:47.707+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:43:47.707+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:43:47.717+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:43:47.717+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:43:47.726+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-08-01T05:44:18.039+0000] {processor.py:157} INFO - Started process (PID=19784) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:44:18.039+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:44:18.041+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:44:18.041+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:44:18.051+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:44:18.065+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:44:18.065+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:44:18.075+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:44:18.075+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:44:18.084+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-08-01T05:44:48.493+0000] {processor.py:157} INFO - Started process (PID=19809) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:44:48.495+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:44:48.498+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:44:48.498+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:44:48.515+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:44:48.527+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:44:48.527+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:44:48.539+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:44:48.539+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:44:48.548+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-01T05:45:18.927+0000] {processor.py:157} INFO - Started process (PID=19834) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:45:18.929+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:45:18.932+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:45:18.932+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:45:18.950+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:45:18.968+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:45:18.967+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:45:18.978+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:45:18.978+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:45:18.986+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-01T05:45:49.387+0000] {processor.py:157} INFO - Started process (PID=19859) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:45:49.390+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:45:49.392+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:45:49.392+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:45:49.403+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:45:49.418+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:45:49.418+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:45:49.428+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:45:49.428+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:45:49.437+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-01T05:46:19.788+0000] {processor.py:157} INFO - Started process (PID=19884) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:46:19.789+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:46:19.792+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:46:19.792+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:46:19.808+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:46:19.824+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:46:19.824+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:46:19.836+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:46:19.836+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:46:19.844+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-01T05:46:50.247+0000] {processor.py:157} INFO - Started process (PID=19909) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:46:50.249+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:46:50.251+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:46:50.251+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:46:50.264+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:46:50.282+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:46:50.282+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:46:50.297+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:46:50.297+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:46:50.308+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-01T05:47:20.657+0000] {processor.py:157} INFO - Started process (PID=19934) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:47:20.659+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:47:20.662+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:47:20.661+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:47:20.673+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:47:20.689+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:47:20.689+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:47:20.699+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:47:20.699+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:47:20.708+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-01T05:47:51.035+0000] {processor.py:157} INFO - Started process (PID=19959) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:47:51.036+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:47:51.037+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:47:51.037+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:47:51.048+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:47:51.058+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:47:51.058+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:47:51.066+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:47:51.066+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:47:51.076+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.042 seconds
[2024-08-01T05:48:21.477+0000] {processor.py:157} INFO - Started process (PID=19984) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:48:21.478+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:48:21.480+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:48:21.480+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:48:21.494+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:48:21.510+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:48:21.510+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:48:21.523+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:48:21.523+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:48:21.532+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-01T05:48:51.882+0000] {processor.py:157} INFO - Started process (PID=20009) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:48:51.884+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:48:51.885+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:48:51.885+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:48:51.893+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:48:51.908+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:48:51.908+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:48:51.917+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:48:51.917+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:48:51.927+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-08-01T05:49:22.226+0000] {processor.py:157} INFO - Started process (PID=20034) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:49:22.228+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:49:22.230+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:49:22.230+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:49:22.245+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:49:22.259+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:49:22.259+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:49:22.272+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:49:22.272+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:49:22.280+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-01T05:49:52.668+0000] {processor.py:157} INFO - Started process (PID=20059) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:49:52.669+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:49:52.672+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:49:52.671+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:49:52.685+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:49:52.701+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:49:52.701+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:49:52.714+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:49:52.714+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:49:52.722+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-01T05:50:23.064+0000] {processor.py:157} INFO - Started process (PID=20084) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:50:23.065+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:50:23.067+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:50:23.067+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:50:23.078+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:50:23.096+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:50:23.096+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:50:23.107+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:50:23.107+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:50:23.117+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-01T05:50:53.486+0000] {processor.py:157} INFO - Started process (PID=20109) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:50:53.487+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:50:53.489+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:50:53.489+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:50:53.499+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:50:53.516+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:50:53.516+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:50:53.526+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:50:53.526+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:50:53.535+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-01T05:51:23.962+0000] {processor.py:157} INFO - Started process (PID=20134) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:51:23.964+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:51:23.966+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:51:23.965+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:51:23.977+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:51:23.996+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:51:23.996+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:51:24.006+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:51:24.006+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:51:24.015+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-01T05:51:54.399+0000] {processor.py:157} INFO - Started process (PID=20159) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:51:54.400+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:51:54.402+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:51:54.402+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:51:54.412+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:51:54.431+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:51:54.430+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:51:54.442+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:51:54.442+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:51:54.451+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-01T05:52:24.862+0000] {processor.py:157} INFO - Started process (PID=20182) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:52:24.862+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:52:24.864+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:52:24.864+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:52:24.873+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:52:24.888+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:52:24.888+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:52:24.898+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:52:24.898+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:52:24.907+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-08-01T05:52:55.261+0000] {processor.py:157} INFO - Started process (PID=20209) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:52:55.264+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:52:55.268+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:52:55.268+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:52:55.284+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:52:55.304+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:52:55.304+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:52:55.314+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:52:55.314+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:52:55.323+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-01T05:53:25.704+0000] {processor.py:157} INFO - Started process (PID=20234) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:53:25.705+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:53:25.707+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:53:25.707+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:53:25.724+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:53:25.740+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:53:25.739+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:53:25.754+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:53:25.753+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:53:25.762+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-01T05:53:56.160+0000] {processor.py:157} INFO - Started process (PID=20259) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:53:56.163+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:53:56.165+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:53:56.165+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:53:56.179+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:53:56.194+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:53:56.194+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:53:56.207+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:53:56.207+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:53:56.217+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-01T05:54:26.596+0000] {processor.py:157} INFO - Started process (PID=20284) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:54:26.597+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:54:26.600+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:54:26.600+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:54:26.616+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:54:26.632+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:54:26.632+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:54:26.642+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:54:26.642+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:54:26.650+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-01T05:54:57.069+0000] {processor.py:157} INFO - Started process (PID=20309) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:54:57.070+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:54:57.072+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:54:57.072+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:54:57.084+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:54:57.106+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:54:57.106+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:54:57.118+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:54:57.118+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:54:57.128+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-01T05:55:27.487+0000] {processor.py:157} INFO - Started process (PID=20334) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:55:27.488+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:55:27.490+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:55:27.489+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:55:27.501+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:55:27.515+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:55:27.515+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:55:27.527+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:55:27.527+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:55:27.535+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-01T05:55:57.965+0000] {processor.py:157} INFO - Started process (PID=20359) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:55:57.969+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:55:57.971+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:55:57.971+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:55:57.988+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:55:58.004+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:55:58.004+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:55:58.014+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:55:58.014+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:55:58.023+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-01T05:56:28.380+0000] {processor.py:157} INFO - Started process (PID=20384) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:56:28.381+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:56:28.384+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:56:28.384+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:56:28.396+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:56:28.412+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:56:28.412+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:56:28.422+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:56:28.422+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:56:28.431+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-01T05:56:58.836+0000] {processor.py:157} INFO - Started process (PID=20409) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:56:58.838+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:56:58.841+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:56:58.840+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:56:58.852+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:56:58.868+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:56:58.868+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:56:58.881+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:56:58.881+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:56:58.889+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-01T05:57:29.285+0000] {processor.py:157} INFO - Started process (PID=20434) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:57:29.286+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:57:29.288+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:57:29.288+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:57:29.300+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:57:29.320+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:57:29.320+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:57:29.331+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:57:29.331+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:57:29.340+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-01T05:57:59.743+0000] {processor.py:157} INFO - Started process (PID=20459) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:57:59.744+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:57:59.746+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:57:59.746+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:57:59.759+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:57:59.778+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:57:59.778+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:57:59.791+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:57:59.791+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:57:59.800+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-01T05:58:30.486+0000] {processor.py:157} INFO - Started process (PID=20483) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:58:30.488+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:58:30.503+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:58:30.503+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:58:30.551+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:58:30.603+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:58:30.603+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:58:30.633+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:58:30.633+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:58:30.648+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.167 seconds
[2024-08-01T05:59:01.219+0000] {processor.py:157} INFO - Started process (PID=20509) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:59:01.223+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:59:01.238+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:59:01.238+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:59:01.262+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:59:01.289+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:59:01.289+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:59:01.311+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:59:01.311+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:59:01.327+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-08-01T05:59:31.722+0000] {processor.py:157} INFO - Started process (PID=20534) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:59:31.723+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T05:59:31.725+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:59:31.725+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:59:31.741+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T05:59:31.760+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:59:31.760+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T05:59:31.776+0000] {logging_mixin.py:151} INFO - [2024-08-01T05:59:31.776+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T05:59:31.785+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-01T06:00:02.160+0000] {processor.py:157} INFO - Started process (PID=20559) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:00:02.161+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:00:02.163+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:00:02.163+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:00:02.175+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:00:02.193+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:00:02.193+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:00:02.206+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:00:02.206+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:00:02.215+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-01T06:00:32.568+0000] {processor.py:157} INFO - Started process (PID=20584) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:00:32.569+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:00:32.573+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:00:32.573+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:00:32.591+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:00:32.614+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:00:32.614+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:00:32.626+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:00:32.626+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:00:32.638+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-01T06:01:03.069+0000] {processor.py:157} INFO - Started process (PID=20609) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:01:03.073+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:01:03.076+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:01:03.075+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:01:03.093+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:01:03.109+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:01:03.109+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:01:03.120+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:01:03.120+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:01:03.130+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-01T06:01:33.524+0000] {processor.py:157} INFO - Started process (PID=20634) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:01:33.525+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:01:33.527+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:01:33.527+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:01:33.543+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:01:33.560+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:01:33.560+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:01:33.574+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:01:33.574+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:01:33.585+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-01T06:02:03.964+0000] {processor.py:157} INFO - Started process (PID=20659) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:02:03.967+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:02:03.968+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:02:03.968+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:02:03.979+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:02:03.994+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:02:03.994+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:02:04.004+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:02:04.004+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:02:04.013+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-01T06:02:34.423+0000] {processor.py:157} INFO - Started process (PID=20684) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:02:34.425+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:02:34.427+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:02:34.427+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:02:34.441+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:02:34.458+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:02:34.457+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:02:34.470+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:02:34.470+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:02:34.480+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-01T06:03:04.833+0000] {processor.py:157} INFO - Started process (PID=20709) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:03:04.835+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:03:04.837+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:03:04.837+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:03:04.854+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:03:04.868+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:03:04.868+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:03:04.880+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:03:04.880+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:03:04.889+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-01T06:03:35.306+0000] {processor.py:157} INFO - Started process (PID=20734) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:03:35.308+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:03:35.310+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:03:35.310+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:03:35.319+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:03:35.335+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:03:35.335+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:03:35.345+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:03:35.345+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:03:35.354+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-01T06:04:05.715+0000] {processor.py:157} INFO - Started process (PID=20759) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:04:05.717+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:04:05.719+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:04:05.719+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:04:05.735+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:04:05.757+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:04:05.757+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:04:05.769+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:04:05.769+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:04:05.779+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-01T06:04:36.202+0000] {processor.py:157} INFO - Started process (PID=20784) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:04:36.203+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:04:36.205+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:04:36.204+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:04:36.221+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:04:36.235+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:04:36.235+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:04:36.248+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:04:36.247+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:04:36.258+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-01T06:05:06.620+0000] {processor.py:157} INFO - Started process (PID=20809) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:05:06.620+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:05:06.621+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:05:06.621+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:05:06.628+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:05:06.642+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:05:06.642+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:05:06.650+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:05:06.650+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:05:06.662+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.044 seconds
[2024-08-01T06:05:37.072+0000] {processor.py:157} INFO - Started process (PID=20834) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:05:37.074+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:05:37.076+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:05:37.076+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:05:37.093+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:05:37.109+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:05:37.109+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:05:37.121+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:05:37.121+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:05:37.129+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-01T06:06:07.516+0000] {processor.py:157} INFO - Started process (PID=20859) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:06:07.517+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:06:07.521+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:06:07.520+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:06:07.534+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:06:07.564+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:06:07.564+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:06:07.587+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:06:07.587+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:06:07.605+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-08-01T06:06:37.997+0000] {processor.py:157} INFO - Started process (PID=20884) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:06:38.000+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:06:38.003+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:06:38.003+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:06:38.016+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:06:38.034+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:06:38.034+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:06:38.046+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:06:38.046+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:06:38.057+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-01T06:07:08.475+0000] {processor.py:157} INFO - Started process (PID=20908) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:07:08.476+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:07:08.480+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:07:08.480+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:07:08.504+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:07:08.521+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:07:08.521+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:07:08.533+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:07:08.533+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:07:08.541+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-01T06:07:38.845+0000] {processor.py:157} INFO - Started process (PID=20934) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:07:38.847+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:07:38.849+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:07:38.848+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:07:38.863+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:07:38.878+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:07:38.878+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:07:38.888+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:07:38.888+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:07:38.899+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-01T06:08:09.216+0000] {processor.py:157} INFO - Started process (PID=20959) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:08:09.218+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:08:09.220+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:08:09.220+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:08:09.230+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:08:09.247+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:08:09.246+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:08:09.257+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:08:09.257+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:08:09.266+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-01T06:08:39.678+0000] {processor.py:157} INFO - Started process (PID=20984) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:08:39.679+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:08:39.681+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:08:39.681+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:08:39.695+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:08:39.710+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:08:39.710+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:08:39.721+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:08:39.721+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:08:39.731+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-01T06:09:10.132+0000] {processor.py:157} INFO - Started process (PID=21009) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:09:10.135+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:09:10.137+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:09:10.137+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:09:10.156+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:09:10.172+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:09:10.172+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:09:10.182+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:09:10.182+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:09:10.192+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-01T06:09:40.616+0000] {processor.py:157} INFO - Started process (PID=21034) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:09:40.617+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:09:40.619+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:09:40.619+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:09:40.637+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:09:40.657+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:09:40.657+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:09:40.672+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:09:40.672+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:09:40.680+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-01T06:10:10.982+0000] {processor.py:157} INFO - Started process (PID=21059) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:10:10.985+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:10:10.989+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:10:10.988+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:10:11.000+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:10:11.021+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:10:11.021+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:10:11.033+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:10:11.032+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:10:11.043+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-01T06:10:41.406+0000] {processor.py:157} INFO - Started process (PID=21084) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:10:41.408+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:10:41.409+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:10:41.409+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:10:41.421+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:10:41.438+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:10:41.438+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:10:41.449+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:10:41.449+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:10:41.460+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-01T06:11:11.800+0000] {processor.py:157} INFO - Started process (PID=21109) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:11:11.802+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:11:11.804+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:11:11.804+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:11:11.820+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:11:11.833+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:11:11.833+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:11:11.845+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:11:11.845+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:11:11.856+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-01T06:11:42.249+0000] {processor.py:157} INFO - Started process (PID=21134) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:11:42.251+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:11:42.254+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:11:42.254+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:11:42.264+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:11:42.279+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:11:42.279+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:11:42.290+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:11:42.290+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:11:42.300+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-01T06:12:12.963+0000] {processor.py:157} INFO - Started process (PID=21159) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:12:12.966+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:12:12.971+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:12:12.970+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:12:12.999+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:12:13.044+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:12:13.044+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:12:13.065+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:12:13.065+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:12:13.080+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-08-01T06:12:43.389+0000] {processor.py:157} INFO - Started process (PID=21184) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:12:43.390+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:12:43.392+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:12:43.391+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:12:43.401+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:12:43.414+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:12:43.414+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:12:43.423+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:12:43.423+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:12:43.432+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-08-01T06:13:13.871+0000] {processor.py:157} INFO - Started process (PID=21209) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:13:13.872+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:13:13.876+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:13:13.876+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:13:13.932+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:13:13.966+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:13:13.966+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:13:13.980+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:13:13.980+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:13:13.992+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-08-01T06:13:44.347+0000] {processor.py:157} INFO - Started process (PID=21234) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:13:44.348+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:13:44.350+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:13:44.350+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:13:44.365+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:13:44.378+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:13:44.378+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:13:44.389+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:13:44.389+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:13:44.399+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-01T06:14:14.774+0000] {processor.py:157} INFO - Started process (PID=21259) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:14:14.776+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:14:14.778+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:14:14.778+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:14:14.798+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:14:14.817+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:14:14.816+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:14:14.831+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:14:14.831+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:14:14.843+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-01T06:14:45.263+0000] {processor.py:157} INFO - Started process (PID=21284) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:14:45.265+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:14:45.267+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:14:45.267+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:14:45.277+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:14:45.293+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:14:45.292+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:14:45.304+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:14:45.304+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:14:45.315+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-01T06:15:15.759+0000] {processor.py:157} INFO - Started process (PID=21309) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:15:15.762+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:15:15.766+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:15:15.766+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:15:15.791+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:15:15.807+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:15:15.807+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:15:15.821+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:15:15.821+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:15:15.830+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-08-01T06:15:46.190+0000] {processor.py:157} INFO - Started process (PID=21334) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:15:46.191+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:15:46.192+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:15:46.192+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:15:46.201+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:15:46.217+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:15:46.217+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:15:46.227+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:15:46.227+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:15:46.235+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-08-01T06:16:16.595+0000] {processor.py:157} INFO - Started process (PID=21359) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:16:16.596+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:16:16.598+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:16:16.598+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:16:16.608+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:16:16.625+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:16:16.625+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:16:16.637+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:16:16.637+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:16:16.648+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-01T06:16:47.043+0000] {processor.py:157} INFO - Started process (PID=21384) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:16:47.046+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:16:47.048+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:16:47.048+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:16:47.059+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:16:47.076+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:16:47.076+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:16:47.088+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:16:47.088+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:16:47.098+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-01T06:17:17.456+0000] {processor.py:157} INFO - Started process (PID=21409) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:17:17.458+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:17:17.481+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:17:17.481+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:17:17.504+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:17:17.534+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:17:17.534+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:17:17.566+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:17:17.566+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:17:17.577+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-08-01T06:17:48.006+0000] {processor.py:157} INFO - Started process (PID=21434) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:17:48.008+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:17:48.010+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:17:48.010+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:17:48.026+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:17:48.039+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:17:48.039+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:17:48.049+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:17:48.049+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:17:48.059+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-01T06:18:18.373+0000] {processor.py:157} INFO - Started process (PID=21459) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:18:18.376+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:18:18.379+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:18:18.379+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:18:18.389+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:18:18.406+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:18:18.406+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:18:18.417+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:18:18.417+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:18:18.426+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-01T06:18:48.806+0000] {processor.py:157} INFO - Started process (PID=21484) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:18:48.809+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:18:48.812+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:18:48.812+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:18:48.832+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:18:48.850+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:18:48.850+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:18:48.862+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:18:48.862+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:18:48.874+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-01T06:19:19.217+0000] {processor.py:157} INFO - Started process (PID=21509) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:19:19.218+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:19:19.219+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:19:19.219+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:19:19.226+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:19:19.238+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:19:19.238+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:19:19.249+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:19:19.249+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:19:19.259+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.044 seconds
[2024-08-01T06:19:49.663+0000] {processor.py:157} INFO - Started process (PID=21534) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:19:49.665+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:19:49.666+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:19:49.666+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:19:49.679+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:19:49.694+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:19:49.694+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:19:49.705+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:19:49.704+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:19:49.715+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-01T06:20:20.050+0000] {processor.py:157} INFO - Started process (PID=21559) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:20:20.052+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:20:20.053+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:20:20.053+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:20:20.064+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:20:20.083+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:20:20.083+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:20:20.093+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:20:20.093+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:20:20.104+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-01T06:20:50.498+0000] {processor.py:157} INFO - Started process (PID=21584) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:20:50.500+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:20:50.502+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:20:50.502+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:20:50.515+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:20:50.536+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:20:50.536+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:20:50.549+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:20:50.549+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:20:50.563+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-01T06:21:21.021+0000] {processor.py:157} INFO - Started process (PID=21608) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:21:21.022+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:21:21.026+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:21:21.026+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:21:21.066+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:21:21.091+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:21:21.091+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:21:21.103+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:21:21.103+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:21:21.114+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-08-01T06:21:51.493+0000] {processor.py:157} INFO - Started process (PID=21634) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:21:51.498+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:21:51.501+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:21:51.501+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:21:51.518+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:21:51.537+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:21:51.537+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:21:51.549+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:21:51.549+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:21:51.559+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-01T06:22:21.943+0000] {processor.py:157} INFO - Started process (PID=21659) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:22:21.945+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:22:21.947+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:22:21.947+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:22:21.959+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:22:21.975+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:22:21.975+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:22:21.989+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:22:21.989+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:22:21.998+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-01T06:22:52.331+0000] {processor.py:157} INFO - Started process (PID=21684) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:22:52.332+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:22:52.333+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:22:52.333+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:22:52.344+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:22:52.357+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:22:52.357+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:22:52.365+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:22:52.365+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:22:52.375+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-08-01T06:23:22.738+0000] {processor.py:157} INFO - Started process (PID=21709) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:23:22.740+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:23:22.741+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:23:22.741+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:23:22.754+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:23:22.770+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:23:22.770+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:23:22.780+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:23:22.780+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:23:22.788+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-01T06:23:53.175+0000] {processor.py:157} INFO - Started process (PID=21734) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:23:53.177+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:23:53.180+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:23:53.180+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:23:53.198+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:23:53.219+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:23:53.218+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:23:53.231+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:23:53.231+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:23:53.241+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-01T06:24:23.611+0000] {processor.py:157} INFO - Started process (PID=21759) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:24:23.612+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:24:23.614+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:24:23.613+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:24:23.631+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:24:23.644+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:24:23.644+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:24:23.653+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:24:23.653+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:24:23.661+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-01T06:24:54.023+0000] {processor.py:157} INFO - Started process (PID=21784) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:24:54.024+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:24:54.026+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:24:54.026+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:24:54.040+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:24:54.054+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:24:54.054+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:24:54.064+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:24:54.064+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:24:54.073+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-01T06:25:24.458+0000] {processor.py:157} INFO - Started process (PID=21808) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:25:24.461+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:25:24.469+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:25:24.469+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:25:24.489+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:25:24.514+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:25:24.514+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:25:24.527+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:25:24.527+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:25:24.539+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-08-01T06:25:54.953+0000] {processor.py:157} INFO - Started process (PID=21834) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:25:54.954+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:25:54.957+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:25:54.957+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:25:54.972+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:25:54.986+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:25:54.986+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:25:54.998+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:25:54.998+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:25:55.008+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-01T06:26:25.349+0000] {processor.py:157} INFO - Started process (PID=21858) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:26:25.353+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:26:25.356+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:26:25.356+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:26:25.375+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:26:25.402+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:26:25.402+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:26:25.416+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:26:25.416+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:26:25.427+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-08-01T06:26:55.856+0000] {processor.py:157} INFO - Started process (PID=21884) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:26:55.858+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:26:55.860+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:26:55.860+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:26:55.876+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:26:55.891+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:26:55.891+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:26:55.901+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:26:55.901+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:26:55.910+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-01T06:27:26.352+0000] {processor.py:157} INFO - Started process (PID=21909) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:27:26.358+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:27:26.373+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:27:26.373+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:27:26.411+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:27:26.444+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:27:26.443+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:27:26.467+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:27:26.467+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:27:26.480+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.145 seconds
[2024-08-01T06:27:56.918+0000] {processor.py:157} INFO - Started process (PID=21934) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:27:56.919+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:27:56.921+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:27:56.921+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:27:56.933+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:27:56.950+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:27:56.950+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:27:56.962+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:27:56.962+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:27:56.973+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-01T06:28:27.335+0000] {processor.py:157} INFO - Started process (PID=21959) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:28:27.338+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:28:27.341+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:28:27.341+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:28:27.358+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:28:27.381+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:28:27.381+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:28:27.395+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:28:27.394+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:28:27.405+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-08-01T06:28:57.799+0000] {processor.py:157} INFO - Started process (PID=21984) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:28:57.800+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:28:57.803+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:28:57.802+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:28:57.818+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:28:57.834+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:28:57.834+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:28:57.843+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:28:57.843+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:28:57.852+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-01T06:29:28.255+0000] {processor.py:157} INFO - Started process (PID=22009) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:29:28.257+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:29:28.260+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:29:28.260+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:29:28.270+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:29:28.286+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:29:28.286+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:29:28.296+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:29:28.296+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:29:28.305+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-01T06:29:58.588+0000] {processor.py:157} INFO - Started process (PID=22034) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:29:58.589+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:29:58.592+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:29:58.592+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:29:58.605+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:29:58.624+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:29:58.623+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:29:58.634+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:29:58.634+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:29:58.643+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-01T06:30:28.985+0000] {processor.py:157} INFO - Started process (PID=22059) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:30:28.987+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:30:28.989+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:30:28.989+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:30:29.000+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:30:29.016+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:30:29.016+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:30:29.028+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:30:29.028+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:30:29.037+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-01T06:30:59.407+0000] {processor.py:157} INFO - Started process (PID=22084) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:30:59.411+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:30:59.415+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:30:59.415+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:30:59.433+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:30:59.455+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:30:59.455+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:30:59.468+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:30:59.468+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:30:59.478+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-08-01T06:31:29.875+0000] {processor.py:157} INFO - Started process (PID=22109) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:31:29.875+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:31:29.877+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:31:29.877+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:31:29.893+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:31:29.909+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:31:29.909+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:31:29.922+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:31:29.922+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:31:29.932+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-01T06:32:00.327+0000] {processor.py:157} INFO - Started process (PID=22134) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:32:00.329+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:32:00.331+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:32:00.331+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:32:00.341+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:32:00.358+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:32:00.358+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:32:00.367+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:32:00.367+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:32:00.376+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-01T06:32:30.724+0000] {processor.py:157} INFO - Started process (PID=22159) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:32:30.724+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:32:30.726+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:32:30.726+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:32:30.740+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:32:30.756+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:32:30.756+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:32:30.770+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:32:30.770+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:32:30.779+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-01T06:33:01.141+0000] {processor.py:157} INFO - Started process (PID=22184) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:33:01.142+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:33:01.144+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:33:01.143+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:33:01.153+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:33:01.168+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:33:01.168+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:33:01.182+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:33:01.182+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:33:01.192+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-01T06:33:31.592+0000] {processor.py:157} INFO - Started process (PID=22209) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:33:31.594+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:33:31.603+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:33:31.603+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:33:31.632+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:33:31.687+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:33:31.686+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:33:31.703+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:33:31.703+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:33:31.716+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-08-01T06:34:02.183+0000] {processor.py:157} INFO - Started process (PID=22234) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:34:02.186+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:34:02.193+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:34:02.192+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:34:02.216+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:34:02.252+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:34:02.252+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:34:02.275+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:34:02.275+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:34:02.292+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-08-01T06:34:32.706+0000] {processor.py:157} INFO - Started process (PID=22259) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:34:32.708+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:34:32.710+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:34:32.710+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:34:32.719+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:34:32.734+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:34:32.734+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:34:32.744+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:34:32.744+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:34:32.754+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-01T06:35:03.136+0000] {processor.py:157} INFO - Started process (PID=22284) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:35:03.141+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:35:03.144+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:35:03.144+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:35:03.163+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:35:03.198+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:35:03.198+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:35:03.210+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:35:03.210+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:35:03.222+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-08-01T06:35:33.595+0000] {processor.py:157} INFO - Started process (PID=22309) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:35:33.596+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:35:33.598+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:35:33.598+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:35:33.617+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:35:33.632+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:35:33.632+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:35:33.643+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:35:33.643+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:35:33.651+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-01T06:36:04.055+0000] {processor.py:157} INFO - Started process (PID=22334) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:36:04.058+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:36:04.060+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:36:04.060+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:36:04.072+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:36:04.089+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:36:04.089+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:36:04.098+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:36:04.098+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:36:04.108+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-01T06:36:34.489+0000] {processor.py:157} INFO - Started process (PID=22359) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:36:34.492+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:36:34.495+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:36:34.495+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:36:34.512+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:36:34.534+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:36:34.533+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:36:34.546+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:36:34.546+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:36:34.556+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-01T06:37:04.912+0000] {processor.py:157} INFO - Started process (PID=22384) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:37:04.912+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:37:04.914+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:37:04.914+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:37:04.929+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:37:04.942+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:37:04.942+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:37:04.952+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:37:04.951+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:37:04.960+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-01T06:37:35.309+0000] {processor.py:157} INFO - Started process (PID=22409) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:37:35.312+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:37:35.314+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:37:35.314+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:37:35.321+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:37:35.337+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:37:35.337+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:37:35.346+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:37:35.346+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:37:35.356+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-01T06:38:05.721+0000] {processor.py:157} INFO - Started process (PID=22434) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:38:05.721+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:38:05.723+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:38:05.723+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:38:05.733+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:38:05.748+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:38:05.748+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:38:05.759+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:38:05.759+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:38:05.767+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-01T06:38:36.203+0000] {processor.py:157} INFO - Started process (PID=22459) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:38:36.205+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:38:36.208+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:38:36.208+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:38:36.226+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:38:36.248+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:38:36.248+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:38:36.261+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:38:36.261+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:38:36.272+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-01T06:39:06.653+0000] {processor.py:157} INFO - Started process (PID=22484) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:39:06.654+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:39:06.656+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:39:06.655+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:39:06.668+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:39:06.684+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:39:06.684+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:39:06.697+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:39:06.697+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:39:06.707+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-01T06:39:37.046+0000] {processor.py:157} INFO - Started process (PID=22509) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:39:37.051+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:39:37.053+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:39:37.053+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:39:37.073+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:39:37.103+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:39:37.103+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:39:37.117+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:39:37.117+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:39:37.128+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-01T06:40:07.495+0000] {processor.py:157} INFO - Started process (PID=22534) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:40:07.496+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:40:07.498+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:40:07.497+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:40:07.509+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:40:07.527+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:40:07.527+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:40:07.539+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:40:07.539+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:40:07.548+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-01T06:40:37.903+0000] {processor.py:157} INFO - Started process (PID=22559) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:40:37.904+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:40:37.905+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:40:37.905+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:40:37.920+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:40:37.933+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:40:37.932+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:40:37.942+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:40:37.942+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:40:37.951+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-01T06:41:08.383+0000] {processor.py:157} INFO - Started process (PID=22584) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:41:08.386+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:41:08.389+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:41:08.388+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:41:08.410+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:41:08.428+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:41:08.428+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:41:08.441+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:41:08.441+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:41:08.451+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-01T06:41:38.845+0000] {processor.py:157} INFO - Started process (PID=22609) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:41:38.846+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:41:38.850+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:41:38.850+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:41:38.863+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:41:38.879+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:41:38.878+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:41:38.890+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:41:38.890+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:41:38.905+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-01T06:42:09.319+0000] {processor.py:157} INFO - Started process (PID=22634) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:42:09.321+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:42:09.323+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:42:09.323+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:42:09.335+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:42:09.353+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:42:09.353+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:42:09.364+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:42:09.364+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:42:09.373+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-01T06:42:39.737+0000] {processor.py:157} INFO - Started process (PID=22659) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:42:39.738+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:42:39.741+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:42:39.740+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:42:39.759+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:42:39.781+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:42:39.781+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:42:39.795+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:42:39.794+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:42:39.805+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-01T06:43:10.193+0000] {processor.py:157} INFO - Started process (PID=22684) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:43:10.196+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:43:10.198+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:43:10.198+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:43:10.212+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:43:10.232+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:43:10.232+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:43:10.241+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:43:10.241+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:43:10.251+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-01T06:43:40.662+0000] {processor.py:157} INFO - Started process (PID=22709) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:43:40.664+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:43:40.667+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:43:40.667+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:43:40.682+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:43:40.703+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:43:40.702+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:43:40.714+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:43:40.714+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:43:40.723+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-01T06:44:11.063+0000] {processor.py:157} INFO - Started process (PID=22734) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:44:11.065+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:44:11.067+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:44:11.067+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:44:11.082+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:44:11.101+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:44:11.101+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:44:11.111+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:44:11.111+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:44:11.121+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-01T06:44:41.559+0000] {processor.py:157} INFO - Started process (PID=22759) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:44:41.565+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:44:41.571+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:44:41.571+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:44:41.585+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:44:41.602+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:44:41.602+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:44:41.616+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:44:41.615+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:44:41.625+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-08-01T06:45:11.999+0000] {processor.py:157} INFO - Started process (PID=22784) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:45:12.001+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:45:12.004+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:45:12.003+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:45:12.021+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:45:12.041+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:45:12.041+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:45:12.055+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:45:12.055+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:45:12.064+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-01T06:45:42.555+0000] {processor.py:157} INFO - Started process (PID=22809) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:45:42.557+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:45:42.562+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:45:42.562+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:45:42.587+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:45:42.615+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:45:42.615+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:45:42.636+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:45:42.635+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:45:42.646+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-08-01T06:46:13.015+0000] {processor.py:157} INFO - Started process (PID=22834) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:46:13.016+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:46:13.019+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:46:13.019+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:46:13.032+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:46:13.046+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:46:13.046+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:46:13.056+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:46:13.056+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:46:13.066+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-01T06:46:43.434+0000] {processor.py:157} INFO - Started process (PID=22859) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:46:43.436+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:46:43.439+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:46:43.438+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:46:43.479+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:46:43.529+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:46:43.528+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:46:43.542+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:46:43.542+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:46:43.553+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-08-01T06:47:13.934+0000] {processor.py:157} INFO - Started process (PID=22884) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:47:13.937+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:47:13.939+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:47:13.938+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:47:13.950+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:47:13.967+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:47:13.967+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:47:13.977+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:47:13.977+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:47:13.986+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-01T06:47:44.383+0000] {processor.py:157} INFO - Started process (PID=22908) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:47:44.385+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:47:44.388+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:47:44.387+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:47:44.417+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:47:44.460+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:47:44.460+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:47:44.475+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:47:44.475+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:47:44.485+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-08-01T06:48:14.906+0000] {processor.py:157} INFO - Started process (PID=22934) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:48:14.907+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:48:14.910+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:48:14.910+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:48:14.930+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:48:14.949+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:48:14.948+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:48:14.960+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:48:14.960+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:48:14.969+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-01T06:48:45.356+0000] {processor.py:157} INFO - Started process (PID=22959) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:48:45.358+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:48:45.362+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:48:45.361+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:48:45.397+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:48:45.423+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:48:45.423+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:48:45.437+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:48:45.437+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:48:45.448+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-08-01T06:49:15.823+0000] {processor.py:157} INFO - Started process (PID=22984) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:49:15.824+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:49:15.826+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:49:15.826+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:49:15.839+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:49:15.854+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:49:15.854+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:49:15.865+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:49:15.865+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:49:15.875+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-01T06:49:46.179+0000] {processor.py:157} INFO - Started process (PID=23009) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:49:46.180+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:49:46.183+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:49:46.183+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:49:46.195+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:49:46.211+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:49:46.211+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:49:46.220+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:49:46.220+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:49:46.229+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-01T06:50:16.640+0000] {processor.py:157} INFO - Started process (PID=23034) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:50:16.641+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:50:16.642+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:50:16.642+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:50:16.657+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:50:16.673+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:50:16.673+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:50:16.685+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:50:16.685+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:50:16.693+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-01T06:50:47.093+0000] {processor.py:157} INFO - Started process (PID=23059) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:50:47.096+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:50:47.098+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:50:47.098+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:50:47.112+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:50:47.131+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:50:47.131+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:50:47.142+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:50:47.142+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:50:47.151+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-01T06:51:17.572+0000] {processor.py:157} INFO - Started process (PID=23084) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:51:17.573+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:51:17.574+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:51:17.574+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:51:17.589+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:51:17.607+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:51:17.607+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:51:17.617+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:51:17.617+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:51:17.627+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-01T06:51:48.036+0000] {processor.py:157} INFO - Started process (PID=23109) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:51:48.039+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:51:48.041+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:51:48.041+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:51:48.055+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:51:48.075+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:51:48.075+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:51:48.086+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:51:48.085+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:51:48.095+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-01T06:52:18.483+0000] {processor.py:157} INFO - Started process (PID=23134) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:52:18.485+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:52:18.489+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:52:18.489+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:52:18.518+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:52:18.568+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:52:18.568+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:52:18.580+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:52:18.580+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:52:18.591+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-08-01T06:52:49.048+0000] {processor.py:157} INFO - Started process (PID=23159) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:52:49.051+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:52:49.054+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:52:49.054+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:52:49.067+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:52:49.086+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:52:49.086+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:52:49.098+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:52:49.098+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:52:49.108+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-01T06:53:19.453+0000] {processor.py:157} INFO - Started process (PID=23184) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:53:19.455+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:53:19.459+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:53:19.458+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:53:19.480+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:53:19.514+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:53:19.513+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:53:19.528+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:53:19.527+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:53:19.541+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-08-01T06:53:49.959+0000] {processor.py:157} INFO - Started process (PID=23209) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:53:49.963+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:53:49.965+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:53:49.965+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:53:49.999+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:53:50.026+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:53:50.025+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:53:50.037+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:53:50.037+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:53:50.046+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-08-01T06:54:20.393+0000] {processor.py:157} INFO - Started process (PID=23234) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:54:20.394+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:54:20.396+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:54:20.396+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:54:20.416+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:54:20.435+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:54:20.435+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:54:20.451+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:54:20.451+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:54:20.460+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-01T06:54:50.904+0000] {processor.py:157} INFO - Started process (PID=23259) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:54:50.905+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:54:50.910+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:54:50.910+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:54:50.927+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:54:50.946+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:54:50.946+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:54:50.956+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:54:50.956+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:54:50.966+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-01T06:55:21.390+0000] {processor.py:157} INFO - Started process (PID=23284) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:55:21.393+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:55:21.396+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:55:21.396+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:55:21.428+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:55:21.456+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:55:21.456+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:55:21.469+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:55:21.469+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:55:21.479+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-08-01T06:55:51.907+0000] {processor.py:157} INFO - Started process (PID=23309) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:55:51.908+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:55:51.915+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:55:51.914+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:55:51.938+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:55:51.969+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:55:51.969+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:55:51.989+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:55:51.989+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:55:52.002+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-08-01T06:56:22.320+0000] {processor.py:157} INFO - Started process (PID=23334) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:56:22.322+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:56:22.324+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:56:22.324+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:56:22.336+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:56:22.352+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:56:22.352+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:56:22.362+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:56:22.362+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:56:22.372+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-01T06:56:52.735+0000] {processor.py:157} INFO - Started process (PID=23359) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:56:52.736+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:56:52.738+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:56:52.738+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:56:52.748+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:56:52.763+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:56:52.763+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:56:52.773+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:56:52.773+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:56:52.782+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-01T06:57:23.209+0000] {processor.py:157} INFO - Started process (PID=23384) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:57:23.211+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:57:23.214+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:57:23.213+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:57:23.226+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:57:23.244+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:57:23.243+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:57:23.256+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:57:23.256+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:57:23.265+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-01T06:57:53.594+0000] {processor.py:157} INFO - Started process (PID=23409) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:57:53.596+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:57:53.597+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:57:53.597+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:57:53.615+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:57:53.637+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:57:53.637+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:57:53.654+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:57:53.654+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:57:53.666+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-01T06:58:24.017+0000] {processor.py:157} INFO - Started process (PID=23434) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:58:24.018+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:58:24.020+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:58:24.020+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:58:24.037+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:58:24.052+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:58:24.052+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:58:24.063+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:58:24.063+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:58:24.076+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-01T06:58:54.475+0000] {processor.py:157} INFO - Started process (PID=23459) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:58:54.476+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:58:54.480+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:58:54.480+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:58:54.504+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:58:54.522+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:58:54.522+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:58:54.535+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:58:54.535+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:58:54.546+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-08-01T06:59:24.954+0000] {processor.py:157} INFO - Started process (PID=23484) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:59:24.957+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:59:24.958+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:59:24.958+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:59:24.972+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:59:24.986+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:59:24.986+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:59:24.998+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:59:24.998+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:59:25.009+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-01T06:59:55.408+0000] {processor.py:157} INFO - Started process (PID=23509) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:59:55.410+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T06:59:55.413+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:59:55.413+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:59:55.425+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T06:59:55.441+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:59:55.441+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T06:59:55.455+0000] {logging_mixin.py:151} INFO - [2024-08-01T06:59:55.455+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T06:59:55.463+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-01T07:00:25.866+0000] {processor.py:157} INFO - Started process (PID=23534) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:00:25.866+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:00:25.868+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:00:25.868+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:00:25.878+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:00:25.895+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:00:25.895+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:00:25.904+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:00:25.904+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:00:25.915+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-01T07:00:56.334+0000] {processor.py:157} INFO - Started process (PID=23558) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:00:56.337+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:00:56.340+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:00:56.340+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:00:56.359+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:00:56.374+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:00:56.374+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:00:56.387+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:00:56.387+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:00:56.398+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-01T07:01:26.702+0000] {processor.py:157} INFO - Started process (PID=23584) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:01:26.703+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:01:26.704+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:01:26.704+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:01:26.720+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:01:26.765+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:01:26.764+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:01:26.778+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:01:26.778+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:01:26.789+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-08-01T07:01:57.226+0000] {processor.py:157} INFO - Started process (PID=23609) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:01:57.228+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:01:57.231+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:01:57.231+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:01:57.264+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:01:57.282+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:01:57.282+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:01:57.294+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:01:57.294+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:01:57.304+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-08-01T07:02:27.755+0000] {processor.py:157} INFO - Started process (PID=23634) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:02:27.756+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:02:27.768+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:02:27.766+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:02:27.811+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:02:27.863+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:02:27.863+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:02:27.887+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:02:27.887+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:02:27.899+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.151 seconds
[2024-08-01T07:02:58.426+0000] {processor.py:157} INFO - Started process (PID=23659) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:02:58.429+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:02:58.434+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:02:58.434+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:02:58.455+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:02:58.496+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:02:58.496+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:02:58.510+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:02:58.510+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:02:58.522+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-08-01T07:03:29.505+0000] {processor.py:157} INFO - Started process (PID=23684) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:03:29.508+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:03:29.514+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:03:29.513+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:03:29.535+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:03:29.574+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:03:29.574+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:03:29.593+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:03:29.593+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:03:29.607+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-08-01T07:03:59.945+0000] {processor.py:157} INFO - Started process (PID=23709) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:03:59.946+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:03:59.948+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:03:59.948+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:03:59.960+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:03:59.976+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:03:59.976+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:03:59.988+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:03:59.988+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:04:00.001+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-01T07:04:30.436+0000] {processor.py:157} INFO - Started process (PID=23734) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:04:30.441+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:04:30.457+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:04:30.457+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:04:30.478+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:04:30.529+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:04:30.529+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:04:30.547+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:04:30.547+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:04:30.559+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-08-01T07:05:00.945+0000] {processor.py:157} INFO - Started process (PID=23759) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:05:00.948+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:05:00.951+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:05:00.951+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:05:00.971+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:05:01.002+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:05:01.002+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:05:01.015+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:05:01.015+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:05:01.027+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-01T07:05:31.439+0000] {processor.py:157} INFO - Started process (PID=23784) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:05:31.441+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:05:31.445+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:05:31.445+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:05:31.469+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:05:31.500+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:05:31.500+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:05:31.521+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:05:31.521+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:05:31.537+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-08-01T07:06:01.893+0000] {processor.py:157} INFO - Started process (PID=23809) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:06:01.895+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:06:01.898+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:06:01.897+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:06:01.918+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:06:01.942+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:06:01.942+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:06:01.955+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:06:01.955+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:06:01.967+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-08-01T07:06:32.370+0000] {processor.py:157} INFO - Started process (PID=23834) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:06:32.371+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:06:32.373+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:06:32.373+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:06:32.385+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:06:32.402+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:06:32.402+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:06:32.412+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:06:32.412+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:06:32.423+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-01T07:07:02.742+0000] {processor.py:157} INFO - Started process (PID=23859) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:07:02.744+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:07:02.745+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:07:02.745+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:07:02.757+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:07:02.773+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:07:02.773+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:07:02.787+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:07:02.787+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:07:02.796+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-01T07:07:33.168+0000] {processor.py:157} INFO - Started process (PID=23884) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:07:33.173+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:07:33.177+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:07:33.176+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:07:33.191+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:07:33.206+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:07:33.206+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:07:33.215+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:07:33.215+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:07:33.225+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-01T07:08:03.643+0000] {processor.py:157} INFO - Started process (PID=23909) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:08:03.644+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:08:03.647+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:08:03.647+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:08:03.658+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:08:03.674+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:08:03.674+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:08:03.685+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:08:03.685+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:08:03.694+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-01T07:08:34.085+0000] {processor.py:157} INFO - Started process (PID=23934) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:08:34.086+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:08:34.088+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:08:34.087+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:08:34.103+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:08:34.127+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:08:34.127+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:08:34.142+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:08:34.142+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:08:34.153+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-01T07:09:04.522+0000] {processor.py:157} INFO - Started process (PID=23959) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:09:04.525+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:09:04.528+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:09:04.528+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:09:04.542+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:09:04.558+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:09:04.558+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:09:04.568+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:09:04.568+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:09:04.577+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-01T07:09:34.937+0000] {processor.py:157} INFO - Started process (PID=23984) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:09:34.939+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:09:34.940+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:09:34.940+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:09:34.953+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:09:34.968+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:09:34.968+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:09:34.978+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:09:34.978+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:09:34.989+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-01T07:10:05.328+0000] {processor.py:157} INFO - Started process (PID=24009) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:10:05.329+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:10:05.330+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:10:05.330+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:10:05.344+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:10:05.366+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:10:05.366+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:10:05.379+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:10:05.379+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:10:05.389+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-01T07:10:35.794+0000] {processor.py:157} INFO - Started process (PID=24034) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:10:35.796+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:10:35.799+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:10:35.799+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:10:35.817+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:10:35.835+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:10:35.835+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:10:35.846+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:10:35.846+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:10:35.861+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-08-01T07:11:06.270+0000] {processor.py:157} INFO - Started process (PID=24059) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:11:06.270+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:11:06.273+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:11:06.273+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:11:06.295+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:11:06.313+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:11:06.313+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:11:06.328+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:11:06.328+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:11:06.338+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-01T07:11:36.776+0000] {processor.py:157} INFO - Started process (PID=24084) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:11:36.780+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:11:36.783+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:11:36.783+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:11:36.801+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:11:36.816+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:11:36.816+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:11:36.828+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:11:36.828+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:11:36.835+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-01T07:12:07.259+0000] {processor.py:157} INFO - Started process (PID=24109) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:12:07.261+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:12:07.263+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:12:07.263+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:12:07.279+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:12:07.299+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:12:07.299+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:12:07.311+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:12:07.311+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:12:07.331+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-01T07:12:37.769+0000] {processor.py:157} INFO - Started process (PID=24133) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:12:37.771+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:12:37.775+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:12:37.774+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:12:37.792+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:12:37.808+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:12:37.808+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:12:37.818+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:12:37.818+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:12:37.826+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-01T07:13:08.213+0000] {processor.py:157} INFO - Started process (PID=24159) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:13:08.214+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:13:08.217+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:13:08.216+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:13:08.235+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:13:08.256+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:13:08.255+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:13:08.268+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:13:08.268+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:13:08.281+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-01T07:13:38.724+0000] {processor.py:157} INFO - Started process (PID=24184) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:13:38.726+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:13:38.727+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:13:38.727+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:13:38.738+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:13:38.753+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:13:38.753+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:13:38.763+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:13:38.763+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:13:38.771+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-01T07:14:09.132+0000] {processor.py:157} INFO - Started process (PID=24209) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:14:09.135+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:14:09.137+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:14:09.137+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:14:09.150+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:14:09.165+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:14:09.165+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:14:09.175+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:14:09.175+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:14:09.183+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-01T07:14:39.546+0000] {processor.py:157} INFO - Started process (PID=24234) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:14:39.548+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:14:39.550+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:14:39.550+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:14:39.565+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:14:39.585+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:14:39.584+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:14:39.597+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:14:39.597+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:14:39.607+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-01T07:15:09.922+0000] {processor.py:157} INFO - Started process (PID=24259) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:15:09.923+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:15:09.925+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:15:09.925+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:15:09.940+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:15:09.953+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:15:09.953+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:15:09.964+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:15:09.964+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:15:09.971+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-01T07:15:40.397+0000] {processor.py:157} INFO - Started process (PID=24284) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:15:40.399+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:15:40.404+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:15:40.404+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:15:40.422+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:15:40.447+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:15:40.447+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:15:40.459+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:15:40.459+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:15:40.468+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-01T07:16:10.907+0000] {processor.py:157} INFO - Started process (PID=24309) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:16:10.907+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:16:10.909+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:16:10.909+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:16:10.923+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:16:10.940+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:16:10.940+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:16:10.949+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:16:10.949+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:16:10.956+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-01T07:16:41.306+0000] {processor.py:157} INFO - Started process (PID=24334) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:16:41.307+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:16:41.311+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:16:41.311+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:16:41.333+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:16:41.356+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:16:41.356+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:16:41.382+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:16:41.382+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:16:41.392+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-08-01T07:17:11.850+0000] {processor.py:157} INFO - Started process (PID=24359) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:17:11.851+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:17:11.853+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:17:11.853+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:17:11.870+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:17:11.887+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:17:11.887+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:17:11.901+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:17:11.901+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:17:11.910+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-01T07:17:42.264+0000] {processor.py:157} INFO - Started process (PID=24384) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:17:42.265+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:17:42.269+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:17:42.269+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:17:42.288+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:17:42.312+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:17:42.312+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:17:42.324+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:17:42.324+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:17:42.334+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-01T07:18:12.788+0000] {processor.py:157} INFO - Started process (PID=24409) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:18:12.790+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:18:12.793+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:18:12.792+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:18:12.805+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:18:12.821+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:18:12.821+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:18:12.831+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:18:12.831+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:18:12.839+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-01T07:18:43.283+0000] {processor.py:157} INFO - Started process (PID=24434) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:18:43.285+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:18:43.288+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:18:43.288+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:18:43.304+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:18:43.324+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:18:43.324+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:18:43.338+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:18:43.338+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:18:43.347+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-01T07:19:13.788+0000] {processor.py:157} INFO - Started process (PID=24459) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:19:13.791+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:19:13.795+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:19:13.794+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:19:13.806+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:19:13.824+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:19:13.824+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:19:13.834+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:19:13.834+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:19:13.844+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-01T07:19:44.242+0000] {processor.py:157} INFO - Started process (PID=24484) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:19:44.243+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:19:44.245+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:19:44.245+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:19:44.257+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:19:44.274+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:19:44.274+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:19:44.285+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:19:44.285+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:19:44.293+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-01T07:20:14.713+0000] {processor.py:157} INFO - Started process (PID=24509) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:20:14.714+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:20:14.717+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:20:14.717+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:20:14.734+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:20:14.754+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:20:14.754+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:20:14.766+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:20:14.766+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:20:14.777+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-01T07:20:45.230+0000] {processor.py:157} INFO - Started process (PID=24534) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:20:45.232+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:20:45.234+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:20:45.234+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:20:45.247+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:20:45.265+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:20:45.264+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:20:45.277+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:20:45.277+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:20:45.287+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-01T07:21:15.705+0000] {processor.py:157} INFO - Started process (PID=24559) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:21:15.710+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:21:15.715+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:21:15.715+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:21:15.728+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:21:15.744+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:21:15.744+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:21:15.758+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:21:15.758+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:21:15.767+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-01T07:21:46.151+0000] {processor.py:157} INFO - Started process (PID=24584) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:21:46.154+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:21:46.156+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:21:46.156+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:21:46.168+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:21:46.192+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:21:46.192+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:21:46.204+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:21:46.204+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:21:46.214+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-01T07:22:16.619+0000] {processor.py:157} INFO - Started process (PID=24609) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:22:16.620+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:22:16.623+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:22:16.622+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:22:16.635+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:22:16.652+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:22:16.652+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:22:16.667+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:22:16.666+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:22:16.689+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-01T07:22:47.067+0000] {processor.py:157} INFO - Started process (PID=24634) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:22:47.069+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:22:47.072+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:22:47.072+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:22:47.089+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:22:47.109+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:22:47.109+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:22:47.122+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:22:47.122+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:22:47.131+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-01T07:23:17.512+0000] {processor.py:157} INFO - Started process (PID=24659) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:23:17.513+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:23:17.519+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:23:17.518+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:23:17.535+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:23:17.551+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:23:17.551+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:23:17.562+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:23:17.562+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:23:17.573+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-01T07:23:48.019+0000] {processor.py:157} INFO - Started process (PID=24684) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:23:48.020+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:23:48.023+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:23:48.022+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:23:48.037+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:23:48.058+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:23:48.058+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:23:48.070+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:23:48.070+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:23:48.079+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-01T07:24:18.485+0000] {processor.py:157} INFO - Started process (PID=24709) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:24:18.486+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:24:18.488+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:24:18.487+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:24:18.499+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:24:18.517+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:24:18.517+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:24:18.533+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:24:18.532+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:24:18.544+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-01T07:24:48.943+0000] {processor.py:157} INFO - Started process (PID=24734) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:24:48.946+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:24:48.948+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:24:48.948+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:24:48.963+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:24:48.979+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:24:48.979+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:24:48.988+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:24:48.988+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:24:48.996+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-01T07:25:19.338+0000] {processor.py:157} INFO - Started process (PID=24759) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:25:19.338+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:25:19.340+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:25:19.340+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:25:19.348+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:25:19.363+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:25:19.363+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:25:19.375+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:25:19.375+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:25:19.384+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-08-01T07:25:49.777+0000] {processor.py:157} INFO - Started process (PID=24784) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:25:49.779+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:25:49.783+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:25:49.783+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:25:49.796+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:25:49.814+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:25:49.814+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:25:49.824+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:25:49.824+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:25:49.832+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-01T07:26:20.295+0000] {processor.py:157} INFO - Started process (PID=24809) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:26:20.297+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:26:20.307+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:26:20.306+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:26:20.340+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:26:20.399+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:26:20.399+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:26:20.418+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:26:20.418+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:26:20.435+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.150 seconds
[2024-08-01T07:26:50.890+0000] {processor.py:157} INFO - Started process (PID=24834) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:26:50.894+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:26:50.897+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:26:50.897+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:26:50.916+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:26:50.948+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:26:50.948+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:26:50.961+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:26:50.961+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:26:50.971+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-08-01T07:27:21.491+0000] {processor.py:157} INFO - Started process (PID=24859) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:27:21.493+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:27:21.498+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:27:21.498+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:27:21.520+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:27:21.559+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:27:21.559+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:27:21.574+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:27:21.574+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:27:21.587+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-08-01T07:27:52.030+0000] {processor.py:157} INFO - Started process (PID=24884) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:27:52.032+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:27:52.036+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:27:52.036+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:27:52.058+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:27:52.108+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:27:52.108+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:27:52.122+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:27:52.122+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:27:52.134+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-08-01T07:28:22.581+0000] {processor.py:157} INFO - Started process (PID=24908) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:28:22.583+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:28:22.586+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:28:22.586+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:28:22.605+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:28:22.633+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:28:22.633+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:28:22.647+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:28:22.647+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:28:22.665+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-08-01T07:28:53.201+0000] {processor.py:157} INFO - Started process (PID=24934) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:28:53.205+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:28:53.209+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:28:53.209+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:28:53.230+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:28:53.259+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:28:53.259+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:28:53.273+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:28:53.273+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:28:53.284+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-01T07:29:23.706+0000] {processor.py:157} INFO - Started process (PID=24959) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:29:23.709+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:29:23.711+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:29:23.711+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:29:23.724+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:29:23.740+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:29:23.740+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:29:23.754+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:29:23.753+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:29:23.772+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-01T07:29:54.175+0000] {processor.py:157} INFO - Started process (PID=24984) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:29:54.176+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:29:54.178+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:29:54.178+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:29:54.190+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:29:54.208+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:29:54.208+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:29:54.218+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:29:54.218+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:29:54.228+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-01T07:30:24.657+0000] {processor.py:157} INFO - Started process (PID=25009) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:30:24.665+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:30:24.669+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:30:24.668+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:30:24.690+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:30:24.724+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:30:24.724+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:30:24.744+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:30:24.744+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:30:24.757+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-08-01T07:30:55.158+0000] {processor.py:157} INFO - Started process (PID=25034) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:30:55.159+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:30:55.160+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:30:55.160+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:30:55.175+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:30:55.189+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:30:55.189+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:30:55.202+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:30:55.202+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:30:55.212+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-01T07:31:26.094+0000] {processor.py:157} INFO - Started process (PID=25059) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:31:26.100+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:31:26.106+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:31:26.105+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:31:26.141+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:31:26.188+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:31:26.188+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:31:26.217+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:31:26.216+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:31:26.231+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.143 seconds
[2024-08-01T07:31:56.685+0000] {processor.py:157} INFO - Started process (PID=25084) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:31:56.686+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:31:56.689+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:31:56.689+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:31:56.707+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:31:56.729+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:31:56.729+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:31:56.741+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:31:56.741+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:31:56.750+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-01T07:32:27.148+0000] {processor.py:157} INFO - Started process (PID=25109) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:32:27.149+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:32:27.151+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:32:27.151+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:32:27.168+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:32:27.187+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:32:27.187+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:32:27.198+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:32:27.198+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:32:27.206+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-01T07:32:57.581+0000] {processor.py:157} INFO - Started process (PID=25134) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:32:57.583+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:32:57.585+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:32:57.585+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:32:57.600+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:32:57.616+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:32:57.615+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:32:57.626+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:32:57.626+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:32:57.636+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-01T07:33:27.948+0000] {processor.py:157} INFO - Started process (PID=25159) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:33:27.949+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:33:27.951+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:33:27.950+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:33:27.961+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:33:27.974+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:33:27.974+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:33:27.984+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:33:27.984+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:33:27.995+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-08-01T07:33:58.868+0000] {processor.py:157} INFO - Started process (PID=25184) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:33:58.869+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:33:58.871+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:33:58.870+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:33:58.888+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:33:58.914+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:33:58.914+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:33:58.927+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:33:58.927+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:33:58.936+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-01T07:34:29.314+0000] {processor.py:157} INFO - Started process (PID=25209) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:34:29.316+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:34:29.317+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:34:29.317+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:34:29.327+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:34:29.344+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:34:29.344+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:34:29.354+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:34:29.354+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:34:29.364+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-01T07:34:59.751+0000] {processor.py:157} INFO - Started process (PID=25234) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:34:59.752+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:34:59.754+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:34:59.754+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:34:59.776+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:34:59.798+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:34:59.797+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:34:59.811+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:34:59.811+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:34:59.822+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-08-01T07:35:30.171+0000] {processor.py:157} INFO - Started process (PID=25259) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:35:30.180+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:35:30.197+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:35:30.197+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:35:30.216+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:35:30.238+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:35:30.238+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:35:30.250+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:35:30.250+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:35:30.260+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-08-01T07:36:00.672+0000] {processor.py:157} INFO - Started process (PID=25284) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:36:00.673+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:36:00.676+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:36:00.675+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:36:00.690+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:36:00.706+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:36:00.705+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:36:00.716+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:36:00.716+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:36:00.726+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-01T07:36:31.064+0000] {processor.py:157} INFO - Started process (PID=25309) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:36:31.065+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:36:31.066+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:36:31.066+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:36:31.078+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:36:31.089+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:36:31.089+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:36:31.098+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:36:31.098+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:36:31.105+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.043 seconds
[2024-08-01T07:37:01.550+0000] {processor.py:157} INFO - Started process (PID=25334) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:37:01.551+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:37:01.554+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:37:01.554+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:37:01.567+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:37:01.583+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:37:01.583+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:37:01.595+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:37:01.595+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:37:01.605+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-01T07:37:31.999+0000] {processor.py:157} INFO - Started process (PID=25359) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:37:32.001+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:37:32.003+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:37:32.003+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:37:32.026+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:37:32.056+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:37:32.056+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:37:32.072+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:37:32.072+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:37:32.083+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-08-01T07:38:02.501+0000] {processor.py:157} INFO - Started process (PID=25384) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:38:02.502+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:38:02.504+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:38:02.504+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:38:02.517+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:38:02.535+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:38:02.534+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:38:02.546+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:38:02.546+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:38:02.554+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-01T07:38:32.966+0000] {processor.py:157} INFO - Started process (PID=25409) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:38:32.967+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:38:32.970+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:38:32.970+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:38:32.983+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:38:33.000+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:38:33.000+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:38:33.011+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:38:33.011+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:38:33.021+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-01T07:39:03.354+0000] {processor.py:157} INFO - Started process (PID=25434) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:39:03.355+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:39:03.358+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:39:03.358+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:39:03.374+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:39:03.417+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:39:03.417+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:39:03.431+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:39:03.431+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:39:03.443+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-08-01T07:39:33.854+0000] {processor.py:157} INFO - Started process (PID=25459) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:39:33.858+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:39:33.861+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:39:33.861+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:39:33.874+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:39:33.892+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:39:33.892+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:39:33.904+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:39:33.904+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:39:33.912+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-01T07:40:04.232+0000] {processor.py:157} INFO - Started process (PID=25484) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:40:04.233+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:40:04.235+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:40:04.235+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:40:04.248+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:40:04.268+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:40:04.268+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:40:04.283+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:40:04.283+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:40:04.300+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-01T07:40:34.719+0000] {processor.py:157} INFO - Started process (PID=25509) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:40:34.722+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:40:34.724+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:40:34.724+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:40:34.741+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:40:34.754+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:40:34.754+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:40:34.766+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:40:34.766+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:40:34.775+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-01T07:41:05.148+0000] {processor.py:157} INFO - Started process (PID=25534) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:41:05.149+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:41:05.152+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:41:05.152+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:41:05.162+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:41:05.179+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:41:05.179+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:41:05.188+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:41:05.188+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:41:05.196+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-01T07:41:35.583+0000] {processor.py:157} INFO - Started process (PID=25559) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:41:35.586+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:41:35.588+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:41:35.587+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:41:35.606+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:41:35.629+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:41:35.629+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:41:35.642+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:41:35.642+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:41:35.653+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-01T07:42:06.048+0000] {processor.py:157} INFO - Started process (PID=25584) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:42:06.049+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:42:06.051+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:42:06.051+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:42:06.061+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:42:06.078+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:42:06.078+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:42:06.088+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:42:06.088+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:42:06.240+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.195 seconds
[2024-08-01T07:42:36.676+0000] {processor.py:157} INFO - Started process (PID=25609) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:42:36.677+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:42:36.680+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:42:36.680+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:42:36.693+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:42:36.709+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:42:36.709+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:42:36.721+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:42:36.721+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:42:36.730+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-01T07:43:07.129+0000] {processor.py:157} INFO - Started process (PID=25634) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:43:07.130+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:43:07.134+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:43:07.134+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:43:07.146+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:43:07.162+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:43:07.162+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:43:07.172+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:43:07.172+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:43:07.181+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-01T07:43:37.538+0000] {processor.py:157} INFO - Started process (PID=25659) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:43:37.541+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:43:37.545+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:43:37.545+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:43:37.559+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:43:37.585+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:43:37.584+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:43:37.597+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:43:37.597+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:43:37.606+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-01T07:44:07.995+0000] {processor.py:157} INFO - Started process (PID=25684) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:44:07.996+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:44:07.998+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:44:07.998+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:44:08.012+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:44:08.025+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:44:08.025+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:44:08.036+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:44:08.036+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:44:08.045+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-01T07:44:38.341+0000] {processor.py:157} INFO - Started process (PID=25709) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:44:38.342+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:44:38.344+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:44:38.344+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:44:38.354+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:44:38.370+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:44:38.370+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:44:38.381+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:44:38.380+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:44:38.392+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-01T07:45:08.737+0000] {processor.py:157} INFO - Started process (PID=25734) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:45:08.738+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:45:08.741+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:45:08.741+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:45:08.751+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:45:08.769+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:45:08.769+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:45:08.781+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:45:08.780+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:45:08.965+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.233 seconds
[2024-08-01T07:45:39.383+0000] {processor.py:157} INFO - Started process (PID=25759) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:45:39.386+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:45:39.388+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:45:39.388+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:45:39.405+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:45:39.420+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:45:39.420+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:45:39.435+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:45:39.435+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:45:39.445+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-01T07:46:09.862+0000] {processor.py:157} INFO - Started process (PID=25784) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:46:09.862+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:46:09.865+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:46:09.865+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:46:09.877+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:46:09.893+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:46:09.893+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:46:09.903+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:46:09.903+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:46:09.913+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-01T07:46:40.300+0000] {processor.py:157} INFO - Started process (PID=25809) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:46:40.301+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:46:40.303+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:46:40.303+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:46:40.316+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:46:40.336+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:46:40.335+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:46:40.349+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:46:40.349+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:46:40.359+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-01T07:47:10.782+0000] {processor.py:157} INFO - Started process (PID=25834) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:47:10.783+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:47:10.786+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:47:10.785+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:47:10.799+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:47:10.812+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:47:10.812+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:47:10.823+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:47:10.823+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:47:10.832+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-01T07:47:41.229+0000] {processor.py:157} INFO - Started process (PID=25859) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:47:41.231+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:47:41.233+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:47:41.233+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:47:41.248+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:47:41.264+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:47:41.264+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:47:41.274+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:47:41.274+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:47:41.285+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-01T07:48:11.653+0000] {processor.py:157} INFO - Started process (PID=25884) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:48:11.655+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:48:11.657+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:48:11.657+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:48:11.669+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:48:11.686+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:48:11.686+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:48:11.700+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:48:11.700+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:48:11.709+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-01T07:48:42.124+0000] {processor.py:157} INFO - Started process (PID=25909) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:48:42.125+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:48:42.127+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:48:42.127+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:48:42.139+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:48:42.154+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:48:42.154+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:48:42.164+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:48:42.164+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:48:42.173+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-01T07:49:12.508+0000] {processor.py:157} INFO - Started process (PID=25934) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:49:12.509+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:49:12.510+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:49:12.510+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:49:12.520+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:49:12.535+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:49:12.535+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:49:12.545+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:49:12.545+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:49:12.553+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-08-01T07:49:42.923+0000] {processor.py:157} INFO - Started process (PID=25959) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:49:42.926+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:49:42.928+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:49:42.928+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:49:42.946+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:49:42.960+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:49:42.960+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:49:42.971+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:49:42.970+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:49:42.979+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-01T07:50:13.316+0000] {processor.py:157} INFO - Started process (PID=25984) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:50:13.317+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:50:13.319+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:50:13.319+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:50:13.336+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:50:13.352+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:50:13.352+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:50:13.367+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:50:13.367+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:50:13.375+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-01T07:50:43.673+0000] {processor.py:157} INFO - Started process (PID=26009) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:50:43.676+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:50:43.678+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:50:43.678+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:50:43.694+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:50:43.715+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:50:43.715+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:50:43.728+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:50:43.728+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:50:43.861+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.191 seconds
[2024-08-01T07:51:14.416+0000] {processor.py:157} INFO - Started process (PID=26034) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:51:14.419+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:51:14.422+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:51:14.422+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:51:14.439+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:51:14.454+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:51:14.454+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:51:14.467+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:51:14.467+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:51:14.476+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-01T07:51:44.773+0000] {processor.py:157} INFO - Started process (PID=26059) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:51:44.775+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:51:44.778+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:51:44.778+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:51:44.809+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:51:44.835+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:51:44.835+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:51:44.848+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:51:44.847+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:51:44.857+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-01T07:52:15.314+0000] {processor.py:157} INFO - Started process (PID=26084) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:52:15.316+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:52:15.319+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:52:15.318+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:52:15.338+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:52:15.352+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:52:15.352+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:52:15.363+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:52:15.363+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:52:15.374+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-01T07:52:45.757+0000] {processor.py:157} INFO - Started process (PID=26109) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:52:45.759+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:52:45.762+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:52:45.761+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:52:45.775+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:52:45.790+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:52:45.790+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:52:45.800+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:52:45.800+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:52:45.810+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-01T07:53:16.216+0000] {processor.py:157} INFO - Started process (PID=26134) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:53:16.217+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:53:16.219+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:53:16.219+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:53:16.237+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:53:16.250+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:53:16.250+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:53:16.262+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:53:16.262+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:53:16.272+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-01T07:53:46.591+0000] {processor.py:157} INFO - Started process (PID=26159) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:53:46.592+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:53:46.594+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:53:46.594+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:53:46.608+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:53:46.624+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:53:46.624+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:53:46.637+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:53:46.637+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:53:46.766+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.177 seconds
[2024-08-01T07:54:17.318+0000] {processor.py:157} INFO - Started process (PID=26183) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:54:17.328+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:54:17.340+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:54:17.340+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:54:17.363+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:54:17.385+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:54:17.385+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:54:17.411+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:54:17.411+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:54:17.421+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-08-01T07:54:47.802+0000] {processor.py:157} INFO - Started process (PID=26209) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:54:47.803+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:54:47.806+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:54:47.806+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:54:47.818+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:54:47.841+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:54:47.841+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:54:47.852+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:54:47.852+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:54:47.863+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-01T07:55:18.346+0000] {processor.py:157} INFO - Started process (PID=26233) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:55:18.347+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:55:18.353+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:55:18.352+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:55:18.372+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:55:18.406+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:55:18.406+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:55:18.422+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:55:18.421+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:55:18.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-08-01T07:55:48.764+0000] {processor.py:157} INFO - Started process (PID=26259) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:55:48.766+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:55:48.769+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:55:48.768+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:55:48.779+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:55:48.795+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:55:48.795+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:55:48.807+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:55:48.807+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:55:48.819+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-01T07:56:19.182+0000] {processor.py:157} INFO - Started process (PID=26284) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:56:19.183+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:56:19.186+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:56:19.186+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:56:19.202+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:56:19.224+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:56:19.224+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:56:19.236+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:56:19.236+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:56:19.402+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.224 seconds
[2024-08-01T07:56:49.873+0000] {processor.py:157} INFO - Started process (PID=26309) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:56:49.874+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:56:49.876+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:56:49.876+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:56:49.892+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:56:49.907+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:56:49.907+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:56:49.989+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:56:49.988+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:56:49.996+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-08-01T07:57:20.426+0000] {processor.py:157} INFO - Started process (PID=26334) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:57:20.429+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:57:20.431+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:57:20.431+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:57:20.454+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:57:20.472+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:57:20.472+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:57:20.486+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:57:20.486+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:57:20.496+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-01T07:57:50.815+0000] {processor.py:157} INFO - Started process (PID=26359) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:57:50.816+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:57:50.819+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:57:50.819+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:57:50.832+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:57:50.851+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:57:50.851+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:57:50.861+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:57:50.861+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:57:50.870+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-01T07:58:21.288+0000] {processor.py:157} INFO - Started process (PID=26384) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:58:21.292+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:58:21.295+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:58:21.295+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:58:21.317+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:58:21.333+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:58:21.333+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:58:21.346+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:58:21.346+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:58:21.357+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-01T07:58:51.745+0000] {processor.py:157} INFO - Started process (PID=26409) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:58:51.747+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:58:51.749+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:58:51.749+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:58:51.761+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:58:51.776+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:58:51.776+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:58:51.787+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:58:51.787+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:58:51.796+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-01T07:59:22.209+0000] {processor.py:157} INFO - Started process (PID=26434) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:59:22.210+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:59:22.214+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:59:22.213+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:59:22.230+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:59:22.244+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:59:22.244+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:59:22.256+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:59:22.256+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:59:22.400+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.195 seconds
[2024-08-01T07:59:52.765+0000] {processor.py:157} INFO - Started process (PID=26459) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:59:52.767+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T07:59:52.770+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:59:52.769+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:59:52.789+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T07:59:52.809+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:59:52.809+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T07:59:52.823+0000] {logging_mixin.py:151} INFO - [2024-08-01T07:59:52.823+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T07:59:52.834+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-01T08:00:23.192+0000] {processor.py:157} INFO - Started process (PID=26484) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:00:23.193+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:00:23.196+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:00:23.195+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:00:23.210+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:00:23.229+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:00:23.229+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:00:23.241+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:00:23.241+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:00:23.250+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-01T08:00:53.581+0000] {processor.py:157} INFO - Started process (PID=26509) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:00:53.582+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:00:53.583+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:00:53.583+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:00:53.598+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:00:53.613+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:00:53.613+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:00:53.623+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:00:53.623+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:00:53.632+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-01T08:01:23.965+0000] {processor.py:157} INFO - Started process (PID=26534) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:01:23.966+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:01:23.967+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:01:23.967+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:01:23.978+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:01:23.995+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:01:23.995+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:01:24.004+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:01:24.004+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:01:24.014+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-01T08:01:54.447+0000] {processor.py:157} INFO - Started process (PID=26559) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:01:54.448+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:01:54.451+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:01:54.450+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:01:54.468+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:01:54.488+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:01:54.488+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:01:54.501+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:01:54.500+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:01:54.512+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-01T08:02:24.904+0000] {processor.py:157} INFO - Started process (PID=26584) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:02:24.905+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:02:24.908+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:02:24.908+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:02:24.920+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:02:24.936+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:02:24.936+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:02:25.082+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:02:25.081+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:02:25.092+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.191 seconds
[2024-08-01T08:02:55.660+0000] {processor.py:157} INFO - Started process (PID=26609) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:02:55.665+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:02:55.669+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:02:55.669+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:02:55.685+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:02:55.706+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:02:55.706+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:02:55.719+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:02:55.719+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:02:55.731+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-08-01T08:03:26.113+0000] {processor.py:157} INFO - Started process (PID=26634) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:03:26.115+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:03:26.118+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:03:26.117+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:03:26.129+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:03:26.146+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:03:26.145+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:03:26.156+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:03:26.156+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:03:26.166+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-01T08:03:56.504+0000] {processor.py:157} INFO - Started process (PID=26659) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:03:56.506+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:03:56.508+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:03:56.508+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:03:56.521+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:03:56.541+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:03:56.541+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:03:56.553+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:03:56.553+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:03:56.565+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-01T08:04:26.929+0000] {processor.py:157} INFO - Started process (PID=26684) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:04:26.930+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:04:26.933+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:04:26.933+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:04:26.951+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:04:26.970+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:04:26.970+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:04:26.983+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:04:26.983+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:04:26.992+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-01T08:04:57.382+0000] {processor.py:157} INFO - Started process (PID=26709) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:04:57.384+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:04:57.386+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:04:57.386+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:04:57.404+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:04:57.421+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:04:57.421+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:04:57.431+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:04:57.431+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:04:57.569+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.190 seconds
[2024-08-01T08:05:27.983+0000] {processor.py:157} INFO - Started process (PID=26734) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:05:27.985+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:05:27.987+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:05:27.987+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:05:27.999+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:05:28.017+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:05:28.017+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:05:28.100+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:05:28.100+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:05:28.108+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-08-01T08:05:58.619+0000] {processor.py:157} INFO - Started process (PID=26759) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:05:58.620+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:05:58.622+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:05:58.622+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:05:58.636+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:05:58.650+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:05:58.650+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:05:58.659+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:05:58.659+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:05:58.670+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-01T08:06:28.957+0000] {processor.py:157} INFO - Started process (PID=26784) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:06:28.962+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:06:28.966+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:06:28.966+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:06:28.984+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:06:29.004+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:06:29.004+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:06:29.018+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:06:29.018+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:06:29.028+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-01T08:06:59.429+0000] {processor.py:157} INFO - Started process (PID=26809) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:06:59.431+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:06:59.434+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:06:59.434+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:06:59.445+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:06:59.461+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:06:59.461+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:06:59.474+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:06:59.474+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:06:59.483+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-01T08:07:29.915+0000] {processor.py:157} INFO - Started process (PID=26834) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:07:29.917+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:07:29.918+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:07:29.918+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:07:29.929+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:07:29.946+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:07:29.945+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:07:29.957+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:07:29.957+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:07:29.969+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-01T08:08:00.390+0000] {processor.py:157} INFO - Started process (PID=26859) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:08:00.393+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:08:00.395+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:08:00.395+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:08:00.414+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:08:00.437+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:08:00.437+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:08:00.450+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:08:00.450+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:08:00.599+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.213 seconds
[2024-08-01T08:08:31.017+0000] {processor.py:157} INFO - Started process (PID=26884) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:08:31.018+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:08:31.020+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:08:31.020+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:08:31.038+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:08:31.065+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:08:31.065+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:08:31.145+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:08:31.145+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:08:31.153+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-08-01T08:09:01.745+0000] {processor.py:157} INFO - Started process (PID=26909) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:09:01.748+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:09:01.751+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:09:01.751+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:09:01.768+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:09:01.790+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:09:01.790+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:09:01.804+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:09:01.804+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:09:01.813+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-01T08:09:32.193+0000] {processor.py:157} INFO - Started process (PID=26934) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:09:32.194+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:09:32.196+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:09:32.196+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:09:32.210+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:09:32.234+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:09:32.234+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:09:32.244+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:09:32.244+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:09:32.255+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-01T08:10:02.639+0000] {processor.py:157} INFO - Started process (PID=26959) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:10:02.640+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:10:02.644+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:10:02.644+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:10:02.686+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:10:02.710+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:10:02.710+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:10:02.723+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:10:02.723+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:10:02.735+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-08-01T08:10:33.076+0000] {processor.py:157} INFO - Started process (PID=26984) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:10:33.079+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:10:33.081+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:10:33.081+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:10:33.093+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:10:33.114+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:10:33.114+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:10:33.126+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:10:33.126+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:10:33.136+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-01T08:11:03.576+0000] {processor.py:157} INFO - Started process (PID=27009) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:11:03.579+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:11:03.583+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:11:03.583+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:11:03.600+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:11:03.629+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:11:03.629+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:11:03.855+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:11:03.855+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:11:03.863+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.302 seconds
[2024-08-01T08:11:34.247+0000] {processor.py:157} INFO - Started process (PID=27034) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:11:34.248+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:11:34.251+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:11:34.251+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:11:34.269+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:11:34.283+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:11:34.283+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:11:34.294+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:11:34.294+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:11:34.304+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-01T08:12:04.717+0000] {processor.py:157} INFO - Started process (PID=27059) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:12:04.720+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:12:04.723+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:12:04.722+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:12:04.738+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:12:04.761+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:12:04.761+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:12:04.774+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:12:04.774+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:12:04.784+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-01T08:12:35.154+0000] {processor.py:157} INFO - Started process (PID=27084) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:12:35.156+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:12:35.157+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:12:35.157+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:12:35.167+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:12:35.183+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:12:35.183+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:12:35.192+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:12:35.192+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:12:35.200+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-08-01T08:13:05.597+0000] {processor.py:157} INFO - Started process (PID=27109) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:13:05.600+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:13:05.601+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:13:05.601+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:13:05.614+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:13:05.629+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:13:05.629+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:13:05.640+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:13:05.640+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:13:05.648+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-01T08:13:36.075+0000] {processor.py:157} INFO - Started process (PID=27134) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:13:36.076+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:13:36.078+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:13:36.078+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:13:36.096+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:13:36.118+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:13:36.118+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:13:36.134+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:13:36.134+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:13:36.305+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.233 seconds
[2024-08-01T08:14:06.737+0000] {processor.py:157} INFO - Started process (PID=27159) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:14:06.739+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:14:06.744+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:14:06.743+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:14:06.760+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:14:06.777+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:14:06.777+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:14:06.874+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:14:06.874+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:14:06.882+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.150 seconds
[2024-08-01T08:14:37.294+0000] {processor.py:157} INFO - Started process (PID=27184) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:14:37.296+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:14:37.298+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:14:37.298+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:14:37.316+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:14:37.330+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:14:37.330+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:14:37.342+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:14:37.342+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:14:37.352+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-01T08:15:07.776+0000] {processor.py:157} INFO - Started process (PID=27209) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:15:07.779+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:15:07.782+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:15:07.782+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:15:07.796+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:15:07.816+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:15:07.816+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:15:07.828+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:15:07.828+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:15:07.840+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-01T08:15:38.206+0000] {processor.py:157} INFO - Started process (PID=27234) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:15:38.207+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:15:38.209+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:15:38.208+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:15:38.224+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:15:38.236+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:15:38.236+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:15:38.245+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:15:38.245+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:15:38.255+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-01T08:16:08.659+0000] {processor.py:157} INFO - Started process (PID=27259) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:16:08.660+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:16:08.662+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:16:08.662+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:16:08.677+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:16:08.691+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:16:08.691+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:16:08.701+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:16:08.701+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:16:08.713+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-01T08:16:39.069+0000] {processor.py:157} INFO - Started process (PID=27284) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:16:39.071+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:16:39.074+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:16:39.073+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:16:39.093+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:16:39.115+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:16:39.115+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:16:39.130+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:16:39.130+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:16:39.269+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.204 seconds
[2024-08-01T08:17:09.975+0000] {processor.py:157} INFO - Started process (PID=27309) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:17:09.979+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:17:09.984+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:17:09.984+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:17:10.011+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:17:10.035+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:17:10.035+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:17:10.194+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:17:10.194+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:17:10.202+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.232 seconds
[2024-08-01T08:17:40.692+0000] {processor.py:157} INFO - Started process (PID=27334) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:17:40.694+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:17:40.696+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:17:40.696+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:17:40.708+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:17:40.722+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:17:40.722+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:17:40.731+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:17:40.731+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:17:40.739+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-01T08:18:11.114+0000] {processor.py:157} INFO - Started process (PID=27359) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:18:11.116+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:18:11.119+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:18:11.119+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:18:11.135+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:18:11.151+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:18:11.151+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:18:11.162+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:18:11.162+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:18:11.172+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-01T08:18:41.546+0000] {processor.py:157} INFO - Started process (PID=27384) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:18:41.547+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:18:41.551+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:18:41.551+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:18:41.565+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:18:41.585+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:18:41.585+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:18:41.597+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:18:41.597+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:18:41.606+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-01T08:19:11.942+0000] {processor.py:157} INFO - Started process (PID=27409) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:19:11.943+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:19:11.945+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:19:11.944+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:19:11.960+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:19:11.976+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:19:11.976+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:19:11.987+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:19:11.986+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:19:11.998+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-01T08:19:42.451+0000] {processor.py:157} INFO - Started process (PID=27434) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:19:42.452+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:19:42.454+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:19:42.454+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:19:42.469+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:19:42.489+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:19:42.489+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:19:42.601+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:19:42.601+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:19:42.611+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.163 seconds
[2024-08-01T08:20:13.182+0000] {processor.py:157} INFO - Started process (PID=27459) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:20:13.185+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:20:13.188+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:20:13.188+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:20:13.204+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:20:13.227+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:20:13.227+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:20:13.240+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:20:13.240+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:20:13.249+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-01T08:20:43.605+0000] {processor.py:157} INFO - Started process (PID=27484) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:20:43.606+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:20:43.608+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:20:43.608+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:20:43.620+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:20:43.640+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:20:43.640+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:20:43.652+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:20:43.652+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:20:43.662+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-01T08:21:14.111+0000] {processor.py:157} INFO - Started process (PID=27509) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:21:14.114+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:21:14.118+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:21:14.117+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:21:14.133+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:21:14.150+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:21:14.150+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:21:14.161+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:21:14.161+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:21:14.171+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-01T08:21:44.546+0000] {processor.py:157} INFO - Started process (PID=27534) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:21:44.548+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:21:44.550+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:21:44.550+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:21:44.569+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:21:44.585+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:21:44.585+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:21:44.599+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:21:44.599+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:21:44.610+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-01T08:22:15.180+0000] {processor.py:157} INFO - Started process (PID=27558) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:22:15.184+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:22:15.194+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:22:15.193+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:22:15.229+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:22:15.270+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:22:15.270+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:22:15.300+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:22:15.300+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:22:15.471+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.298 seconds
[2024-08-01T08:22:46.057+0000] {processor.py:157} INFO - Started process (PID=27584) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:22:46.060+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:22:46.064+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:22:46.064+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:22:46.088+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:22:46.117+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:22:46.117+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:22:46.312+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:22:46.311+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:22:46.323+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.271 seconds
[2024-08-01T08:23:16.941+0000] {processor.py:157} INFO - Started process (PID=27607) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:23:16.943+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:23:16.947+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:23:16.946+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:23:16.976+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:23:17.016+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:23:17.016+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:23:17.033+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:23:17.033+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:23:17.042+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-08-01T08:23:47.460+0000] {processor.py:157} INFO - Started process (PID=27634) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:23:47.463+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:23:47.467+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:23:47.467+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:23:47.491+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:23:47.527+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:23:47.527+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:23:47.547+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:23:47.547+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:23:47.566+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-08-01T08:24:17.934+0000] {processor.py:157} INFO - Started process (PID=27659) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:24:17.936+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:24:17.942+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:24:17.941+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:24:17.979+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:24:18.010+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:24:18.010+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:24:18.025+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:24:18.025+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:24:18.038+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-08-01T08:24:48.429+0000] {processor.py:157} INFO - Started process (PID=27684) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:24:48.430+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:24:48.431+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:24:48.431+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:24:48.445+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:24:48.471+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:24:48.471+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:24:48.485+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:24:48.485+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:24:48.501+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-08-01T08:25:18.849+0000] {processor.py:157} INFO - Started process (PID=27709) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:25:18.850+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:25:18.854+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:25:18.854+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:25:18.870+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:25:18.893+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:25:18.893+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:25:19.040+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:25:19.040+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:25:19.049+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.203 seconds
[2024-08-01T08:25:49.566+0000] {processor.py:157} INFO - Started process (PID=27734) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:25:49.568+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:25:49.571+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:25:49.570+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:25:49.581+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:25:49.598+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:25:49.598+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:25:49.681+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:25:49.681+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:25:49.689+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-08-01T08:26:20.254+0000] {processor.py:157} INFO - Started process (PID=27759) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:26:20.260+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:26:20.263+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:26:20.263+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:26:20.280+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:26:20.301+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:26:20.301+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:26:20.313+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:26:20.313+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:26:20.322+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-01T08:26:50.630+0000] {processor.py:157} INFO - Started process (PID=27784) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:26:50.631+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:26:50.633+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:26:50.632+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:26:50.642+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:26:50.656+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:26:50.656+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:26:50.664+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:26:50.664+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:26:50.673+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-08-01T08:27:21.122+0000] {processor.py:157} INFO - Started process (PID=27809) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:27:21.123+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:27:21.127+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:27:21.127+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:27:21.147+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:27:21.177+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:27:21.177+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:27:21.191+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:27:21.191+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:27:21.201+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-08-01T08:27:51.596+0000] {processor.py:157} INFO - Started process (PID=27834) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:27:51.600+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:27:51.603+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:27:51.603+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:27:51.623+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:27:51.656+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:27:51.656+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:27:51.671+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:27:51.671+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:27:51.853+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.262 seconds
[2024-08-01T08:28:22.286+0000] {processor.py:157} INFO - Started process (PID=27859) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:28:22.286+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:28:22.288+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:28:22.288+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:28:22.300+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:28:22.319+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:28:22.319+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:28:22.403+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:28:22.403+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:28:22.412+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-08-01T08:28:52.919+0000] {processor.py:157} INFO - Started process (PID=27884) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:28:52.921+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:28:52.923+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:28:52.923+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:28:52.935+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:28:52.956+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:28:52.955+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:28:53.042+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:28:53.042+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:28:53.051+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-08-01T08:29:23.612+0000] {processor.py:157} INFO - Started process (PID=27909) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:29:23.614+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:29:23.618+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:29:23.618+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:29:23.635+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:29:23.656+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:29:23.656+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:29:23.670+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:29:23.669+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:29:23.680+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-01T08:29:54.053+0000] {processor.py:157} INFO - Started process (PID=27934) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:29:54.055+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:29:54.058+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:29:54.057+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:29:54.073+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:29:54.087+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:29:54.087+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:29:54.099+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:29:54.099+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:29:54.108+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-01T08:30:24.505+0000] {processor.py:157} INFO - Started process (PID=27959) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:30:24.507+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:30:24.509+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:30:24.509+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:30:24.521+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:30:24.538+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:30:24.538+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:30:24.550+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:30:24.550+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:30:24.560+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-01T08:30:54.938+0000] {processor.py:157} INFO - Started process (PID=27984) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:30:54.943+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:30:54.946+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:30:54.946+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:30:54.968+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:30:55.004+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:30:55.004+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:30:55.028+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:30:55.028+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:30:55.208+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.275 seconds
[2024-08-01T08:31:25.668+0000] {processor.py:157} INFO - Started process (PID=28009) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:31:25.669+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:31:25.671+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:31:25.671+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:31:25.685+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:31:25.704+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:31:25.703+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:31:25.819+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:31:25.819+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:31:25.827+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.163 seconds
[2024-08-01T08:31:56.234+0000] {processor.py:157} INFO - Started process (PID=28034) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:31:56.237+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:31:56.239+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:31:56.239+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:31:56.254+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:31:56.278+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:31:56.277+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:31:56.290+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:31:56.290+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:31:56.300+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-01T08:32:26.728+0000] {processor.py:157} INFO - Started process (PID=28059) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:32:26.730+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:32:26.733+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:32:26.733+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:32:26.744+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:32:26.760+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:32:26.760+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:32:26.769+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:32:26.769+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:32:26.778+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-01T08:32:57.146+0000] {processor.py:157} INFO - Started process (PID=28084) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:32:57.147+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:32:57.150+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:32:57.150+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:32:57.167+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:32:57.186+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:32:57.185+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:32:57.197+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:32:57.197+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:32:57.206+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-01T08:33:27.612+0000] {processor.py:157} INFO - Started process (PID=28109) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:33:27.614+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:33:27.617+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:33:27.617+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:33:27.635+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:33:27.654+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:33:27.654+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:33:27.668+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:33:27.668+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:33:27.677+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-01T08:33:58.048+0000] {processor.py:157} INFO - Started process (PID=28134) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:33:58.050+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:33:58.052+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:33:58.052+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:33:58.069+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:33:58.089+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:33:58.089+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:33:58.273+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:33:58.273+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:33:58.282+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.238 seconds
[2024-08-01T08:34:28.707+0000] {processor.py:157} INFO - Started process (PID=28158) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:34:28.708+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:34:28.712+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:34:28.711+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:34:28.728+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:34:28.752+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:34:28.752+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:34:28.841+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:34:28.841+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:34:28.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.146 seconds
[2024-08-01T08:34:59.376+0000] {processor.py:157} INFO - Started process (PID=28184) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:34:59.377+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:34:59.380+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:34:59.380+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:34:59.398+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:34:59.420+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:34:59.420+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:34:59.431+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:34:59.431+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:34:59.441+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-01T08:35:29.825+0000] {processor.py:157} INFO - Started process (PID=28209) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:35:29.826+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:35:29.828+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:35:29.828+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:35:29.844+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:35:29.862+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:35:29.862+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:35:29.874+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:35:29.874+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:35:29.882+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-01T08:36:00.264+0000] {processor.py:157} INFO - Started process (PID=28234) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:36:00.265+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:36:00.267+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:36:00.267+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:36:00.277+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:36:00.295+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:36:00.295+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:36:00.307+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:36:00.307+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:36:00.316+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-01T08:36:30.708+0000] {processor.py:157} INFO - Started process (PID=28259) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:36:30.710+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:36:30.713+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:36:30.712+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:36:30.728+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:36:30.749+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:36:30.749+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:36:30.767+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:36:30.767+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:36:30.935+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.231 seconds
[2024-08-01T08:37:01.506+0000] {processor.py:157} INFO - Started process (PID=28284) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:37:01.508+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:37:01.510+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:37:01.510+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:37:01.525+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:37:01.545+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:37:01.545+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:37:01.690+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:37:01.689+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:37:01.697+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.194 seconds
[2024-08-01T08:37:32.222+0000] {processor.py:157} INFO - Started process (PID=28309) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:37:32.225+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:37:32.226+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:37:32.226+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:37:32.240+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:37:32.271+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:37:32.271+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:37:32.351+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:37:32.351+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:37:32.359+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-08-01T08:38:02.788+0000] {processor.py:157} INFO - Started process (PID=28334) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:38:02.790+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:38:02.792+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:38:02.791+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:38:02.802+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:38:02.819+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:38:02.819+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:38:02.830+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:38:02.830+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:38:02.839+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-01T08:38:33.288+0000] {processor.py:157} INFO - Started process (PID=28359) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:38:33.289+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:38:33.291+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:38:33.291+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:38:33.302+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:38:33.316+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:38:33.316+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:38:33.327+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:38:33.327+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:38:33.336+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-01T08:39:03.729+0000] {processor.py:157} INFO - Started process (PID=28384) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:39:03.730+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:39:03.732+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:39:03.732+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:39:03.746+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:39:03.764+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:39:03.763+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:39:03.777+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:39:03.777+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:39:03.787+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-01T08:39:34.186+0000] {processor.py:157} INFO - Started process (PID=28409) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:39:34.188+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:39:34.190+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:39:34.190+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:39:34.201+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:39:34.219+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:39:34.219+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:39:34.230+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:39:34.230+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:39:34.395+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.212 seconds
[2024-08-01T08:40:04.951+0000] {processor.py:157} INFO - Started process (PID=28434) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:40:04.954+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:40:04.956+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:40:04.956+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:40:04.971+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:40:04.987+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:40:04.987+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:40:05.068+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:40:05.068+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:40:05.077+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-08-01T08:40:35.445+0000] {processor.py:157} INFO - Started process (PID=28459) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:40:35.446+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:40:35.448+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:40:35.447+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:40:35.463+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:40:35.553+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:40:35.553+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:40:35.561+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:40:35.561+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:40:35.570+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-08-01T08:41:06.146+0000] {processor.py:157} INFO - Started process (PID=28484) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:41:06.149+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:41:06.152+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:41:06.152+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:41:06.167+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:41:06.182+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:41:06.182+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:41:06.193+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:41:06.193+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:41:06.202+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-01T08:41:36.559+0000] {processor.py:157} INFO - Started process (PID=28509) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:41:36.561+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:41:36.563+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:41:36.562+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:41:36.579+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:41:36.598+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:41:36.598+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:41:36.610+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:41:36.609+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:41:36.618+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-01T08:42:07.064+0000] {processor.py:157} INFO - Started process (PID=28534) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:42:07.065+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:42:07.066+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:42:07.066+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:42:07.078+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:42:07.093+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:42:07.093+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:42:07.103+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:42:07.103+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:42:07.235+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.173 seconds
[2024-08-01T08:42:37.604+0000] {processor.py:157} INFO - Started process (PID=28559) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:42:37.606+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:42:37.608+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:42:37.608+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:42:37.622+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:42:37.639+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:42:37.639+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:42:37.729+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:42:37.729+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:42:37.736+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-08-01T08:43:08.183+0000] {processor.py:157} INFO - Started process (PID=28584) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:43:08.186+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:43:08.187+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:43:08.187+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:43:08.202+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:43:08.217+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:43:08.217+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:43:08.294+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:43:08.294+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:43:08.303+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-08-01T08:43:38.864+0000] {processor.py:157} INFO - Started process (PID=28609) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:43:38.867+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:43:38.869+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:43:38.869+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:43:38.889+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:43:38.907+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:43:38.907+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:43:38.919+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:43:38.919+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:43:38.928+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-01T08:44:09.317+0000] {processor.py:157} INFO - Started process (PID=28634) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:44:09.317+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:44:09.321+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:44:09.321+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:44:09.335+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:44:09.356+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:44:09.356+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:44:09.369+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:44:09.369+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:44:09.381+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-01T08:44:39.727+0000] {processor.py:157} INFO - Started process (PID=28659) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:44:39.728+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:44:39.729+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:44:39.729+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:44:39.739+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:44:39.757+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:44:39.757+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:44:39.770+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:44:39.770+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:44:39.780+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-01T08:45:10.222+0000] {processor.py:157} INFO - Started process (PID=28684) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:45:10.224+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:45:10.226+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:45:10.226+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:45:10.235+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:45:10.251+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:45:10.251+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:45:10.261+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:45:10.261+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:45:10.406+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.187 seconds
[2024-08-01T08:45:41.010+0000] {processor.py:157} INFO - Started process (PID=28709) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:45:41.012+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:45:41.014+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:45:41.014+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:45:41.029+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:45:41.045+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:45:41.045+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:45:41.136+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:45:41.136+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:45:41.145+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-08-01T08:46:11.561+0000] {processor.py:157} INFO - Started process (PID=28734) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:46:11.562+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:46:11.564+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:46:11.563+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:46:11.580+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:46:11.598+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:46:11.598+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:46:11.674+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:46:11.674+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:46:11.682+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-08-01T08:46:42.270+0000] {processor.py:157} INFO - Started process (PID=28759) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:46:42.273+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:46:42.275+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:46:42.275+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:46:42.299+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:46:42.319+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:46:42.319+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:46:42.330+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:46:42.330+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:46:42.339+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-01T08:47:12.683+0000] {processor.py:157} INFO - Started process (PID=28784) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:47:12.684+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:47:12.686+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:47:12.686+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:47:12.696+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:47:12.709+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:47:12.709+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:47:12.719+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:47:12.719+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:47:12.728+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-08-01T08:47:43.151+0000] {processor.py:157} INFO - Started process (PID=28809) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:47:43.153+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:47:43.156+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:47:43.156+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:47:43.167+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:47:43.185+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:47:43.185+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:47:43.199+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:47:43.199+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:47:43.209+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-01T08:48:14.009+0000] {processor.py:157} INFO - Started process (PID=28834) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:48:14.011+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:48:14.017+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:48:14.017+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:48:14.048+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:48:14.084+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:48:14.084+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:48:14.259+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:48:14.258+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:48:14.271+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.271 seconds
[2024-08-01T08:48:44.775+0000] {processor.py:157} INFO - Started process (PID=28859) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:48:44.777+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:48:44.786+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:48:44.786+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:48:44.814+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:48:44.855+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:48:44.855+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:48:45.498+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:48:45.498+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:48:45.523+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.754 seconds
[2024-08-01T08:49:15.967+0000] {processor.py:157} INFO - Started process (PID=28884) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:49:15.968+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:49:15.969+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:49:15.969+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:49:15.988+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:49:16.190+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:49:16.190+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:49:16.199+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:49:16.199+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:49:16.208+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.244 seconds
[2024-08-01T08:49:46.763+0000] {processor.py:157} INFO - Started process (PID=28909) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:49:46.765+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:49:46.767+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:49:46.767+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:49:46.778+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:49:46.795+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:49:46.795+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:49:46.804+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:49:46.804+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:49:46.814+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-01T08:50:17.216+0000] {processor.py:157} INFO - Started process (PID=28934) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:50:17.217+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:50:17.219+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:50:17.219+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:50:17.236+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:50:17.255+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:50:17.255+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:50:17.267+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:50:17.267+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:50:17.276+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-01T08:50:47.640+0000] {processor.py:157} INFO - Started process (PID=28959) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:50:47.643+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:50:47.646+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:50:47.646+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:50:47.668+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:50:47.686+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:50:47.686+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:50:47.698+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:50:47.698+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:50:47.800+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.166 seconds
[2024-08-01T08:51:18.226+0000] {processor.py:157} INFO - Started process (PID=28984) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:51:18.230+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:51:18.233+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:51:18.233+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:51:18.242+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:51:18.255+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:51:18.255+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:51:18.338+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:51:18.338+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:51:18.347+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-08-01T08:51:48.751+0000] {processor.py:157} INFO - Started process (PID=29009) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:51:48.752+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:51:48.754+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:51:48.754+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:51:48.766+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:51:48.782+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:51:48.781+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:51:48.873+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:51:48.873+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:51:48.881+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-08-01T08:52:19.431+0000] {processor.py:157} INFO - Started process (PID=29034) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:52:19.434+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:52:19.436+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:52:19.436+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:52:19.449+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:52:19.536+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:52:19.535+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:52:19.543+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:52:19.543+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:52:19.550+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-08-01T08:52:49.950+0000] {processor.py:157} INFO - Started process (PID=29059) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:52:49.952+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:52:49.954+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:52:49.954+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:52:49.967+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:52:49.988+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:52:49.988+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:52:50.004+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:52:50.004+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:52:50.013+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-01T08:53:20.388+0000] {processor.py:157} INFO - Started process (PID=29084) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:53:20.391+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:53:20.392+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:53:20.392+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:53:20.405+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:53:20.420+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:53:20.420+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:53:20.431+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:53:20.431+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:53:20.443+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-01T08:53:50.770+0000] {processor.py:157} INFO - Started process (PID=29109) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:53:50.773+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:53:50.774+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:53:50.774+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:53:50.786+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:53:50.801+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:53:50.801+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:53:50.814+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:53:50.814+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:53:50.907+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-08-01T08:54:21.401+0000] {processor.py:157} INFO - Started process (PID=29134) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:54:21.402+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:54:21.404+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:54:21.404+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:54:21.418+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:54:21.433+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:54:21.433+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:54:21.512+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:54:21.511+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:54:21.519+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-08-01T08:54:51.888+0000] {processor.py:157} INFO - Started process (PID=29159) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:54:51.889+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:54:51.890+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:54:51.890+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:54:51.898+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:54:51.979+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:54:51.979+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:54:51.987+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:54:51.987+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:54:51.997+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-08-01T08:55:22.527+0000] {processor.py:157} INFO - Started process (PID=29184) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:55:22.528+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:55:22.530+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:55:22.530+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:55:22.542+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:55:22.558+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:55:22.558+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:55:22.572+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:55:22.571+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:55:22.580+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-01T08:55:52.987+0000] {processor.py:157} INFO - Started process (PID=29209) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:55:52.989+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:55:52.992+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:55:52.992+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:55:53.003+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:55:53.020+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:55:53.020+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:55:53.030+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:55:53.030+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:55:53.039+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-01T08:56:23.371+0000] {processor.py:157} INFO - Started process (PID=29234) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:56:23.372+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:56:23.373+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:56:23.373+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:56:23.384+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:56:23.397+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:56:23.397+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:56:23.407+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:56:23.406+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:56:23.417+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-08-01T08:56:53.737+0000] {processor.py:157} INFO - Started process (PID=29259) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:56:53.738+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:56:53.741+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:56:53.741+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:56:53.757+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:56:53.771+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:56:53.771+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:56:53.869+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:56:53.869+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:56:53.877+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.147 seconds
[2024-08-01T08:57:24.250+0000] {processor.py:157} INFO - Started process (PID=29284) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:57:24.252+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:57:24.253+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:57:24.253+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:57:24.268+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:57:24.289+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:57:24.289+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:57:24.376+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:57:24.376+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:57:24.385+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-08-01T08:57:54.920+0000] {processor.py:157} INFO - Started process (PID=29309) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:57:54.921+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:57:54.922+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:57:54.922+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:57:54.936+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:57:55.032+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:57:55.032+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:57:55.040+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:57:55.040+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:57:55.047+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-08-01T08:58:25.449+0000] {processor.py:157} INFO - Started process (PID=29334) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:58:25.450+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:58:25.452+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:58:25.452+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:58:25.467+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:58:25.485+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:58:25.485+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:58:25.495+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:58:25.495+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:58:25.503+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-01T08:58:55.935+0000] {processor.py:157} INFO - Started process (PID=29359) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:58:55.937+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:58:55.939+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:58:55.939+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:58:55.953+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:58:55.967+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:58:55.967+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:58:55.979+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:58:55.979+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:58:55.986+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-01T08:59:26.358+0000] {processor.py:157} INFO - Started process (PID=29384) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:59:26.360+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:59:26.362+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:59:26.362+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:59:26.374+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:59:26.389+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:59:26.389+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:59:26.400+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:59:26.400+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:59:26.483+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-08-01T08:59:56.903+0000] {processor.py:157} INFO - Started process (PID=29409) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:59:56.904+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T08:59:56.906+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:59:56.906+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:59:56.923+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T08:59:56.937+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:59:56.937+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T08:59:57.012+0000] {logging_mixin.py:151} INFO - [2024-08-01T08:59:57.012+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T08:59:57.022+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-08-01T09:00:27.525+0000] {processor.py:157} INFO - Started process (PID=29434) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:00:27.527+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:00:27.529+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:00:27.529+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:00:27.539+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:00:27.555+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:00:27.555+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:00:27.632+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:00:27.632+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:00:27.641+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-08-01T09:00:58.151+0000] {processor.py:157} INFO - Started process (PID=29459) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:00:58.152+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:00:58.153+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:00:58.153+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:00:58.163+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:00:58.258+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:00:58.258+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:00:58.266+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:00:58.265+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:00:58.273+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-08-01T09:01:28.818+0000] {processor.py:157} INFO - Started process (PID=29484) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:01:28.819+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:01:28.821+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:01:28.821+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:01:28.835+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:01:28.853+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:01:28.853+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:01:28.863+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:01:28.863+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:01:28.871+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-01T09:01:59.231+0000] {processor.py:157} INFO - Started process (PID=29509) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:01:59.234+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:01:59.236+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:01:59.236+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:01:59.250+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:01:59.271+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:01:59.271+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:01:59.281+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:01:59.281+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:01:59.291+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-01T09:02:29.667+0000] {processor.py:157} INFO - Started process (PID=29534) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:02:29.670+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:02:29.673+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:02:29.673+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:02:29.687+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:02:29.705+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:02:29.705+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:02:29.801+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:02:29.801+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:02:29.810+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.146 seconds
[2024-08-01T09:03:00.232+0000] {processor.py:157} INFO - Started process (PID=29559) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:03:00.235+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:03:00.237+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:03:00.237+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:03:00.250+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:03:00.265+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:03:00.264+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:03:00.348+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:03:00.348+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:03:00.356+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-08-01T09:03:30.776+0000] {processor.py:157} INFO - Started process (PID=29584) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:03:30.778+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:03:30.781+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:03:30.781+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:03:30.793+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:03:30.880+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:03:30.880+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:03:30.888+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:03:30.888+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:03:30.896+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-08-01T09:04:01.382+0000] {processor.py:157} INFO - Started process (PID=29609) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:04:01.383+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:04:01.384+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:04:01.384+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:04:01.470+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:04:01.483+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:04:01.483+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:04:01.491+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:04:01.491+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:04:01.498+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-08-01T09:04:31.876+0000] {processor.py:157} INFO - Started process (PID=29634) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:04:31.878+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:04:31.880+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:04:31.880+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:04:31.901+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:04:31.918+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:04:31.918+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:04:31.932+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:04:31.932+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:04:31.943+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-01T09:05:02.299+0000] {processor.py:157} INFO - Started process (PID=29659) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:05:02.304+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:05:02.305+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:05:02.305+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:05:02.315+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:05:02.327+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:05:02.327+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:05:02.337+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:05:02.337+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:05:02.451+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.154 seconds
[2024-08-01T09:05:32.927+0000] {processor.py:157} INFO - Started process (PID=29684) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:05:32.929+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:05:32.931+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:05:32.931+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:05:32.944+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:05:32.961+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:05:32.961+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:05:33.043+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:05:33.043+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:05:33.051+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-08-01T09:06:03.449+0000] {processor.py:157} INFO - Started process (PID=29708) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:06:03.452+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:06:03.454+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:06:03.454+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:06:03.473+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:06:03.520+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:06:03.520+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:06:03.650+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:06:03.650+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:06:03.658+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.213 seconds
[2024-08-01T09:06:34.221+0000] {processor.py:157} INFO - Started process (PID=29734) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:06:34.223+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:06:34.224+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:06:34.224+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:06:34.243+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:06:34.326+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:06:34.326+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:06:34.335+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:06:34.335+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:06:34.343+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-08-01T09:07:04.868+0000] {processor.py:157} INFO - Started process (PID=29759) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:07:04.872+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:07:04.876+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:07:04.875+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:07:04.892+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:07:04.913+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:07:04.913+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:07:04.925+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:07:04.925+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:07:04.935+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-01T09:07:35.314+0000] {processor.py:157} INFO - Started process (PID=29784) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:07:35.317+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:07:35.320+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:07:35.319+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:07:35.336+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:07:35.350+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:07:35.350+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:07:35.362+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:07:35.362+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:07:35.373+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-01T09:08:05.685+0000] {processor.py:157} INFO - Started process (PID=29809) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:08:05.686+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:08:05.688+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:08:05.688+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:08:05.698+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:08:05.714+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:08:05.714+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:08:05.724+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:08:05.724+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:08:05.869+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.187 seconds
[2024-08-01T09:08:36.423+0000] {processor.py:157} INFO - Started process (PID=29834) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:08:36.424+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:08:36.426+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:08:36.426+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:08:36.445+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:08:36.460+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:08:36.460+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:08:36.536+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:08:36.536+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:08:36.544+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-08-01T09:09:06.912+0000] {processor.py:157} INFO - Started process (PID=29859) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:09:06.913+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:09:06.914+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:09:06.914+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:09:06.925+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:09:06.941+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:09:06.941+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:09:07.018+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:09:07.018+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:09:07.026+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-08-01T09:09:37.454+0000] {processor.py:157} INFO - Started process (PID=29884) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:09:37.457+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:09:37.459+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:09:37.459+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:09:37.478+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:09:37.603+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:09:37.603+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:09:37.612+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:09:37.612+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:09:37.620+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.170 seconds
[2024-08-01T09:10:08.159+0000] {processor.py:157} INFO - Started process (PID=29909) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:10:08.161+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:10:08.163+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:10:08.163+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:10:08.176+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:10:08.194+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:10:08.194+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:10:08.206+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:10:08.206+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:10:08.214+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-01T09:10:38.589+0000] {processor.py:157} INFO - Started process (PID=29934) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:10:38.591+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:10:38.593+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:10:38.593+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:10:38.613+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:10:38.626+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:10:38.626+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:10:38.637+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:10:38.637+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:10:38.648+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-01T09:11:09.062+0000] {processor.py:157} INFO - Started process (PID=29959) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:11:09.065+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:11:09.069+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:11:09.069+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:11:09.086+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:11:09.107+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:11:09.107+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:11:09.227+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:11:09.227+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:11:09.237+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.179 seconds
[2024-08-01T09:11:39.736+0000] {processor.py:157} INFO - Started process (PID=29984) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:11:39.738+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:11:39.741+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:11:39.740+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:11:39.752+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:11:39.769+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:11:39.769+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:11:39.846+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:11:39.846+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:11:39.855+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-08-01T09:12:10.389+0000] {processor.py:157} INFO - Started process (PID=30009) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:12:10.394+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:12:10.398+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:12:10.397+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:12:10.422+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:12:10.603+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:12:10.602+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:12:10.614+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:12:10.614+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:12:10.624+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.240 seconds
[2024-08-01T09:12:41.227+0000] {processor.py:157} INFO - Started process (PID=30034) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:12:41.229+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:12:41.237+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:12:41.237+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:12:41.386+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:12:41.399+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:12:41.398+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:12:41.408+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:12:41.408+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:12:41.417+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.196 seconds
[2024-08-01T09:13:11.796+0000] {processor.py:157} INFO - Started process (PID=30059) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:13:11.799+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:13:11.801+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:13:11.801+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:13:11.818+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:13:11.841+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:13:11.841+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:13:11.853+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:13:11.853+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:13:11.862+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-01T09:13:42.212+0000] {processor.py:157} INFO - Started process (PID=30084) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:13:42.213+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:13:42.215+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:13:42.215+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:13:42.232+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:13:42.254+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:13:42.254+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:13:42.268+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:13:42.267+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:13:42.502+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.294 seconds
[2024-08-01T09:14:12.917+0000] {processor.py:157} INFO - Started process (PID=30107) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:14:12.920+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:14:12.925+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:14:12.924+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:14:12.955+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:14:13.003+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:14:13.003+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:14:13.135+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:14:13.135+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:14:13.143+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.235 seconds
[2024-08-01T09:14:43.660+0000] {processor.py:157} INFO - Started process (PID=30134) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:14:43.662+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:14:43.665+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:14:43.664+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:14:43.678+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:14:43.691+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:14:43.691+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:14:43.802+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:14:43.802+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:14:43.808+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.150 seconds
[2024-08-01T09:15:14.214+0000] {processor.py:157} INFO - Started process (PID=30159) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:15:14.217+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:15:14.221+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:15:14.221+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:15:14.241+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:15:14.375+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:15:14.375+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:15:14.386+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:15:14.386+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:15:14.394+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.185 seconds
[2024-08-01T09:15:44.806+0000] {processor.py:157} INFO - Started process (PID=30184) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:15:44.810+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:15:44.814+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:15:44.814+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:15:44.832+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:15:44.851+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:15:44.851+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:15:44.866+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:15:44.866+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:15:44.876+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-01T09:16:15.205+0000] {processor.py:157} INFO - Started process (PID=30209) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:16:15.207+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:16:15.209+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:16:15.209+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:16:15.226+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:16:15.247+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:16:15.247+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:16:15.261+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:16:15.261+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:16:15.279+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-08-01T09:16:45.726+0000] {processor.py:157} INFO - Started process (PID=30233) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:16:45.729+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:16:45.734+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:16:45.733+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:16:45.770+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:16:45.794+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:16:45.794+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:16:45.810+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:16:45.810+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:16:45.967+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.246 seconds
[2024-08-01T09:17:16.589+0000] {processor.py:157} INFO - Started process (PID=30259) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:17:16.590+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:17:16.592+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:17:16.592+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:17:16.604+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:17:16.621+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:17:16.620+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:17:16.714+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:17:16.714+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:17:16.722+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-08-01T09:17:47.112+0000] {processor.py:157} INFO - Started process (PID=30284) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:17:47.113+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:17:47.118+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:17:47.118+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:17:47.137+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:17:47.270+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:17:47.270+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:17:47.279+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:17:47.279+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:17:47.288+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.182 seconds
[2024-08-01T09:18:17.804+0000] {processor.py:157} INFO - Started process (PID=30309) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:18:17.806+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:18:17.810+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:18:17.809+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:18:17.830+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:18:17.987+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:18:17.987+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:18:17.996+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:18:17.996+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:18:18.006+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.205 seconds
[2024-08-01T09:18:48.562+0000] {processor.py:157} INFO - Started process (PID=30334) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:18:48.567+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:18:48.697+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:18:48.697+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:18:48.704+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:18:48.718+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:18:48.718+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:18:48.728+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:18:48.728+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:18:48.738+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.180 seconds
[2024-08-01T09:19:19.308+0000] {processor.py:157} INFO - Started process (PID=30359) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:19:19.309+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:19:19.312+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:19:19.312+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:19:19.327+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:19:19.350+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:19:19.349+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:19:19.362+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:19:19.362+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:19:19.374+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-01T09:19:49.754+0000] {processor.py:157} INFO - Started process (PID=30384) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:19:49.755+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:19:49.756+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:19:49.756+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:19:49.763+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:19:49.776+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:19:49.775+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:19:49.785+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:19:49.785+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:19:49.793+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.041 seconds
[2024-08-01T09:20:20.152+0000] {processor.py:157} INFO - Started process (PID=30409) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:20:20.153+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:20:20.154+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:20:20.154+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:20:20.167+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:20:20.180+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:20:20.180+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:20:20.189+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:20:20.189+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:20:20.197+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-08-01T09:20:50.580+0000] {processor.py:157} INFO - Started process (PID=30434) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:20:50.581+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:20:50.582+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:20:50.582+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:20:50.592+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:20:50.609+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:20:50.609+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:20:50.618+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:20:50.618+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:20:50.627+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-01T09:21:20.950+0000] {processor.py:157} INFO - Started process (PID=30459) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:21:20.953+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:21:20.955+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:21:20.954+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:21:20.968+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:21:20.985+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:21:20.985+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:21:20.997+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:21:20.997+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:21:21.005+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-01T09:21:51.415+0000] {processor.py:157} INFO - Started process (PID=30484) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:21:51.417+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:21:51.419+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:21:51.419+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:21:51.435+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:21:51.455+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:21:51.455+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:21:51.466+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:21:51.466+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:21:51.476+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-01T09:22:21.874+0000] {processor.py:157} INFO - Started process (PID=30509) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:22:21.877+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:22:21.879+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:22:21.879+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:22:21.892+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:22:21.907+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:22:21.907+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:22:21.919+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:22:21.919+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:22:21.927+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-01T09:22:52.319+0000] {processor.py:157} INFO - Started process (PID=30534) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:22:52.320+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:22:52.321+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:22:52.321+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:22:52.332+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:22:52.347+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:22:52.347+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:22:52.360+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:22:52.360+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:22:52.369+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-01T09:23:22.784+0000] {processor.py:157} INFO - Started process (PID=30559) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:23:22.785+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:23:22.787+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:23:22.787+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:23:22.798+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:23:22.814+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:23:22.814+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:23:22.824+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:23:22.824+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:23:22.833+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-01T09:23:53.177+0000] {processor.py:157} INFO - Started process (PID=30584) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:23:53.177+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:23:53.179+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:23:53.179+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:23:53.190+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:23:53.207+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:23:53.207+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:23:53.221+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:23:53.221+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:23:53.229+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-01T09:24:23.585+0000] {processor.py:157} INFO - Started process (PID=30609) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:24:23.588+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:24:23.589+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:24:23.589+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:24:23.599+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:24:23.615+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:24:23.615+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:24:23.628+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:24:23.628+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:24:23.638+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-01T09:24:54.009+0000] {processor.py:157} INFO - Started process (PID=30634) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:24:54.013+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:24:54.016+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:24:54.015+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:24:54.030+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:24:54.050+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:24:54.050+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:24:54.063+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:24:54.063+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:24:54.075+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-01T09:25:24.467+0000] {processor.py:157} INFO - Started process (PID=30659) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:25:24.469+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:25:24.471+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:25:24.471+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:25:24.487+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:25:24.502+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:25:24.502+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:25:24.512+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:25:24.512+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:25:24.521+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-01T09:25:54.892+0000] {processor.py:157} INFO - Started process (PID=30684) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:25:54.893+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:25:54.894+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:25:54.894+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:25:54.906+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:25:54.925+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:25:54.925+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:25:54.938+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:25:54.938+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:25:54.946+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-01T09:26:25.219+0000] {processor.py:157} INFO - Started process (PID=30709) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:26:25.221+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:26:25.223+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:26:25.223+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:26:25.238+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:26:25.253+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:26:25.253+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:26:25.264+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:26:25.264+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:26:25.274+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-01T09:26:55.662+0000] {processor.py:157} INFO - Started process (PID=30734) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:26:55.666+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:26:55.669+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:26:55.669+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:26:55.683+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:26:55.702+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:26:55.702+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:26:55.715+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:26:55.715+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:26:55.724+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-01T09:27:26.109+0000] {processor.py:157} INFO - Started process (PID=30759) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:27:26.110+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:27:26.111+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:27:26.111+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:27:26.123+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:27:26.137+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:27:26.137+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:27:26.147+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:27:26.147+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:27:26.157+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-01T09:27:56.567+0000] {processor.py:157} INFO - Started process (PID=30784) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:27:56.568+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:27:56.570+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:27:56.569+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:27:56.580+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:27:56.598+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:27:56.597+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:27:56.608+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:27:56.608+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:27:56.618+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-01T09:28:26.972+0000] {processor.py:157} INFO - Started process (PID=30809) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:28:26.978+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:28:26.979+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:28:26.979+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:28:26.989+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:28:27.002+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:28:27.002+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:28:27.011+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:28:27.011+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:28:27.020+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-01T09:28:57.317+0000] {processor.py:157} INFO - Started process (PID=30834) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:28:57.319+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:28:57.321+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:28:57.320+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:28:57.333+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:28:57.349+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:28:57.349+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:28:57.364+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:28:57.364+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:28:57.373+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-01T09:29:27.694+0000] {processor.py:157} INFO - Started process (PID=30859) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:29:27.695+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:29:27.697+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:29:27.697+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:29:27.707+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:29:27.725+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:29:27.725+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:29:27.735+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:29:27.735+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:29:27.743+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-01T09:29:58.084+0000] {processor.py:157} INFO - Started process (PID=30884) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:29:58.088+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:29:58.090+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:29:58.090+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:29:58.106+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:29:58.126+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:29:58.126+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:29:58.137+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:29:58.137+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:29:58.147+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-01T09:30:28.544+0000] {processor.py:157} INFO - Started process (PID=30909) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:30:28.545+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:30:28.547+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:30:28.547+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:30:28.558+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:30:28.575+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:30:28.575+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:30:28.587+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:30:28.587+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:30:28.596+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-01T09:30:59.027+0000] {processor.py:157} INFO - Started process (PID=30934) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:30:59.033+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:30:59.035+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:30:59.035+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:30:59.045+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:30:59.059+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:30:59.059+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:30:59.070+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:30:59.070+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:30:59.079+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-01T09:31:29.453+0000] {processor.py:157} INFO - Started process (PID=30959) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:31:29.454+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:31:29.456+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:31:29.456+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:31:29.468+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:31:29.487+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:31:29.487+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:31:29.502+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:31:29.502+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:31:29.511+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-01T09:31:59.906+0000] {processor.py:157} INFO - Started process (PID=30984) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:31:59.907+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:31:59.908+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:31:59.908+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:31:59.922+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:31:59.936+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:31:59.936+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:31:59.948+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:31:59.948+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:31:59.958+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-01T09:32:30.304+0000] {processor.py:157} INFO - Started process (PID=31009) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:32:30.304+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:32:30.306+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:32:30.306+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:32:30.316+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:32:30.334+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:32:30.333+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:32:30.346+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:32:30.346+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:32:30.355+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-01T09:33:00.786+0000] {processor.py:157} INFO - Started process (PID=31034) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:33:00.788+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:33:00.790+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:33:00.790+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:33:00.806+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:33:00.820+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:33:00.820+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:33:00.831+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:33:00.831+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:33:00.841+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-01T09:33:31.273+0000] {processor.py:157} INFO - Started process (PID=31059) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:33:31.274+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:33:31.277+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:33:31.277+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:33:31.289+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:33:31.306+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:33:31.306+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:33:31.317+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:33:31.317+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:33:31.326+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-01T09:34:01.708+0000] {processor.py:157} INFO - Started process (PID=31084) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:34:01.709+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:34:01.712+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:34:01.712+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:34:01.732+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:34:01.767+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:34:01.767+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:34:01.787+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:34:01.787+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:34:01.801+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-08-01T09:34:32.253+0000] {processor.py:157} INFO - Started process (PID=31109) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:34:32.256+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:34:32.258+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:34:32.258+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:34:32.271+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:34:32.287+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:34:32.287+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:34:32.299+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:34:32.299+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:34:32.308+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-01T09:35:02.732+0000] {processor.py:157} INFO - Started process (PID=31134) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:35:02.734+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:35:02.736+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:35:02.735+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:35:02.747+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:35:02.763+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:35:02.763+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:35:02.776+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:35:02.776+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:35:02.784+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-01T09:35:33.219+0000] {processor.py:157} INFO - Started process (PID=31159) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:35:33.221+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:35:33.223+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:35:33.223+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:35:33.239+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:35:33.260+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:35:33.260+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:35:33.273+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:35:33.273+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:35:33.283+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-01T09:36:03.670+0000] {processor.py:157} INFO - Started process (PID=31184) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:36:03.671+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:36:03.673+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:36:03.672+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:36:03.683+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:36:03.701+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:36:03.701+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:36:03.713+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:36:03.713+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:36:03.723+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-01T09:36:34.172+0000] {processor.py:157} INFO - Started process (PID=31209) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:36:34.173+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:36:34.177+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:36:34.176+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:36:34.195+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:36:34.221+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:36:34.221+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:36:34.254+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:36:34.254+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:36:34.265+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-08-01T09:37:04.641+0000] {processor.py:157} INFO - Started process (PID=31234) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:37:04.642+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:37:04.644+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:37:04.644+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:37:04.658+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:37:04.677+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:37:04.677+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:37:04.688+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:37:04.688+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:37:04.697+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-01T09:37:35.167+0000] {processor.py:157} INFO - Started process (PID=31259) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:37:35.170+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:37:35.172+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:37:35.172+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:37:35.182+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:37:35.196+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:37:35.196+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:37:35.208+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:37:35.208+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:37:35.215+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-01T09:38:05.553+0000] {processor.py:157} INFO - Started process (PID=31284) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:38:05.555+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:38:05.558+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:38:05.558+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:38:05.569+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:38:05.589+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:38:05.589+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:38:05.601+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:38:05.601+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:38:05.610+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-01T09:38:35.971+0000] {processor.py:157} INFO - Started process (PID=31309) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:38:35.973+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:38:35.974+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:38:35.974+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:38:35.984+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:38:36.003+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:38:36.003+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:38:36.016+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:38:36.016+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:38:36.027+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-01T09:39:06.381+0000] {processor.py:157} INFO - Started process (PID=31334) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:39:06.383+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:39:06.384+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:39:06.384+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:39:06.399+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:39:06.415+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:39:06.415+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:39:06.426+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:39:06.426+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:39:06.436+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-01T09:39:36.745+0000] {processor.py:157} INFO - Started process (PID=31359) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:39:36.746+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:39:36.748+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:39:36.748+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:39:36.760+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:39:36.773+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:39:36.773+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:39:36.783+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:39:36.783+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:39:36.793+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-01T09:40:07.135+0000] {processor.py:157} INFO - Started process (PID=31384) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:40:07.136+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:40:07.138+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:40:07.138+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:40:07.148+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:40:07.164+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:40:07.164+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:40:07.174+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:40:07.174+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:40:07.184+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-01T09:40:37.594+0000] {processor.py:157} INFO - Started process (PID=31409) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:40:37.596+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:40:37.599+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:40:37.599+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:40:37.616+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:40:37.645+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:40:37.645+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:40:37.659+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:40:37.659+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:40:37.670+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-08-01T09:41:08.086+0000] {processor.py:157} INFO - Started process (PID=31434) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:41:08.087+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:41:08.089+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:41:08.089+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:41:08.104+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:41:08.120+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:41:08.120+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:41:08.133+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:41:08.133+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:41:08.143+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-01T09:41:38.560+0000] {processor.py:157} INFO - Started process (PID=31459) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:41:38.561+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:41:38.563+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:41:38.563+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:41:38.577+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:41:38.592+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:41:38.592+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:41:38.601+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:41:38.601+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:41:38.610+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-01T09:42:08.972+0000] {processor.py:157} INFO - Started process (PID=31484) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:42:08.973+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:42:08.974+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:42:08.974+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:42:08.982+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:42:08.995+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:42:08.995+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:42:09.004+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:42:09.004+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:42:09.015+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-08-01T09:42:39.468+0000] {processor.py:157} INFO - Started process (PID=31508) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:42:39.469+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:42:39.473+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:42:39.472+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:42:39.487+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:42:39.509+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:42:39.509+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:42:39.522+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:42:39.522+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:42:39.532+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-01T09:43:09.924+0000] {processor.py:157} INFO - Started process (PID=31534) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:43:09.925+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:43:09.927+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:43:09.927+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:43:09.936+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:43:09.954+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:43:09.954+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:43:09.964+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:43:09.964+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:43:09.972+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-01T09:43:40.392+0000] {processor.py:157} INFO - Started process (PID=31559) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:43:40.393+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:43:40.396+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:43:40.395+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:43:40.410+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:43:40.425+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:43:40.425+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:43:40.437+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:43:40.437+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:43:40.445+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-01T09:44:10.886+0000] {processor.py:157} INFO - Started process (PID=31584) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:44:10.888+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:44:10.890+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:44:10.890+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:44:10.901+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:44:10.916+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:44:10.916+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:44:10.926+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:44:10.926+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:44:10.935+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-01T09:44:41.291+0000] {processor.py:157} INFO - Started process (PID=31609) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:44:41.292+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:44:41.294+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:44:41.294+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:44:41.306+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:44:41.323+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:44:41.323+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:44:41.336+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:44:41.336+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:44:41.344+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-01T09:45:11.746+0000] {processor.py:157} INFO - Started process (PID=31634) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:45:11.749+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:45:11.752+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:45:11.752+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:45:11.766+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:45:11.787+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:45:11.787+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:45:11.800+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:45:11.800+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:45:11.810+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-01T09:45:42.153+0000] {processor.py:157} INFO - Started process (PID=31659) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:45:42.153+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:45:42.155+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:45:42.155+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:45:42.165+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:45:42.181+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:45:42.181+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:45:42.191+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:45:42.191+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:45:42.199+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-08-01T09:46:12.628+0000] {processor.py:157} INFO - Started process (PID=31684) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:46:12.629+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:46:12.631+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:46:12.631+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:46:12.641+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:46:12.658+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:46:12.658+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:46:12.668+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:46:12.668+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:46:12.677+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-01T09:46:43.082+0000] {processor.py:157} INFO - Started process (PID=31709) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:46:43.086+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:46:43.090+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:46:43.089+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:46:43.108+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:46:43.132+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:46:43.132+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:46:43.145+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:46:43.145+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:46:43.157+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-08-01T09:47:13.647+0000] {processor.py:157} INFO - Started process (PID=31734) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:47:13.648+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:47:13.649+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:47:13.649+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:47:13.661+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:47:13.676+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:47:13.676+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:47:13.686+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:47:13.686+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:47:13.694+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-01T09:47:44.120+0000] {processor.py:157} INFO - Started process (PID=31759) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:47:44.121+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:47:44.125+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:47:44.125+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:47:44.141+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:47:44.165+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:47:44.164+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:47:44.187+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:47:44.187+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:47:44.198+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-08-01T09:48:14.617+0000] {processor.py:157} INFO - Started process (PID=31784) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:48:14.618+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:48:14.620+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:48:14.620+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:48:14.637+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:48:14.652+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:48:14.652+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:48:14.664+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:48:14.664+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:48:14.676+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-01T09:48:45.030+0000] {processor.py:157} INFO - Started process (PID=31809) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:48:45.031+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:48:45.032+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:48:45.032+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:48:45.049+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:48:45.063+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:48:45.063+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:48:45.074+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:48:45.074+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:48:45.085+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-01T09:49:15.402+0000] {processor.py:157} INFO - Started process (PID=31834) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:49:15.403+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:49:15.405+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:49:15.405+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:49:15.421+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:49:15.437+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:49:15.437+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:49:15.446+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:49:15.446+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:49:15.456+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-01T09:49:45.826+0000] {processor.py:157} INFO - Started process (PID=31859) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:49:45.829+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:49:45.832+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:49:45.832+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:49:45.848+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:49:45.868+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:49:45.868+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:49:45.881+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:49:45.881+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:49:45.890+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-01T09:50:16.257+0000] {processor.py:157} INFO - Started process (PID=31884) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:50:16.258+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:50:16.260+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:50:16.259+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:50:16.270+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:50:16.287+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:50:16.286+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:50:16.298+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:50:16.298+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:50:16.308+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-01T09:50:46.664+0000] {processor.py:157} INFO - Started process (PID=31909) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:50:46.665+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:50:46.667+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:50:46.666+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:50:46.677+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:50:46.693+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:50:46.693+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:50:46.703+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:50:46.703+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:50:46.712+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-01T09:51:17.143+0000] {processor.py:157} INFO - Started process (PID=31934) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:51:17.145+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:51:17.146+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:51:17.146+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:51:17.158+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:51:17.176+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:51:17.176+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:51:17.187+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:51:17.186+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:51:17.194+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-01T09:51:47.586+0000] {processor.py:157} INFO - Started process (PID=31959) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:51:47.589+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:51:47.591+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:51:47.591+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:51:47.600+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:51:47.616+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:51:47.616+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:51:47.628+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:51:47.628+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:51:47.635+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-01T09:52:18.039+0000] {processor.py:157} INFO - Started process (PID=31984) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:52:18.040+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:52:18.042+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:52:18.041+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:52:18.052+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:52:18.068+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:52:18.068+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:52:18.080+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:52:18.079+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:52:18.087+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-01T09:52:48.465+0000] {processor.py:157} INFO - Started process (PID=32009) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:52:48.466+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:52:48.467+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:52:48.467+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:52:48.478+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:52:48.493+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:52:48.493+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:52:48.502+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:52:48.501+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:52:48.512+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-08-01T09:53:18.890+0000] {processor.py:157} INFO - Started process (PID=32034) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:53:18.893+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:53:18.895+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:53:18.895+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:53:18.910+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:53:18.932+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:53:18.932+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:53:18.946+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:53:18.946+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:53:18.958+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-01T09:53:49.375+0000] {processor.py:157} INFO - Started process (PID=32059) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:53:49.375+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:53:49.377+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:53:49.377+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:53:49.386+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:53:49.401+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:53:49.401+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:53:49.412+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:53:49.412+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:53:49.420+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-08-01T09:54:19.838+0000] {processor.py:157} INFO - Started process (PID=32084) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:54:19.839+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:54:19.840+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:54:19.840+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:54:19.849+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:54:19.865+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:54:19.865+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:54:19.876+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:54:19.876+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:54:19.887+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-01T09:54:50.308+0000] {processor.py:157} INFO - Started process (PID=32109) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:54:50.309+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:54:50.311+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:54:50.311+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:54:50.323+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:54:50.338+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:54:50.338+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:54:50.348+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:54:50.348+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:54:50.357+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-01T09:55:20.748+0000] {processor.py:157} INFO - Started process (PID=32134) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:55:20.749+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:55:20.751+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:55:20.751+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:55:20.760+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:55:20.776+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:55:20.776+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:55:20.786+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:55:20.786+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:55:20.796+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-01T09:55:51.244+0000] {processor.py:157} INFO - Started process (PID=32159) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:55:51.248+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:55:51.250+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:55:51.250+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:55:51.266+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:55:51.286+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:55:51.286+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:55:51.298+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:55:51.298+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:55:51.307+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-01T09:56:21.664+0000] {processor.py:157} INFO - Started process (PID=32184) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:56:21.665+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:56:21.666+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:56:21.666+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:56:21.673+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:56:21.688+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:56:21.688+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:56:21.699+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:56:21.699+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:56:21.709+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-08-01T09:56:52.093+0000] {processor.py:157} INFO - Started process (PID=32209) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:56:52.095+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:56:52.097+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:56:52.097+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:56:52.110+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:56:52.125+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:56:52.125+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:56:52.137+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:56:52.137+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:56:52.148+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-01T09:57:22.540+0000] {processor.py:157} INFO - Started process (PID=32234) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:57:22.543+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:57:22.545+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:57:22.544+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:57:22.561+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:57:22.573+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:57:22.573+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:57:22.583+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:57:22.583+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:57:22.592+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-01T09:57:52.995+0000] {processor.py:157} INFO - Started process (PID=32259) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:57:52.995+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:57:52.997+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:57:52.997+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:57:53.011+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:57:53.027+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:57:53.027+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:57:53.036+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:57:53.036+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:57:53.044+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-01T09:58:23.415+0000] {processor.py:157} INFO - Started process (PID=32284) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:58:23.416+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:58:23.418+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:58:23.418+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:58:23.433+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:58:23.447+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:58:23.447+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:58:23.458+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:58:23.458+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:58:23.468+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-01T09:58:53.818+0000] {processor.py:157} INFO - Started process (PID=32309) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:58:53.821+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:58:53.824+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:58:53.823+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:58:53.839+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:58:53.861+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:58:53.861+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:58:53.872+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:58:53.872+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:58:53.882+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-01T09:59:24.311+0000] {processor.py:157} INFO - Started process (PID=32334) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:59:24.313+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:59:24.315+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:59:24.315+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:59:24.329+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:59:24.344+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:59:24.344+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:59:24.357+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:59:24.357+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:59:24.366+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-01T09:59:54.694+0000] {processor.py:157} INFO - Started process (PID=32359) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:59:54.696+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T09:59:54.697+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:59:54.697+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:59:54.705+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T09:59:54.718+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:59:54.718+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T09:59:54.730+0000] {logging_mixin.py:151} INFO - [2024-08-01T09:59:54.730+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T09:59:54.737+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.044 seconds
[2024-08-01T10:00:25.139+0000] {processor.py:157} INFO - Started process (PID=32384) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:00:25.140+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:00:25.141+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:00:25.141+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:00:25.155+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:00:25.168+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:00:25.168+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:00:25.180+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:00:25.180+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:00:25.189+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-01T10:00:55.669+0000] {processor.py:157} INFO - Started process (PID=32407) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:00:55.670+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:00:55.673+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:00:55.673+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:00:55.689+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:00:55.711+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:00:55.711+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:00:55.723+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:00:55.723+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:00:55.734+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-01T10:01:26.092+0000] {processor.py:157} INFO - Started process (PID=32434) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:01:26.092+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:01:26.093+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:01:26.093+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:01:26.103+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:01:26.118+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:01:26.118+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:01:26.130+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:01:26.130+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:01:26.140+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-01T10:01:56.508+0000] {processor.py:157} INFO - Started process (PID=32459) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:01:56.509+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:01:56.511+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:01:56.511+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:01:56.528+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:01:56.543+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:01:56.543+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:01:56.555+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:01:56.555+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:01:56.563+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-01T10:02:26.970+0000] {processor.py:157} INFO - Started process (PID=32484) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:02:26.973+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:02:26.975+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:02:26.975+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:02:26.991+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:02:27.012+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:02:27.011+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:02:27.024+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:02:27.024+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:02:27.034+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-01T10:02:57.451+0000] {processor.py:157} INFO - Started process (PID=32509) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:02:57.453+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:02:57.456+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:02:57.455+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:02:57.470+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:02:57.485+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:02:57.485+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:02:57.497+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:02:57.497+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:02:57.505+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-01T10:03:27.888+0000] {processor.py:157} INFO - Started process (PID=32534) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:03:27.889+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:03:27.890+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:03:27.890+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:03:27.898+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:03:27.913+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:03:27.913+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:03:27.924+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:03:27.924+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:03:27.934+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-08-01T10:03:58.300+0000] {processor.py:157} INFO - Started process (PID=32559) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:03:58.302+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:03:58.304+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:03:58.303+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:03:58.319+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:03:58.332+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:03:58.332+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:03:58.342+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:03:58.342+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:03:58.350+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-01T10:04:28.754+0000] {processor.py:157} INFO - Started process (PID=32584) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:04:28.756+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:04:28.759+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:04:28.759+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:04:28.797+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:04:28.823+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:04:28.823+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:04:28.836+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:04:28.836+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:04:28.846+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-08-01T10:04:59.253+0000] {processor.py:157} INFO - Started process (PID=32609) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:04:59.255+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:04:59.256+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:04:59.256+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:04:59.271+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:04:59.285+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:04:59.285+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:04:59.296+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:04:59.296+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:04:59.306+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-01T10:05:29.688+0000] {processor.py:157} INFO - Started process (PID=32634) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:05:29.688+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:05:29.692+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:05:29.692+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:05:29.705+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:05:29.727+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:05:29.727+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:05:29.737+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:05:29.737+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:05:29.744+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-01T10:06:00.147+0000] {processor.py:157} INFO - Started process (PID=32657) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:06:00.149+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:06:00.153+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:06:00.153+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:06:00.170+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:06:00.194+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:06:00.194+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:06:00.208+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:06:00.207+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:06:00.217+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-01T10:06:30.693+0000] {processor.py:157} INFO - Started process (PID=32684) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:06:30.695+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:06:30.704+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:06:30.704+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:06:30.713+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:06:30.730+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:06:30.730+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:06:30.740+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:06:30.740+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:06:30.749+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-01T10:07:01.117+0000] {processor.py:157} INFO - Started process (PID=32709) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:07:01.118+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:07:01.120+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:07:01.120+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:07:01.138+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:07:01.155+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:07:01.155+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:07:01.168+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:07:01.168+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:07:01.176+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-01T10:07:31.625+0000] {processor.py:157} INFO - Started process (PID=32734) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:07:31.626+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:07:31.627+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:07:31.627+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:07:31.641+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:07:31.655+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:07:31.655+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:07:31.665+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:07:31.665+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:07:31.675+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-01T10:08:02.072+0000] {processor.py:157} INFO - Started process (PID=32759) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:08:02.075+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:08:02.077+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:08:02.076+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:08:02.093+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:08:02.109+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:08:02.109+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:08:02.120+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:08:02.120+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:08:02.129+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-01T10:08:32.554+0000] {processor.py:157} INFO - Started process (PID=32784) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:08:32.555+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:08:32.558+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:08:32.558+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:08:32.574+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:08:32.595+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:08:32.594+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:08:32.607+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:08:32.607+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:08:32.616+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-01T10:09:03.009+0000] {processor.py:157} INFO - Started process (PID=32809) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:09:03.011+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:09:03.013+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:09:03.013+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:09:03.023+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:09:03.042+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:09:03.042+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:09:03.055+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:09:03.055+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:09:03.064+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-01T10:09:33.452+0000] {processor.py:157} INFO - Started process (PID=32834) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:09:33.453+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:09:33.454+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:09:33.454+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:09:33.468+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:09:33.483+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:09:33.482+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:09:33.493+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:09:33.493+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:09:33.501+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-01T10:10:03.917+0000] {processor.py:157} INFO - Started process (PID=32859) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:10:03.920+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:10:03.924+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:10:03.923+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:10:03.944+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:10:03.962+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:10:03.962+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:10:03.975+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:10:03.975+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:10:03.986+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-01T10:10:34.358+0000] {processor.py:157} INFO - Started process (PID=32884) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:10:34.360+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:10:34.362+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:10:34.362+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:10:34.368+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:10:34.383+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:10:34.383+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:10:34.393+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:10:34.393+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:10:34.403+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-08-01T10:11:04.815+0000] {processor.py:157} INFO - Started process (PID=32909) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:11:04.817+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:11:04.819+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:11:04.819+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:11:04.833+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:11:04.847+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:11:04.847+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:11:04.858+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:11:04.858+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:11:04.867+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-01T10:11:35.269+0000] {processor.py:157} INFO - Started process (PID=32934) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:11:35.270+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:11:35.272+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:11:35.272+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:11:35.284+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:11:35.297+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:11:35.297+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:11:35.307+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:11:35.307+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:11:35.315+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-08-01T10:12:05.650+0000] {processor.py:157} INFO - Started process (PID=32959) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:12:05.651+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:12:05.653+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:12:05.653+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:12:05.662+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:12:05.679+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:12:05.679+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:12:05.689+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:12:05.689+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:12:05.698+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-01T10:12:36.106+0000] {processor.py:157} INFO - Started process (PID=32984) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:12:36.106+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:12:36.109+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:12:36.109+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:12:36.119+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:12:36.136+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:12:36.136+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:12:36.148+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:12:36.148+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:12:36.158+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-01T10:13:06.539+0000] {processor.py:157} INFO - Started process (PID=33008) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:13:06.541+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:13:06.545+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:13:06.544+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:13:06.570+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:13:06.616+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:13:06.616+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:13:06.629+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:13:06.629+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:13:06.639+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-08-01T10:13:37.009+0000] {processor.py:157} INFO - Started process (PID=33034) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:13:37.010+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:13:37.011+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:13:37.011+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:13:37.023+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:13:37.040+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:13:37.040+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:13:37.051+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:13:37.051+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:13:37.060+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-01T10:14:07.397+0000] {processor.py:157} INFO - Started process (PID=33059) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:14:07.398+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:14:07.400+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:14:07.400+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:14:07.416+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:14:07.442+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:14:07.441+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:14:07.460+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:14:07.460+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:14:07.471+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-08-01T10:14:37.840+0000] {processor.py:157} INFO - Started process (PID=33084) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:14:37.840+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:14:37.842+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:14:37.842+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:14:37.850+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:14:37.866+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:14:37.866+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:14:37.876+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:14:37.876+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:14:37.885+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-08-01T10:15:08.306+0000] {processor.py:157} INFO - Started process (PID=33109) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:15:08.308+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:15:08.310+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:15:08.310+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:15:08.325+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:15:08.339+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:15:08.339+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:15:08.351+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:15:08.351+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:15:08.360+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-01T10:15:38.699+0000] {processor.py:157} INFO - Started process (PID=33134) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:15:38.700+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:15:38.703+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:15:38.702+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:15:38.718+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:15:38.748+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:15:38.748+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:15:38.760+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:15:38.760+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:15:38.770+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-08-01T10:16:09.145+0000] {processor.py:157} INFO - Started process (PID=33159) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:16:09.145+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:16:09.147+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:16:09.147+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:16:09.156+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:16:09.173+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:16:09.173+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:16:09.183+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:16:09.183+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:16:09.192+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-01T10:16:39.571+0000] {processor.py:157} INFO - Started process (PID=33184) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:16:39.573+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:16:39.574+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:16:39.574+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:16:39.590+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:16:39.606+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:16:39.606+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:16:39.617+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:16:39.617+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:16:39.628+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-01T10:17:09.991+0000] {processor.py:157} INFO - Started process (PID=33209) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:17:09.992+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:17:09.993+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:17:09.993+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:17:10.007+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:17:10.028+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:17:10.028+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:17:10.039+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:17:10.039+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:17:10.050+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-01T10:17:40.437+0000] {processor.py:157} INFO - Started process (PID=33234) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:17:40.441+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:17:40.444+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:17:40.444+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:17:40.458+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:17:40.479+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:17:40.479+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:17:40.493+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:17:40.493+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:17:40.502+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-01T10:18:10.855+0000] {processor.py:157} INFO - Started process (PID=33259) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:18:10.856+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:18:10.858+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:18:10.858+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:18:10.868+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:18:10.881+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:18:10.881+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:18:10.889+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:18:10.889+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:18:10.897+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.042 seconds
[2024-08-01T10:18:41.335+0000] {processor.py:157} INFO - Started process (PID=33284) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:18:41.336+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:18:41.338+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:18:41.338+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:18:41.355+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:18:41.368+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:18:41.368+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:18:41.380+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:18:41.380+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:18:41.391+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-01T10:19:11.791+0000] {processor.py:157} INFO - Started process (PID=33309) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:19:11.792+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:19:11.794+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:19:11.794+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:19:11.811+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:19:11.827+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:19:11.827+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:19:11.837+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:19:11.837+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:19:11.847+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-01T10:19:42.235+0000] {processor.py:157} INFO - Started process (PID=33334) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:19:42.236+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:19:42.238+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:19:42.238+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:19:42.253+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:19:42.267+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:19:42.267+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:19:42.280+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:19:42.280+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:19:42.291+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-01T10:20:12.771+0000] {processor.py:157} INFO - Started process (PID=33359) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:20:12.774+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:20:12.776+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:20:12.776+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:20:12.792+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:20:12.813+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:20:12.813+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:20:12.826+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:20:12.826+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:20:12.836+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-01T10:20:43.241+0000] {processor.py:157} INFO - Started process (PID=33384) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:20:43.242+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:20:43.246+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:20:43.245+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:20:43.260+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:20:43.280+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:20:43.280+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:20:43.289+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:20:43.289+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:20:43.298+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-01T10:21:13.764+0000] {processor.py:157} INFO - Started process (PID=33409) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:21:13.765+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:21:13.767+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:21:13.767+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:21:13.782+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:21:13.795+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:21:13.795+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:21:13.806+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:21:13.806+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:21:13.814+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-01T10:21:44.174+0000] {processor.py:157} INFO - Started process (PID=33434) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:21:44.175+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:21:44.176+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:21:44.176+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:21:44.188+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:21:44.207+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:21:44.207+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:21:44.217+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:21:44.217+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:21:44.226+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-01T10:22:14.716+0000] {processor.py:157} INFO - Started process (PID=33459) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:22:14.716+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:22:14.719+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:22:14.719+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:22:14.730+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:22:14.750+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:22:14.750+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:22:14.763+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:22:14.763+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:22:14.774+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-01T10:22:45.125+0000] {processor.py:157} INFO - Started process (PID=33484) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:22:45.129+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:22:45.131+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:22:45.131+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:22:45.145+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:22:45.165+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:22:45.165+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:22:45.177+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:22:45.177+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:22:45.186+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-01T10:23:15.624+0000] {processor.py:157} INFO - Started process (PID=33509) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:23:15.625+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:23:15.627+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:23:15.627+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:23:15.643+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:23:15.657+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:23:15.657+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:23:15.670+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:23:15.670+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:23:15.680+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-01T10:23:46.041+0000] {processor.py:157} INFO - Started process (PID=33534) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:23:46.042+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:23:46.044+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:23:46.043+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:23:46.060+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:23:46.075+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:23:46.075+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:23:46.086+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:23:46.086+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:23:46.094+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-01T10:24:16.524+0000] {processor.py:157} INFO - Started process (PID=33559) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:24:16.526+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:24:16.528+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:24:16.527+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:24:16.538+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:24:16.556+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:24:16.556+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:24:16.569+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:24:16.569+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:24:16.579+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-01T10:24:46.988+0000] {processor.py:157} INFO - Started process (PID=33584) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:24:46.989+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:24:46.992+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:24:46.992+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:24:47.010+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:24:47.027+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:24:47.027+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:24:47.041+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:24:47.041+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:24:47.051+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-01T10:25:17.421+0000] {processor.py:157} INFO - Started process (PID=33609) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:25:17.424+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:25:17.425+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:25:17.425+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:25:17.434+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:25:17.450+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:25:17.450+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:25:17.460+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:25:17.460+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:25:17.469+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-01T10:25:47.880+0000] {processor.py:157} INFO - Started process (PID=33634) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:25:47.881+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:25:47.882+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:25:47.882+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:25:47.898+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:25:47.912+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:25:47.912+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:25:47.921+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:25:47.921+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:25:47.930+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-01T10:26:18.284+0000] {processor.py:157} INFO - Started process (PID=33659) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:26:18.285+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:26:18.286+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:26:18.286+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:26:18.295+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:26:18.312+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:26:18.312+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:26:18.323+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:26:18.323+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:26:18.330+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-08-01T10:26:48.712+0000] {processor.py:157} INFO - Started process (PID=33684) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:26:48.714+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:26:48.716+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:26:48.716+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:26:48.726+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:26:48.742+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:26:48.742+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:26:48.752+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:26:48.752+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:26:48.761+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-01T10:27:19.146+0000] {processor.py:157} INFO - Started process (PID=33709) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:27:19.147+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:27:19.149+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:27:19.149+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:27:19.161+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:27:19.182+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:27:19.182+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:27:19.195+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:27:19.195+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:27:19.203+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-01T10:27:49.629+0000] {processor.py:157} INFO - Started process (PID=33734) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:27:49.631+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:27:49.634+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:27:49.634+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:27:49.648+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:27:49.667+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:27:49.666+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:27:49.679+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:27:49.679+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:27:49.687+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-01T10:28:20.132+0000] {processor.py:157} INFO - Started process (PID=33759) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:28:20.133+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:28:20.136+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:28:20.135+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:28:20.151+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:28:20.168+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:28:20.168+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:28:20.180+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:28:20.180+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:28:20.191+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-01T10:28:50.580+0000] {processor.py:157} INFO - Started process (PID=33784) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:28:50.582+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:28:50.584+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:28:50.584+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:28:50.597+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:28:50.610+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:28:50.610+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:28:50.621+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:28:50.621+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:28:50.632+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-01T10:29:21.004+0000] {processor.py:157} INFO - Started process (PID=33809) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:29:21.005+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:29:21.007+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:29:21.007+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:29:21.019+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:29:21.035+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:29:21.035+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:29:21.046+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:29:21.046+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:29:21.056+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-01T10:29:51.455+0000] {processor.py:157} INFO - Started process (PID=33834) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:29:51.456+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:29:51.457+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:29:51.457+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:29:51.471+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:29:51.486+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:29:51.486+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:29:51.501+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:29:51.501+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:29:51.512+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-01T10:30:21.906+0000] {processor.py:157} INFO - Started process (PID=33859) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:30:21.908+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:30:21.911+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:30:21.911+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:30:21.927+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:30:21.946+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:30:21.946+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:30:21.958+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:30:21.958+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:30:21.967+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-01T10:30:52.331+0000] {processor.py:157} INFO - Started process (PID=33884) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:30:52.332+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:30:52.334+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:30:52.334+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:30:52.346+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:30:52.364+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:30:52.363+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:30:52.378+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:30:52.378+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:30:52.388+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-01T10:31:22.816+0000] {processor.py:157} INFO - Started process (PID=33909) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:31:22.817+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:31:22.819+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:31:22.819+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:31:22.832+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:31:22.854+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:31:22.854+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:31:22.869+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:31:22.869+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:31:22.879+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-01T10:31:53.357+0000] {processor.py:157} INFO - Started process (PID=33934) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:31:53.358+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:31:53.362+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:31:53.361+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:31:53.378+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:31:53.416+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:31:53.416+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:31:53.437+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:31:53.437+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:31:53.459+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-08-01T10:32:24.278+0000] {processor.py:157} INFO - Started process (PID=33959) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:32:24.280+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:32:24.287+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:32:24.286+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:32:24.309+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:32:24.342+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:32:24.341+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:32:24.357+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:32:24.357+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:32:24.376+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-08-01T10:32:54.800+0000] {processor.py:157} INFO - Started process (PID=33984) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:32:54.802+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:32:54.806+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:32:54.806+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:32:54.827+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:32:54.853+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:32:54.852+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:32:54.866+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:32:54.866+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:32:54.877+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-08-01T10:33:25.247+0000] {processor.py:157} INFO - Started process (PID=34009) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:33:25.253+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:33:25.265+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:33:25.265+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:33:25.283+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:33:25.309+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:33:25.309+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:33:25.324+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:33:25.324+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:33:25.334+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-08-01T10:33:55.689+0000] {processor.py:157} INFO - Started process (PID=34034) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:33:55.690+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:33:55.693+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:33:55.692+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:33:55.710+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:33:55.733+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:33:55.732+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:33:55.747+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:33:55.747+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:33:55.758+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-01T10:34:26.120+0000] {processor.py:157} INFO - Started process (PID=34059) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:34:26.121+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:34:26.123+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:34:26.123+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:34:26.134+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:34:26.150+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:34:26.150+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:34:26.160+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:34:26.160+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:34:26.168+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-01T10:34:56.537+0000] {processor.py:157} INFO - Started process (PID=34084) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:34:56.540+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:34:56.541+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:34:56.541+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:34:56.554+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:34:56.574+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:34:56.574+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:34:56.588+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:34:56.587+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:34:56.604+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-01T10:35:27.011+0000] {processor.py:157} INFO - Started process (PID=34109) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:35:27.012+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:35:27.014+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:35:27.013+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:35:27.027+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:35:27.042+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:35:27.042+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:35:27.052+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:35:27.052+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:35:27.060+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-01T10:35:57.484+0000] {processor.py:157} INFO - Started process (PID=34134) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:35:57.487+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:35:57.490+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:35:57.490+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:35:57.507+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:35:57.531+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:35:57.531+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:35:57.546+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:35:57.546+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:35:57.555+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-01T10:36:27.902+0000] {processor.py:157} INFO - Started process (PID=34159) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:36:27.905+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:36:27.906+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:36:27.906+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:36:27.917+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:36:27.933+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:36:27.933+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:36:27.943+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:36:27.943+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:36:27.952+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-01T10:36:58.344+0000] {processor.py:157} INFO - Started process (PID=34184) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:36:58.347+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:36:58.350+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:36:58.350+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:36:58.367+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:36:58.410+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:36:58.410+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:36:58.424+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:36:58.424+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:36:58.435+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-08-01T10:37:28.771+0000] {processor.py:157} INFO - Started process (PID=34209) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:37:28.772+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:37:28.773+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:37:28.773+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:37:28.790+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:37:28.808+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:37:28.808+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:37:28.820+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:37:28.820+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:37:28.830+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-01T10:37:59.239+0000] {processor.py:157} INFO - Started process (PID=34234) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:37:59.242+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:37:59.245+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:37:59.245+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:37:59.260+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:37:59.281+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:37:59.281+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:37:59.295+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:37:59.295+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:37:59.304+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-01T10:38:29.670+0000] {processor.py:157} INFO - Started process (PID=34259) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:38:29.671+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:38:29.672+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:38:29.672+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:38:29.679+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:38:29.693+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:38:29.693+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:38:29.702+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:38:29.702+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:38:29.710+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.041 seconds
[2024-08-01T10:39:00.115+0000] {processor.py:157} INFO - Started process (PID=34284) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:39:00.116+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:39:00.118+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:39:00.118+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:39:00.128+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:39:00.146+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:39:00.146+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:39:00.155+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:39:00.155+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:39:00.163+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-01T10:39:30.530+0000] {processor.py:157} INFO - Started process (PID=34309) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:39:30.532+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:39:30.534+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:39:30.534+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:39:30.550+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:39:30.563+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:39:30.563+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:39:30.573+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:39:30.573+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:39:30.581+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-01T10:40:00.990+0000] {processor.py:157} INFO - Started process (PID=34334) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:40:00.996+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:40:00.999+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:40:00.999+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:40:01.016+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:40:01.060+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:40:01.060+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:40:01.075+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:40:01.075+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:40:01.085+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-08-01T10:40:31.513+0000] {processor.py:157} INFO - Started process (PID=34359) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:40:31.518+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:40:31.520+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:40:31.519+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:40:31.536+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:40:31.563+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:40:31.562+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:40:31.577+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:40:31.577+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:40:31.590+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-08-01T10:41:02.036+0000] {processor.py:157} INFO - Started process (PID=34384) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:41:02.039+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:41:02.045+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:41:02.045+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:41:02.090+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:41:02.153+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:41:02.153+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:41:02.175+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:41:02.175+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:41:02.186+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.156 seconds
[2024-08-01T10:41:32.661+0000] {processor.py:157} INFO - Started process (PID=34409) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:41:32.664+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:41:32.675+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:41:32.673+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:41:32.720+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:41:32.752+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:41:32.752+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:41:32.769+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:41:32.769+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:41:32.785+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-08-01T10:42:03.203+0000] {processor.py:157} INFO - Started process (PID=34434) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:42:03.204+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:42:03.207+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:42:03.207+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:42:03.218+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:42:03.235+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:42:03.234+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:42:03.245+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:42:03.245+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:42:03.255+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-01T10:42:33.653+0000] {processor.py:157} INFO - Started process (PID=34459) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:42:33.657+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:42:33.662+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:42:33.662+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:42:33.685+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:42:33.726+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:42:33.726+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:42:33.746+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:42:33.746+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:42:33.759+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-08-01T10:43:04.233+0000] {processor.py:157} INFO - Started process (PID=34483) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:43:04.234+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:43:04.238+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:43:04.237+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:43:04.255+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:43:04.287+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:43:04.287+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:43:04.302+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:43:04.302+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:43:04.312+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-08-01T10:43:34.680+0000] {processor.py:157} INFO - Started process (PID=34509) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:43:34.682+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:43:34.683+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:43:34.683+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:43:34.692+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:43:34.708+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:43:34.708+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:43:34.718+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:43:34.718+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:43:34.726+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-08-01T10:44:05.097+0000] {processor.py:157} INFO - Started process (PID=34534) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:44:05.103+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:44:05.106+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:44:05.105+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:44:05.117+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:44:05.132+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:44:05.132+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:44:05.143+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:44:05.143+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:44:05.150+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-01T10:44:35.599+0000] {processor.py:157} INFO - Started process (PID=34559) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:44:35.603+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:44:35.606+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:44:35.606+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:44:35.642+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:44:35.683+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:44:35.683+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:44:35.700+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:44:35.700+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:44:35.713+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-08-01T10:45:06.269+0000] {processor.py:157} INFO - Started process (PID=34584) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:45:06.272+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:45:06.276+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:45:06.274+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:45:06.303+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:45:06.328+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:45:06.327+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:45:06.343+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:45:06.343+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:45:06.353+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-08-01T10:45:36.775+0000] {processor.py:157} INFO - Started process (PID=34609) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:45:36.776+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:45:36.779+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:45:36.779+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:45:36.794+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:45:36.819+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:45:36.819+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:45:36.833+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:45:36.833+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:45:36.844+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-01T10:46:07.180+0000] {processor.py:157} INFO - Started process (PID=34634) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:46:07.183+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:46:07.186+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:46:07.185+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:46:07.201+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:46:07.227+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:46:07.227+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:46:07.240+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:46:07.240+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:46:07.250+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-01T10:46:37.702+0000] {processor.py:157} INFO - Started process (PID=34659) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:46:37.706+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:46:37.709+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:46:37.709+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:46:37.734+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:46:37.775+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:46:37.775+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:46:37.792+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:46:37.791+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:46:37.803+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-08-01T10:47:08.232+0000] {processor.py:157} INFO - Started process (PID=34683) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:47:08.234+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:47:08.238+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:47:08.237+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:47:08.259+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:47:08.281+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:47:08.281+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:47:08.296+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:47:08.296+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:47:08.308+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-08-01T10:47:38.646+0000] {processor.py:157} INFO - Started process (PID=34709) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:47:38.649+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:47:38.651+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:47:38.650+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:47:38.662+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:47:38.680+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:47:38.680+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:47:38.689+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:47:38.689+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:47:38.700+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-01T10:48:09.044+0000] {processor.py:157} INFO - Started process (PID=34734) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:48:09.045+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:48:09.047+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:48:09.047+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:48:09.060+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:48:09.071+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:48:09.071+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:48:09.081+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:48:09.081+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:48:09.092+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-01T10:48:39.468+0000] {processor.py:157} INFO - Started process (PID=34759) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:48:39.471+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:48:39.473+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:48:39.473+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:48:39.489+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:48:39.516+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:48:39.516+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:48:39.529+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:48:39.529+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:48:39.543+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-08-01T10:49:09.941+0000] {processor.py:157} INFO - Started process (PID=34784) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:49:09.942+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:49:09.944+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:49:09.944+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:49:09.959+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:49:09.973+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:49:09.973+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:49:09.984+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:49:09.984+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:49:09.993+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-01T10:49:40.369+0000] {processor.py:157} INFO - Started process (PID=34809) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:49:40.370+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:49:40.374+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:49:40.374+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:49:40.391+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:49:40.417+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:49:40.417+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:49:40.431+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:49:40.431+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:49:40.442+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-08-01T10:50:10.910+0000] {processor.py:157} INFO - Started process (PID=34834) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:50:10.912+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:50:10.916+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:50:10.916+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:50:10.947+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:50:10.972+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:50:10.972+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:50:10.987+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:50:10.987+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:50:10.998+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-08-01T10:50:41.379+0000] {processor.py:157} INFO - Started process (PID=34859) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:50:41.385+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:50:41.390+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:50:41.390+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:50:41.410+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:50:41.439+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:50:41.439+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:50:41.463+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:50:41.463+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:50:41.478+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-08-01T10:51:11.852+0000] {processor.py:157} INFO - Started process (PID=34884) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:51:11.854+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:51:11.857+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:51:11.857+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:51:11.870+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:51:11.895+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:51:11.895+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:51:11.915+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:51:11.915+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:51:11.956+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-08-01T10:51:42.392+0000] {processor.py:157} INFO - Started process (PID=34909) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:51:42.395+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:51:42.399+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:51:42.399+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:51:42.415+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:51:42.439+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:51:42.439+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:51:42.453+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:51:42.453+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:51:42.470+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-01T10:52:12.890+0000] {processor.py:157} INFO - Started process (PID=34934) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:52:12.893+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:52:12.896+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:52:12.896+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:52:12.913+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:52:12.949+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:52:12.949+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:52:12.964+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:52:12.964+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:52:12.984+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-08-01T10:52:43.444+0000] {processor.py:157} INFO - Started process (PID=34959) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:52:43.447+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:52:43.456+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:52:43.453+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:52:43.488+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:52:43.531+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:52:43.531+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:52:43.554+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:52:43.554+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:52:43.568+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-08-01T10:53:14.065+0000] {processor.py:157} INFO - Started process (PID=34984) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:53:14.070+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:53:14.073+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:53:14.073+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:53:14.102+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:53:14.160+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:53:14.159+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:53:14.184+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:53:14.183+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:53:14.196+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.137 seconds
[2024-08-01T10:53:44.673+0000] {processor.py:157} INFO - Started process (PID=35009) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:53:44.678+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:53:44.687+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:53:44.686+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:53:44.712+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:53:44.743+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:53:44.743+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:53:44.767+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:53:44.766+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:53:44.779+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-08-01T10:54:15.158+0000] {processor.py:157} INFO - Started process (PID=35034) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:54:15.166+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:54:15.173+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:54:15.173+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:54:15.192+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:54:15.222+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:54:15.222+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:54:15.254+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:54:15.254+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:54:15.271+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-08-01T10:54:45.732+0000] {processor.py:157} INFO - Started process (PID=35059) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:54:45.740+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:54:45.745+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:54:45.745+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:54:45.773+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:54:45.816+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:54:45.816+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:54:45.832+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:54:45.832+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:54:45.851+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-08-01T10:55:16.306+0000] {processor.py:157} INFO - Started process (PID=35084) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:55:16.307+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:55:16.312+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:55:16.312+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:55:16.355+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:55:16.400+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:55:16.400+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:55:16.426+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:55:16.426+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:55:16.444+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.145 seconds
[2024-08-01T10:55:46.949+0000] {processor.py:157} INFO - Started process (PID=35109) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:55:46.951+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:55:46.954+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:55:46.954+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:55:46.977+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:55:47.002+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:55:47.002+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:55:47.018+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:55:47.018+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:55:47.035+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-08-01T10:56:17.489+0000] {processor.py:157} INFO - Started process (PID=35134) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:56:17.490+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:56:17.494+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:56:17.494+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:56:17.511+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:56:17.546+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:56:17.546+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:56:17.567+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:56:17.567+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:56:17.580+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-08-01T10:56:48.030+0000] {processor.py:157} INFO - Started process (PID=35158) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:56:48.034+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:56:48.038+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:56:48.038+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:56:48.061+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:56:48.097+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:56:48.097+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:56:48.120+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:56:48.120+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:56:48.139+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-08-01T10:57:18.655+0000] {processor.py:157} INFO - Started process (PID=35184) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:57:18.657+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:57:18.661+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:57:18.661+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:57:18.680+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:57:18.722+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:57:18.722+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:57:18.739+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:57:18.739+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:57:18.750+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-08-01T10:57:49.247+0000] {processor.py:157} INFO - Started process (PID=35209) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:57:49.252+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:57:49.259+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:57:49.259+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:57:49.286+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:57:49.324+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:57:49.324+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:57:49.342+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:57:49.342+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:57:49.354+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-08-01T10:58:19.840+0000] {processor.py:157} INFO - Started process (PID=35234) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:58:19.842+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:58:19.847+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:58:19.847+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:58:19.883+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:58:19.929+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:58:19.929+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:58:19.947+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:58:19.947+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:58:19.959+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-08-01T10:58:50.453+0000] {processor.py:157} INFO - Started process (PID=35259) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:58:50.460+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:58:50.466+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:58:50.465+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:58:50.552+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:58:50.598+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:58:50.598+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:58:50.631+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:58:50.631+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:58:50.647+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.198 seconds
[2024-08-01T10:59:21.069+0000] {processor.py:157} INFO - Started process (PID=35283) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:59:21.071+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:59:21.074+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:59:21.074+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:59:21.093+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:59:21.133+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:59:21.133+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:59:21.151+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:59:21.151+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:59:21.165+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-08-01T10:59:51.612+0000] {processor.py:157} INFO - Started process (PID=35309) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:59:51.617+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T10:59:51.620+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:59:51.620+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:59:51.640+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T10:59:51.683+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:59:51.683+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T10:59:51.702+0000] {logging_mixin.py:151} INFO - [2024-08-01T10:59:51.702+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T10:59:51.716+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-08-01T11:00:22.181+0000] {processor.py:157} INFO - Started process (PID=35334) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:00:22.187+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:00:22.191+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:00:22.191+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:00:22.213+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:00:22.266+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:00:22.266+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:00:22.345+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:00:22.345+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:00:22.363+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.187 seconds
[2024-08-01T11:00:52.971+0000] {processor.py:157} INFO - Started process (PID=35359) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:00:52.980+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:00:52.985+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:00:52.985+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:00:53.003+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:00:53.048+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:00:53.048+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:00:53.067+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:00:53.066+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:00:53.080+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-08-01T11:01:23.458+0000] {processor.py:157} INFO - Started process (PID=35383) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:01:23.461+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:01:23.464+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:01:23.464+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:01:23.505+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:01:23.573+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:01:23.572+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:01:23.601+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:01:23.601+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:01:23.616+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.164 seconds
[2024-08-01T11:01:54.084+0000] {processor.py:157} INFO - Started process (PID=35409) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:01:54.085+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:01:54.087+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:01:54.087+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:01:54.108+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:01:54.159+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:01:54.159+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:01:54.173+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:01:54.173+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:01:54.184+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-08-01T11:02:24.576+0000] {processor.py:157} INFO - Started process (PID=35434) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:02:24.579+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:02:24.580+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:02:24.580+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:02:24.593+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:02:24.612+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:02:24.612+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:02:24.628+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:02:24.628+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:02:24.640+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-01T11:02:55.091+0000] {processor.py:157} INFO - Started process (PID=35459) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:02:55.096+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:02:55.099+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:02:55.099+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:02:55.117+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:02:55.144+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:02:55.144+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:02:55.159+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:02:55.159+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:02:55.181+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-08-01T11:03:25.586+0000] {processor.py:157} INFO - Started process (PID=35484) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:03:25.591+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:03:25.597+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:03:25.596+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:03:25.614+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:03:25.641+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:03:25.641+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:03:25.663+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:03:25.663+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:03:25.674+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-08-01T11:03:56.020+0000] {processor.py:157} INFO - Started process (PID=35509) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:03:56.022+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:03:56.023+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:03:56.023+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:03:56.032+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:03:56.050+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:03:56.050+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:03:56.062+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:03:56.062+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:03:56.073+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-01T11:04:26.466+0000] {processor.py:157} INFO - Started process (PID=35533) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:04:26.468+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:04:26.471+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:04:26.471+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:04:26.496+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:04:26.522+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:04:26.522+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:04:26.546+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:04:26.546+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:04:26.560+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-08-01T11:04:56.994+0000] {processor.py:157} INFO - Started process (PID=35559) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:04:56.996+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:04:57.001+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:04:57.001+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:04:57.028+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:04:57.067+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:04:57.067+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:04:57.100+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:04:57.100+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:04:57.114+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-08-01T11:05:27.436+0000] {processor.py:157} INFO - Started process (PID=35584) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:05:27.437+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:05:27.439+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:05:27.439+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:05:27.454+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:05:27.474+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:05:27.473+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:05:27.485+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:05:27.485+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:05:27.496+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-01T11:05:58.049+0000] {processor.py:157} INFO - Started process (PID=35608) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:05:58.053+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:05:58.056+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:05:58.055+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:05:58.074+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:05:58.118+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:05:58.118+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:05:58.134+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:05:58.134+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:05:58.145+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-08-01T11:06:28.548+0000] {processor.py:157} INFO - Started process (PID=35634) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:06:28.549+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:06:28.550+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:06:28.550+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:06:28.560+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:06:28.576+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:06:28.576+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:06:28.587+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:06:28.587+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:06:28.594+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-01T11:06:59.014+0000] {processor.py:157} INFO - Started process (PID=35658) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:06:59.017+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:06:59.019+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:06:59.019+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:06:59.036+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:06:59.062+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:06:59.062+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:06:59.087+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:06:59.087+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:06:59.097+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-08-01T11:07:29.479+0000] {processor.py:157} INFO - Started process (PID=35684) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:07:29.479+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:07:29.481+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:07:29.481+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:07:29.497+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:07:29.509+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:07:29.509+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:07:29.518+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:07:29.518+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:07:29.529+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-01T11:07:59.900+0000] {processor.py:157} INFO - Started process (PID=35709) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:07:59.902+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:07:59.903+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:07:59.903+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:07:59.912+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:07:59.929+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:07:59.928+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:07:59.939+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:07:59.939+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:07:59.948+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-01T11:08:30.349+0000] {processor.py:157} INFO - Started process (PID=35734) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:08:30.350+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:08:30.352+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:08:30.352+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:08:30.363+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:08:30.379+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:08:30.379+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:08:30.392+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:08:30.392+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:08:30.400+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-01T11:09:00.772+0000] {processor.py:157} INFO - Started process (PID=35759) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:09:00.778+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:09:00.790+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:09:00.789+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:09:00.806+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:09:00.833+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:09:00.833+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:09:00.858+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:09:00.858+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:09:00.871+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-08-01T11:09:31.229+0000] {processor.py:157} INFO - Started process (PID=35784) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:09:31.230+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:09:31.233+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:09:31.232+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:09:31.247+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:09:31.265+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:09:31.265+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:09:31.280+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:09:31.280+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:09:31.290+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-01T11:10:01.607+0000] {processor.py:157} INFO - Started process (PID=35809) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:10:01.608+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:10:01.611+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:10:01.611+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:10:01.627+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:10:01.653+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:10:01.653+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:10:01.672+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:10:01.672+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:10:01.684+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-08-01T11:10:32.040+0000] {processor.py:157} INFO - Started process (PID=35834) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:10:32.041+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:10:32.043+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:10:32.043+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:10:32.055+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:10:32.072+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:10:32.072+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:10:32.085+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:10:32.085+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:10:32.097+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-01T11:11:02.453+0000] {processor.py:157} INFO - Started process (PID=35858) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:11:02.456+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:11:02.465+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:11:02.464+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:11:02.497+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:11:02.531+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:11:02.531+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:11:02.561+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:11:02.561+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:11:02.575+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-08-01T11:11:32.924+0000] {processor.py:157} INFO - Started process (PID=35884) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:11:32.925+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:11:32.926+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:11:32.926+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:11:32.937+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:11:32.954+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:11:32.954+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:11:32.964+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:11:32.963+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:11:32.973+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-01T11:12:03.384+0000] {processor.py:157} INFO - Started process (PID=35909) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:12:03.385+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:12:03.387+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:12:03.386+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:12:03.398+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:12:03.416+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:12:03.416+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:12:03.425+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:12:03.425+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:12:03.434+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-01T11:12:33.829+0000] {processor.py:157} INFO - Started process (PID=35934) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:12:33.830+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:12:33.832+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:12:33.832+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:12:33.838+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:12:33.851+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:12:33.851+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:12:33.861+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:12:33.861+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:12:33.869+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.041 seconds
[2024-08-01T11:13:04.249+0000] {processor.py:157} INFO - Started process (PID=35959) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:13:04.250+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:13:04.251+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:13:04.251+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:13:04.263+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:13:04.280+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:13:04.279+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:13:04.291+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:13:04.290+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:13:04.299+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-01T11:13:34.726+0000] {processor.py:157} INFO - Started process (PID=35984) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:13:34.727+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:13:34.730+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:13:34.730+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:13:34.747+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:13:34.770+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:13:34.770+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:13:34.783+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:13:34.783+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:13:34.793+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-01T11:14:05.170+0000] {processor.py:157} INFO - Started process (PID=36009) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:14:05.171+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:14:05.173+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:14:05.173+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:14:05.183+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:14:05.202+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:14:05.201+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:14:05.213+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:14:05.213+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:14:05.221+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-01T11:14:35.626+0000] {processor.py:157} INFO - Started process (PID=36034) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:14:35.627+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:14:35.628+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:14:35.628+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:14:35.638+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:14:35.658+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:14:35.658+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:14:35.669+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:14:35.669+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:14:35.681+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-01T11:15:06.076+0000] {processor.py:157} INFO - Started process (PID=36059) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:15:06.079+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:15:06.084+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:15:06.083+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:15:06.108+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:15:06.138+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:15:06.138+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:15:06.154+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:15:06.154+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:15:06.167+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-08-01T11:15:36.603+0000] {processor.py:157} INFO - Started process (PID=36084) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:15:36.604+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:15:36.609+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:15:36.608+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:15:36.654+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:15:36.874+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:15:36.873+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:15:36.906+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:15:36.906+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:15:36.919+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.320 seconds
[2024-08-01T11:16:07.298+0000] {processor.py:157} INFO - Started process (PID=36109) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:16:07.300+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:16:07.302+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:16:07.302+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:16:07.314+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:16:07.336+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:16:07.335+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:16:07.346+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:16:07.346+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:16:07.359+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-01T11:16:37.696+0000] {processor.py:157} INFO - Started process (PID=36134) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:16:37.700+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:16:37.703+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:16:37.703+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:16:37.721+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:16:37.749+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:16:37.749+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:16:37.767+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:16:37.767+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:16:37.781+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-01T11:17:08.141+0000] {processor.py:157} INFO - Started process (PID=36159) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:17:08.144+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:17:08.147+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:17:08.147+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:17:08.167+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:17:08.195+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:17:08.195+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:17:08.218+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:17:08.218+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:17:08.240+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-08-01T11:17:38.671+0000] {processor.py:157} INFO - Started process (PID=36184) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:17:38.672+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:17:38.675+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:17:38.674+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:17:38.689+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:17:38.727+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:17:38.727+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:17:38.751+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:17:38.751+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:17:38.771+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-08-01T11:18:09.209+0000] {processor.py:157} INFO - Started process (PID=36209) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:18:09.213+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:18:09.216+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:18:09.216+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:18:09.239+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:18:09.299+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:18:09.299+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:18:09.318+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:18:09.318+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:18:09.332+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-08-01T11:18:39.677+0000] {processor.py:157} INFO - Started process (PID=36234) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:18:39.683+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:18:39.703+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:18:39.703+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:18:39.733+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:18:39.785+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:18:39.785+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:18:39.816+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:18:39.816+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:18:39.834+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.163 seconds
[2024-08-01T11:19:10.242+0000] {processor.py:157} INFO - Started process (PID=36259) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:19:10.244+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:19:10.248+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:19:10.248+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:19:10.271+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:19:10.308+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:19:10.308+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:19:10.331+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:19:10.331+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:19:10.346+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-08-01T11:19:40.804+0000] {processor.py:157} INFO - Started process (PID=36284) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:19:40.807+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:19:40.811+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:19:40.811+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:19:40.832+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:19:40.880+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:19:40.880+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:19:40.899+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:19:40.898+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:19:40.914+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-08-01T11:20:11.306+0000] {processor.py:157} INFO - Started process (PID=36308) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:20:11.309+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:20:11.314+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:20:11.314+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:20:11.336+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:20:11.378+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:20:11.378+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:20:11.399+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:20:11.398+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:20:11.412+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-08-01T11:20:41.837+0000] {processor.py:157} INFO - Started process (PID=36334) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:20:41.842+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:20:41.864+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:20:41.864+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:20:41.890+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:20:41.927+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:20:41.927+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:20:41.947+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:20:41.947+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:20:41.962+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-08-01T11:21:12.328+0000] {processor.py:157} INFO - Started process (PID=36359) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:21:12.329+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:21:12.333+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:21:12.332+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:21:12.353+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:21:12.376+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:21:12.376+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:21:12.388+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:21:12.388+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:21:12.399+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-08-01T11:21:42.890+0000] {processor.py:157} INFO - Started process (PID=36383) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:21:42.892+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:21:42.895+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:21:42.895+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:21:42.926+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:21:42.978+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:21:42.977+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:21:42.997+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:21:42.996+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:21:43.020+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-08-01T11:22:13.373+0000] {processor.py:157} INFO - Started process (PID=36408) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:22:13.374+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:22:13.378+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:22:13.378+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:22:13.398+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:22:13.426+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:22:13.426+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:22:13.446+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:22:13.446+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:22:13.460+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-08-01T11:22:43.894+0000] {processor.py:157} INFO - Started process (PID=36434) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:22:43.896+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:22:43.899+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:22:43.898+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:22:43.918+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:22:43.947+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:22:43.947+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:22:43.966+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:22:43.966+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:22:43.979+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-08-01T11:23:14.389+0000] {processor.py:157} INFO - Started process (PID=36459) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:23:14.391+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:23:14.396+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:23:14.395+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:23:14.415+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:23:14.457+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:23:14.456+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:23:14.473+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:23:14.473+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:23:14.486+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-08-01T11:23:44.922+0000] {processor.py:157} INFO - Started process (PID=36484) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:23:44.925+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:23:44.933+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:23:44.932+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:23:44.959+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:23:44.994+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:23:44.994+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:23:45.012+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:23:45.011+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:23:45.029+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-08-01T11:24:15.429+0000] {processor.py:157} INFO - Started process (PID=36509) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:24:15.437+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:24:15.448+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:24:15.448+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:24:15.467+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:24:15.504+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:24:15.504+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:24:15.521+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:24:15.521+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:24:15.533+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-08-01T11:24:45.899+0000] {processor.py:157} INFO - Started process (PID=36534) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:24:45.903+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:24:45.913+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:24:45.911+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:24:45.944+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:24:45.980+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:24:45.980+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:24:46.000+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:24:45.999+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:24:46.013+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-08-01T11:25:16.495+0000] {processor.py:157} INFO - Started process (PID=36559) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:25:16.503+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:25:16.509+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:25:16.509+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:25:16.545+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:25:16.588+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:25:16.588+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:25:16.618+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:25:16.618+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:25:16.645+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.165 seconds
[2024-08-01T11:25:47.125+0000] {processor.py:157} INFO - Started process (PID=36584) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:25:47.128+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:25:47.133+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:25:47.133+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:25:47.180+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:25:47.215+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:25:47.215+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:25:47.245+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:25:47.245+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:25:47.261+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-08-01T11:26:17.689+0000] {processor.py:157} INFO - Started process (PID=36609) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:26:17.692+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:26:17.694+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:26:17.694+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:26:17.713+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:26:17.756+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:26:17.756+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:26:17.775+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:26:17.775+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:26:17.790+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-08-01T11:26:48.180+0000] {processor.py:157} INFO - Started process (PID=36634) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:26:48.181+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:26:48.183+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:26:48.183+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:26:48.196+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:26:48.216+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:26:48.216+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:26:48.228+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:26:48.228+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:26:48.240+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-01T11:27:18.684+0000] {processor.py:157} INFO - Started process (PID=36659) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:27:18.686+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:27:18.691+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:27:18.691+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:27:18.711+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:27:18.755+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:27:18.755+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:27:18.781+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:27:18.781+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:27:18.795+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-08-01T11:27:49.495+0000] {processor.py:157} INFO - Started process (PID=36684) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:27:49.496+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:27:49.501+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:27:49.501+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:27:49.543+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:27:49.603+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:27:49.603+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:27:49.628+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:27:49.628+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:27:49.639+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.149 seconds
[2024-08-01T11:28:20.032+0000] {processor.py:157} INFO - Started process (PID=36709) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:28:20.034+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:28:20.038+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:28:20.038+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:28:20.058+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:28:20.098+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:28:20.098+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:28:20.113+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:28:20.113+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:28:20.125+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-08-01T11:28:50.510+0000] {processor.py:157} INFO - Started process (PID=36734) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:28:50.512+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:28:50.515+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:28:50.515+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:28:50.533+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:28:50.580+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:28:50.580+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:28:50.610+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:28:50.610+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:28:50.624+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-08-01T11:29:20.993+0000] {processor.py:157} INFO - Started process (PID=36759) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:29:20.998+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:29:21.002+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:29:21.001+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:29:21.034+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:29:21.073+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:29:21.073+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:29:21.097+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:29:21.097+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:29:21.120+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-08-01T11:29:51.526+0000] {processor.py:157} INFO - Started process (PID=36784) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:29:51.528+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:29:51.531+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:29:51.531+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:29:51.565+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:29:51.594+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:29:51.594+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:29:51.611+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:29:51.611+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:29:51.629+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-08-01T11:30:22.041+0000] {processor.py:157} INFO - Started process (PID=36809) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:30:22.042+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:30:22.050+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:30:22.050+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:30:22.136+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:30:22.220+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:30:22.220+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:30:22.243+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:30:22.243+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:30:22.261+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.225 seconds
[2024-08-01T11:30:52.596+0000] {processor.py:157} INFO - Started process (PID=36834) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:30:52.601+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:30:52.604+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:30:52.604+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:30:52.639+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:30:52.670+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:30:52.669+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:30:52.697+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:30:52.697+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:30:52.710+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-08-01T11:31:23.139+0000] {processor.py:157} INFO - Started process (PID=36859) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:31:23.149+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:31:23.163+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:31:23.162+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:31:23.194+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:31:23.231+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:31:23.231+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:31:23.251+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:31:23.251+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:31:23.267+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-08-01T11:31:53.691+0000] {processor.py:157} INFO - Started process (PID=36884) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:31:53.696+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:31:53.699+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:31:53.699+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:31:53.723+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:31:53.793+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:31:53.792+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:31:53.816+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:31:53.816+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:31:53.830+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.142 seconds
[2024-08-01T11:32:24.314+0000] {processor.py:157} INFO - Started process (PID=36909) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:32:24.316+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:32:24.321+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:32:24.320+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:32:24.344+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:32:24.403+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:32:24.403+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:32:24.425+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:32:24.424+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:32:24.438+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-08-01T11:32:54.814+0000] {processor.py:157} INFO - Started process (PID=36934) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:32:54.817+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:32:54.818+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:32:54.818+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:32:54.830+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:32:54.853+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:32:54.853+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:32:54.867+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:32:54.867+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:32:54.880+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-01T11:33:25.291+0000] {processor.py:157} INFO - Started process (PID=36959) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:33:25.296+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:33:25.308+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:33:25.307+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:33:25.345+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:33:25.410+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:33:25.409+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:33:25.437+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:33:25.437+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:33:25.456+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.179 seconds
[2024-08-01T11:33:55.788+0000] {processor.py:157} INFO - Started process (PID=36984) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:33:55.789+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:33:55.790+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:33:55.790+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:33:55.807+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:33:55.823+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:33:55.823+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:33:55.838+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:33:55.838+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:33:55.850+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-01T11:34:26.283+0000] {processor.py:157} INFO - Started process (PID=37009) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:34:26.286+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:34:26.292+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:34:26.291+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:34:26.339+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:34:26.376+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:34:26.376+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:34:26.406+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:34:26.406+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:34:26.425+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.149 seconds
[2024-08-01T11:34:56.882+0000] {processor.py:157} INFO - Started process (PID=37033) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:34:56.884+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:34:56.894+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:34:56.893+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:34:56.947+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:34:56.996+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:34:56.996+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:34:57.013+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:34:57.013+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:34:57.029+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.153 seconds
[2024-08-01T11:35:27.464+0000] {processor.py:157} INFO - Started process (PID=37059) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:35:27.465+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:35:27.471+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:35:27.470+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:35:27.519+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:35:27.559+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:35:27.558+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:35:27.578+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:35:27.578+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:35:27.602+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.142 seconds
[2024-08-01T11:35:57.992+0000] {processor.py:157} INFO - Started process (PID=37084) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:35:57.995+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:35:58.000+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:35:57.999+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:35:58.025+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:35:58.079+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:35:58.079+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:35:58.101+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:35:58.101+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:35:58.115+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-08-01T11:36:28.561+0000] {processor.py:157} INFO - Started process (PID=37109) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:36:28.563+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:36:28.568+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:36:28.567+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:36:28.598+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:36:28.634+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:36:28.634+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:36:28.650+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:36:28.650+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:36:28.667+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-08-01T11:36:59.114+0000] {processor.py:157} INFO - Started process (PID=37134) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:36:59.118+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:36:59.132+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:36:59.130+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:36:59.171+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:36:59.219+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:36:59.219+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:36:59.243+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:36:59.243+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:36:59.257+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.151 seconds
[2024-08-01T11:37:29.727+0000] {processor.py:157} INFO - Started process (PID=37159) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:37:29.733+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:37:29.736+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:37:29.735+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:37:29.780+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:37:29.838+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:37:29.837+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:37:29.862+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:37:29.862+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:37:29.875+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.151 seconds
[2024-08-01T11:38:00.311+0000] {processor.py:157} INFO - Started process (PID=37184) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:38:00.315+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:38:00.317+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:38:00.317+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:38:00.335+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:38:00.359+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:38:00.359+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:38:00.373+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:38:00.373+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:38:00.385+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-08-01T11:38:30.828+0000] {processor.py:157} INFO - Started process (PID=37209) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:38:30.831+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:38:30.843+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:38:30.839+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:38:30.892+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:38:30.932+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:38:30.931+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:38:30.953+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:38:30.953+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:38:30.967+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.142 seconds
[2024-08-01T11:39:01.408+0000] {processor.py:157} INFO - Started process (PID=37233) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:39:01.410+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:39:01.414+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:39:01.414+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:39:01.441+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:39:01.475+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:39:01.475+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:39:01.492+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:39:01.492+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:39:01.505+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-08-01T11:39:31.861+0000] {processor.py:157} INFO - Started process (PID=37259) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:39:31.863+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:39:31.867+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:39:31.866+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:39:31.885+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:39:31.933+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:39:31.933+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:39:31.952+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:39:31.952+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:39:31.965+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-08-01T11:40:02.384+0000] {processor.py:157} INFO - Started process (PID=37284) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:40:02.388+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:40:02.398+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:40:02.397+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:40:02.415+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:40:02.455+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:40:02.455+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:40:02.471+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:40:02.471+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:40:02.484+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-08-01T11:40:32.879+0000] {processor.py:157} INFO - Started process (PID=37309) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:40:32.882+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:40:32.891+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:40:32.890+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:40:32.915+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:40:32.954+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:40:32.954+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:40:32.974+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:40:32.974+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:40:32.996+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-08-01T11:41:03.388+0000] {processor.py:157} INFO - Started process (PID=37334) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:41:03.393+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:41:03.397+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:41:03.397+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:41:03.422+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:41:03.482+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:41:03.482+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:41:03.502+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:41:03.502+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:41:03.516+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-08-01T11:41:33.912+0000] {processor.py:157} INFO - Started process (PID=37359) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:41:33.914+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:41:33.916+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:41:33.916+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:41:33.937+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:41:33.967+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:41:33.967+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:41:33.986+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:41:33.985+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:41:33.999+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-08-01T11:42:04.436+0000] {processor.py:157} INFO - Started process (PID=37384) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:42:04.437+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:42:04.439+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:42:04.439+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:42:04.454+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:42:04.474+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:42:04.474+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:42:04.488+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:42:04.488+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:42:04.501+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-01T11:42:35.009+0000] {processor.py:157} INFO - Started process (PID=37409) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:42:35.014+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:42:35.018+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:42:35.018+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:42:35.037+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:42:35.095+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:42:35.095+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:42:35.115+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:42:35.115+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:42:35.125+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-08-01T11:43:05.661+0000] {processor.py:157} INFO - Started process (PID=37434) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:43:05.662+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:43:05.675+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:43:05.673+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:43:05.713+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:43:05.759+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:43:05.759+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:43:05.803+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:43:05.803+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:43:05.821+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.163 seconds
[2024-08-01T11:43:36.279+0000] {processor.py:157} INFO - Started process (PID=37459) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:43:36.282+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:43:36.292+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:43:36.292+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:43:36.323+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:43:36.361+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:43:36.361+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:43:36.379+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:43:36.379+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:43:36.391+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-08-01T11:44:06.818+0000] {processor.py:157} INFO - Started process (PID=37484) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:44:06.824+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:44:06.827+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:44:06.827+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:44:06.851+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:44:06.893+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:44:06.893+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:44:06.913+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:44:06.913+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:44:06.929+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-08-01T11:44:37.334+0000] {processor.py:157} INFO - Started process (PID=37509) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:44:37.337+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:44:37.341+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:44:37.341+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:44:37.363+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:44:37.400+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:44:37.400+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:44:37.419+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:44:37.419+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:44:37.434+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-08-01T11:45:07.772+0000] {processor.py:157} INFO - Started process (PID=37534) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:45:07.774+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:45:07.777+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:45:07.776+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:45:07.788+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:45:07.812+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:45:07.812+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:45:07.836+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:45:07.836+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:45:07.853+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-08-01T11:45:38.190+0000] {processor.py:157} INFO - Started process (PID=37558) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:45:38.191+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:45:38.195+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:45:38.194+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:45:38.214+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:45:38.245+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:45:38.244+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:45:38.263+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:45:38.262+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:45:38.277+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-08-01T11:46:08.679+0000] {processor.py:157} INFO - Started process (PID=37584) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:46:08.681+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:46:08.685+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:46:08.684+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:46:08.703+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:46:08.735+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:46:08.735+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:46:08.762+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:46:08.762+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:46:08.778+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-08-01T11:46:39.315+0000] {processor.py:157} INFO - Started process (PID=37609) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:46:39.316+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:46:39.320+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:46:39.320+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:46:39.338+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:46:39.377+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:46:39.377+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:46:39.398+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:46:39.398+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:46:39.413+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-08-01T11:47:09.849+0000] {processor.py:157} INFO - Started process (PID=37634) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:47:09.853+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:47:09.857+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:47:09.857+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:47:09.902+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:47:09.942+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:47:09.942+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:47:09.963+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:47:09.963+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:47:09.976+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-08-01T11:47:40.397+0000] {processor.py:157} INFO - Started process (PID=37658) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:47:40.400+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:47:40.406+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:47:40.406+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:47:40.427+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:47:40.457+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:47:40.457+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:47:40.474+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:47:40.474+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:47:40.488+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-08-01T11:48:10.930+0000] {processor.py:157} INFO - Started process (PID=37684) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:48:10.933+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:48:10.947+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:48:10.941+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:48:10.985+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:48:11.047+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:48:11.046+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:48:11.094+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:48:11.094+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:48:11.120+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.195 seconds
[2024-08-01T11:48:41.497+0000] {processor.py:157} INFO - Started process (PID=37709) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:48:41.505+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:48:41.508+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:48:41.508+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:48:41.532+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:48:41.578+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:48:41.578+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:48:41.598+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:48:41.598+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:48:41.611+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-08-01T11:49:12.086+0000] {processor.py:157} INFO - Started process (PID=37734) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:49:12.092+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:49:12.102+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:49:12.102+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:49:12.126+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:49:12.174+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:49:12.174+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:49:12.195+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:49:12.195+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:49:12.211+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-08-01T11:49:42.665+0000] {processor.py:157} INFO - Started process (PID=37759) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:49:42.670+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:49:42.677+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:49:42.677+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:49:42.701+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:49:42.734+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:49:42.734+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:49:42.751+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:49:42.751+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:49:42.775+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-08-01T11:50:13.135+0000] {processor.py:157} INFO - Started process (PID=37784) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:50:13.137+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:50:13.143+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:50:13.142+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:50:13.166+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:50:13.197+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:50:13.197+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:50:13.218+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:50:13.218+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:50:13.235+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-08-01T11:50:43.666+0000] {processor.py:157} INFO - Started process (PID=37808) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:50:43.668+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:50:43.673+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:50:43.673+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:50:43.701+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:50:43.739+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:50:43.739+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:50:43.759+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:50:43.759+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:50:43.772+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-08-01T11:51:14.200+0000] {processor.py:157} INFO - Started process (PID=37834) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:51:14.203+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:51:14.209+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:51:14.208+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:51:14.231+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:51:14.274+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:51:14.274+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:51:14.295+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:51:14.295+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:51:14.309+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-08-01T11:51:44.780+0000] {processor.py:157} INFO - Started process (PID=37859) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:51:44.782+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:51:44.788+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:51:44.788+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:51:44.813+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:51:44.851+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:51:44.850+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:51:44.883+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:51:44.882+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:51:44.899+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-08-01T11:52:15.353+0000] {processor.py:157} INFO - Started process (PID=37884) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:52:15.355+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:52:15.359+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:52:15.358+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:52:15.379+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:52:15.422+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:52:15.422+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:52:15.440+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:52:15.440+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:52:15.453+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-08-01T11:52:45.903+0000] {processor.py:157} INFO - Started process (PID=37909) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:52:45.906+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:52:45.911+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:52:45.910+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:52:45.931+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:52:45.969+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:52:45.968+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:52:46.002+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:52:46.002+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:52:46.019+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-08-01T11:53:16.452+0000] {processor.py:157} INFO - Started process (PID=37934) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:53:16.456+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:53:16.480+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:53:16.478+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:53:16.510+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:53:16.543+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:53:16.543+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:53:16.562+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:53:16.562+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:53:16.582+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-08-01T11:53:47.022+0000] {processor.py:157} INFO - Started process (PID=37959) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:53:47.025+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:53:47.032+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:53:47.032+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:53:47.059+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:53:47.106+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:53:47.106+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:53:47.128+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:53:47.128+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:53:47.144+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-08-01T11:54:17.620+0000] {processor.py:157} INFO - Started process (PID=37984) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:54:17.625+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:54:17.628+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:54:17.628+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:54:17.659+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:54:17.692+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:54:17.692+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:54:17.716+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:54:17.716+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:54:17.731+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-08-01T11:54:48.170+0000] {processor.py:157} INFO - Started process (PID=38009) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:54:48.174+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:54:48.202+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:54:48.197+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:54:48.231+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:54:48.269+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:54:48.268+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:54:48.291+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:54:48.291+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:54:48.307+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.143 seconds
[2024-08-01T11:55:18.763+0000] {processor.py:157} INFO - Started process (PID=38034) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:55:18.766+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:55:18.770+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:55:18.770+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:55:18.808+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:55:18.865+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:55:18.864+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:55:18.898+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:55:18.898+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:55:18.913+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.167 seconds
[2024-08-01T11:55:49.309+0000] {processor.py:157} INFO - Started process (PID=38059) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:55:49.318+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:55:49.327+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:55:49.327+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:55:49.347+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:55:49.376+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:55:49.376+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:55:49.406+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:55:49.406+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:55:49.420+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-08-01T11:56:19.802+0000] {processor.py:157} INFO - Started process (PID=38084) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:56:19.805+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:56:19.810+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:56:19.810+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:56:19.834+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:56:19.883+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:56:19.883+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:56:19.901+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:56:19.901+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:56:19.918+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-08-01T11:56:50.297+0000] {processor.py:157} INFO - Started process (PID=38109) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:56:50.302+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:56:50.304+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:56:50.304+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:56:50.334+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:56:50.402+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:56:50.402+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:56:50.426+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:56:50.426+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:56:50.455+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.163 seconds
[2024-08-01T11:57:20.904+0000] {processor.py:157} INFO - Started process (PID=38134) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:57:20.908+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:57:20.911+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:57:20.910+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:57:20.929+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:57:20.958+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:57:20.958+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:57:20.975+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:57:20.975+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:57:20.988+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-08-01T11:57:51.435+0000] {processor.py:157} INFO - Started process (PID=38159) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:57:51.437+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:57:51.440+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:57:51.440+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:57:51.474+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:57:51.507+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:57:51.507+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:57:51.528+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:57:51.528+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:57:51.542+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-08-01T11:58:22.045+0000] {processor.py:157} INFO - Started process (PID=38184) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:58:22.047+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:58:22.062+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:58:22.062+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:58:22.085+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:58:22.141+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:58:22.141+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:58:22.169+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:58:22.169+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:58:22.185+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.145 seconds
[2024-08-01T11:58:52.552+0000] {processor.py:157} INFO - Started process (PID=38209) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:58:52.553+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:58:52.560+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:58:52.559+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:58:52.578+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:58:52.612+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:58:52.612+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:58:52.635+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:58:52.634+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:58:52.646+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-08-01T11:59:23.047+0000] {processor.py:157} INFO - Started process (PID=38234) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:59:23.048+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:59:23.054+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:59:23.053+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:59:23.077+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:59:23.123+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:59:23.123+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:59:23.142+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:59:23.142+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:59:23.158+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-08-01T11:59:53.488+0000] {processor.py:157} INFO - Started process (PID=38259) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:59:53.490+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T11:59:53.499+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:59:53.498+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:59:53.520+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T11:59:53.549+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:59:53.549+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T11:59:53.575+0000] {logging_mixin.py:151} INFO - [2024-08-01T11:59:53.575+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T11:59:53.589+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-08-01T12:00:24.016+0000] {processor.py:157} INFO - Started process (PID=38284) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:00:24.025+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T12:00:24.033+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:00:24.033+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:00:24.052+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:00:24.086+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:00:24.086+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T12:00:24.104+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:00:24.104+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T12:00:24.118+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-08-01T12:00:54.512+0000] {processor.py:157} INFO - Started process (PID=38308) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:00:54.514+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T12:00:54.519+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:00:54.519+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:00:54.546+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:00:54.584+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:00:54.583+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T12:00:54.603+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:00:54.603+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T12:00:54.620+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-08-01T12:01:24.976+0000] {processor.py:157} INFO - Started process (PID=38334) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:01:24.978+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T12:01:24.983+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:01:24.982+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:01:25.004+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:01:25.037+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:01:25.037+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T12:01:25.056+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:01:25.056+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T12:01:25.072+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-08-01T12:01:55.455+0000] {processor.py:157} INFO - Started process (PID=38359) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:01:55.457+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T12:01:55.462+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:01:55.461+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:01:55.481+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:01:55.515+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:01:55.515+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T12:01:55.533+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:01:55.533+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T12:01:55.547+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-08-01T12:02:25.922+0000] {processor.py:157} INFO - Started process (PID=38384) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:02:25.924+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T12:02:25.929+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:02:25.928+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:02:25.954+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:02:25.979+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:02:25.978+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T12:02:26.016+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:02:26.016+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T12:02:26.034+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-08-01T12:02:56.447+0000] {processor.py:157} INFO - Started process (PID=38407) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:02:56.450+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T12:02:56.456+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:02:56.456+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:02:56.482+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:02:56.545+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:02:56.545+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T12:02:56.566+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:02:56.566+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T12:02:56.579+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-08-01T12:03:27.049+0000] {processor.py:157} INFO - Started process (PID=38434) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:03:27.054+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T12:03:27.059+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:03:27.058+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:03:27.089+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:03:27.151+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:03:27.150+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T12:03:27.220+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:03:27.220+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T12:03:27.249+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.206 seconds
[2024-08-01T12:03:57.836+0000] {processor.py:157} INFO - Started process (PID=38459) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:03:57.837+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T12:03:57.839+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:03:57.839+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:03:57.873+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:03:57.906+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:03:57.906+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T12:03:57.923+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:03:57.923+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T12:03:57.935+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-08-01T12:04:28.360+0000] {processor.py:157} INFO - Started process (PID=38484) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:04:28.364+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T12:04:28.375+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:04:28.373+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:04:28.408+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:04:28.447+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:04:28.447+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T12:04:28.478+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:04:28.478+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T12:04:28.491+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.141 seconds
[2024-08-01T12:04:58.794+0000] {processor.py:157} INFO - Started process (PID=38509) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:04:58.796+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T12:04:58.800+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:04:58.799+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:04:58.856+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:04:58.897+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:04:58.897+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T12:04:58.920+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:04:58.919+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T12:04:58.934+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.149 seconds
[2024-08-01T12:05:29.360+0000] {processor.py:157} INFO - Started process (PID=38534) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:05:29.363+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T12:05:29.369+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:05:29.368+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:05:29.395+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:05:29.437+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:05:29.437+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T12:05:29.458+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:05:29.458+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T12:05:29.472+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-08-01T12:05:59.910+0000] {processor.py:157} INFO - Started process (PID=38559) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:05:59.913+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T12:05:59.918+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:05:59.918+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:05:59.943+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:06:00.007+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:06:00.007+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T12:06:00.031+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:06:00.031+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T12:06:00.056+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.153 seconds
[2024-08-01T12:06:30.444+0000] {processor.py:157} INFO - Started process (PID=38584) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:06:30.446+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T12:06:30.450+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:06:30.449+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:06:30.480+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:06:30.510+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:06:30.510+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T12:06:30.526+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:06:30.526+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T12:06:30.539+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-08-01T12:07:00.916+0000] {processor.py:157} INFO - Started process (PID=38609) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:07:00.919+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T12:07:00.923+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:07:00.923+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:07:00.945+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:07:00.976+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:07:00.976+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T12:07:01.009+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:07:01.009+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T12:07:01.023+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-08-01T12:07:31.446+0000] {processor.py:157} INFO - Started process (PID=38634) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:07:31.453+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T12:07:31.457+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:07:31.457+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:07:31.506+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:07:31.543+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:07:31.543+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T12:07:31.565+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:07:31.564+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T12:07:31.588+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.147 seconds
[2024-08-01T12:08:01.936+0000] {processor.py:157} INFO - Started process (PID=38659) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:08:01.938+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T12:08:01.943+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:08:01.942+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:08:01.962+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:08:01.993+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:08:01.993+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T12:08:02.014+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:08:02.014+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T12:08:02.028+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-08-01T12:08:32.390+0000] {processor.py:157} INFO - Started process (PID=38684) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:08:32.392+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T12:08:32.402+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:08:32.401+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:08:32.433+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:08:32.465+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:08:32.465+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T12:08:32.500+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:08:32.500+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T12:08:32.513+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-08-01T12:09:02.863+0000] {processor.py:157} INFO - Started process (PID=38709) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:09:02.865+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T12:09:02.869+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:09:02.869+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:09:02.907+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:09:02.945+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:09:02.945+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T12:09:02.963+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:09:02.963+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T12:09:02.975+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-08-01T12:09:33.431+0000] {processor.py:157} INFO - Started process (PID=38734) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:09:33.433+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T12:09:33.436+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:09:33.436+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:09:33.462+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:09:33.499+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:09:33.499+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T12:09:33.522+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:09:33.522+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T12:09:33.539+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-08-01T12:10:03.951+0000] {processor.py:157} INFO - Started process (PID=38759) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:10:03.953+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T12:10:03.964+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:10:03.959+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:10:03.989+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:10:04.031+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:10:04.031+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T12:10:04.048+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:10:04.048+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T12:10:04.078+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-08-01T12:10:34.509+0000] {processor.py:157} INFO - Started process (PID=38784) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:10:34.511+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T12:10:34.515+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:10:34.515+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:10:34.539+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:10:34.592+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:10:34.592+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T12:10:34.608+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:10:34.608+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T12:10:34.620+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-08-01T12:11:05.056+0000] {processor.py:157} INFO - Started process (PID=38809) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:11:05.059+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T12:11:05.076+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:11:05.075+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:11:05.116+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:11:05.163+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:11:05.163+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T12:11:05.189+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:11:05.188+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T12:11:05.221+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.171 seconds
[2024-08-01T12:11:35.663+0000] {processor.py:157} INFO - Started process (PID=38834) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:11:35.666+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T12:11:35.671+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:11:35.671+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:11:35.697+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:11:35.765+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:11:35.765+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T12:11:35.789+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:11:35.789+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T12:11:35.807+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.149 seconds
[2024-08-01T12:12:06.266+0000] {processor.py:157} INFO - Started process (PID=38858) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:12:06.269+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T12:12:06.275+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:12:06.275+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:12:06.298+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:12:06.354+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:12:06.354+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T12:12:06.375+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:12:06.375+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T12:12:06.390+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-08-01T12:12:36.883+0000] {processor.py:157} INFO - Started process (PID=38884) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:12:36.887+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T12:12:36.890+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:12:36.890+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:12:36.913+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:12:36.972+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:12:36.971+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T12:12:36.994+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:12:36.994+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T12:12:37.008+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-08-01T12:13:07.436+0000] {processor.py:157} INFO - Started process (PID=38909) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:13:07.438+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T12:13:07.455+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:13:07.453+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:13:07.476+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:13:07.523+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:13:07.523+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T12:13:07.542+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:13:07.541+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T12:13:07.557+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-08-01T12:13:38.016+0000] {processor.py:157} INFO - Started process (PID=38934) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:13:38.018+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T12:13:38.023+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:13:38.023+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:13:38.060+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:13:38.091+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:13:38.091+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T12:13:38.109+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:13:38.109+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T12:13:38.122+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-08-01T12:14:08.541+0000] {processor.py:157} INFO - Started process (PID=38959) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:14:08.543+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T12:14:08.548+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:14:08.547+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:14:08.575+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:14:08.614+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:14:08.614+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T12:14:08.638+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:14:08.638+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T12:14:08.653+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-08-01T12:14:39.126+0000] {processor.py:157} INFO - Started process (PID=38984) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:14:39.130+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T12:14:39.147+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:14:39.146+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:14:39.170+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:14:39.201+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:14:39.201+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T12:14:39.227+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:14:39.226+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T12:14:39.241+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-08-01T12:15:09.910+0000] {processor.py:157} INFO - Started process (PID=39009) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:15:09.912+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T12:15:09.916+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:15:09.916+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:15:09.938+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:15:09.982+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:15:09.982+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T12:15:10.007+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:15:10.007+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T12:15:10.021+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-08-01T12:15:40.428+0000] {processor.py:157} INFO - Started process (PID=39034) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:15:40.436+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T12:15:40.444+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:15:40.443+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:15:40.466+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:15:40.501+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:15:40.501+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T12:15:40.522+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:15:40.522+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T12:15:40.539+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-08-01T12:16:10.948+0000] {processor.py:157} INFO - Started process (PID=39059) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:16:10.951+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T12:16:10.955+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:16:10.955+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:16:10.979+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:16:11.015+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:16:11.015+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T12:16:11.038+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:16:11.038+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T12:16:11.053+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-08-01T12:16:41.360+0000] {processor.py:157} INFO - Started process (PID=39084) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:16:41.361+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T12:16:41.363+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:16:41.363+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:16:41.375+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:16:41.393+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:16:41.393+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T12:16:41.406+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:16:41.406+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T12:16:41.418+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-01T12:17:11.835+0000] {processor.py:157} INFO - Started process (PID=39109) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:17:11.837+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T12:17:11.842+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:17:11.842+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:17:11.872+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:17:11.914+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:17:11.914+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T12:17:11.940+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:17:11.939+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T12:17:11.956+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-08-01T12:17:42.362+0000] {processor.py:157} INFO - Started process (PID=39134) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:17:42.363+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T12:17:42.366+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:17:42.366+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:17:42.382+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:17:42.406+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:17:42.405+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T12:17:42.421+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:17:42.420+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T12:17:42.432+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-01T12:18:12.815+0000] {processor.py:157} INFO - Started process (PID=39159) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:18:12.817+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T12:18:12.818+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:18:12.818+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:18:12.829+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:18:12.845+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:18:12.845+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T12:18:12.855+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:18:12.855+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T12:18:12.866+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-01T12:18:43.228+0000] {processor.py:157} INFO - Started process (PID=39184) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:18:43.228+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T12:18:43.232+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:18:43.231+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:18:43.249+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:18:43.270+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:18:43.270+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T12:18:43.283+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:18:43.282+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T12:18:43.292+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-01T12:19:13.678+0000] {processor.py:157} INFO - Started process (PID=39209) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:19:13.679+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T12:19:13.680+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:19:13.680+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:19:13.695+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:19:13.710+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:19:13.710+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T12:19:13.721+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:19:13.721+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T12:19:13.730+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-01T12:19:44.100+0000] {processor.py:157} INFO - Started process (PID=39234) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:19:44.102+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T12:19:44.103+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:19:44.103+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:19:44.111+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:19:44.125+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:19:44.125+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T12:19:44.135+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:19:44.135+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T12:19:44.145+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-01T12:20:14.495+0000] {processor.py:157} INFO - Started process (PID=39259) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:20:14.496+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T12:20:14.498+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:20:14.498+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:20:14.509+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:20:14.526+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:20:14.526+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T12:20:14.536+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:20:14.536+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T12:20:14.547+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-01T12:20:45.210+0000] {processor.py:157} INFO - Started process (PID=39284) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:20:45.213+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T12:20:45.220+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:20:45.219+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:20:45.254+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:20:45.301+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:20:45.301+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T12:20:45.332+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:20:45.332+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T12:20:45.349+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.166 seconds
[2024-08-01T12:21:16.027+0000] {processor.py:157} INFO - Started process (PID=39309) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:21:16.029+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T12:21:16.032+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:21:16.032+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:21:16.046+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:21:16.068+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:21:16.068+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T12:21:16.081+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:21:16.081+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T12:21:16.091+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-01T12:21:46.552+0000] {processor.py:157} INFO - Started process (PID=39334) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:21:46.552+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T12:21:46.554+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:21:46.554+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:21:46.565+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:21:46.582+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:21:46.582+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T12:21:46.592+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:21:46.592+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T12:21:46.601+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-01T12:28:28.606+0000] {processor.py:157} INFO - Started process (PID=39361) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:28:28.608+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T12:28:28.609+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:28:28.609+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:28:28.625+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:28:28.657+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:28:28.657+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T12:28:28.702+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:28:28.701+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T12:28:28.735+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-08-01T12:46:05.056+0000] {processor.py:157} INFO - Started process (PID=39385) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:46:05.060+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T12:46:05.072+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:46:05.070+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:46:05.130+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:46:05.196+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:46:05.196+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T12:46:05.230+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:46:05.229+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T12:46:05.255+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.204 seconds
[2024-08-01T12:46:35.925+0000] {processor.py:157} INFO - Started process (PID=39411) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:46:35.926+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T12:46:35.930+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:46:35.929+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:46:35.948+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:46:35.989+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:46:35.989+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T12:46:36.006+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:46:36.005+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T12:46:36.016+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-08-01T12:47:06.520+0000] {processor.py:157} INFO - Started process (PID=39436) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:47:06.521+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T12:47:06.527+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:47:06.527+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:47:06.542+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:47:06.561+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:47:06.561+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T12:47:06.578+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:47:06.578+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T12:47:06.587+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-01T12:47:37.016+0000] {processor.py:157} INFO - Started process (PID=39461) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:47:37.017+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T12:47:37.018+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:47:37.018+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:47:37.026+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:47:37.047+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:47:37.047+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T12:47:37.059+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:47:37.059+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T12:47:37.069+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-01T12:48:07.432+0000] {processor.py:157} INFO - Started process (PID=39486) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:48:07.433+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T12:48:07.434+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:48:07.434+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:48:07.448+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:48:07.462+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:48:07.462+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T12:48:07.474+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:48:07.474+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T12:48:07.483+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-01T12:48:37.847+0000] {processor.py:157} INFO - Started process (PID=39511) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:48:37.849+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T12:48:37.851+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:48:37.851+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:48:37.864+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:48:37.884+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:48:37.884+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T12:48:37.896+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:48:37.896+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T12:48:37.906+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-01T12:49:21.613+0000] {processor.py:157} INFO - Started process (PID=39538) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:49:21.616+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T12:49:21.618+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:49:21.617+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:49:21.634+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:49:21.660+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:49:21.659+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T12:49:21.675+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:49:21.675+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T12:49:21.685+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-08-01T12:50:03.779+0000] {processor.py:157} INFO - Started process (PID=39563) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:50:03.781+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T12:50:03.784+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:50:03.784+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:50:03.822+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:50:03.849+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:50:03.849+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T12:50:03.862+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:50:03.862+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T12:50:03.873+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-08-01T12:50:34.270+0000] {processor.py:157} INFO - Started process (PID=39588) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:50:34.271+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T12:50:34.273+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:50:34.273+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:50:34.283+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T12:50:34.299+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:50:34.298+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T12:50:34.308+0000] {logging_mixin.py:151} INFO - [2024-08-01T12:50:34.308+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T12:50:34.317+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-01T13:00:17.324+0000] {processor.py:157} INFO - Started process (PID=39612) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:00:17.329+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:00:17.332+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:00:17.331+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:00:17.356+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:00:17.383+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:00:17.383+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:00:17.408+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:00:17.408+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:00:17.436+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-08-01T13:00:47.986+0000] {processor.py:157} INFO - Started process (PID=39638) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:00:47.987+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:00:47.990+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:00:47.990+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:00:48.007+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:00:48.045+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:00:48.045+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:00:48.060+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:00:48.060+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:00:48.073+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-08-01T13:01:18.430+0000] {processor.py:157} INFO - Started process (PID=39663) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:01:18.431+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:01:18.433+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:01:18.433+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:01:18.445+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:01:18.462+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:01:18.461+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:01:18.473+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:01:18.473+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:01:18.482+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-01T13:01:48.821+0000] {processor.py:157} INFO - Started process (PID=39688) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:01:48.821+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:01:48.823+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:01:48.823+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:01:48.833+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:01:48.850+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:01:48.850+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:01:48.861+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:01:48.861+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:01:48.871+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-01T13:02:19.253+0000] {processor.py:157} INFO - Started process (PID=39713) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:02:19.257+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:02:19.259+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:02:19.259+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:02:19.279+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:02:19.296+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:02:19.296+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:02:19.308+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:02:19.308+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:02:19.319+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-01T13:02:49.704+0000] {processor.py:157} INFO - Started process (PID=39738) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:02:49.706+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:02:49.707+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:02:49.707+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:02:49.718+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:02:49.738+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:02:49.738+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:02:49.751+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:02:49.751+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:02:49.761+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-01T13:03:20.193+0000] {processor.py:157} INFO - Started process (PID=39763) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:03:20.194+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:03:20.195+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:03:20.195+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:03:20.206+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:03:20.223+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:03:20.223+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:03:20.235+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:03:20.235+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:03:20.245+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-01T13:03:50.643+0000] {processor.py:157} INFO - Started process (PID=39788) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:03:50.644+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:03:50.647+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:03:50.647+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:03:50.662+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:03:50.680+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:03:50.680+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:03:50.691+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:03:50.691+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:03:50.702+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-01T13:04:21.033+0000] {processor.py:157} INFO - Started process (PID=39813) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:04:21.034+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:04:21.038+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:04:21.037+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:04:21.054+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:04:21.076+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:04:21.076+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:04:21.089+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:04:21.089+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:04:21.099+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-01T13:04:51.495+0000] {processor.py:157} INFO - Started process (PID=39838) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:04:51.497+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:04:51.499+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:04:51.499+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:04:51.516+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:04:51.531+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:04:51.531+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:04:51.543+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:04:51.543+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:04:51.551+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-01T13:05:21.956+0000] {processor.py:157} INFO - Started process (PID=39863) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:05:21.958+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:05:21.960+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:05:21.960+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:05:21.971+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:05:21.990+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:05:21.990+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:05:22.003+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:05:22.003+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:05:22.011+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-01T13:05:52.462+0000] {processor.py:157} INFO - Started process (PID=39888) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:05:52.463+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:05:52.466+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:05:52.465+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:05:52.484+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:05:52.502+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:05:52.502+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:05:52.514+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:05:52.514+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:05:52.522+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-01T13:06:22.918+0000] {processor.py:157} INFO - Started process (PID=39913) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:06:22.921+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:06:22.923+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:06:22.923+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:06:22.939+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:06:22.958+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:06:22.958+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:06:22.975+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:06:22.975+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:06:22.984+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-01T13:06:53.371+0000] {processor.py:157} INFO - Started process (PID=39938) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:06:53.371+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:06:53.373+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:06:53.373+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:06:53.383+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:06:53.399+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:06:53.399+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:06:53.410+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:06:53.410+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:06:53.420+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-01T13:07:23.838+0000] {processor.py:157} INFO - Started process (PID=39963) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:07:23.839+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:07:23.841+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:07:23.841+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:07:23.858+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:07:23.876+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:07:23.876+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:07:23.892+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:07:23.892+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:07:23.901+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-01T13:07:54.293+0000] {processor.py:157} INFO - Started process (PID=39987) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:07:54.294+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:07:54.298+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:07:54.297+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:07:54.313+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:07:54.334+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:07:54.334+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:07:54.347+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:07:54.347+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:07:54.357+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-01T13:08:24.788+0000] {processor.py:157} INFO - Started process (PID=40013) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:08:24.792+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:08:24.794+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:08:24.794+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:08:24.806+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:08:24.825+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:08:24.825+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:08:24.836+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:08:24.836+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:08:24.846+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-01T13:08:55.230+0000] {processor.py:157} INFO - Started process (PID=40038) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:08:55.232+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:08:55.234+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:08:55.234+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:08:55.251+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:08:55.271+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:08:55.270+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:08:55.284+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:08:55.284+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:08:55.294+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-01T13:09:25.730+0000] {processor.py:157} INFO - Started process (PID=40063) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:09:25.731+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:09:25.734+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:09:25.734+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:09:25.757+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:09:25.775+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:09:25.775+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:09:25.789+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:09:25.789+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:09:25.798+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-01T13:09:56.130+0000] {processor.py:157} INFO - Started process (PID=40088) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:09:56.130+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:09:56.133+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:09:56.132+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:09:56.145+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:09:56.162+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:09:56.162+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:09:56.175+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:09:56.175+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:09:56.184+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-01T13:10:26.413+0000] {processor.py:157} INFO - Started process (PID=40113) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:10:26.414+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:10:26.418+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:10:26.418+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:10:26.456+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:10:26.478+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:10:26.478+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:10:26.491+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:10:26.491+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:10:26.503+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-08-01T13:10:56.914+0000] {processor.py:157} INFO - Started process (PID=40138) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:10:56.919+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:10:56.922+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:10:56.922+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:10:56.931+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:10:56.946+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:10:56.946+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:10:56.958+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:10:56.958+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:10:56.966+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-01T13:11:27.350+0000] {processor.py:157} INFO - Started process (PID=40163) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:11:27.351+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:11:27.353+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:11:27.352+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:11:27.363+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:11:27.380+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:11:27.380+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:11:27.392+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:11:27.392+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:11:27.401+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-01T13:11:57.833+0000] {processor.py:157} INFO - Started process (PID=40188) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:11:57.834+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:11:57.839+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:11:57.839+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:11:57.859+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:11:57.906+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:11:57.906+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:11:57.919+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:11:57.919+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:11:57.931+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-08-01T13:12:28.319+0000] {processor.py:157} INFO - Started process (PID=40213) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:12:28.323+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:12:28.326+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:12:28.326+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:12:28.345+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:12:28.365+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:12:28.365+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:12:28.379+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:12:28.379+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:12:28.392+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-08-01T13:12:58.817+0000] {processor.py:157} INFO - Started process (PID=40238) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:12:58.819+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:12:58.821+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:12:58.820+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:12:58.835+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:12:58.849+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:12:58.849+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:12:58.865+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:12:58.865+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:12:58.874+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-01T13:13:29.202+0000] {processor.py:157} INFO - Started process (PID=40263) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:13:29.204+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:13:29.206+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:13:29.206+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:13:29.217+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:13:29.233+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:13:29.233+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:13:29.243+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:13:29.243+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:13:29.253+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-01T13:13:59.608+0000] {processor.py:157} INFO - Started process (PID=40288) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:13:59.609+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:13:59.611+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:13:59.611+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:13:59.622+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:13:59.638+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:13:59.638+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:13:59.648+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:13:59.648+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:13:59.658+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-01T13:14:30.074+0000] {processor.py:157} INFO - Started process (PID=40313) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:14:30.075+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:14:30.078+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:14:30.078+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:14:30.096+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:14:30.119+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:14:30.118+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:14:30.132+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:14:30.132+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:14:30.142+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-01T13:15:00.470+0000] {processor.py:157} INFO - Started process (PID=40338) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:15:00.471+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:15:00.473+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:15:00.473+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:15:00.485+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:15:00.502+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:15:00.502+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:15:00.512+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:15:00.512+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:15:00.522+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-01T13:15:30.939+0000] {processor.py:157} INFO - Started process (PID=40363) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:15:30.940+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:15:30.943+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:15:30.943+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:15:30.960+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:15:30.982+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:15:30.982+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:15:30.995+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:15:30.995+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:15:31.005+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-01T13:16:01.343+0000] {processor.py:157} INFO - Started process (PID=40388) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:16:01.344+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:16:01.346+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:16:01.346+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:16:01.359+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:16:01.374+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:16:01.374+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:16:01.385+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:16:01.385+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:16:01.391+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-01T13:16:31.777+0000] {processor.py:157} INFO - Started process (PID=40413) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:16:31.778+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:16:31.781+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:16:31.780+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:16:31.797+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:16:31.811+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:16:31.811+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:16:31.825+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:16:31.825+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:16:31.834+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-01T13:17:02.202+0000] {processor.py:157} INFO - Started process (PID=40438) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:17:02.204+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:17:02.206+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:17:02.206+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:17:02.220+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:17:02.239+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:17:02.239+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:17:02.250+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:17:02.249+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:17:02.257+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-01T13:17:32.584+0000] {processor.py:157} INFO - Started process (PID=40463) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:17:32.585+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:17:32.587+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:17:32.587+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:17:32.598+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:17:32.613+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:17:32.613+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:17:32.626+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:17:32.626+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:17:32.634+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-01T13:18:02.994+0000] {processor.py:157} INFO - Started process (PID=40488) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:18:02.994+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:18:02.997+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:18:02.997+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:18:03.008+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:18:03.030+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:18:03.030+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:18:03.042+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:18:03.042+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:18:03.051+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-01T13:18:33.417+0000] {processor.py:157} INFO - Started process (PID=40513) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:18:33.417+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:18:33.419+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:18:33.419+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:18:33.433+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:18:33.448+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:18:33.448+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:18:33.459+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:18:33.459+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:18:33.467+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-01T13:19:03.903+0000] {processor.py:157} INFO - Started process (PID=40538) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:19:03.906+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:19:03.909+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:19:03.908+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:19:03.926+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:19:03.948+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:19:03.948+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:19:03.962+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:19:03.962+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:19:03.972+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-01T13:19:34.342+0000] {processor.py:157} INFO - Started process (PID=40563) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:19:34.343+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:19:34.344+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:19:34.343+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:19:34.353+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:19:34.368+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:19:34.368+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:19:34.378+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:19:34.378+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:19:34.386+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-08-01T13:20:04.758+0000] {processor.py:157} INFO - Started process (PID=40588) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:20:04.759+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:20:04.761+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:20:04.761+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:20:04.776+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:20:04.792+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:20:04.791+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:20:04.803+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:20:04.803+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:20:04.811+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-01T13:20:35.249+0000] {processor.py:157} INFO - Started process (PID=40613) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:20:35.250+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:20:35.252+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:20:35.252+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:20:35.266+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:20:35.280+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:20:35.280+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:20:35.291+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:20:35.291+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:20:35.301+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-01T13:21:05.597+0000] {processor.py:157} INFO - Started process (PID=40638) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:21:05.599+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:21:05.600+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:21:05.600+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:21:05.612+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:21:05.627+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:21:05.627+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:21:05.638+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:21:05.638+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:21:05.647+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-01T13:21:36.061+0000] {processor.py:157} INFO - Started process (PID=40663) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:21:36.062+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:21:36.063+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:21:36.062+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:21:36.072+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:21:36.085+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:21:36.085+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:21:36.095+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:21:36.095+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:21:36.103+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.044 seconds
[2024-08-01T13:22:06.518+0000] {processor.py:157} INFO - Started process (PID=40688) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:22:06.519+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:22:06.523+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:22:06.523+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:22:06.536+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:22:06.552+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:22:06.552+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:22:06.563+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:22:06.563+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:22:06.571+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-01T13:22:37.016+0000] {processor.py:157} INFO - Started process (PID=40713) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:22:37.018+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:22:37.020+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:22:37.020+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:22:37.037+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:22:37.058+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:22:37.058+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:22:37.071+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:22:37.071+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:22:37.080+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-01T13:23:07.421+0000] {processor.py:157} INFO - Started process (PID=40738) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:23:07.422+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:23:07.423+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:23:07.423+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:23:07.430+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:23:07.444+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:23:07.444+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:23:07.454+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:23:07.454+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:23:07.463+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.044 seconds
[2024-08-01T13:23:37.844+0000] {processor.py:157} INFO - Started process (PID=40763) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:23:37.851+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:23:37.854+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:23:37.854+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:23:37.861+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:23:37.874+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:23:37.874+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:23:37.883+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:23:37.883+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:23:37.890+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-08-01T13:24:08.240+0000] {processor.py:157} INFO - Started process (PID=40788) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:24:08.243+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:24:08.245+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:24:08.245+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:24:08.262+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:24:08.283+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:24:08.283+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:24:08.313+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:24:08.313+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:24:08.323+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-08-01T13:24:38.606+0000] {processor.py:157} INFO - Started process (PID=40813) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:24:38.607+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:24:38.608+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:24:38.608+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:24:38.619+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:24:38.634+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:24:38.634+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:24:38.645+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:24:38.645+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:24:38.654+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-01T13:25:09.021+0000] {processor.py:157} INFO - Started process (PID=40838) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:25:09.022+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:25:09.024+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:25:09.024+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:25:09.039+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:25:09.053+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:25:09.053+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:25:09.065+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:25:09.065+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:25:09.074+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-01T13:25:39.501+0000] {processor.py:157} INFO - Started process (PID=40863) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:25:39.502+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:25:39.504+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:25:39.503+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:25:39.515+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:25:39.533+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:25:39.533+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:25:39.546+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:25:39.545+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:25:39.555+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-01T13:26:09.968+0000] {processor.py:157} INFO - Started process (PID=40888) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:26:09.969+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:26:09.971+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:26:09.971+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:26:09.986+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:26:09.998+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:26:09.998+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:26:10.012+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:26:10.012+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:26:10.021+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-01T13:26:40.431+0000] {processor.py:157} INFO - Started process (PID=40913) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:26:40.432+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:26:40.435+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:26:40.434+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:26:40.449+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:26:40.465+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:26:40.464+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:26:40.475+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:26:40.475+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:26:40.484+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-01T13:27:10.814+0000] {processor.py:157} INFO - Started process (PID=40938) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:27:10.815+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:27:10.817+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:27:10.817+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:27:10.828+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:27:10.843+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:27:10.843+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:27:10.854+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:27:10.854+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:27:10.862+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-01T13:27:41.297+0000] {processor.py:157} INFO - Started process (PID=40963) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:27:41.298+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:27:41.302+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:27:41.302+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:27:41.319+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:27:41.340+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:27:41.340+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:27:41.353+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:27:41.352+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:27:41.363+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-01T13:28:11.732+0000] {processor.py:157} INFO - Started process (PID=40988) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:28:11.734+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:28:11.735+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:28:11.735+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:28:11.745+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:28:11.761+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:28:11.761+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:28:11.771+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:28:11.771+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:28:11.781+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-01T13:28:42.169+0000] {processor.py:157} INFO - Started process (PID=41013) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:28:42.169+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:28:42.171+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:28:42.171+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:28:42.186+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:28:42.199+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:28:42.199+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:28:42.209+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:28:42.209+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:28:42.219+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-01T13:29:12.643+0000] {processor.py:157} INFO - Started process (PID=41038) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:29:12.645+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:29:12.647+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:29:12.647+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:29:12.660+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:29:12.676+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:29:12.676+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:29:12.687+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:29:12.687+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:29:12.698+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-01T13:29:43.011+0000] {processor.py:157} INFO - Started process (PID=41063) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:29:43.012+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:29:43.013+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:29:43.013+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:29:43.025+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:29:43.042+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:29:43.042+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:29:43.053+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:29:43.053+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:29:43.064+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-01T13:30:13.445+0000] {processor.py:157} INFO - Started process (PID=41088) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:30:13.447+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:30:13.449+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:30:13.449+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:30:13.466+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:30:13.480+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:30:13.480+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:30:13.493+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:30:13.493+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:30:13.502+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-01T13:30:43.860+0000] {processor.py:157} INFO - Started process (PID=41112) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:30:43.861+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:30:43.863+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:30:43.862+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:30:43.872+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:30:43.886+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:30:43.886+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:30:43.898+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:30:43.898+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:30:43.905+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-08-01T13:31:14.318+0000] {processor.py:157} INFO - Started process (PID=41138) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:31:14.320+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:31:14.323+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:31:14.323+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:31:14.343+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:31:14.364+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:31:14.364+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:31:14.377+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:31:14.377+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:31:14.389+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-01T13:31:44.743+0000] {processor.py:157} INFO - Started process (PID=41163) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:31:44.743+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:31:44.745+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:31:44.745+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:31:44.758+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:31:44.775+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:31:44.775+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:31:44.786+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:31:44.786+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:31:44.793+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-01T13:32:15.203+0000] {processor.py:157} INFO - Started process (PID=41188) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:32:15.204+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:32:15.206+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:32:15.206+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:32:15.222+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:32:15.234+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:32:15.234+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:32:15.246+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:32:15.246+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:32:15.257+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-01T13:32:45.603+0000] {processor.py:157} INFO - Started process (PID=41213) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:32:45.605+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:32:45.607+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:32:45.607+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:32:45.620+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:32:45.638+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:32:45.637+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:32:45.650+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:32:45.650+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:32:45.662+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-01T13:33:16.005+0000] {processor.py:157} INFO - Started process (PID=41238) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:33:16.008+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:33:16.010+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:33:16.010+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:33:16.029+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:33:16.044+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:33:16.043+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:33:16.054+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:33:16.054+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:33:16.063+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-01T13:33:46.473+0000] {processor.py:157} INFO - Started process (PID=41263) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:33:46.474+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:33:46.476+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:33:46.476+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:33:46.491+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:33:46.516+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:33:46.516+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:33:46.529+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:33:46.529+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:33:46.537+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-01T13:34:16.943+0000] {processor.py:157} INFO - Started process (PID=41287) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:34:16.946+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:34:16.948+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:34:16.948+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:34:16.959+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:34:16.974+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:34:16.974+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:34:16.987+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:34:16.987+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:34:16.995+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-01T13:34:47.380+0000] {processor.py:157} INFO - Started process (PID=41313) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:34:47.382+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:34:47.386+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:34:47.385+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:34:47.404+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:34:47.423+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:34:47.423+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:34:47.436+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:34:47.436+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:34:47.446+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-01T13:35:17.874+0000] {processor.py:157} INFO - Started process (PID=41338) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:35:17.874+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:35:17.876+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:35:17.876+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:35:17.894+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:35:17.907+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:35:17.907+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:35:17.919+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:35:17.919+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:35:17.928+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-01T13:35:48.312+0000] {processor.py:157} INFO - Started process (PID=41363) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:35:48.316+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:35:48.322+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:35:48.320+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:35:48.355+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:35:48.382+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:35:48.382+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:35:48.397+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:35:48.397+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:35:48.408+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-08-01T13:36:18.848+0000] {processor.py:157} INFO - Started process (PID=41388) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:36:18.850+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:36:18.851+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:36:18.851+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:36:18.865+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:36:18.884+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:36:18.884+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:36:18.895+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:36:18.895+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:36:18.906+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-01T13:36:49.333+0000] {processor.py:157} INFO - Started process (PID=41413) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:36:49.336+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:36:49.344+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:36:49.343+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:36:49.373+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:36:49.432+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:36:49.432+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:36:49.447+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:36:49.446+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:36:49.459+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.163 seconds
[2024-08-01T13:37:19.884+0000] {processor.py:157} INFO - Started process (PID=41438) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:37:19.887+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:37:19.891+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:37:19.891+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:37:19.907+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:37:19.932+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:37:19.931+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:37:19.947+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:37:19.947+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:37:19.957+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-08-01T13:37:50.332+0000] {processor.py:157} INFO - Started process (PID=41463) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:37:50.333+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:37:50.334+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:37:50.334+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:37:50.345+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:37:50.362+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:37:50.362+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:37:50.376+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:37:50.375+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:37:50.384+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-01T13:38:20.811+0000] {processor.py:157} INFO - Started process (PID=41488) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:38:20.813+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:38:20.829+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:38:20.829+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:38:20.850+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:38:20.892+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:38:20.892+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:38:20.907+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:38:20.907+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:38:20.918+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-08-01T13:38:51.299+0000] {processor.py:157} INFO - Started process (PID=41513) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:38:51.300+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:38:51.302+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:38:51.302+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:38:51.318+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:38:51.330+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:38:51.330+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:38:51.341+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:38:51.341+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:38:51.352+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-01T13:39:21.738+0000] {processor.py:157} INFO - Started process (PID=41538) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:39:21.740+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:39:21.742+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:39:21.742+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:39:21.764+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:39:21.799+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:39:21.799+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:39:21.813+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:39:21.813+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:39:21.822+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-08-01T13:39:52.132+0000] {processor.py:157} INFO - Started process (PID=41563) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:39:52.133+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:39:52.135+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:39:52.135+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:39:52.144+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:39:52.161+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:39:52.161+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:39:52.172+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:39:52.172+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:39:52.181+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-01T13:40:22.535+0000] {processor.py:157} INFO - Started process (PID=41588) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:40:22.535+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:40:22.537+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:40:22.537+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:40:22.549+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:40:22.564+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:40:22.564+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:40:22.574+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:40:22.574+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:40:22.583+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-01T13:40:52.954+0000] {processor.py:157} INFO - Started process (PID=41613) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:40:52.955+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:40:52.957+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:40:52.957+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:40:52.973+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:40:52.988+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:40:52.988+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:40:52.997+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:40:52.997+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:40:53.008+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-01T13:41:23.326+0000] {processor.py:157} INFO - Started process (PID=41638) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:41:23.327+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:41:23.330+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:41:23.329+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:41:23.346+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:41:23.379+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:41:23.379+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:41:23.396+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:41:23.396+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:41:23.405+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-08-01T13:41:53.819+0000] {processor.py:157} INFO - Started process (PID=41663) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:41:53.820+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:41:53.822+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:41:53.822+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:41:53.838+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:41:53.854+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:41:53.854+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:41:53.864+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:41:53.864+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:41:53.871+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-01T13:42:24.233+0000] {processor.py:157} INFO - Started process (PID=41688) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:42:24.235+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:42:24.238+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:42:24.237+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:42:24.249+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:42:24.263+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:42:24.263+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:42:24.274+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:42:24.274+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:42:24.283+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-01T13:42:54.655+0000] {processor.py:157} INFO - Started process (PID=41713) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:42:54.657+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:42:54.659+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:42:54.658+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:42:54.671+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:42:54.687+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:42:54.686+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:42:54.696+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:42:54.696+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:42:54.706+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-01T13:43:25.106+0000] {processor.py:157} INFO - Started process (PID=41738) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:43:25.108+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:43:25.109+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:43:25.109+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:43:25.121+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:43:25.136+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:43:25.136+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:43:25.148+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:43:25.148+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:43:25.158+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-01T13:43:55.508+0000] {processor.py:157} INFO - Started process (PID=41763) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:43:55.510+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:43:55.512+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:43:55.512+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:43:55.529+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:43:55.543+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:43:55.543+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:43:55.553+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:43:55.553+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:43:55.562+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-01T13:44:25.969+0000] {processor.py:157} INFO - Started process (PID=41788) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:44:25.970+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:44:25.973+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:44:25.973+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:44:25.991+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:44:26.012+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:44:26.011+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:44:26.025+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:44:26.025+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:44:26.035+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-01T13:44:56.412+0000] {processor.py:157} INFO - Started process (PID=41813) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:44:56.412+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:44:56.413+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:44:56.413+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:44:56.419+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:44:56.431+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:44:56.431+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:44:56.441+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:44:56.441+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:44:56.450+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.040 seconds
[2024-08-01T13:45:26.814+0000] {processor.py:157} INFO - Started process (PID=41838) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:45:26.817+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:45:26.819+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:45:26.819+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:45:26.833+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:45:26.848+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:45:26.848+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:45:26.858+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:45:26.858+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:45:26.866+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-01T13:45:57.286+0000] {processor.py:157} INFO - Started process (PID=41863) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:45:57.287+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:45:57.289+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:45:57.288+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:45:57.299+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:45:57.315+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:45:57.315+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:45:57.326+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:45:57.326+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:45:57.335+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-01T13:46:27.736+0000] {processor.py:157} INFO - Started process (PID=41888) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:46:27.738+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:46:27.741+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:46:27.741+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:46:27.753+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:46:27.770+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:46:27.770+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:46:27.781+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:46:27.781+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:46:27.791+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-01T13:46:58.229+0000] {processor.py:157} INFO - Started process (PID=41913) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:46:58.231+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:46:58.233+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:46:58.232+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:46:58.247+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:46:58.268+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:46:58.268+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:46:58.283+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:46:58.283+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:46:58.292+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-01T13:47:28.690+0000] {processor.py:157} INFO - Started process (PID=41938) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:47:28.691+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:47:28.693+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:47:28.693+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:47:28.705+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:47:28.722+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:47:28.722+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:47:28.733+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:47:28.733+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:47:28.742+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-01T13:47:59.154+0000] {processor.py:157} INFO - Started process (PID=41963) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:47:59.156+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:47:59.158+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:47:59.158+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:47:59.176+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:47:59.189+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:47:59.189+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:47:59.200+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:47:59.200+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:47:59.210+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-01T13:48:29.594+0000] {processor.py:157} INFO - Started process (PID=41988) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:48:29.597+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:48:29.599+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:48:29.599+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:48:29.608+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:48:29.626+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:48:29.626+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:48:29.636+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:48:29.636+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:48:29.643+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-01T13:49:00.023+0000] {processor.py:157} INFO - Started process (PID=42013) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:49:00.025+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:49:00.026+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:49:00.026+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:49:00.043+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:49:00.055+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:49:00.055+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:49:00.065+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:49:00.065+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:49:00.076+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-01T13:49:30.473+0000] {processor.py:157} INFO - Started process (PID=42038) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:49:30.476+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:49:30.478+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:49:30.478+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:49:30.501+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:49:30.520+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:49:30.520+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:49:30.533+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:49:30.533+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:49:30.543+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-01T13:50:00.954+0000] {processor.py:157} INFO - Started process (PID=42063) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:50:00.956+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:50:00.959+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:50:00.958+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:50:00.970+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:50:00.985+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:50:00.985+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:50:00.997+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:50:00.997+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:50:01.005+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-01T13:50:31.383+0000] {processor.py:157} INFO - Started process (PID=42088) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:50:31.385+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:50:31.387+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:50:31.387+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:50:31.396+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:50:31.413+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:50:31.413+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:50:31.424+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:50:31.424+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:50:31.432+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-01T13:51:01.742+0000] {processor.py:157} INFO - Started process (PID=42113) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:51:01.743+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:51:01.745+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:51:01.745+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:51:01.753+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:51:01.769+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:51:01.769+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:51:01.780+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:51:01.780+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:51:01.789+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-01T13:51:32.161+0000] {processor.py:157} INFO - Started process (PID=42138) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:51:32.165+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:51:32.168+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:51:32.168+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:51:32.185+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:51:32.198+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:51:32.198+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:51:32.209+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:51:32.209+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:51:32.218+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-01T13:52:02.634+0000] {processor.py:157} INFO - Started process (PID=42163) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:52:02.635+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:52:02.636+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:52:02.636+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:52:02.650+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:52:02.672+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:52:02.672+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:52:02.686+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:52:02.686+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:52:02.696+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-01T13:52:33.077+0000] {processor.py:157} INFO - Started process (PID=42188) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:52:33.079+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:52:33.081+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:52:33.081+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:52:33.094+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:52:33.109+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:52:33.109+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:52:33.124+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:52:33.124+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:52:33.134+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-01T13:53:03.582+0000] {processor.py:157} INFO - Started process (PID=42213) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:53:03.584+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:53:03.589+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:53:03.588+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:53:03.609+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:53:03.632+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:53:03.632+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:53:03.645+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:53:03.645+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:53:03.656+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-08-01T13:53:34.013+0000] {processor.py:157} INFO - Started process (PID=42238) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:53:34.014+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:53:34.016+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:53:34.016+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:53:34.027+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:53:34.043+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:53:34.043+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:53:34.057+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:53:34.057+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:53:34.065+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-01T13:54:04.469+0000] {processor.py:157} INFO - Started process (PID=42263) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:54:04.470+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:54:04.472+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:54:04.472+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:54:04.484+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:54:04.500+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:54:04.500+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:54:04.510+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:54:04.509+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:54:04.519+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-01T13:54:34.893+0000] {processor.py:157} INFO - Started process (PID=42287) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:54:34.896+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:54:34.899+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:54:34.899+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:54:34.916+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:54:34.939+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:54:34.939+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:54:34.952+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:54:34.952+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:54:34.961+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-01T13:55:05.400+0000] {processor.py:157} INFO - Started process (PID=42313) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:55:05.403+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:55:05.404+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:55:05.404+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:55:05.415+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:55:05.430+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:55:05.430+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:55:05.441+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:55:05.441+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:55:05.451+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-01T13:55:35.920+0000] {processor.py:157} INFO - Started process (PID=42337) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:55:35.921+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:55:35.924+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:55:35.924+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:55:35.952+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:55:35.974+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:55:35.974+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:55:35.988+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:55:35.987+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:55:35.997+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-08-01T13:56:06.379+0000] {processor.py:157} INFO - Started process (PID=42363) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:56:06.382+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:56:06.383+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:56:06.383+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:56:06.393+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:56:06.410+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:56:06.410+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:56:06.421+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:56:06.421+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:56:06.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-01T13:56:36.861+0000] {processor.py:157} INFO - Started process (PID=42388) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:56:36.862+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:56:36.866+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:56:36.866+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:56:36.888+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:56:36.911+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:56:36.911+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:56:36.924+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:56:36.924+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:56:36.935+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-08-01T13:57:07.353+0000] {processor.py:157} INFO - Started process (PID=42413) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:57:07.355+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:57:07.357+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:57:07.357+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:57:07.372+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:57:07.390+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:57:07.390+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:57:07.401+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:57:07.401+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:57:07.408+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-01T13:57:37.782+0000] {processor.py:157} INFO - Started process (PID=42438) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:57:37.784+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:57:37.786+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:57:37.785+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:57:37.798+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:57:37.813+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:57:37.813+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:57:37.825+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:57:37.825+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:57:37.833+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-01T13:58:08.138+0000] {processor.py:157} INFO - Started process (PID=42463) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:58:08.139+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:58:08.141+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:58:08.141+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:58:08.156+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:58:08.172+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:58:08.172+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:58:08.184+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:58:08.184+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:58:08.192+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-01T13:58:38.638+0000] {processor.py:157} INFO - Started process (PID=42488) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:58:38.639+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:58:38.642+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:58:38.641+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:58:38.658+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:58:38.680+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:58:38.680+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:58:38.694+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:58:38.694+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:58:38.703+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-01T13:59:09.091+0000] {processor.py:157} INFO - Started process (PID=42513) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:59:09.093+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:59:09.094+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:59:09.094+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:59:09.103+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:59:09.117+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:59:09.116+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:59:09.128+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:59:09.127+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:59:09.136+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-08-01T13:59:39.565+0000] {processor.py:157} INFO - Started process (PID=42538) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:59:39.566+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T13:59:39.568+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:59:39.568+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:59:39.584+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T13:59:39.596+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:59:39.596+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T13:59:39.610+0000] {logging_mixin.py:151} INFO - [2024-08-01T13:59:39.610+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T13:59:39.619+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-01T14:00:10.005+0000] {processor.py:157} INFO - Started process (PID=42563) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:00:10.008+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:00:10.010+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:00:10.009+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:00:10.020+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:00:10.035+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:00:10.035+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:00:10.045+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:00:10.045+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:00:10.054+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-01T14:00:40.444+0000] {processor.py:157} INFO - Started process (PID=42588) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:00:40.447+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:00:40.450+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:00:40.449+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:00:40.465+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:00:40.486+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:00:40.486+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:00:40.499+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:00:40.499+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:00:40.510+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-01T14:01:10.950+0000] {processor.py:157} INFO - Started process (PID=42613) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:01:10.952+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:01:10.954+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:01:10.953+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:01:10.969+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:01:10.983+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:01:10.983+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:01:10.994+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:01:10.994+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:01:11.003+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-01T14:01:41.340+0000] {processor.py:157} INFO - Started process (PID=42638) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:01:41.341+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:01:41.344+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:01:41.344+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:01:41.363+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:01:41.383+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:01:41.382+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:01:41.395+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:01:41.395+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:01:41.405+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-01T14:02:11.800+0000] {processor.py:157} INFO - Started process (PID=42663) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:02:11.801+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:02:11.803+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:02:11.803+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:02:11.816+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:02:11.832+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:02:11.832+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:02:11.842+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:02:11.842+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:02:11.852+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-01T14:02:42.235+0000] {processor.py:157} INFO - Started process (PID=42688) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:02:42.236+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:02:42.239+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:02:42.238+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:02:42.254+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:02:42.275+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:02:42.275+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:02:42.288+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:02:42.288+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:02:42.298+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-01T14:03:12.717+0000] {processor.py:157} INFO - Started process (PID=42713) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:03:12.721+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:03:12.724+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:03:12.723+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:03:12.738+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:03:12.754+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:03:12.753+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:03:12.769+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:03:12.769+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:03:12.778+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-01T14:03:43.162+0000] {processor.py:157} INFO - Started process (PID=42738) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:03:43.163+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:03:43.165+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:03:43.165+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:03:43.176+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:03:43.192+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:03:43.192+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:03:43.202+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:03:43.202+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:03:43.211+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-01T14:04:13.619+0000] {processor.py:157} INFO - Started process (PID=42763) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:04:13.620+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:04:13.622+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:04:13.622+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:04:13.636+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:04:13.658+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:04:13.658+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:04:13.672+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:04:13.672+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:04:13.684+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-01T14:04:44.096+0000] {processor.py:157} INFO - Started process (PID=42788) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:04:44.097+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:04:44.099+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:04:44.099+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:04:44.111+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:04:44.126+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:04:44.126+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:04:44.136+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:04:44.136+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:04:44.146+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-01T14:05:14.524+0000] {processor.py:157} INFO - Started process (PID=42813) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:05:14.528+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:05:14.531+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:05:14.530+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:05:14.547+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:05:14.561+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:05:14.561+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:05:14.573+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:05:14.573+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:05:14.582+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-01T14:05:45.000+0000] {processor.py:157} INFO - Started process (PID=42838) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:05:45.003+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:05:45.006+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:05:45.006+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:05:45.022+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:05:45.044+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:05:45.043+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:05:45.059+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:05:45.059+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:05:45.069+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-01T14:06:15.468+0000] {processor.py:157} INFO - Started process (PID=42863) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:06:15.470+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:06:15.473+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:06:15.473+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:06:15.489+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:06:15.509+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:06:15.509+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:06:15.522+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:06:15.522+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:06:15.532+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-01T14:06:45.902+0000] {processor.py:157} INFO - Started process (PID=42888) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:06:45.903+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:06:45.905+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:06:45.905+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:06:45.916+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:06:45.933+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:06:45.933+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:06:45.944+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:06:45.944+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:06:45.953+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-01T14:07:16.311+0000] {processor.py:157} INFO - Started process (PID=42913) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:07:16.312+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:07:16.314+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:07:16.313+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:07:16.326+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:07:16.340+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:07:16.340+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:07:16.353+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:07:16.353+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:07:16.361+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-01T14:07:46.744+0000] {processor.py:157} INFO - Started process (PID=42938) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:07:46.747+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:07:46.749+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:07:46.749+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:07:46.765+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:07:46.779+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:07:46.779+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:07:46.791+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:07:46.791+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:07:46.801+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-01T14:08:17.248+0000] {processor.py:157} INFO - Started process (PID=42963) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:08:17.250+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:08:17.252+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:08:17.252+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:08:17.291+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:08:17.316+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:08:17.316+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:08:17.331+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:08:17.331+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:08:17.347+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-08-01T14:08:47.747+0000] {processor.py:157} INFO - Started process (PID=42988) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:08:47.751+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:08:47.753+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:08:47.753+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:08:47.769+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:08:47.782+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:08:47.782+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:08:47.794+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:08:47.794+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:08:47.804+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-01T14:09:18.202+0000] {processor.py:157} INFO - Started process (PID=43013) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:09:18.205+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:09:18.208+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:09:18.207+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:09:18.223+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:09:18.244+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:09:18.244+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:09:18.257+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:09:18.257+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:09:18.267+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-01T14:09:48.634+0000] {processor.py:157} INFO - Started process (PID=43038) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:09:48.634+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:09:48.636+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:09:48.636+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:09:48.644+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:09:48.658+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:09:48.658+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:09:48.670+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:09:48.670+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:09:48.679+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-08-01T14:10:19.073+0000] {processor.py:157} INFO - Started process (PID=43063) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:10:19.075+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:10:19.077+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:10:19.077+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:10:19.091+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:10:19.105+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:10:19.105+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:10:19.119+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:10:19.119+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:10:19.127+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-01T14:10:49.575+0000] {processor.py:157} INFO - Started process (PID=43088) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:10:49.577+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:10:49.580+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:10:49.580+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:10:49.593+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:10:49.608+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:10:49.608+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:10:49.618+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:10:49.617+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:10:49.626+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-01T14:11:20.073+0000] {processor.py:157} INFO - Started process (PID=43113) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:11:20.077+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:11:20.079+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:11:20.078+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:11:20.092+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:11:20.108+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:11:20.108+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:11:20.118+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:11:20.118+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:11:20.127+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-01T14:11:50.521+0000] {processor.py:157} INFO - Started process (PID=43138) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:11:50.522+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:11:50.524+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:11:50.524+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:11:50.538+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:11:50.561+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:11:50.561+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:11:50.588+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:11:50.588+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:11:50.598+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-08-01T14:12:20.981+0000] {processor.py:157} INFO - Started process (PID=43163) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:12:20.984+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:12:20.986+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:12:20.986+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:12:21.000+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:12:21.014+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:12:21.014+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:12:21.025+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:12:21.025+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:12:21.036+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-01T14:12:51.482+0000] {processor.py:157} INFO - Started process (PID=43188) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:12:51.483+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:12:51.486+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:12:51.486+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:12:51.501+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:12:51.518+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:12:51.518+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:12:51.529+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:12:51.529+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:12:51.539+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-01T14:13:21.916+0000] {processor.py:157} INFO - Started process (PID=43212) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:13:21.917+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:13:21.918+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:13:21.918+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:13:21.931+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:13:21.951+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:13:21.951+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:13:21.963+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:13:21.963+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:13:21.972+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-01T14:13:52.387+0000] {processor.py:157} INFO - Started process (PID=43238) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:13:52.388+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:13:52.393+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:13:52.392+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:13:52.406+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:13:52.423+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:13:52.423+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:13:52.434+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:13:52.433+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:13:52.444+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-01T14:14:22.846+0000] {processor.py:157} INFO - Started process (PID=43263) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:14:22.849+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:14:22.851+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:14:22.851+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:14:22.864+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:14:22.885+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:14:22.885+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:14:22.897+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:14:22.897+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:14:22.907+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-01T14:14:53.320+0000] {processor.py:157} INFO - Started process (PID=43288) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:14:53.321+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:14:53.322+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:14:53.322+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:14:53.336+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:14:53.351+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:14:53.350+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:14:53.363+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:14:53.363+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:14:53.373+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-01T14:15:23.830+0000] {processor.py:157} INFO - Started process (PID=43313) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:15:23.831+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:15:23.835+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:15:23.834+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:15:23.848+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:15:23.865+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:15:23.865+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:15:23.876+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:15:23.876+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:15:23.885+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-01T14:15:54.270+0000] {processor.py:157} INFO - Started process (PID=43338) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:15:54.272+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:15:54.274+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:15:54.274+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:15:54.288+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:15:54.310+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:15:54.310+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:15:54.323+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:15:54.323+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:15:54.333+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-01T14:16:24.789+0000] {processor.py:157} INFO - Started process (PID=43363) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:16:24.791+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:16:24.794+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:16:24.794+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:16:24.810+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:16:24.826+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:16:24.826+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:16:24.839+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:16:24.839+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:16:24.849+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-01T14:16:55.201+0000] {processor.py:157} INFO - Started process (PID=43388) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:16:55.202+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:16:55.205+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:16:55.205+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:16:55.215+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:16:55.232+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:16:55.232+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:16:55.245+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:16:55.245+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:16:55.252+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-01T14:17:25.696+0000] {processor.py:157} INFO - Started process (PID=43412) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:17:25.698+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:17:25.699+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:17:25.699+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:17:25.711+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:17:25.734+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:17:25.734+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:17:25.746+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:17:25.746+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:17:25.756+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-01T14:17:56.139+0000] {processor.py:157} INFO - Started process (PID=43437) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:17:56.140+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:17:56.145+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:17:56.145+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:17:56.166+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:17:56.185+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:17:56.185+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:17:56.196+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:17:56.196+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:17:56.206+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-01T14:18:26.609+0000] {processor.py:157} INFO - Started process (PID=43463) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:18:26.609+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:18:26.611+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:18:26.611+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:18:26.626+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:18:26.646+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:18:26.646+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:18:26.659+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:18:26.659+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:18:26.670+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-01T14:18:57.112+0000] {processor.py:157} INFO - Started process (PID=43488) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:18:57.116+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:18:57.118+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:18:57.118+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:18:57.135+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:18:57.155+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:18:57.155+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:18:57.169+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:18:57.169+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:18:57.178+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-01T14:19:27.585+0000] {processor.py:157} INFO - Started process (PID=43513) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:19:27.586+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:19:27.589+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:19:27.588+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:19:27.606+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:19:27.620+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:19:27.620+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:19:27.631+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:19:27.631+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:19:27.642+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-01T14:19:58.049+0000] {processor.py:157} INFO - Started process (PID=43537) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:19:58.051+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:19:58.054+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:19:58.054+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:19:58.096+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:19:58.125+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:19:58.124+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:19:58.139+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:19:58.139+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:19:58.151+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-08-01T14:20:28.663+0000] {processor.py:157} INFO - Started process (PID=43563) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:20:28.666+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:20:28.670+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:20:28.670+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:20:28.693+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:20:28.708+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:20:28.708+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:20:28.720+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:20:28.720+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:20:28.731+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-01T14:20:59.103+0000] {processor.py:157} INFO - Started process (PID=43588) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:20:59.104+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:20:59.106+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:20:59.105+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:20:59.122+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:20:59.141+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:20:59.140+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:20:59.152+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:20:59.152+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:20:59.163+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-01T14:21:29.615+0000] {processor.py:157} INFO - Started process (PID=43613) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:21:29.617+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:21:29.620+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:21:29.619+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:21:29.637+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:21:29.655+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:21:29.655+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:21:29.666+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:21:29.666+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:21:29.674+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-01T14:22:00.053+0000] {processor.py:157} INFO - Started process (PID=43638) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:22:00.056+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:22:00.058+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:22:00.057+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:22:00.090+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:22:00.111+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:22:00.111+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:22:00.125+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:22:00.125+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:22:00.147+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-08-01T14:22:30.548+0000] {processor.py:157} INFO - Started process (PID=43663) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:22:30.549+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:22:30.551+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:22:30.551+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:22:30.566+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:22:30.581+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:22:30.581+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:22:30.593+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:22:30.593+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:22:30.603+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-01T14:23:00.999+0000] {processor.py:157} INFO - Started process (PID=43688) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:23:01.002+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:23:01.007+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:23:01.007+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:23:01.025+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:23:01.048+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:23:01.047+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:23:01.060+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:23:01.060+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:23:01.071+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-08-01T14:23:31.448+0000] {processor.py:157} INFO - Started process (PID=43713) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:23:31.450+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:23:31.451+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:23:31.451+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:23:31.463+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:23:31.477+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:23:31.477+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:23:31.487+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:23:31.487+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:23:31.498+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-01T14:24:01.936+0000] {processor.py:157} INFO - Started process (PID=43737) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:24:01.939+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:24:01.943+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:24:01.943+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:24:01.970+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:24:01.996+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:24:01.996+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:24:02.011+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:24:02.010+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:24:02.021+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-08-01T14:24:32.432+0000] {processor.py:157} INFO - Started process (PID=43763) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:24:32.434+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:24:32.437+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:24:32.436+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:24:32.448+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:24:32.464+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:24:32.464+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:24:32.476+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:24:32.476+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:24:32.487+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-01T14:25:02.892+0000] {processor.py:157} INFO - Started process (PID=43787) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:25:02.896+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:25:02.899+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:25:02.899+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:25:02.937+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:25:02.963+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:25:02.963+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:25:02.977+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:25:02.976+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:25:02.986+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-08-01T14:25:33.452+0000] {processor.py:157} INFO - Started process (PID=43813) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:25:33.452+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:25:33.456+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:25:33.455+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:25:33.477+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:25:33.496+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:25:33.496+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:25:33.509+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:25:33.509+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:25:33.521+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-01T14:26:03.912+0000] {processor.py:157} INFO - Started process (PID=43838) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:26:03.914+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:26:03.915+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:26:03.915+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:26:03.924+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:26:03.942+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:26:03.941+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:26:03.952+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:26:03.952+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:26:03.960+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-01T14:26:34.351+0000] {processor.py:157} INFO - Started process (PID=43863) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:26:34.352+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:26:34.355+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:26:34.355+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:26:34.369+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:26:34.389+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:26:34.389+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:26:34.402+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:26:34.402+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:26:34.414+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-01T14:27:04.808+0000] {processor.py:157} INFO - Started process (PID=43888) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:27:04.809+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:27:04.810+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:27:04.810+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:27:04.822+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:27:04.837+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:27:04.837+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:27:04.849+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:27:04.849+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:27:04.857+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-01T14:27:35.339+0000] {processor.py:157} INFO - Started process (PID=43913) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:27:35.342+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:27:35.345+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:27:35.345+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:27:35.361+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:27:35.391+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:27:35.391+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:27:35.404+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:27:35.404+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:27:35.416+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-08-01T14:28:05.808+0000] {processor.py:157} INFO - Started process (PID=43938) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:28:05.810+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:28:05.812+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:28:05.812+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:28:05.823+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:28:05.841+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:28:05.841+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:28:05.854+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:28:05.854+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:28:05.864+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-01T14:28:36.315+0000] {processor.py:157} INFO - Started process (PID=43963) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:28:36.316+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:28:36.320+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:28:36.320+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:28:36.336+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:28:36.357+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:28:36.357+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:28:36.369+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:28:36.369+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:28:36.379+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-01T14:29:06.901+0000] {processor.py:157} INFO - Started process (PID=43988) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:29:06.904+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:29:06.908+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:29:06.907+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:29:06.928+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:29:06.947+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:29:06.947+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:29:06.960+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:29:06.960+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:29:06.971+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-08-01T14:29:37.508+0000] {processor.py:157} INFO - Started process (PID=44013) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:29:37.510+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:29:37.514+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:29:37.513+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:29:37.533+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:29:37.561+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:29:37.561+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:29:37.575+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:29:37.575+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:29:37.583+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-08-01T14:30:08.009+0000] {processor.py:157} INFO - Started process (PID=44038) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:30:08.011+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:30:08.013+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:30:08.012+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:30:08.022+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:30:08.040+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:30:08.039+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:30:08.051+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:30:08.051+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:30:08.059+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-01T14:30:38.447+0000] {processor.py:157} INFO - Started process (PID=44063) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:30:38.449+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:30:38.451+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:30:38.451+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:30:38.462+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:30:38.479+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:30:38.479+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:30:38.490+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:30:38.490+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:30:38.498+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-01T14:31:08.842+0000] {processor.py:157} INFO - Started process (PID=44088) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:31:08.845+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:31:08.848+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:31:08.848+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:31:08.892+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:31:08.919+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:31:08.919+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:31:08.934+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:31:08.934+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:31:08.945+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-08-01T14:31:39.361+0000] {processor.py:157} INFO - Started process (PID=44113) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:31:39.362+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:31:39.364+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:31:39.364+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:31:39.377+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:31:39.389+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:31:39.389+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:31:39.402+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:31:39.402+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:31:39.412+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-01T14:32:09.797+0000] {processor.py:157} INFO - Started process (PID=44138) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:32:09.798+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:32:09.801+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:32:09.801+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:32:09.813+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:32:09.830+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:32:09.830+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:32:09.839+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:32:09.839+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:32:09.850+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-01T14:32:40.251+0000] {processor.py:157} INFO - Started process (PID=44163) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:32:40.254+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:32:40.256+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:32:40.256+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:32:40.274+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:32:40.294+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:32:40.294+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:32:40.308+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:32:40.308+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:32:40.319+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-01T14:33:10.682+0000] {processor.py:157} INFO - Started process (PID=44188) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:33:10.682+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:33:10.684+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:33:10.684+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:33:10.697+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:33:10.712+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:33:10.712+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:33:10.723+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:33:10.723+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:33:10.732+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-01T14:33:41.129+0000] {processor.py:157} INFO - Started process (PID=44213) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:33:41.129+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:33:41.131+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:33:41.131+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:33:41.142+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:33:41.159+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:33:41.159+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:33:41.169+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:33:41.169+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:33:41.177+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-01T14:34:11.558+0000] {processor.py:157} INFO - Started process (PID=44238) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:34:11.561+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:34:11.564+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:34:11.564+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:34:11.582+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:34:11.608+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:34:11.608+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:34:11.623+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:34:11.623+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:34:11.634+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-08-01T14:34:42.025+0000] {processor.py:157} INFO - Started process (PID=44263) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:34:42.026+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:34:42.028+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:34:42.028+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:34:42.041+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:34:42.061+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:34:42.061+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:34:42.075+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:34:42.075+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:34:42.084+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-01T14:35:12.480+0000] {processor.py:157} INFO - Started process (PID=44288) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:35:12.481+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:35:12.487+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:35:12.487+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:35:12.525+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:35:12.549+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:35:12.549+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:35:12.562+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:35:12.562+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:35:12.578+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-08-01T14:35:42.936+0000] {processor.py:157} INFO - Started process (PID=44313) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:35:42.938+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:35:42.939+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:35:42.939+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:35:42.952+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:35:42.969+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:35:42.969+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:35:42.979+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:35:42.979+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:35:42.988+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-01T14:36:13.397+0000] {processor.py:157} INFO - Started process (PID=44338) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:36:13.405+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:36:13.419+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:36:13.418+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:36:13.434+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:36:13.459+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:36:13.459+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:36:13.471+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:36:13.471+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:36:13.484+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-08-01T14:36:43.919+0000] {processor.py:157} INFO - Started process (PID=44363) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:36:43.919+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:36:43.920+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:36:43.920+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:36:43.928+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:36:43.940+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:36:43.940+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:36:43.949+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:36:43.949+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:36:43.959+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.042 seconds
[2024-08-01T14:37:14.383+0000] {processor.py:157} INFO - Started process (PID=44388) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:37:14.385+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:37:14.396+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:37:14.396+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:37:14.435+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:37:14.460+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:37:14.460+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:37:14.473+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:37:14.473+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:37:14.483+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-08-01T14:37:44.968+0000] {processor.py:157} INFO - Started process (PID=44413) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:37:44.969+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:37:44.972+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:37:44.972+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:37:44.989+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:37:45.015+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:37:45.015+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:37:45.034+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:37:45.034+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:37:45.045+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-08-01T14:38:15.473+0000] {processor.py:157} INFO - Started process (PID=44438) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:38:15.475+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:38:15.477+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:38:15.476+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:38:15.491+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:38:15.509+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:38:15.509+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:38:15.519+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:38:15.519+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:38:15.527+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-01T14:38:45.920+0000] {processor.py:157} INFO - Started process (PID=44463) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:38:45.921+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:38:45.924+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:38:45.924+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:38:45.935+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:38:45.952+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:38:45.952+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:38:45.965+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:38:45.965+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:38:45.972+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-01T14:39:16.414+0000] {processor.py:157} INFO - Started process (PID=44487) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:39:16.429+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:39:16.438+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:39:16.438+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:39:16.455+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:39:16.480+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:39:16.480+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:39:16.493+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:39:16.493+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:39:16.503+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-08-01T14:39:46.952+0000] {processor.py:157} INFO - Started process (PID=44513) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:39:46.954+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:39:46.956+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:39:46.956+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:39:46.968+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:39:46.987+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:39:46.987+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:39:46.997+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:39:46.997+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:39:47.005+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-01T14:40:17.319+0000] {processor.py:157} INFO - Started process (PID=44538) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:40:17.323+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:40:17.325+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:40:17.325+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:40:17.342+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:40:17.364+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:40:17.364+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:40:17.376+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:40:17.376+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:40:17.387+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-01T14:40:47.824+0000] {processor.py:157} INFO - Started process (PID=44563) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:40:47.826+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:40:47.829+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:40:47.829+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:40:47.843+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:40:47.859+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:40:47.859+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:40:47.870+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:40:47.870+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:40:47.878+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-01T14:41:18.221+0000] {processor.py:157} INFO - Started process (PID=44588) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:41:18.223+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:41:18.237+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:41:18.233+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:41:18.270+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:41:18.296+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:41:18.296+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:41:18.310+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:41:18.310+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:41:18.320+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-08-01T14:41:48.743+0000] {processor.py:157} INFO - Started process (PID=44613) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:41:48.745+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:41:48.748+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:41:48.748+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:41:48.766+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:41:48.781+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:41:48.781+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:41:48.794+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:41:48.793+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:41:48.803+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-01T14:42:19.198+0000] {processor.py:157} INFO - Started process (PID=44638) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:42:19.202+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:42:19.205+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:42:19.205+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:42:19.220+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:42:19.242+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:42:19.242+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:42:19.254+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:42:19.253+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:42:19.263+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-01T14:42:49.637+0000] {processor.py:157} INFO - Started process (PID=44663) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:42:49.638+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:42:49.640+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:42:49.640+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:42:49.650+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:42:49.665+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:42:49.665+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:42:49.674+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:42:49.674+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:42:49.686+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-01T14:43:20.139+0000] {processor.py:157} INFO - Started process (PID=44688) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:43:20.146+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:43:20.150+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:43:20.150+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:43:20.158+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:43:20.174+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:43:20.174+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:43:20.186+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:43:20.186+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:43:20.196+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-01T14:43:50.640+0000] {processor.py:157} INFO - Started process (PID=44713) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:43:50.641+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:43:50.643+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:43:50.643+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:43:50.659+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:43:50.699+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:43:50.699+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:43:50.718+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:43:50.718+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:43:50.727+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-08-01T14:44:21.172+0000] {processor.py:157} INFO - Started process (PID=44738) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:44:21.175+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:44:21.178+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:44:21.177+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:44:21.191+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:44:21.209+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:44:21.209+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:44:21.222+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:44:21.221+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:44:21.232+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-01T14:44:51.605+0000] {processor.py:157} INFO - Started process (PID=44763) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:44:51.606+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:44:51.608+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:44:51.608+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:44:51.625+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:44:51.652+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:44:51.652+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:44:51.685+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:44:51.685+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:44:51.697+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-08-01T14:45:22.114+0000] {processor.py:157} INFO - Started process (PID=44788) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:45:22.116+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:45:22.119+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:45:22.119+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:45:22.144+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:45:22.164+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:45:22.164+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:45:22.174+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:45:22.174+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:45:22.182+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-01T14:45:52.626+0000] {processor.py:157} INFO - Started process (PID=44813) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:45:52.627+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:45:52.630+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:45:52.630+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:45:52.663+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:45:52.697+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:45:52.697+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:45:52.710+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:45:52.710+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:45:52.722+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-08-01T14:46:23.130+0000] {processor.py:157} INFO - Started process (PID=44838) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:46:23.132+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:46:23.136+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:46:23.135+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:46:23.162+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:46:23.180+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:46:23.180+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:46:23.192+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:46:23.192+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:46:23.202+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-08-01T14:46:53.556+0000] {processor.py:157} INFO - Started process (PID=44863) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:46:53.558+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:46:53.560+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:46:53.560+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:46:53.574+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:46:53.615+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:46:53.615+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:46:53.629+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:46:53.629+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:46:53.639+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-08-01T14:47:24.071+0000] {processor.py:157} INFO - Started process (PID=44888) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:47:24.073+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:47:24.076+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:47:24.076+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:47:24.090+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:47:24.107+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:47:24.107+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:47:24.117+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:47:24.117+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:47:24.127+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-01T14:47:54.478+0000] {processor.py:157} INFO - Started process (PID=44913) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:47:54.478+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:47:54.480+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:47:54.480+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:47:54.492+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:47:54.508+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:47:54.508+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:47:54.518+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:47:54.518+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:47:54.527+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-01T14:48:24.923+0000] {processor.py:157} INFO - Started process (PID=44938) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:48:24.925+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:48:24.928+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:48:24.928+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:48:24.944+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:48:24.973+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:48:24.973+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:48:24.986+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:48:24.986+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:48:24.998+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-08-01T14:48:55.444+0000] {processor.py:157} INFO - Started process (PID=44963) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:48:55.445+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:48:55.447+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:48:55.447+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:48:55.460+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:48:55.477+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:48:55.477+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:48:55.488+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:48:55.488+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:48:55.497+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-01T14:49:25.941+0000] {processor.py:157} INFO - Started process (PID=44988) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:49:25.944+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:49:25.947+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:49:25.947+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:49:25.963+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:49:25.984+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:49:25.984+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:49:25.998+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:49:25.997+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:49:26.007+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-01T14:49:56.340+0000] {processor.py:157} INFO - Started process (PID=45013) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:49:56.342+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:49:56.343+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:49:56.343+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:49:56.354+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:49:56.371+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:49:56.370+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:49:56.381+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:49:56.381+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:49:56.390+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-01T14:50:26.821+0000] {processor.py:157} INFO - Started process (PID=45038) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:50:26.824+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:50:26.827+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:50:26.827+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:50:26.845+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:50:26.879+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:50:26.878+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:50:26.904+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:50:26.904+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:50:26.915+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-08-01T14:50:57.400+0000] {processor.py:157} INFO - Started process (PID=45063) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:50:57.401+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:50:57.403+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:50:57.403+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:50:57.414+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:50:57.432+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:50:57.431+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:50:57.441+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:50:57.441+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:50:57.450+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-01T14:51:27.844+0000] {processor.py:157} INFO - Started process (PID=45088) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:51:27.845+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:51:27.849+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:51:27.849+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:51:27.865+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:51:27.889+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:51:27.889+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:51:27.902+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:51:27.902+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:51:27.913+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-01T14:51:58.309+0000] {processor.py:157} INFO - Started process (PID=45113) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:51:58.310+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:51:58.312+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:51:58.312+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:51:58.321+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:51:58.337+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:51:58.337+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:51:58.347+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:51:58.347+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:51:58.356+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-01T14:52:28.767+0000] {processor.py:157} INFO - Started process (PID=45138) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:52:28.768+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:52:28.771+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:52:28.771+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:52:28.789+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:52:28.810+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:52:28.810+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:52:28.825+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:52:28.824+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:52:28.834+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-01T14:52:59.245+0000] {processor.py:157} INFO - Started process (PID=45163) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:52:59.247+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:52:59.249+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:52:59.249+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:52:59.264+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:52:59.309+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:52:59.309+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:52:59.321+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:52:59.321+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:52:59.330+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-01T14:53:29.733+0000] {processor.py:157} INFO - Started process (PID=45187) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:53:29.735+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:53:29.744+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:53:29.743+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:53:29.763+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:53:29.784+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:53:29.784+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:53:29.797+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:53:29.797+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:53:29.808+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-08-01T14:54:00.255+0000] {processor.py:157} INFO - Started process (PID=45213) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:54:00.257+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:54:00.260+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:54:00.259+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:54:00.270+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:54:00.285+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:54:00.285+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:54:00.296+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:54:00.295+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:54:00.305+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-01T14:54:30.713+0000] {processor.py:157} INFO - Started process (PID=45238) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:54:30.717+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:54:30.721+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:54:30.721+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:54:30.740+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:54:30.753+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:54:30.753+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:54:30.766+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:54:30.766+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:54:30.776+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-01T14:55:01.211+0000] {processor.py:157} INFO - Started process (PID=45263) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:55:01.213+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:55:01.216+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:55:01.215+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:55:01.234+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:55:01.275+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:55:01.275+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:55:01.293+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:55:01.293+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:55:01.304+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-08-01T14:55:31.751+0000] {processor.py:157} INFO - Started process (PID=45288) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:55:31.753+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:55:31.756+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:55:31.755+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:55:31.768+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:55:31.786+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:55:31.786+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:55:31.800+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:55:31.800+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:55:31.811+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-01T14:56:02.227+0000] {processor.py:157} INFO - Started process (PID=45313) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:56:02.231+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:56:02.233+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:56:02.233+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:56:02.264+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:56:02.297+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:56:02.297+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:56:02.308+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:56:02.308+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:56:02.318+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-08-01T14:56:32.759+0000] {processor.py:157} INFO - Started process (PID=45338) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:56:32.762+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:56:32.766+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:56:32.766+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:56:32.778+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:56:32.793+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:56:32.793+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:56:32.806+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:56:32.806+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:56:32.815+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-01T14:57:03.176+0000] {processor.py:157} INFO - Started process (PID=45363) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:57:03.177+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:57:03.180+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:57:03.180+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:57:03.191+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:57:03.207+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:57:03.207+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:57:03.219+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:57:03.219+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:57:03.231+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-01T14:57:33.674+0000] {processor.py:157} INFO - Started process (PID=45388) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:57:33.675+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:57:33.678+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:57:33.678+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:57:33.695+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:57:33.708+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:57:33.708+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:57:33.718+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:57:33.717+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:57:33.725+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-01T14:58:04.140+0000] {processor.py:157} INFO - Started process (PID=45413) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:58:04.142+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:58:04.145+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:58:04.145+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:58:04.165+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:58:04.183+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:58:04.183+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:58:04.195+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:58:04.195+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:58:04.202+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-01T14:58:34.615+0000] {processor.py:157} INFO - Started process (PID=45438) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:58:34.615+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:58:34.617+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:58:34.617+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:58:34.632+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:58:34.646+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:58:34.646+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:58:34.657+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:58:34.656+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:58:34.664+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-01T14:59:05.041+0000] {processor.py:157} INFO - Started process (PID=45463) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:59:05.043+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:59:05.044+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:59:05.044+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:59:05.055+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:59:05.070+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:59:05.070+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:59:05.080+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:59:05.080+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:59:05.089+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-01T14:59:35.458+0000] {processor.py:157} INFO - Started process (PID=45488) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:59:35.460+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T14:59:35.462+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:59:35.462+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:59:35.474+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T14:59:35.489+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:59:35.489+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T14:59:35.500+0000] {logging_mixin.py:151} INFO - [2024-08-01T14:59:35.500+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T14:59:35.507+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-01T15:00:05.917+0000] {processor.py:157} INFO - Started process (PID=45513) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:00:05.920+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:00:05.924+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:00:05.924+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:00:05.955+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:00:05.981+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:00:05.981+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:00:05.996+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:00:05.996+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:00:06.010+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-08-01T15:00:36.444+0000] {processor.py:157} INFO - Started process (PID=45538) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:00:36.446+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:00:36.448+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:00:36.448+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:00:36.461+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:00:36.477+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:00:36.477+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:00:36.486+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:00:36.486+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:00:36.495+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-01T15:01:06.914+0000] {processor.py:157} INFO - Started process (PID=45563) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:01:06.916+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:01:06.919+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:01:06.919+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:01:06.936+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:01:06.957+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:01:06.957+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:01:06.971+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:01:06.971+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:01:06.979+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-01T15:01:37.282+0000] {processor.py:157} INFO - Started process (PID=45588) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:01:37.283+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:01:37.286+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:01:37.285+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:01:37.296+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:01:37.311+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:01:37.311+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:01:37.320+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:01:37.320+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:01:37.330+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-01T15:02:07.756+0000] {processor.py:157} INFO - Started process (PID=45611) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:02:07.758+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:02:07.761+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:02:07.761+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:02:07.783+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:02:07.801+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:02:07.801+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:02:07.814+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:02:07.814+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:02:07.823+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-01T15:02:38.226+0000] {processor.py:157} INFO - Started process (PID=45638) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:02:38.229+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:02:38.231+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:02:38.231+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:02:38.241+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:02:38.257+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:02:38.257+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:02:38.268+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:02:38.267+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:02:38.276+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-01T15:03:08.708+0000] {processor.py:157} INFO - Started process (PID=45663) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:03:08.710+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:03:08.712+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:03:08.712+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:03:08.724+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:03:08.741+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:03:08.741+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:03:08.753+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:03:08.753+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:03:08.761+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-01T15:03:39.172+0000] {processor.py:157} INFO - Started process (PID=45688) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:03:39.173+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:03:39.174+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:03:39.174+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:03:39.182+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:03:39.196+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:03:39.196+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:03:39.205+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:03:39.205+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:03:39.214+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.044 seconds
[2024-08-01T15:04:09.656+0000] {processor.py:157} INFO - Started process (PID=45712) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:04:09.657+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:04:09.660+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:04:09.660+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:04:09.677+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:04:09.703+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:04:09.702+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:04:09.717+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:04:09.717+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:04:09.727+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-08-01T15:04:40.179+0000] {processor.py:157} INFO - Started process (PID=45738) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:04:40.180+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:04:40.182+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:04:40.182+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:04:40.197+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:04:40.211+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:04:40.211+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:04:40.220+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:04:40.220+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:04:40.229+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-01T15:05:10.668+0000] {processor.py:157} INFO - Started process (PID=45763) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:05:10.672+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:05:10.676+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:05:10.676+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:05:10.692+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:05:10.714+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:05:10.714+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:05:10.728+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:05:10.728+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:05:10.737+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-01T15:05:41.202+0000] {processor.py:157} INFO - Started process (PID=45788) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:05:41.203+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:05:41.205+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:05:41.204+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:05:41.220+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:05:41.234+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:05:41.234+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:05:41.245+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:05:41.245+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:05:41.253+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-01T15:06:11.591+0000] {processor.py:157} INFO - Started process (PID=45813) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:06:11.592+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:06:11.593+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:06:11.593+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:06:11.604+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:06:11.620+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:06:11.620+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:06:11.629+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:06:11.629+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:06:11.638+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-01T15:06:42.006+0000] {processor.py:157} INFO - Started process (PID=45838) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:06:42.009+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:06:42.012+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:06:42.011+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:06:42.029+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:06:42.050+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:06:42.050+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:06:42.063+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:06:42.063+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:06:42.073+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-01T15:07:12.475+0000] {processor.py:157} INFO - Started process (PID=45863) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:07:12.475+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:07:12.477+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:07:12.476+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:07:12.484+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:07:12.498+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:07:12.498+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:07:12.509+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:07:12.509+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:07:12.518+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-08-01T15:07:42.929+0000] {processor.py:157} INFO - Started process (PID=45888) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:07:42.932+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:07:42.935+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:07:42.935+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:07:42.951+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:07:42.979+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:07:42.979+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:07:43.006+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:07:43.006+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:07:43.022+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-08-01T15:08:13.440+0000] {processor.py:157} INFO - Started process (PID=45913) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:08:13.440+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:08:13.442+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:08:13.442+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:08:13.453+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:08:13.469+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:08:13.469+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:08:13.480+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:08:13.480+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:08:13.490+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-01T15:08:43.875+0000] {processor.py:157} INFO - Started process (PID=45938) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:08:43.878+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:08:43.881+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:08:43.881+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:08:43.902+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:08:43.932+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:08:43.932+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:08:43.945+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:08:43.945+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:08:43.956+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-08-01T15:09:14.374+0000] {processor.py:157} INFO - Started process (PID=45963) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:09:14.377+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:09:14.379+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:09:14.379+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:09:14.389+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:09:14.405+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:09:14.405+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:09:14.417+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:09:14.417+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:09:14.427+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-01T15:09:44.815+0000] {processor.py:157} INFO - Started process (PID=45988) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:09:44.816+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:09:44.819+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:09:44.818+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:09:44.831+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:09:44.847+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:09:44.847+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:09:44.858+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:09:44.857+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:09:44.867+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-01T15:10:15.281+0000] {processor.py:157} INFO - Started process (PID=46013) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:10:15.284+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:10:15.287+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:10:15.286+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:10:15.303+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:10:15.323+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:10:15.323+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:10:15.334+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:10:15.334+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:10:15.343+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-01T15:10:45.699+0000] {processor.py:157} INFO - Started process (PID=46038) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:10:45.700+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:10:45.702+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:10:45.702+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:10:45.714+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:10:45.729+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:10:45.729+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:10:45.741+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:10:45.741+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:10:45.750+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-01T15:11:16.109+0000] {processor.py:157} INFO - Started process (PID=46063) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:11:16.110+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:11:16.112+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:11:16.112+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:11:16.126+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:11:16.139+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:11:16.139+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:11:16.151+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:11:16.151+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:11:16.162+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-01T15:11:46.506+0000] {processor.py:157} INFO - Started process (PID=46088) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:11:46.508+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:11:46.511+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:11:46.510+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:11:46.528+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:11:46.541+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:11:46.541+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:11:46.550+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:11:46.550+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:11:46.559+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-01T15:12:16.971+0000] {processor.py:157} INFO - Started process (PID=46113) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:12:16.973+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:12:16.976+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:12:16.976+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:12:16.993+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:12:17.015+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:12:17.015+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:12:17.027+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:12:17.027+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:12:17.038+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-01T15:12:47.446+0000] {processor.py:157} INFO - Started process (PID=46138) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:12:47.448+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:12:47.450+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:12:47.450+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:12:47.459+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:12:47.475+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:12:47.475+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:12:47.485+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:12:47.485+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:12:47.494+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-01T15:13:17.903+0000] {processor.py:157} INFO - Started process (PID=46163) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:13:17.905+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:13:17.907+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:13:17.906+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:13:17.919+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:13:17.932+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:13:17.932+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:13:17.941+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:13:17.941+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:13:17.950+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-01T15:13:48.358+0000] {processor.py:157} INFO - Started process (PID=46188) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:13:48.360+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:13:48.361+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:13:48.361+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:13:48.380+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:13:48.395+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:13:48.395+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:13:48.406+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:13:48.406+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:13:48.414+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-01T15:14:18.755+0000] {processor.py:157} INFO - Started process (PID=46212) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:14:18.758+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:14:18.760+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:14:18.760+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:14:18.798+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:14:18.822+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:14:18.822+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:14:18.835+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:14:18.835+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:14:18.847+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-08-01T15:14:49.262+0000] {processor.py:157} INFO - Started process (PID=46238) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:14:49.263+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:14:49.265+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:14:49.265+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:14:49.277+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:14:49.292+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:14:49.292+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:14:49.301+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:14:49.301+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:14:49.312+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-01T15:15:19.664+0000] {processor.py:157} INFO - Started process (PID=46263) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:15:19.665+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:15:19.667+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:15:19.667+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:15:19.679+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:15:19.696+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:15:19.696+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:15:19.710+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:15:19.710+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:15:19.719+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-01T15:15:50.195+0000] {processor.py:157} INFO - Started process (PID=46288) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:15:50.198+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:15:50.201+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:15:50.200+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:15:50.217+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:15:50.239+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:15:50.239+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:15:50.252+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:15:50.252+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:15:50.263+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-01T15:16:20.692+0000] {processor.py:157} INFO - Started process (PID=46313) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:16:20.694+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:16:20.696+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:16:20.696+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:16:20.708+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:16:20.724+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:16:20.724+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:16:20.734+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:16:20.734+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:16:20.742+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-01T15:16:51.129+0000] {processor.py:157} INFO - Started process (PID=46338) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:16:51.133+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:16:51.136+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:16:51.136+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:16:51.151+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:16:51.173+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:16:51.173+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:16:51.187+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:16:51.186+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:16:51.195+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-01T15:17:21.562+0000] {processor.py:157} INFO - Started process (PID=46363) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:17:21.565+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:17:21.567+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:17:21.567+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:17:21.577+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:17:21.593+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:17:21.593+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:17:21.606+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:17:21.606+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:17:21.614+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-01T15:17:51.970+0000] {processor.py:157} INFO - Started process (PID=46388) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:17:51.971+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:17:51.973+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:17:51.972+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:17:51.985+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:17:52.000+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:17:52.000+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:17:52.011+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:17:52.011+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:17:52.020+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-01T15:18:22.448+0000] {processor.py:157} INFO - Started process (PID=46413) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:18:22.450+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:18:22.453+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:18:22.453+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:18:22.470+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:18:22.490+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:18:22.490+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:18:22.502+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:18:22.502+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:18:22.512+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-01T15:18:52.906+0000] {processor.py:157} INFO - Started process (PID=46438) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:18:52.907+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:18:52.909+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:18:52.909+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:18:52.921+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:18:52.937+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:18:52.937+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:18:52.947+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:18:52.947+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:18:52.955+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-01T15:19:23.342+0000] {processor.py:157} INFO - Started process (PID=46463) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:19:23.343+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:19:23.345+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:19:23.345+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:19:23.356+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:19:23.373+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:19:23.373+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:19:23.384+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:19:23.384+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:19:23.392+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-01T15:19:53.817+0000] {processor.py:157} INFO - Started process (PID=46488) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:19:53.821+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:19:53.825+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:19:53.825+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:19:53.840+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:19:53.861+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:19:53.861+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:19:53.876+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:19:53.876+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:19:53.886+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-01T15:20:24.314+0000] {processor.py:157} INFO - Started process (PID=46513) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:20:24.316+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:20:24.318+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:20:24.318+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:20:24.335+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:20:24.355+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:20:24.355+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:20:24.366+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:20:24.366+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:20:24.375+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-01T15:20:54.820+0000] {processor.py:157} INFO - Started process (PID=46538) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:20:54.822+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:20:54.824+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:20:54.824+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:20:54.834+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:20:54.850+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:20:54.850+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:20:54.860+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:20:54.860+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:20:54.870+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-01T15:21:25.318+0000] {processor.py:157} INFO - Started process (PID=46563) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:21:25.320+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:21:25.323+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:21:25.323+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:21:25.340+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:21:25.362+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:21:25.362+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:21:25.376+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:21:25.376+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:21:25.385+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-01T15:21:55.860+0000] {processor.py:157} INFO - Started process (PID=46588) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:21:55.862+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:21:55.865+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:21:55.864+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:21:55.884+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:21:55.905+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:21:55.905+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:21:55.922+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:21:55.922+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:21:55.933+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-08-01T15:22:26.356+0000] {processor.py:157} INFO - Started process (PID=46613) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:22:26.358+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:22:26.360+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:22:26.360+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:22:26.373+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:22:26.396+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:22:26.395+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:22:26.408+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:22:26.407+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:22:26.417+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-01T15:22:56.863+0000] {processor.py:157} INFO - Started process (PID=46638) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:22:56.865+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:22:56.868+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:22:56.867+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:22:56.883+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:22:56.900+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:22:56.899+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:22:56.909+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:22:56.909+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:22:56.918+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-01T15:23:27.322+0000] {processor.py:157} INFO - Started process (PID=46663) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:23:27.322+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:23:27.326+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:23:27.326+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:23:27.345+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:23:27.377+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:23:27.376+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:23:27.390+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:23:27.390+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:23:27.400+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-08-01T15:23:57.784+0000] {processor.py:157} INFO - Started process (PID=46688) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:23:57.786+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:23:57.788+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:23:57.788+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:23:57.798+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:23:57.820+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:23:57.820+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:23:57.830+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:23:57.830+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:23:57.840+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-01T15:24:28.272+0000] {processor.py:157} INFO - Started process (PID=46713) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:24:28.274+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:24:28.281+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:24:28.280+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:24:28.298+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:24:28.323+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:24:28.323+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:24:28.337+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:24:28.337+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:24:28.347+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-08-01T15:24:58.745+0000] {processor.py:157} INFO - Started process (PID=46737) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:24:58.748+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:24:58.756+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:24:58.756+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:24:58.774+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:24:58.802+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:24:58.802+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:24:58.827+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:24:58.827+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:24:58.838+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-08-01T15:25:29.206+0000] {processor.py:157} INFO - Started process (PID=46763) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:25:29.206+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:25:29.208+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:25:29.208+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:25:29.220+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:25:29.235+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:25:29.235+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:25:29.245+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:25:29.244+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:25:29.254+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-01T15:25:59.693+0000] {processor.py:157} INFO - Started process (PID=46788) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:25:59.695+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:25:59.698+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:25:59.698+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:25:59.739+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:25:59.768+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:25:59.768+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:25:59.783+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:25:59.783+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:25:59.794+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-08-01T15:26:30.199+0000] {processor.py:157} INFO - Started process (PID=46813) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:26:30.199+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:26:30.202+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:26:30.201+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:26:30.213+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:26:30.232+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:26:30.232+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:26:30.249+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:26:30.249+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:26:30.260+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-01T15:27:00.694+0000] {processor.py:157} INFO - Started process (PID=46838) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:27:00.699+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:27:00.702+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:27:00.702+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:27:00.719+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:27:00.768+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:27:00.768+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:27:00.782+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:27:00.782+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:27:00.794+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-08-01T15:27:31.198+0000] {processor.py:157} INFO - Started process (PID=46863) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:27:31.199+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:27:31.201+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:27:31.201+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:27:31.217+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:27:31.234+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:27:31.234+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:27:31.245+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:27:31.245+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:27:31.255+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-01T15:28:01.622+0000] {processor.py:157} INFO - Started process (PID=46888) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:28:01.624+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:28:01.627+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:28:01.627+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:28:01.644+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:28:01.666+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:28:01.666+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:28:01.679+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:28:01.679+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:28:01.689+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-01T15:28:32.105+0000] {processor.py:157} INFO - Started process (PID=46913) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:28:32.106+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:28:32.108+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:28:32.108+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:28:32.119+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:28:32.135+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:28:32.135+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:28:32.145+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:28:32.145+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:28:32.153+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-01T15:29:02.497+0000] {processor.py:157} INFO - Started process (PID=46938) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:29:02.499+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:29:02.501+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:29:02.501+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:29:02.512+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:29:02.548+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:29:02.548+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:29:02.558+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:29:02.558+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:29:02.570+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-08-01T15:29:32.999+0000] {processor.py:157} INFO - Started process (PID=46963) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:29:33.001+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:29:33.003+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:29:33.002+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:29:33.022+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:29:33.044+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:29:33.044+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:29:33.056+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:29:33.056+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:29:33.067+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-01T15:30:03.464+0000] {processor.py:157} INFO - Started process (PID=46988) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:30:03.465+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:30:03.467+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:30:03.467+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:30:03.483+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:30:03.500+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:30:03.500+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:30:03.510+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:30:03.509+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:30:03.519+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-01T15:30:33.903+0000] {processor.py:157} INFO - Started process (PID=47013) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:30:33.903+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:30:33.905+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:30:33.905+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:30:33.917+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:30:33.931+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:30:33.931+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:30:33.939+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:30:33.939+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:30:33.948+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-08-01T15:31:04.310+0000] {processor.py:157} INFO - Started process (PID=47038) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:31:04.313+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:31:04.315+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:31:04.314+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:31:04.329+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:31:04.351+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:31:04.350+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:31:04.362+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:31:04.362+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:31:04.372+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-01T15:31:34.746+0000] {processor.py:157} INFO - Started process (PID=47063) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:31:34.748+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:31:34.750+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:31:34.750+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:31:34.763+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:31:34.780+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:31:34.780+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:31:34.792+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:31:34.792+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:31:34.800+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-01T15:32:05.196+0000] {processor.py:157} INFO - Started process (PID=47088) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:32:05.197+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:32:05.199+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:32:05.199+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:32:05.211+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:32:05.231+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:32:05.231+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:32:05.244+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:32:05.244+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:32:05.254+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-01T15:32:35.648+0000] {processor.py:157} INFO - Started process (PID=47112) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:32:35.651+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:32:35.660+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:32:35.653+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:32:35.689+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:32:35.715+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:32:35.715+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:32:35.729+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:32:35.729+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:32:35.738+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-08-01T15:33:06.197+0000] {processor.py:157} INFO - Started process (PID=47138) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:33:06.198+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:33:06.200+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:33:06.200+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:33:06.212+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:33:06.231+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:33:06.231+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:33:06.240+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:33:06.240+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:33:06.248+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-01T15:33:36.600+0000] {processor.py:157} INFO - Started process (PID=47163) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:33:36.601+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:33:36.603+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:33:36.603+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:33:36.622+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:33:36.635+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:33:36.635+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:33:36.645+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:33:36.644+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:33:36.653+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-01T15:34:07.445+0000] {processor.py:157} INFO - Started process (PID=47188) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:34:07.448+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:34:07.457+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:34:07.457+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:34:07.493+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:34:07.531+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:34:07.531+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:34:07.552+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:34:07.552+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:34:07.573+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-08-01T15:34:38.105+0000] {processor.py:157} INFO - Started process (PID=47212) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:34:38.107+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:34:38.114+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:34:38.113+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:34:38.145+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:34:38.213+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:34:38.213+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:34:38.247+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:34:38.247+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:34:38.267+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.173 seconds
[2024-08-01T15:35:09.061+0000] {processor.py:157} INFO - Started process (PID=47238) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:35:09.065+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:35:09.069+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:35:09.069+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:35:09.103+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:35:09.154+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:35:09.154+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:35:09.181+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:35:09.181+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:35:09.193+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-08-01T15:35:39.712+0000] {processor.py:157} INFO - Started process (PID=47263) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:35:39.715+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:35:39.718+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:35:39.718+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:35:39.737+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:35:39.761+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:35:39.761+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:35:39.775+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:35:39.775+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:35:39.788+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-08-01T15:36:10.246+0000] {processor.py:157} INFO - Started process (PID=47288) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:36:10.252+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:36:10.254+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:36:10.254+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:36:10.277+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:36:10.308+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:36:10.308+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:36:10.323+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:36:10.323+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:36:10.347+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-08-01T15:36:40.781+0000] {processor.py:157} INFO - Started process (PID=47313) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:36:40.783+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:36:40.792+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:36:40.790+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:36:40.827+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:36:40.854+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:36:40.854+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:36:40.867+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:36:40.867+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:36:40.878+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-08-01T15:37:11.344+0000] {processor.py:157} INFO - Started process (PID=47338) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:37:11.356+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:37:11.361+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:37:11.360+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:37:11.378+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:37:11.416+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:37:11.415+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:37:11.430+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:37:11.430+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:37:11.441+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-08-01T15:37:41.797+0000] {processor.py:157} INFO - Started process (PID=47363) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:37:41.798+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:37:41.800+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:37:41.800+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:37:41.813+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:37:41.831+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:37:41.831+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:37:41.844+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:37:41.843+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:37:41.854+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-01T15:38:12.230+0000] {processor.py:157} INFO - Started process (PID=47388) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:38:12.233+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:38:12.237+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:38:12.236+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:38:12.257+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:38:12.276+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:38:12.276+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:38:12.286+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:38:12.286+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:38:12.294+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-01T15:38:42.693+0000] {processor.py:157} INFO - Started process (PID=47413) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:38:42.694+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:38:42.697+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:38:42.696+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:38:42.709+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:38:42.730+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:38:42.730+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:38:42.751+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:38:42.751+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:38:42.764+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-01T15:39:13.194+0000] {processor.py:157} INFO - Started process (PID=47438) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:39:13.195+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:39:13.198+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:39:13.197+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:39:13.215+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:39:13.236+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:39:13.235+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:39:13.245+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:39:13.245+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:39:13.254+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-01T15:39:43.626+0000] {processor.py:157} INFO - Started process (PID=47463) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:39:43.626+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:39:43.627+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:39:43.627+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:39:43.635+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:39:43.649+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:39:43.649+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:39:43.662+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:39:43.662+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:39:43.672+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-08-01T15:40:13.966+0000] {processor.py:157} INFO - Started process (PID=47488) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:40:13.968+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:40:13.970+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:40:13.970+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:40:13.988+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:40:14.007+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:40:14.007+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:40:14.021+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:40:14.020+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:40:14.031+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-01T15:40:44.381+0000] {processor.py:157} INFO - Started process (PID=47513) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:40:44.384+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:40:44.386+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:40:44.386+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:40:44.402+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:40:44.422+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:40:44.422+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:40:44.435+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:40:44.435+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:40:44.442+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-01T15:41:14.819+0000] {processor.py:157} INFO - Started process (PID=47538) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:41:14.821+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:41:14.823+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:41:14.822+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:41:14.832+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:41:14.849+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:41:14.849+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:41:14.862+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:41:14.862+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:41:14.871+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-01T15:41:45.298+0000] {processor.py:157} INFO - Started process (PID=47563) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:41:45.300+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:41:45.302+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:41:45.302+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:41:45.314+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:41:45.332+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:41:45.332+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:41:45.344+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:41:45.344+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:41:45.353+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-01T15:42:15.742+0000] {processor.py:157} INFO - Started process (PID=47588) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:42:15.744+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:42:15.760+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:42:15.757+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:42:15.791+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:42:15.814+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:42:15.814+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:42:15.826+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:42:15.826+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:42:15.837+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-08-01T15:42:46.227+0000] {processor.py:157} INFO - Started process (PID=47613) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:42:46.228+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:42:46.230+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:42:46.230+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:42:46.242+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:42:46.259+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:42:46.259+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:42:46.268+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:42:46.268+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:42:46.277+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-01T15:43:16.677+0000] {processor.py:157} INFO - Started process (PID=47638) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:43:16.681+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:43:16.684+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:43:16.683+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:43:16.724+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:43:16.751+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:43:16.751+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:43:16.766+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:43:16.765+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:43:16.776+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-08-01T15:43:47.201+0000] {processor.py:157} INFO - Started process (PID=47663) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:43:47.202+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:43:47.203+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:43:47.203+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:43:47.219+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:43:47.233+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:43:47.233+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:43:47.243+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:43:47.243+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:43:47.251+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-01T15:44:17.744+0000] {processor.py:157} INFO - Started process (PID=47687) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:44:17.745+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:44:17.749+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:44:17.749+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:44:17.768+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:44:17.793+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:44:17.793+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:44:17.806+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:44:17.806+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:44:17.818+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-08-01T15:44:48.178+0000] {processor.py:157} INFO - Started process (PID=47713) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:44:48.180+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:44:48.182+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:44:48.182+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:44:48.193+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:44:48.205+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:44:48.205+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:44:48.215+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:44:48.215+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:44:48.222+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-01T15:45:18.617+0000] {processor.py:157} INFO - Started process (PID=47738) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:45:18.618+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:45:18.621+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:45:18.621+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:45:18.637+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:45:18.653+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:45:18.653+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:45:18.664+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:45:18.664+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:45:18.674+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-01T15:45:49.066+0000] {processor.py:157} INFO - Started process (PID=47763) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:45:49.067+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:45:49.069+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:45:49.069+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:45:49.083+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:45:49.105+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:45:49.105+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:45:49.119+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:45:49.118+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:45:49.128+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-01T15:46:19.545+0000] {processor.py:157} INFO - Started process (PID=47788) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:46:19.547+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:46:19.551+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:46:19.551+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:46:19.567+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:46:19.583+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:46:19.583+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:46:19.592+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:46:19.592+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:46:19.603+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-01T15:46:49.953+0000] {processor.py:157} INFO - Started process (PID=47813) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:46:49.954+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:46:49.955+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:46:49.955+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:46:49.962+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:46:49.984+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:46:49.984+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:46:50.019+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:46:50.019+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:46:50.030+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-08-01T15:47:20.480+0000] {processor.py:157} INFO - Started process (PID=47838) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:47:20.484+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:47:20.486+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:47:20.486+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:47:20.514+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:47:20.533+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:47:20.533+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:47:20.544+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:47:20.544+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:47:20.553+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-08-01T15:47:50.918+0000] {processor.py:157} INFO - Started process (PID=47863) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:47:50.919+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:47:50.921+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:47:50.921+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:47:50.931+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:47:50.955+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:47:50.954+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:47:50.967+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:47:50.967+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:47:50.990+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-08-01T15:48:21.419+0000] {processor.py:157} INFO - Started process (PID=47888) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:48:21.431+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:48:21.445+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:48:21.445+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:48:21.465+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:48:21.485+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:48:21.485+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:48:21.498+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:48:21.498+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:48:21.508+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-08-01T15:48:51.909+0000] {processor.py:157} INFO - Started process (PID=47913) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:48:51.911+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:48:51.913+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:48:51.913+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:48:51.926+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:48:51.947+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:48:51.947+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:48:51.959+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:48:51.959+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:48:51.968+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-01T15:49:22.394+0000] {processor.py:157} INFO - Started process (PID=47938) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:49:22.396+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:49:22.401+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:49:22.401+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:49:22.441+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:49:22.460+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:49:22.460+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:49:22.470+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:49:22.470+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:49:22.480+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-08-01T15:49:52.880+0000] {processor.py:157} INFO - Started process (PID=47963) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:49:52.882+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:49:52.884+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:49:52.884+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:49:52.897+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:49:52.918+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:49:52.918+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:49:52.932+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:49:52.932+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:49:52.942+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-01T15:50:23.326+0000] {processor.py:157} INFO - Started process (PID=47988) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:50:23.328+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:50:23.331+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:50:23.331+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:50:23.348+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:50:23.367+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:50:23.367+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:50:23.379+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:50:23.379+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:50:23.388+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-01T15:50:53.790+0000] {processor.py:157} INFO - Started process (PID=48013) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:50:53.791+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:50:53.792+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:50:53.792+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:50:53.809+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:50:53.824+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:50:53.824+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:50:53.835+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:50:53.835+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:50:53.843+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-01T15:51:24.192+0000] {processor.py:157} INFO - Started process (PID=48038) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:51:24.193+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:51:24.196+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:51:24.196+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:51:24.218+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:51:24.248+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:51:24.248+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:51:24.261+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:51:24.261+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:51:24.271+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-08-01T15:51:54.731+0000] {processor.py:157} INFO - Started process (PID=48063) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:51:54.732+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:51:54.735+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:51:54.734+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:51:54.746+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:51:54.764+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:51:54.764+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:51:54.775+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:51:54.775+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:51:54.784+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-01T15:52:25.135+0000] {processor.py:157} INFO - Started process (PID=48088) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:52:25.138+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:52:25.140+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:52:25.140+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:52:25.150+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:52:25.167+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:52:25.167+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:52:25.177+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:52:25.177+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:52:25.186+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-01T15:52:55.631+0000] {processor.py:157} INFO - Started process (PID=48113) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:52:55.637+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:52:55.649+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:52:55.643+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:52:55.669+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:52:55.693+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:52:55.693+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:52:55.706+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:52:55.706+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:52:55.716+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-08-01T15:53:26.112+0000] {processor.py:157} INFO - Started process (PID=48138) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:53:26.114+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:53:26.116+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:53:26.116+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:53:26.124+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:53:26.141+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:53:26.141+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:53:26.152+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:53:26.152+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:53:26.161+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-01T15:53:56.507+0000] {processor.py:157} INFO - Started process (PID=48163) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:53:56.509+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:53:56.512+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:53:56.512+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:53:56.528+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:53:56.549+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:53:56.549+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:53:56.562+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:53:56.562+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:53:56.572+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-01T15:54:26.987+0000] {processor.py:157} INFO - Started process (PID=48188) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:54:26.989+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:54:26.991+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:54:26.991+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:54:27.004+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:54:27.023+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:54:27.023+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:54:27.034+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:54:27.034+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:54:27.043+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-01T15:54:57.422+0000] {processor.py:157} INFO - Started process (PID=48212) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:54:57.425+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:54:57.435+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:54:57.433+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:54:57.475+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:54:57.502+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:54:57.502+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:54:57.515+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:54:57.515+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:54:57.527+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-08-01T15:55:27.970+0000] {processor.py:157} INFO - Started process (PID=48238) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:55:27.972+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:55:27.973+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:55:27.973+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:55:27.983+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:55:28.000+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:55:28.000+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:55:28.012+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:55:28.012+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:55:28.020+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-01T15:55:58.458+0000] {processor.py:157} INFO - Started process (PID=48263) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:55:58.459+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:55:58.463+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:55:58.463+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:55:58.486+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:55:58.532+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:55:58.532+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:55:58.545+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:55:58.545+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:55:58.554+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-08-01T15:56:28.965+0000] {processor.py:157} INFO - Started process (PID=48286) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:56:28.967+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:56:28.968+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:56:28.968+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:56:28.981+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:56:29.000+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:56:29.000+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:56:29.010+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:56:29.010+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:56:29.018+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-01T15:56:59.374+0000] {processor.py:157} INFO - Started process (PID=48313) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:56:59.377+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:56:59.379+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:56:59.379+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:56:59.394+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:56:59.421+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:56:59.421+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:56:59.446+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:56:59.446+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:56:59.456+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-08-01T15:57:29.872+0000] {processor.py:157} INFO - Started process (PID=48338) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:57:29.874+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:57:29.876+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:57:29.875+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:57:29.889+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:57:29.907+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:57:29.907+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:57:29.919+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:57:29.919+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:57:29.928+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-01T15:58:00.322+0000] {processor.py:157} INFO - Started process (PID=48362) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:58:00.323+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:58:00.325+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:58:00.325+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:58:00.338+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:58:00.355+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:58:00.355+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:58:00.366+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:58:00.365+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:58:00.375+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-01T15:58:30.810+0000] {processor.py:157} INFO - Started process (PID=48388) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:58:30.812+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:58:30.814+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:58:30.814+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:58:30.830+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:58:30.851+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:58:30.851+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:58:30.866+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:58:30.866+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:58:30.876+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-01T15:59:01.275+0000] {processor.py:157} INFO - Started process (PID=48413) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:59:01.278+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:59:01.280+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:59:01.280+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:59:01.293+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:59:01.310+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:59:01.310+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:59:01.320+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:59:01.320+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:59:01.329+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-01T15:59:31.746+0000] {processor.py:157} INFO - Started process (PID=48438) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:59:31.748+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T15:59:31.750+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:59:31.750+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:59:31.765+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T15:59:31.783+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:59:31.783+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T15:59:31.794+0000] {logging_mixin.py:151} INFO - [2024-08-01T15:59:31.794+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T15:59:31.803+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-01T16:00:02.216+0000] {processor.py:157} INFO - Started process (PID=48463) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T16:00:02.220+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T16:00:02.223+0000] {logging_mixin.py:151} INFO - [2024-08-01T16:00:02.223+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T16:00:02.240+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T16:00:02.300+0000] {logging_mixin.py:151} INFO - [2024-08-01T16:00:02.300+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T16:00:02.317+0000] {logging_mixin.py:151} INFO - [2024-08-01T16:00:02.317+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T16:00:02.328+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-08-01T16:00:32.732+0000] {processor.py:157} INFO - Started process (PID=48488) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T16:00:32.733+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T16:00:32.735+0000] {logging_mixin.py:151} INFO - [2024-08-01T16:00:32.735+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T16:00:32.743+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T16:00:32.760+0000] {logging_mixin.py:151} INFO - [2024-08-01T16:00:32.760+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T16:00:32.770+0000] {logging_mixin.py:151} INFO - [2024-08-01T16:00:32.770+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T16:00:32.781+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-01T16:01:03.203+0000] {processor.py:157} INFO - Started process (PID=48513) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T16:01:03.206+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T16:01:03.208+0000] {logging_mixin.py:151} INFO - [2024-08-01T16:01:03.208+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T16:01:03.228+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T16:01:03.271+0000] {logging_mixin.py:151} INFO - [2024-08-01T16:01:03.271+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T16:01:03.287+0000] {logging_mixin.py:151} INFO - [2024-08-01T16:01:03.286+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T16:01:03.297+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-08-01T16:01:33.778+0000] {processor.py:157} INFO - Started process (PID=48538) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T16:01:33.784+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T16:01:33.798+0000] {logging_mixin.py:151} INFO - [2024-08-01T16:01:33.798+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T16:01:33.849+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T16:01:34.028+0000] {logging_mixin.py:151} INFO - [2024-08-01T16:01:34.028+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T16:01:34.095+0000] {logging_mixin.py:151} INFO - [2024-08-01T16:01:34.095+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T16:01:34.107+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.338 seconds
[2024-08-01T16:02:04.574+0000] {processor.py:157} INFO - Started process (PID=48563) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T16:02:04.575+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T16:02:04.579+0000] {logging_mixin.py:151} INFO - [2024-08-01T16:02:04.579+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T16:02:04.600+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T16:02:04.627+0000] {logging_mixin.py:151} INFO - [2024-08-01T16:02:04.627+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T16:02:04.663+0000] {logging_mixin.py:151} INFO - [2024-08-01T16:02:04.663+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T16:02:04.684+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-08-01T16:02:35.440+0000] {processor.py:157} INFO - Started process (PID=48588) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T16:02:35.442+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T16:02:35.451+0000] {logging_mixin.py:151} INFO - [2024-08-01T16:02:35.450+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T16:02:35.480+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T16:02:35.573+0000] {logging_mixin.py:151} INFO - [2024-08-01T16:02:35.572+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T16:02:35.659+0000] {logging_mixin.py:151} INFO - [2024-08-01T16:02:35.659+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T16:02:35.701+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.274 seconds
[2024-08-01T16:03:06.239+0000] {processor.py:157} INFO - Started process (PID=48613) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T16:03:06.240+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T16:03:06.246+0000] {logging_mixin.py:151} INFO - [2024-08-01T16:03:06.245+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T16:03:06.272+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T16:03:06.319+0000] {logging_mixin.py:151} INFO - [2024-08-01T16:03:06.319+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T16:03:06.342+0000] {logging_mixin.py:151} INFO - [2024-08-01T16:03:06.342+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T16:03:06.354+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-08-01T16:03:36.729+0000] {processor.py:157} INFO - Started process (PID=48638) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T16:03:36.731+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T16:03:36.734+0000] {logging_mixin.py:151} INFO - [2024-08-01T16:03:36.733+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T16:03:36.746+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T16:03:36.762+0000] {logging_mixin.py:151} INFO - [2024-08-01T16:03:36.762+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T16:03:36.777+0000] {logging_mixin.py:151} INFO - [2024-08-01T16:03:36.777+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T16:03:36.786+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-01T16:04:07.196+0000] {processor.py:157} INFO - Started process (PID=48663) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T16:04:07.206+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T16:04:07.209+0000] {logging_mixin.py:151} INFO - [2024-08-01T16:04:07.209+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T16:04:07.226+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T16:04:07.251+0000] {logging_mixin.py:151} INFO - [2024-08-01T16:04:07.251+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T16:04:07.265+0000] {logging_mixin.py:151} INFO - [2024-08-01T16:04:07.264+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T16:04:07.274+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-08-01T16:04:37.645+0000] {processor.py:157} INFO - Started process (PID=48688) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T16:04:37.647+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T16:04:37.652+0000] {logging_mixin.py:151} INFO - [2024-08-01T16:04:37.652+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T16:04:37.666+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T16:04:37.681+0000] {logging_mixin.py:151} INFO - [2024-08-01T16:04:37.681+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T16:04:37.690+0000] {logging_mixin.py:151} INFO - [2024-08-01T16:04:37.690+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T16:04:37.698+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-01T16:05:08.094+0000] {processor.py:157} INFO - Started process (PID=48713) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-01T16:05:08.096+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-01T16:05:08.117+0000] {logging_mixin.py:151} INFO - [2024-08-01T16:05:08.116+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T16:05:08.135+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-01T16:05:08.162+0000] {logging_mixin.py:151} INFO - [2024-08-01T16:05:08.162+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-01T16:05:08.176+0000] {logging_mixin.py:151} INFO - [2024-08-01T16:05:08.176+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-01T01:00:00+00:00, run_after=2024-08-02T01:00:00+00:00
[2024-08-01T16:05:08.186+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
