[2024-09-12T00:03:38.905+0000] {processor.py:157} INFO - Started process (PID=58764) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T00:03:38.906+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T00:03:38.912+0000] {logging_mixin.py:151} INFO - [2024-09-12T00:03:38.911+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T00:03:38.934+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T00:03:38.972+0000] {logging_mixin.py:151} INFO - [2024-09-12T00:03:38.972+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T00:03:39.003+0000] {logging_mixin.py:151} INFO - [2024-09-12T00:03:39.002+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-12T00:03:39.020+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-09-12T00:04:09.351+0000] {processor.py:157} INFO - Started process (PID=58773) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T00:04:09.352+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T00:04:09.359+0000] {logging_mixin.py:151} INFO - [2024-09-12T00:04:09.359+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T00:04:09.378+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T00:04:09.405+0000] {logging_mixin.py:151} INFO - [2024-09-12T00:04:09.405+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T00:04:09.419+0000] {logging_mixin.py:151} INFO - [2024-09-12T00:04:09.419+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-12T00:04:09.429+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-12T00:13:59.573+0000] {processor.py:157} INFO - Started process (PID=58787) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T00:13:59.574+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T00:13:59.577+0000] {logging_mixin.py:151} INFO - [2024-09-12T00:13:59.577+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T00:13:59.592+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T00:13:59.609+0000] {logging_mixin.py:151} INFO - [2024-09-12T00:13:59.609+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T00:13:59.618+0000] {logging_mixin.py:151} INFO - [2024-09-12T00:13:59.618+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-12T00:13:59.627+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-12T00:15:57.245+0000] {processor.py:157} INFO - Started process (PID=58797) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T00:15:57.246+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T00:15:57.247+0000] {logging_mixin.py:151} INFO - [2024-09-12T00:15:57.247+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T00:15:57.257+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T00:15:57.300+0000] {logging_mixin.py:151} INFO - [2024-09-12T00:15:57.300+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T00:15:57.313+0000] {logging_mixin.py:151} INFO - [2024-09-12T00:15:57.313+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-12T00:15:57.323+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-09-12T00:16:27.556+0000] {processor.py:157} INFO - Started process (PID=58807) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T00:16:27.558+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T00:16:27.560+0000] {logging_mixin.py:151} INFO - [2024-09-12T00:16:27.560+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T00:16:27.574+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T00:16:27.595+0000] {logging_mixin.py:151} INFO - [2024-09-12T00:16:27.595+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T00:16:27.608+0000] {logging_mixin.py:151} INFO - [2024-09-12T00:16:27.608+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-12T00:16:27.617+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-12T00:42:02.452+0000] {processor.py:157} INFO - Started process (PID=58820) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T00:42:02.454+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T00:42:02.456+0000] {logging_mixin.py:151} INFO - [2024-09-12T00:42:02.456+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T00:42:02.473+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T00:42:02.503+0000] {logging_mixin.py:151} INFO - [2024-09-12T00:42:02.503+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T00:42:02.522+0000] {logging_mixin.py:151} INFO - [2024-09-12T00:42:02.522+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-12T00:42:02.537+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-12T00:43:33.690+0000] {processor.py:157} INFO - Started process (PID=59416) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T00:43:33.693+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T00:43:33.703+0000] {logging_mixin.py:151} INFO - [2024-09-12T00:43:33.702+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T00:43:33.725+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T00:43:33.767+0000] {logging_mixin.py:151} INFO - [2024-09-12T00:43:33.767+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T00:43:33.782+0000] {logging_mixin.py:151} INFO - [2024-09-12T00:43:33.782+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-12T00:43:33.791+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-09-12T00:44:03.962+0000] {processor.py:157} INFO - Started process (PID=59425) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T00:44:03.963+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T00:44:03.966+0000] {logging_mixin.py:151} INFO - [2024-09-12T00:44:03.966+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T00:44:04.001+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T00:44:04.037+0000] {logging_mixin.py:151} INFO - [2024-09-12T00:44:04.037+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T00:44:04.073+0000] {logging_mixin.py:151} INFO - [2024-09-12T00:44:04.072+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-12T00:44:04.085+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-09-12T00:50:21.129+0000] {processor.py:157} INFO - Started process (PID=59603) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T00:50:21.132+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T00:50:21.136+0000] {logging_mixin.py:151} INFO - [2024-09-12T00:50:21.136+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T00:50:21.155+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T00:50:21.177+0000] {logging_mixin.py:151} INFO - [2024-09-12T00:50:21.177+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T00:50:21.190+0000] {logging_mixin.py:151} INFO - [2024-09-12T00:50:21.190+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-12T00:50:21.202+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-12T00:50:51.490+0000] {processor.py:157} INFO - Started process (PID=59613) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T00:50:51.496+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T00:50:51.506+0000] {logging_mixin.py:151} INFO - [2024-09-12T00:50:51.505+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T00:50:51.522+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T00:50:51.546+0000] {logging_mixin.py:151} INFO - [2024-09-12T00:50:51.546+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T00:50:51.558+0000] {logging_mixin.py:151} INFO - [2024-09-12T00:50:51.558+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-12T00:50:51.568+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-12T00:56:35.400+0000] {processor.py:157} INFO - Started process (PID=59623) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T00:56:35.402+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T00:56:35.407+0000] {logging_mixin.py:151} INFO - [2024-09-12T00:56:35.406+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T00:56:35.445+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T00:56:35.488+0000] {logging_mixin.py:151} INFO - [2024-09-12T00:56:35.488+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T00:56:35.518+0000] {logging_mixin.py:151} INFO - [2024-09-12T00:56:35.518+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-10T01:00:00+00:00, run_after=2024-09-11T01:00:00+00:00
[2024-09-12T00:56:35.538+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.144 seconds
[2024-09-12T01:30:42.643+0000] {processor.py:157} INFO - Started process (PID=59633) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T01:30:42.647+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T01:30:42.653+0000] {logging_mixin.py:151} INFO - [2024-09-12T01:30:42.652+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T01:30:42.692+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T01:30:42.740+0000] {logging_mixin.py:151} INFO - [2024-09-12T01:30:42.740+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T01:30:42.774+0000] {logging_mixin.py:151} INFO - [2024-09-12T01:30:42.774+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T01:30:42.798+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.162 seconds
[2024-09-12T01:31:12.956+0000] {processor.py:157} INFO - Started process (PID=59645) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T01:31:12.960+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T01:31:12.964+0000] {logging_mixin.py:151} INFO - [2024-09-12T01:31:12.964+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T01:31:12.984+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T01:31:13.026+0000] {logging_mixin.py:151} INFO - [2024-09-12T01:31:13.026+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T01:31:13.040+0000] {logging_mixin.py:151} INFO - [2024-09-12T01:31:13.039+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T01:31:13.050+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-09-12T01:31:45.022+0000] {processor.py:157} INFO - Started process (PID=59655) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T01:31:45.023+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T01:31:45.025+0000] {logging_mixin.py:151} INFO - [2024-09-12T01:31:45.025+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T01:31:45.035+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T01:31:45.055+0000] {logging_mixin.py:151} INFO - [2024-09-12T01:31:45.054+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T01:31:45.064+0000] {logging_mixin.py:151} INFO - [2024-09-12T01:31:45.064+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T01:31:45.075+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-12T01:32:15.365+0000] {processor.py:157} INFO - Started process (PID=59665) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T01:32:15.366+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T01:32:15.369+0000] {logging_mixin.py:151} INFO - [2024-09-12T01:32:15.369+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T01:32:15.408+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T01:32:15.429+0000] {logging_mixin.py:151} INFO - [2024-09-12T01:32:15.429+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T01:32:15.442+0000] {logging_mixin.py:151} INFO - [2024-09-12T01:32:15.442+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T01:32:15.451+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-12T01:32:48.402+0000] {processor.py:157} INFO - Started process (PID=59675) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T01:32:48.403+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T01:32:48.405+0000] {logging_mixin.py:151} INFO - [2024-09-12T01:32:48.405+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T01:32:48.416+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T01:32:48.431+0000] {logging_mixin.py:151} INFO - [2024-09-12T01:32:48.431+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T01:32:48.445+0000] {logging_mixin.py:151} INFO - [2024-09-12T01:32:48.445+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T01:32:48.453+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-12T01:33:20.459+0000] {processor.py:157} INFO - Started process (PID=59685) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T01:33:20.460+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T01:33:20.462+0000] {logging_mixin.py:151} INFO - [2024-09-12T01:33:20.462+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T01:33:20.475+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T01:33:20.497+0000] {logging_mixin.py:151} INFO - [2024-09-12T01:33:20.496+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T01:33:20.507+0000] {logging_mixin.py:151} INFO - [2024-09-12T01:33:20.507+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T01:33:20.517+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-12T01:33:50.789+0000] {processor.py:157} INFO - Started process (PID=59695) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T01:33:50.792+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T01:33:50.793+0000] {logging_mixin.py:151} INFO - [2024-09-12T01:33:50.793+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T01:33:50.807+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T01:33:50.826+0000] {logging_mixin.py:151} INFO - [2024-09-12T01:33:50.826+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T01:33:50.838+0000] {logging_mixin.py:151} INFO - [2024-09-12T01:33:50.838+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T01:33:50.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-12T01:40:04.293+0000] {processor.py:157} INFO - Started process (PID=59704) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T01:40:04.296+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T01:40:04.305+0000] {logging_mixin.py:151} INFO - [2024-09-12T01:40:04.305+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T01:40:04.322+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T01:40:04.374+0000] {logging_mixin.py:151} INFO - [2024-09-12T01:40:04.374+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T01:40:04.396+0000] {logging_mixin.py:151} INFO - [2024-09-12T01:40:04.396+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T01:40:04.416+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-09-12T01:49:28.238+0000] {processor.py:157} INFO - Started process (PID=59714) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T01:49:28.243+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T01:49:28.250+0000] {logging_mixin.py:151} INFO - [2024-09-12T01:49:28.250+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T01:49:28.277+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T01:49:28.326+0000] {logging_mixin.py:151} INFO - [2024-09-12T01:49:28.326+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T01:49:28.364+0000] {logging_mixin.py:151} INFO - [2024-09-12T01:49:28.364+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T01:49:28.386+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.156 seconds
[2024-09-12T01:49:58.604+0000] {processor.py:157} INFO - Started process (PID=59725) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T01:49:58.607+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T01:49:58.613+0000] {logging_mixin.py:151} INFO - [2024-09-12T01:49:58.612+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T01:49:58.665+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T01:49:58.711+0000] {logging_mixin.py:151} INFO - [2024-09-12T01:49:58.711+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T01:49:58.744+0000] {logging_mixin.py:151} INFO - [2024-09-12T01:49:58.743+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T01:49:58.757+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.162 seconds
[2024-09-12T01:50:28.932+0000] {processor.py:157} INFO - Started process (PID=59735) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T01:50:28.934+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T01:50:28.940+0000] {logging_mixin.py:151} INFO - [2024-09-12T01:50:28.939+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T01:50:28.962+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T01:50:28.998+0000] {logging_mixin.py:151} INFO - [2024-09-12T01:50:28.998+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T01:50:29.016+0000] {logging_mixin.py:151} INFO - [2024-09-12T01:50:29.016+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T01:50:29.030+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-12T01:50:59.257+0000] {processor.py:157} INFO - Started process (PID=59745) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T01:50:59.258+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T01:50:59.259+0000] {logging_mixin.py:151} INFO - [2024-09-12T01:50:59.259+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T01:50:59.272+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T01:50:59.295+0000] {logging_mixin.py:151} INFO - [2024-09-12T01:50:59.295+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T01:50:59.312+0000] {logging_mixin.py:151} INFO - [2024-09-12T01:50:59.312+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T01:50:59.325+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-12T01:51:29.545+0000] {processor.py:157} INFO - Started process (PID=59755) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T01:51:29.547+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T01:51:29.549+0000] {logging_mixin.py:151} INFO - [2024-09-12T01:51:29.549+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T01:51:29.588+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T01:51:29.613+0000] {logging_mixin.py:151} INFO - [2024-09-12T01:51:29.613+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T01:51:29.629+0000] {logging_mixin.py:151} INFO - [2024-09-12T01:51:29.629+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T01:51:29.641+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-12T01:51:59.879+0000] {processor.py:157} INFO - Started process (PID=59765) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T01:51:59.880+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T01:51:59.883+0000] {logging_mixin.py:151} INFO - [2024-09-12T01:51:59.882+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T01:51:59.897+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T01:51:59.938+0000] {logging_mixin.py:151} INFO - [2024-09-12T01:51:59.938+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T01:51:59.951+0000] {logging_mixin.py:151} INFO - [2024-09-12T01:51:59.951+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T01:51:59.961+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-12T01:52:30.224+0000] {processor.py:157} INFO - Started process (PID=59775) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T01:52:30.226+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T01:52:30.228+0000] {logging_mixin.py:151} INFO - [2024-09-12T01:52:30.227+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T01:52:30.236+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T01:52:30.252+0000] {logging_mixin.py:151} INFO - [2024-09-12T01:52:30.252+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T01:52:30.262+0000] {logging_mixin.py:151} INFO - [2024-09-12T01:52:30.262+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T01:52:30.270+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-09-12T01:53:00.529+0000] {processor.py:157} INFO - Started process (PID=59785) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T01:53:00.530+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T01:53:00.533+0000] {logging_mixin.py:151} INFO - [2024-09-12T01:53:00.533+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T01:53:00.547+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T01:53:00.568+0000] {logging_mixin.py:151} INFO - [2024-09-12T01:53:00.568+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T01:53:00.581+0000] {logging_mixin.py:151} INFO - [2024-09-12T01:53:00.581+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T01:53:00.592+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-12T01:53:30.829+0000] {processor.py:157} INFO - Started process (PID=59795) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T01:53:30.829+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T01:53:30.831+0000] {logging_mixin.py:151} INFO - [2024-09-12T01:53:30.831+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T01:53:30.840+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T01:53:30.862+0000] {logging_mixin.py:151} INFO - [2024-09-12T01:53:30.862+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T01:53:30.895+0000] {logging_mixin.py:151} INFO - [2024-09-12T01:53:30.895+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T01:53:30.904+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-12T01:54:01.270+0000] {processor.py:157} INFO - Started process (PID=59805) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T01:54:01.273+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T01:54:01.275+0000] {logging_mixin.py:151} INFO - [2024-09-12T01:54:01.275+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T01:54:01.292+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T01:54:01.318+0000] {logging_mixin.py:151} INFO - [2024-09-12T01:54:01.318+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T01:54:01.333+0000] {logging_mixin.py:151} INFO - [2024-09-12T01:54:01.333+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T01:54:01.348+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-12T01:54:31.620+0000] {processor.py:157} INFO - Started process (PID=59815) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T01:54:31.621+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T01:54:31.623+0000] {logging_mixin.py:151} INFO - [2024-09-12T01:54:31.623+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T01:54:31.635+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T01:54:31.653+0000] {logging_mixin.py:151} INFO - [2024-09-12T01:54:31.653+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T01:54:31.665+0000] {logging_mixin.py:151} INFO - [2024-09-12T01:54:31.665+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T01:54:31.675+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-12T01:55:02.091+0000] {processor.py:157} INFO - Started process (PID=59825) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T01:55:02.094+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T01:55:02.110+0000] {logging_mixin.py:151} INFO - [2024-09-12T01:55:02.110+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T01:55:02.132+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T01:55:02.166+0000] {logging_mixin.py:151} INFO - [2024-09-12T01:55:02.166+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T01:55:02.182+0000] {logging_mixin.py:151} INFO - [2024-09-12T01:55:02.182+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T01:55:02.197+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-09-12T01:55:32.458+0000] {processor.py:157} INFO - Started process (PID=59835) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T01:55:32.460+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T01:55:32.461+0000] {logging_mixin.py:151} INFO - [2024-09-12T01:55:32.461+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T01:55:32.472+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T01:55:32.491+0000] {logging_mixin.py:151} INFO - [2024-09-12T01:55:32.490+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T01:55:32.502+0000] {logging_mixin.py:151} INFO - [2024-09-12T01:55:32.502+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T01:55:32.514+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-12T01:56:02.870+0000] {processor.py:157} INFO - Started process (PID=59845) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T01:56:02.872+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T01:56:02.875+0000] {logging_mixin.py:151} INFO - [2024-09-12T01:56:02.875+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T01:56:02.895+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T01:56:02.954+0000] {logging_mixin.py:151} INFO - [2024-09-12T01:56:02.953+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T01:56:02.972+0000] {logging_mixin.py:151} INFO - [2024-09-12T01:56:02.972+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T01:56:02.984+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-12T01:56:33.269+0000] {processor.py:157} INFO - Started process (PID=59855) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T01:56:33.275+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T01:56:33.277+0000] {logging_mixin.py:151} INFO - [2024-09-12T01:56:33.277+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T01:56:33.286+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T01:56:33.299+0000] {logging_mixin.py:151} INFO - [2024-09-12T01:56:33.299+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T01:56:33.308+0000] {logging_mixin.py:151} INFO - [2024-09-12T01:56:33.308+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T01:56:33.317+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-12T01:57:03.659+0000] {processor.py:157} INFO - Started process (PID=59864) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T01:57:03.661+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T01:57:03.666+0000] {logging_mixin.py:151} INFO - [2024-09-12T01:57:03.665+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T01:57:03.698+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T01:57:03.752+0000] {logging_mixin.py:151} INFO - [2024-09-12T01:57:03.752+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T01:57:03.771+0000] {logging_mixin.py:151} INFO - [2024-09-12T01:57:03.771+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T01:57:03.782+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-09-12T01:57:33.980+0000] {processor.py:157} INFO - Started process (PID=59875) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T01:57:33.982+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T01:57:33.984+0000] {logging_mixin.py:151} INFO - [2024-09-12T01:57:33.984+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T01:57:34.001+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T01:57:34.024+0000] {logging_mixin.py:151} INFO - [2024-09-12T01:57:34.024+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T01:57:34.038+0000] {logging_mixin.py:151} INFO - [2024-09-12T01:57:34.038+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T01:57:34.048+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-12T01:58:04.397+0000] {processor.py:157} INFO - Started process (PID=59885) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T01:58:04.400+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T01:58:04.402+0000] {logging_mixin.py:151} INFO - [2024-09-12T01:58:04.401+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T01:58:04.416+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T01:58:04.439+0000] {logging_mixin.py:151} INFO - [2024-09-12T01:58:04.439+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T01:58:04.455+0000] {logging_mixin.py:151} INFO - [2024-09-12T01:58:04.455+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T01:58:04.466+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-12T01:58:34.770+0000] {processor.py:157} INFO - Started process (PID=59895) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T01:58:34.770+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T01:58:34.772+0000] {logging_mixin.py:151} INFO - [2024-09-12T01:58:34.771+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T01:58:34.782+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T01:58:34.799+0000] {logging_mixin.py:151} INFO - [2024-09-12T01:58:34.799+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T01:58:34.811+0000] {logging_mixin.py:151} INFO - [2024-09-12T01:58:34.811+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T01:58:34.820+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-12T01:59:05.161+0000] {processor.py:157} INFO - Started process (PID=59905) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T01:59:05.162+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T01:59:05.164+0000] {logging_mixin.py:151} INFO - [2024-09-12T01:59:05.164+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T01:59:05.173+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T01:59:05.191+0000] {logging_mixin.py:151} INFO - [2024-09-12T01:59:05.191+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T01:59:05.203+0000] {logging_mixin.py:151} INFO - [2024-09-12T01:59:05.203+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T01:59:05.210+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-12T01:59:35.606+0000] {processor.py:157} INFO - Started process (PID=59914) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T01:59:35.609+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T01:59:35.611+0000] {logging_mixin.py:151} INFO - [2024-09-12T01:59:35.611+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T01:59:35.631+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T01:59:35.663+0000] {logging_mixin.py:151} INFO - [2024-09-12T01:59:35.663+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T01:59:35.676+0000] {logging_mixin.py:151} INFO - [2024-09-12T01:59:35.676+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T01:59:35.685+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-09-12T02:00:05.913+0000] {processor.py:157} INFO - Started process (PID=59925) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:00:05.914+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:00:05.920+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:00:05.920+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:00:05.937+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:00:05.961+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:00:05.961+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:00:05.974+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:00:05.974+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:00:05.986+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-12T02:00:36.321+0000] {processor.py:157} INFO - Started process (PID=59935) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:00:36.321+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:00:36.323+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:00:36.323+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:00:36.332+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:00:36.348+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:00:36.348+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:00:36.358+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:00:36.358+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:00:36.367+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-09-12T02:01:06.740+0000] {processor.py:157} INFO - Started process (PID=59944) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:01:06.741+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:01:06.749+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:01:06.747+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:01:06.773+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:01:06.798+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:01:06.798+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:01:06.811+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:01:06.811+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:01:06.831+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-12T02:01:37.053+0000] {processor.py:157} INFO - Started process (PID=59955) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:01:37.054+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:01:37.062+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:01:37.059+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:01:37.083+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:01:37.108+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:01:37.108+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:01:37.122+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:01:37.122+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:01:37.138+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-12T02:02:07.352+0000] {processor.py:157} INFO - Started process (PID=59965) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:02:07.354+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:02:07.356+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:02:07.356+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:02:07.365+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:02:07.383+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:02:07.383+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:02:07.396+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:02:07.396+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:02:07.404+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-12T02:02:37.775+0000] {processor.py:157} INFO - Started process (PID=59974) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:02:37.776+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:02:37.779+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:02:37.779+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:02:37.794+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:02:37.822+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:02:37.822+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:02:37.851+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:02:37.851+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:02:37.864+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-12T02:03:08.090+0000] {processor.py:157} INFO - Started process (PID=59985) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:03:08.093+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:03:08.095+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:03:08.095+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:03:08.111+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:03:08.133+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:03:08.133+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:03:08.147+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:03:08.147+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:03:08.157+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-12T02:03:38.436+0000] {processor.py:157} INFO - Started process (PID=59995) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:03:38.437+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:03:38.438+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:03:38.438+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:03:38.456+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:03:38.470+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:03:38.470+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:03:38.480+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:03:38.480+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:03:38.488+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-12T02:04:08.814+0000] {processor.py:157} INFO - Started process (PID=60004) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:04:08.816+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:04:08.819+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:04:08.819+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:04:08.835+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:04:08.858+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:04:08.858+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:04:08.870+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:04:08.870+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:04:08.879+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-12T02:04:39.090+0000] {processor.py:157} INFO - Started process (PID=60015) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:04:39.090+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:04:39.092+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:04:39.092+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:04:39.104+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:04:39.121+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:04:39.121+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:04:39.134+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:04:39.134+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:04:39.144+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-12T02:05:09.449+0000] {processor.py:157} INFO - Started process (PID=60025) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:05:09.450+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:05:09.451+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:05:09.451+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:05:09.463+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:05:09.481+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:05:09.480+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:05:09.494+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:05:09.494+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:05:09.505+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-12T02:05:39.877+0000] {processor.py:157} INFO - Started process (PID=60035) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:05:39.879+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:05:39.881+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:05:39.881+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:05:39.896+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:05:39.918+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:05:39.918+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:05:39.932+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:05:39.931+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:05:39.941+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-12T02:06:10.180+0000] {processor.py:157} INFO - Started process (PID=60045) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:06:10.181+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:06:10.183+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:06:10.182+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:06:10.200+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:06:10.215+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:06:10.215+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:06:10.227+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:06:10.227+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:06:10.236+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-12T02:06:40.569+0000] {processor.py:157} INFO - Started process (PID=60055) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:06:40.569+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:06:40.570+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:06:40.570+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:06:40.578+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:06:40.597+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:06:40.597+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:06:40.606+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:06:40.606+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:06:40.616+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-12T02:07:10.969+0000] {processor.py:157} INFO - Started process (PID=60065) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:07:10.971+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:07:10.973+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:07:10.973+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:07:10.992+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:07:11.017+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:07:11.017+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:07:11.031+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:07:11.031+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:07:11.041+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-12T02:07:41.289+0000] {processor.py:157} INFO - Started process (PID=60075) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:07:41.290+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:07:41.291+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:07:41.291+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:07:41.306+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:07:41.320+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:07:41.320+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:07:41.331+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:07:41.331+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:07:41.342+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-12T02:08:11.692+0000] {processor.py:157} INFO - Started process (PID=60085) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:08:11.694+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:08:11.699+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:08:11.699+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:08:11.714+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:08:11.735+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:08:11.735+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:08:11.748+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:08:11.748+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:08:11.758+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-12T02:08:42.136+0000] {processor.py:157} INFO - Started process (PID=60095) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:08:42.138+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:08:42.140+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:08:42.139+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:08:42.153+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:08:42.169+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:08:42.169+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:08:42.182+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:08:42.182+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:08:42.191+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-12T02:09:12.564+0000] {processor.py:157} INFO - Started process (PID=60105) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:09:12.569+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:09:12.574+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:09:12.573+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:09:12.590+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:09:12.615+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:09:12.615+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:09:12.628+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:09:12.628+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:09:12.637+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-12T02:09:42.871+0000] {processor.py:157} INFO - Started process (PID=60115) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:09:42.872+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:09:42.874+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:09:42.874+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:09:42.886+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:09:42.902+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:09:42.902+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:09:42.913+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:09:42.913+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:09:42.923+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-12T02:10:13.306+0000] {processor.py:157} INFO - Started process (PID=60125) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:10:13.308+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:10:13.316+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:10:13.316+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:10:13.333+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:10:13.388+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:10:13.388+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:10:13.407+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:10:13.406+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:10:13.424+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-12T02:10:43.773+0000] {processor.py:157} INFO - Started process (PID=60135) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:10:43.774+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:10:43.775+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:10:43.775+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:10:43.785+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:10:43.803+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:10:43.803+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:10:43.814+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:10:43.813+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:10:43.821+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-12T02:11:14.168+0000] {processor.py:157} INFO - Started process (PID=60145) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:11:14.169+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:11:14.173+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:11:14.173+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:11:14.215+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:11:14.247+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:11:14.247+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:11:14.262+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:11:14.261+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:11:14.272+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-09-12T02:11:44.477+0000] {processor.py:157} INFO - Started process (PID=60155) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:11:44.478+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:11:44.479+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:11:44.479+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:11:44.490+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:11:44.508+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:11:44.508+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:11:44.519+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:11:44.519+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:11:44.529+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-12T02:12:14.852+0000] {processor.py:157} INFO - Started process (PID=60165) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:12:14.853+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:12:14.854+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:12:14.854+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:12:14.865+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:12:14.881+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:12:14.881+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:12:14.891+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:12:14.891+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:12:14.901+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-12T02:12:45.252+0000] {processor.py:157} INFO - Started process (PID=60175) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:12:45.254+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:12:45.258+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:12:45.258+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:12:45.296+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:12:45.332+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:12:45.332+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:12:45.346+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:12:45.346+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:12:45.358+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-12T02:13:15.559+0000] {processor.py:157} INFO - Started process (PID=60185) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:13:15.561+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:13:15.563+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:13:15.563+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:13:15.572+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:13:15.588+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:13:15.588+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:13:15.597+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:13:15.597+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:13:15.607+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-12T02:13:45.920+0000] {processor.py:157} INFO - Started process (PID=60195) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:13:45.922+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:13:45.924+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:13:45.924+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:13:45.939+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:13:45.974+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:13:45.974+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:13:45.995+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:13:45.995+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:13:46.006+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-12T02:14:16.215+0000] {processor.py:157} INFO - Started process (PID=60205) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:14:16.216+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:14:16.218+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:14:16.217+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:14:16.230+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:14:16.245+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:14:16.245+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:14:16.255+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:14:16.255+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:14:16.263+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-12T02:14:46.644+0000] {processor.py:157} INFO - Started process (PID=60215) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:14:46.645+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:14:46.647+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:14:46.647+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:14:46.658+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:14:46.673+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:14:46.673+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:14:46.683+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:14:46.683+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:14:46.693+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-12T02:15:17.037+0000] {processor.py:157} INFO - Started process (PID=60225) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:15:17.038+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:15:17.042+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:15:17.042+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:15:17.059+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:15:17.095+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:15:17.095+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:15:17.119+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:15:17.119+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:15:17.131+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-12T02:15:47.498+0000] {processor.py:157} INFO - Started process (PID=60235) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:15:47.499+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:15:47.501+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:15:47.501+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:15:47.511+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:15:47.530+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:15:47.530+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:15:47.541+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:15:47.541+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:15:47.551+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-12T02:16:17.867+0000] {processor.py:157} INFO - Started process (PID=60244) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:16:17.870+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:16:17.872+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:16:17.872+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:16:17.887+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:16:17.916+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:16:17.916+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:16:17.939+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:16:17.939+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:16:17.958+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-12T02:16:48.260+0000] {processor.py:157} INFO - Started process (PID=60255) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:16:48.261+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:16:48.263+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:16:48.263+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:16:48.275+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:16:48.298+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:16:48.298+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:16:48.342+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:16:48.341+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:16:48.362+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-12T02:17:18.645+0000] {processor.py:157} INFO - Started process (PID=60265) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:17:18.647+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:17:18.649+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:17:18.649+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:17:18.664+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:17:18.703+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:17:18.703+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:17:18.717+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:17:18.717+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:17:18.726+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-12T02:17:48.926+0000] {processor.py:157} INFO - Started process (PID=60275) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:17:48.929+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:17:48.934+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:17:48.933+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:17:48.945+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:17:48.967+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:17:48.967+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:17:48.978+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:17:48.978+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:17:49.003+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-09-12T02:18:19.271+0000] {processor.py:157} INFO - Started process (PID=60285) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:18:19.273+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:18:19.276+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:18:19.276+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:18:19.291+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:18:19.322+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:18:19.322+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:18:19.336+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:18:19.336+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:18:19.346+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-12T02:18:49.577+0000] {processor.py:157} INFO - Started process (PID=60295) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:18:49.578+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:18:49.580+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:18:49.580+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:18:49.589+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:18:49.605+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:18:49.605+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:18:49.615+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:18:49.615+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:18:49.623+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-12T02:19:19.905+0000] {processor.py:157} INFO - Started process (PID=60305) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:19:19.907+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:19:19.910+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:19:19.909+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:19:19.924+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:19:19.949+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:19:19.949+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:19:19.967+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:19:19.967+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:19:19.985+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-12T02:19:50.316+0000] {processor.py:157} INFO - Started process (PID=60315) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:19:50.319+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:19:50.322+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:19:50.321+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:19:50.337+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:19:50.364+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:19:50.363+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:19:50.379+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:19:50.379+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:19:50.390+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-12T02:20:20.591+0000] {processor.py:157} INFO - Started process (PID=60325) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:20:20.592+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:20:20.593+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:20:20.593+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:20:20.605+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:20:20.620+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:20:20.620+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:20:20.634+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:20:20.634+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:20:20.644+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-12T02:20:50.890+0000] {processor.py:157} INFO - Started process (PID=60335) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:20:50.893+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:20:50.896+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:20:50.895+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:20:50.915+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:20:50.935+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:20:50.935+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:20:50.947+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:20:50.946+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:20:50.957+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-12T02:21:21.294+0000] {processor.py:157} INFO - Started process (PID=60344) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:21:21.296+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:21:21.299+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:21:21.299+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:21:21.315+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:21:21.345+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:21:21.345+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:21:21.358+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:21:21.358+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:21:21.369+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-12T02:21:51.723+0000] {processor.py:157} INFO - Started process (PID=60355) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:21:51.726+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:21:51.730+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:21:51.730+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:21:51.746+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:21:51.772+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:21:51.771+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:21:51.784+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:21:51.784+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:21:51.798+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-12T02:22:21.998+0000] {processor.py:157} INFO - Started process (PID=60365) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:22:21.999+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:22:22.000+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:22:22.000+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:22:22.011+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:22:22.026+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:22:22.026+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:22:22.039+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:22:22.038+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:22:22.048+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-12T02:22:52.402+0000] {processor.py:157} INFO - Started process (PID=60375) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:22:52.403+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:22:52.406+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:22:52.406+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:22:52.438+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:22:52.464+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:22:52.464+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:22:52.476+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:22:52.476+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:22:52.487+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-12T02:23:22.711+0000] {processor.py:157} INFO - Started process (PID=60385) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:23:22.712+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:23:22.714+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:23:22.714+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:23:22.728+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:23:22.743+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:23:22.743+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:23:22.754+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:23:22.754+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:23:22.761+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-12T02:23:53.073+0000] {processor.py:157} INFO - Started process (PID=60395) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:23:53.075+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:23:53.077+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:23:53.077+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:23:53.092+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:23:53.114+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:23:53.114+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:23:53.126+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:23:53.126+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:23:53.135+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-12T02:24:23.438+0000] {processor.py:157} INFO - Started process (PID=60405) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:24:23.439+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:24:23.441+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:24:23.441+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:24:23.452+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:24:23.468+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:24:23.467+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:24:23.477+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:24:23.477+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:24:23.486+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-12T02:24:53.790+0000] {processor.py:157} INFO - Started process (PID=60415) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:24:53.792+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:24:53.794+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:24:53.793+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:24:53.805+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:24:53.822+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:24:53.822+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:24:53.832+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:24:53.832+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:24:53.840+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-12T02:25:24.106+0000] {processor.py:157} INFO - Started process (PID=60425) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:25:24.107+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:25:24.108+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:25:24.108+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:25:24.122+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:25:24.135+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:25:24.135+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:25:24.147+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:25:24.147+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:25:24.157+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-12T02:25:54.466+0000] {processor.py:157} INFO - Started process (PID=60435) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:25:54.467+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:25:54.469+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:25:54.468+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:25:54.477+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:25:54.493+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:25:54.493+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:25:54.504+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:25:54.503+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:25:54.513+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-12T02:26:24.819+0000] {processor.py:157} INFO - Started process (PID=60445) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:26:24.821+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:26:24.823+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:26:24.823+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:26:24.835+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:26:24.854+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:26:24.853+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:26:24.867+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:26:24.867+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:26:24.877+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-12T02:26:55.145+0000] {processor.py:157} INFO - Started process (PID=60455) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:26:55.146+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:26:55.149+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:26:55.149+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:26:55.162+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:26:55.182+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:26:55.182+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:26:55.194+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:26:55.194+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:26:55.205+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-12T02:27:25.455+0000] {processor.py:157} INFO - Started process (PID=60465) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:27:25.458+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:27:25.461+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:27:25.461+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:27:25.473+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:27:25.488+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:27:25.488+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:27:25.500+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:27:25.499+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:27:25.510+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-12T02:27:55.817+0000] {processor.py:157} INFO - Started process (PID=60475) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:27:55.818+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:27:55.820+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:27:55.820+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:27:55.833+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:27:55.847+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:27:55.847+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:27:55.856+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:27:55.856+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:27:55.865+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-12T02:28:26.136+0000] {processor.py:157} INFO - Started process (PID=60485) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:28:26.138+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:28:26.140+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:28:26.140+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:28:26.153+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:28:26.167+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:28:26.167+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:28:26.179+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:28:26.179+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:28:26.187+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-12T02:28:56.506+0000] {processor.py:157} INFO - Started process (PID=60495) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:28:56.508+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:28:56.509+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:28:56.509+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:28:56.518+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:28:56.534+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:28:56.534+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:28:56.544+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:28:56.544+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:28:56.553+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-12T02:29:26.845+0000] {processor.py:157} INFO - Started process (PID=60505) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:29:26.846+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:29:26.848+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:29:26.848+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:29:26.862+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:29:26.878+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:29:26.878+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:29:26.889+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:29:26.889+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:29:26.899+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-12T02:29:57.177+0000] {processor.py:157} INFO - Started process (PID=60515) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:29:57.178+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:29:57.180+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:29:57.180+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:29:57.188+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:29:57.203+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:29:57.203+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:29:57.213+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:29:57.212+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:29:57.221+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-09-12T02:30:27.502+0000] {processor.py:157} INFO - Started process (PID=60525) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:30:27.505+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:30:27.507+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:30:27.507+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:30:27.521+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:30:27.544+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:30:27.544+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:30:27.556+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:30:27.556+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:30:27.567+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-12T02:30:57.899+0000] {processor.py:157} INFO - Started process (PID=60535) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:30:57.900+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:30:57.901+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:30:57.901+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:30:57.918+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:30:57.932+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:30:57.932+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:30:57.944+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:30:57.944+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:30:57.954+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-12T02:31:28.334+0000] {processor.py:157} INFO - Started process (PID=60545) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:31:28.334+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:31:28.338+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:31:28.337+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:31:28.374+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:31:28.401+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:31:28.401+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:31:28.416+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:31:28.416+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:31:28.425+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-12T02:31:58.781+0000] {processor.py:157} INFO - Started process (PID=60555) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:31:58.784+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:31:58.794+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:31:58.792+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:31:58.828+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:31:58.858+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:31:58.858+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:31:58.872+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:31:58.872+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:31:58.882+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-12T02:32:29.068+0000] {processor.py:157} INFO - Started process (PID=60565) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:32:29.069+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:32:29.071+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:32:29.070+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:32:29.088+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:32:29.104+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:32:29.104+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:32:29.116+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:32:29.116+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:32:29.127+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-12T02:32:59.437+0000] {processor.py:157} INFO - Started process (PID=60575) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:32:59.438+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:32:59.457+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:32:59.453+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:32:59.495+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:32:59.535+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:32:59.535+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:32:59.567+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:32:59.567+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:32:59.581+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.149 seconds
[2024-09-12T02:33:29.765+0000] {processor.py:157} INFO - Started process (PID=60585) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:33:29.767+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:33:29.770+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:33:29.769+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:33:29.807+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:33:29.856+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:33:29.856+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:33:29.879+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:33:29.879+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:33:29.890+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-09-12T02:34:00.088+0000] {processor.py:157} INFO - Started process (PID=60595) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:34:00.096+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:34:00.104+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:34:00.102+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:34:00.124+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:34:00.150+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:34:00.150+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:34:00.170+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:34:00.170+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:34:00.183+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-12T02:34:30.539+0000] {processor.py:157} INFO - Started process (PID=60605) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:34:30.546+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:34:30.553+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:34:30.553+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:34:30.578+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:34:30.627+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:34:30.627+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:34:30.649+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:34:30.649+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:34:30.659+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-12T02:35:01.028+0000] {processor.py:157} INFO - Started process (PID=60615) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:35:01.033+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:35:01.040+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:35:01.040+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:35:01.076+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:35:01.138+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:35:01.138+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:35:01.157+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:35:01.156+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:35:01.168+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.164 seconds
[2024-09-12T02:35:31.339+0000] {processor.py:157} INFO - Started process (PID=60624) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:35:31.341+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:35:31.344+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:35:31.344+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:35:31.357+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:35:31.379+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:35:31.379+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:35:31.391+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:35:31.391+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:35:31.401+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-12T02:36:01.727+0000] {processor.py:157} INFO - Started process (PID=60635) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:36:01.728+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:36:01.732+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:36:01.732+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:36:01.748+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:36:01.776+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:36:01.776+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:36:01.789+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:36:01.789+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:36:01.800+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-12T02:36:32.022+0000] {processor.py:157} INFO - Started process (PID=60645) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:36:32.024+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:36:32.026+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:36:32.026+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:36:32.038+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:36:32.053+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:36:32.053+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:36:32.065+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:36:32.065+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:36:32.071+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-12T02:37:02.382+0000] {processor.py:157} INFO - Started process (PID=60655) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:37:02.383+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:37:02.391+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:37:02.391+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:37:02.401+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:37:02.418+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:37:02.418+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:37:02.428+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:37:02.427+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:37:02.437+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-12T02:37:32.736+0000] {processor.py:157} INFO - Started process (PID=60665) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:37:32.739+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:37:32.741+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:37:32.741+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:37:32.755+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:37:32.776+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:37:32.776+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:37:32.789+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:37:32.789+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:37:32.799+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-12T02:38:03.053+0000] {processor.py:157} INFO - Started process (PID=60675) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:38:03.054+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:38:03.055+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:38:03.055+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:38:03.066+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:38:03.081+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:38:03.081+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:38:03.092+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:38:03.092+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:38:03.101+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-12T02:38:33.402+0000] {processor.py:157} INFO - Started process (PID=60685) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:38:33.403+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:38:33.405+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:38:33.405+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:38:33.419+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:38:33.434+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:38:33.434+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:38:33.444+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:38:33.444+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:38:33.454+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-12T02:39:03.698+0000] {processor.py:157} INFO - Started process (PID=60695) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:39:03.699+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:39:03.701+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:39:03.701+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:39:03.714+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:39:03.727+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:39:03.727+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:39:03.738+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:39:03.738+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:39:03.748+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-12T02:39:34.056+0000] {processor.py:157} INFO - Started process (PID=60705) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:39:34.057+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:39:34.058+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:39:34.058+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:39:34.070+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:39:34.084+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:39:34.084+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:39:34.093+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:39:34.093+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:39:34.102+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-09-12T02:40:04.397+0000] {processor.py:157} INFO - Started process (PID=60715) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:40:04.398+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:40:04.400+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:40:04.399+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:40:04.407+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:40:04.423+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:40:04.423+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:40:04.434+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:40:04.433+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:40:04.444+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-12T02:40:34.709+0000] {processor.py:157} INFO - Started process (PID=60725) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:40:34.710+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:40:34.712+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:40:34.712+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:40:34.721+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:40:34.738+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:40:34.738+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:40:34.749+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:40:34.749+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:40:34.757+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-12T02:41:05.033+0000] {processor.py:157} INFO - Started process (PID=60735) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:41:05.033+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:41:05.035+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:41:05.035+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:41:05.049+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:41:05.063+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:41:05.063+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:41:05.073+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:41:05.073+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:41:05.083+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-12T02:41:35.463+0000] {processor.py:157} INFO - Started process (PID=60745) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:41:35.466+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:41:35.468+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:41:35.468+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:41:35.483+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:41:35.504+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:41:35.504+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:41:35.516+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:41:35.516+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:41:35.526+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-12T02:42:05.722+0000] {processor.py:157} INFO - Started process (PID=60755) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:42:05.723+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:42:05.725+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:42:05.725+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:42:05.738+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:42:05.754+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:42:05.754+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:42:05.764+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:42:05.764+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:42:05.774+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-12T02:42:36.109+0000] {processor.py:157} INFO - Started process (PID=60765) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:42:36.110+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:42:36.112+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:42:36.112+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:42:36.127+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:42:36.141+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:42:36.141+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:42:36.152+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:42:36.152+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:42:36.160+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-12T02:43:06.505+0000] {processor.py:157} INFO - Started process (PID=60775) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:43:06.506+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:43:06.507+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:43:06.507+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:43:06.516+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:43:06.534+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:43:06.534+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:43:06.545+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:43:06.545+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:43:06.554+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-12T02:43:36.835+0000] {processor.py:157} INFO - Started process (PID=60785) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:43:36.836+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:43:36.837+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:43:36.837+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:43:36.847+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:43:36.863+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:43:36.863+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:43:36.873+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:43:36.873+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:43:36.882+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-12T02:44:07.217+0000] {processor.py:157} INFO - Started process (PID=60795) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:44:07.219+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:44:07.220+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:44:07.220+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:44:07.230+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:44:07.247+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:44:07.247+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:44:07.258+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:44:07.258+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:44:07.270+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-12T02:44:37.522+0000] {processor.py:157} INFO - Started process (PID=60805) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:44:37.523+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:44:37.526+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:44:37.526+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:44:37.535+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:44:37.552+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:44:37.551+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:44:37.561+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:44:37.561+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:44:37.571+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-12T02:45:07.814+0000] {processor.py:157} INFO - Started process (PID=60815) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:45:07.815+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:45:07.817+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:45:07.816+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:45:07.826+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:45:07.842+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:45:07.842+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:45:07.854+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:45:07.854+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:45:07.864+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-12T02:45:38.201+0000] {processor.py:157} INFO - Started process (PID=60825) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:45:38.202+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:45:38.204+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:45:38.204+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:45:38.212+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:45:38.228+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:45:38.228+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:45:38.237+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:45:38.237+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:45:38.245+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-09-12T02:46:08.599+0000] {processor.py:157} INFO - Started process (PID=60835) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:46:08.602+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:46:08.604+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:46:08.604+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:46:08.620+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:46:08.640+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:46:08.640+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:46:08.653+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:46:08.653+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:46:08.664+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-12T02:46:38.903+0000] {processor.py:157} INFO - Started process (PID=60845) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:46:38.905+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:46:38.908+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:46:38.908+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:46:38.916+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:46:38.932+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:46:38.932+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:46:38.942+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:46:38.942+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:46:38.949+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-12T02:47:09.284+0000] {processor.py:157} INFO - Started process (PID=60855) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:47:09.285+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:47:09.287+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:47:09.287+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:47:09.296+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:47:09.312+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:47:09.312+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:47:09.322+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:47:09.322+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:47:09.333+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-12T02:47:39.692+0000] {processor.py:157} INFO - Started process (PID=60865) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:47:39.693+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:47:39.695+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:47:39.695+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:47:39.705+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:47:39.723+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:47:39.723+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:47:39.735+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:47:39.734+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:47:39.744+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-12T02:48:10.011+0000] {processor.py:157} INFO - Started process (PID=60875) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:48:10.012+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:48:10.014+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:48:10.013+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:48:10.023+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:48:10.038+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:48:10.038+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:48:10.048+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:48:10.048+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:48:10.057+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-12T02:48:40.389+0000] {processor.py:157} INFO - Started process (PID=60885) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:48:40.391+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:48:40.393+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:48:40.392+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:48:40.407+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:48:40.428+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:48:40.428+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:48:40.442+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:48:40.442+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:48:40.452+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-12T02:49:10.793+0000] {processor.py:157} INFO - Started process (PID=60895) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:49:10.794+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:49:10.795+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:49:10.795+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:49:10.805+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:49:10.822+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:49:10.822+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:49:10.834+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:49:10.834+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:49:10.844+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-12T02:49:41.145+0000] {processor.py:157} INFO - Started process (PID=60905) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:49:41.146+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:49:41.147+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:49:41.147+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:49:41.156+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:49:41.173+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:49:41.173+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:49:41.186+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:49:41.186+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:49:41.195+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-12T02:50:11.496+0000] {processor.py:157} INFO - Started process (PID=60915) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:50:11.497+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:50:11.498+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:50:11.498+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:50:11.507+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:50:11.523+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:50:11.523+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:50:11.533+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:50:11.533+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:50:11.541+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-09-12T02:50:41.821+0000] {processor.py:157} INFO - Started process (PID=60925) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:50:41.823+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:50:41.826+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:50:41.825+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:50:41.840+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:50:41.860+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:50:41.860+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:50:41.869+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:50:41.869+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:50:41.876+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-12T02:51:12.078+0000] {processor.py:157} INFO - Started process (PID=60935) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:51:12.080+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:51:12.081+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:51:12.081+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:51:12.091+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:51:12.112+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:51:12.112+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:51:12.125+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:51:12.125+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:51:12.135+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-12T02:51:42.442+0000] {processor.py:157} INFO - Started process (PID=60945) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:51:42.443+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:51:42.446+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:51:42.445+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:51:42.462+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:51:42.488+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:51:42.488+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:51:42.499+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:51:42.499+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:51:42.510+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-12T02:52:12.886+0000] {processor.py:157} INFO - Started process (PID=60955) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:52:12.887+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:52:12.889+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:52:12.889+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:52:12.898+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:52:12.915+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:52:12.915+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:52:12.926+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:52:12.926+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:52:12.937+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-12T02:52:43.247+0000] {processor.py:157} INFO - Started process (PID=60965) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:52:43.249+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:52:43.250+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:52:43.250+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:52:43.261+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:52:43.277+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:52:43.277+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:52:43.290+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:52:43.289+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:52:43.298+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-12T02:53:13.608+0000] {processor.py:157} INFO - Started process (PID=60975) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:53:13.610+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:53:13.611+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:53:13.611+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:53:13.624+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:53:13.639+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:53:13.639+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:53:13.651+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:53:13.651+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:53:13.661+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-12T02:53:43.951+0000] {processor.py:157} INFO - Started process (PID=60985) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:53:43.953+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:53:43.955+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:53:43.955+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:53:43.971+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:53:43.989+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:53:43.989+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:53:43.999+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:53:43.999+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:53:44.005+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-12T02:54:14.291+0000] {processor.py:157} INFO - Started process (PID=60995) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:54:14.291+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:54:14.295+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:54:14.294+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:54:14.304+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:54:14.320+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:54:14.320+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:54:14.329+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:54:14.329+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:54:14.337+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-12T02:54:44.726+0000] {processor.py:157} INFO - Started process (PID=61005) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:54:44.727+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:54:44.731+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:54:44.731+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:54:44.745+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:54:44.766+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:54:44.766+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:54:44.778+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:54:44.778+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:54:44.788+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-12T02:55:15.064+0000] {processor.py:157} INFO - Started process (PID=61015) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:55:15.065+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:55:15.068+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:55:15.067+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:55:15.076+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:55:15.094+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:55:15.094+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:55:15.104+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:55:15.104+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:55:15.115+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-12T02:55:45.396+0000] {processor.py:157} INFO - Started process (PID=61025) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:55:45.398+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:55:45.399+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:55:45.399+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:55:45.408+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:55:45.426+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:55:45.426+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:55:45.437+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:55:45.437+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:55:45.445+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-12T02:56:15.710+0000] {processor.py:157} INFO - Started process (PID=61035) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:56:15.711+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:56:15.713+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:56:15.712+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:56:15.727+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:56:15.741+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:56:15.741+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:56:15.751+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:56:15.751+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:56:15.759+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-12T02:56:45.978+0000] {processor.py:157} INFO - Started process (PID=61045) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:56:45.979+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:56:45.980+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:56:45.980+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:56:45.990+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:56:46.006+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:56:46.005+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:56:46.015+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:56:46.015+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:56:46.022+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-09-12T02:57:16.316+0000] {processor.py:157} INFO - Started process (PID=61055) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:57:16.318+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:57:16.319+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:57:16.319+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:57:16.330+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:57:16.346+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:57:16.346+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:57:16.359+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:57:16.359+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:57:16.369+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-12T02:57:46.695+0000] {processor.py:157} INFO - Started process (PID=61065) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:57:46.696+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:57:46.698+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:57:46.698+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:57:46.710+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:57:46.728+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:57:46.727+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:57:46.738+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:57:46.738+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:57:46.749+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-12T02:58:17.083+0000] {processor.py:157} INFO - Started process (PID=61075) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:58:17.084+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:58:17.087+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:58:17.087+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:58:17.102+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:58:17.123+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:58:17.123+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:58:17.137+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:58:17.136+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:58:17.146+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-12T02:58:47.421+0000] {processor.py:157} INFO - Started process (PID=61085) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:58:47.422+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:58:47.423+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:58:47.423+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:58:47.429+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:58:47.442+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:58:47.442+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:58:47.451+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:58:47.451+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:58:47.461+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.042 seconds
[2024-09-12T02:59:17.816+0000] {processor.py:157} INFO - Started process (PID=61095) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:59:17.817+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:59:17.818+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:59:17.818+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:59:17.828+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:59:17.843+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:59:17.843+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:59:17.854+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:59:17.854+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:59:17.864+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-12T02:59:48.184+0000] {processor.py:157} INFO - Started process (PID=61105) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:59:48.185+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T02:59:48.187+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:59:48.187+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:59:48.196+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T02:59:48.214+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:59:48.214+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T02:59:48.225+0000] {logging_mixin.py:151} INFO - [2024-09-12T02:59:48.224+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T02:59:48.235+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-12T03:00:18.549+0000] {processor.py:157} INFO - Started process (PID=61115) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T03:00:18.552+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T03:00:18.554+0000] {logging_mixin.py:151} INFO - [2024-09-12T03:00:18.554+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T03:00:18.564+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T03:00:18.580+0000] {logging_mixin.py:151} INFO - [2024-09-12T03:00:18.580+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T03:00:18.593+0000] {logging_mixin.py:151} INFO - [2024-09-12T03:00:18.593+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T03:00:18.603+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-12T03:00:48.868+0000] {processor.py:157} INFO - Started process (PID=61125) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T03:00:48.870+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T03:00:48.872+0000] {logging_mixin.py:151} INFO - [2024-09-12T03:00:48.872+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T03:00:48.882+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T03:00:48.899+0000] {logging_mixin.py:151} INFO - [2024-09-12T03:00:48.899+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T03:00:48.908+0000] {logging_mixin.py:151} INFO - [2024-09-12T03:00:48.908+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T03:00:48.917+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-12T03:01:19.230+0000] {processor.py:157} INFO - Started process (PID=61135) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T03:01:19.232+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T03:01:19.233+0000] {logging_mixin.py:151} INFO - [2024-09-12T03:01:19.233+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T03:01:19.246+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T03:01:19.258+0000] {logging_mixin.py:151} INFO - [2024-09-12T03:01:19.258+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T03:01:19.271+0000] {logging_mixin.py:151} INFO - [2024-09-12T03:01:19.271+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T03:01:19.283+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-12T03:01:49.597+0000] {processor.py:157} INFO - Started process (PID=61145) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T03:01:49.600+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T03:01:49.602+0000] {logging_mixin.py:151} INFO - [2024-09-12T03:01:49.602+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T03:01:49.617+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T03:01:49.637+0000] {logging_mixin.py:151} INFO - [2024-09-12T03:01:49.637+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T03:01:49.648+0000] {logging_mixin.py:151} INFO - [2024-09-12T03:01:49.648+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T03:01:49.655+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-12T03:02:19.927+0000] {processor.py:157} INFO - Started process (PID=61155) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T03:02:19.928+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T03:02:19.930+0000] {logging_mixin.py:151} INFO - [2024-09-12T03:02:19.930+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T03:02:19.939+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T03:02:19.957+0000] {logging_mixin.py:151} INFO - [2024-09-12T03:02:19.957+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T03:02:19.967+0000] {logging_mixin.py:151} INFO - [2024-09-12T03:02:19.967+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T03:02:19.974+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-12T03:02:50.283+0000] {processor.py:157} INFO - Started process (PID=61165) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T03:02:50.285+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T03:02:50.288+0000] {logging_mixin.py:151} INFO - [2024-09-12T03:02:50.287+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T03:02:50.299+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T03:02:50.316+0000] {logging_mixin.py:151} INFO - [2024-09-12T03:02:50.316+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T03:02:50.327+0000] {logging_mixin.py:151} INFO - [2024-09-12T03:02:50.327+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T03:02:50.337+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-12T03:03:20.558+0000] {processor.py:157} INFO - Started process (PID=61175) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T03:03:20.558+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T03:03:20.560+0000] {logging_mixin.py:151} INFO - [2024-09-12T03:03:20.560+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T03:03:20.568+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T03:03:20.582+0000] {logging_mixin.py:151} INFO - [2024-09-12T03:03:20.582+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T03:03:20.591+0000] {logging_mixin.py:151} INFO - [2024-09-12T03:03:20.591+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T03:03:20.598+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.043 seconds
[2024-09-12T03:03:51.018+0000] {processor.py:157} INFO - Started process (PID=61185) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T03:03:51.021+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T03:03:51.023+0000] {logging_mixin.py:151} INFO - [2024-09-12T03:03:51.023+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T03:03:51.037+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T03:03:51.070+0000] {logging_mixin.py:151} INFO - [2024-09-12T03:03:51.070+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T03:03:51.083+0000] {logging_mixin.py:151} INFO - [2024-09-12T03:03:51.083+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T03:03:51.093+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-12T04:04:58.588+0000] {processor.py:157} INFO - Started process (PID=61196) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T04:04:58.593+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T04:04:58.598+0000] {logging_mixin.py:151} INFO - [2024-09-12T04:04:58.598+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T04:04:58.610+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T04:04:58.646+0000] {logging_mixin.py:151} INFO - [2024-09-12T04:04:58.646+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T04:04:58.668+0000] {logging_mixin.py:151} INFO - [2024-09-12T04:04:58.668+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T04:04:58.687+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-12T04:05:28.873+0000] {processor.py:157} INFO - Started process (PID=61206) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T04:05:28.875+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T04:05:28.879+0000] {logging_mixin.py:151} INFO - [2024-09-12T04:05:28.878+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T04:05:28.916+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T04:05:28.941+0000] {logging_mixin.py:151} INFO - [2024-09-12T04:05:28.941+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T04:05:28.954+0000] {logging_mixin.py:151} INFO - [2024-09-12T04:05:28.954+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T04:05:28.964+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-12T04:06:00.924+0000] {processor.py:157} INFO - Started process (PID=61217) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T04:06:00.926+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T04:06:00.928+0000] {logging_mixin.py:151} INFO - [2024-09-12T04:06:00.928+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T04:06:00.937+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T04:06:00.954+0000] {logging_mixin.py:151} INFO - [2024-09-12T04:06:00.954+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T04:06:00.967+0000] {logging_mixin.py:151} INFO - [2024-09-12T04:06:00.967+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T04:06:00.977+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-12T04:06:34.964+0000] {processor.py:157} INFO - Started process (PID=61227) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T04:06:34.965+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T04:06:34.967+0000] {logging_mixin.py:151} INFO - [2024-09-12T04:06:34.967+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T04:06:34.980+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T04:06:34.997+0000] {logging_mixin.py:151} INFO - [2024-09-12T04:06:34.997+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T04:06:35.009+0000] {logging_mixin.py:151} INFO - [2024-09-12T04:06:35.009+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T04:06:35.019+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-12T04:07:05.322+0000] {processor.py:157} INFO - Started process (PID=61236) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T04:07:05.326+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T04:07:05.329+0000] {logging_mixin.py:151} INFO - [2024-09-12T04:07:05.329+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T04:07:05.344+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T04:07:05.368+0000] {logging_mixin.py:151} INFO - [2024-09-12T04:07:05.368+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T04:07:05.395+0000] {logging_mixin.py:151} INFO - [2024-09-12T04:07:05.395+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T04:07:05.406+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-12T04:07:38.203+0000] {processor.py:157} INFO - Started process (PID=61247) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T04:07:38.204+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T04:07:38.206+0000] {logging_mixin.py:151} INFO - [2024-09-12T04:07:38.206+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T04:07:38.215+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T04:07:38.233+0000] {logging_mixin.py:151} INFO - [2024-09-12T04:07:38.233+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T04:07:38.245+0000] {logging_mixin.py:151} INFO - [2024-09-12T04:07:38.245+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T04:07:38.255+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-12T04:41:10.405+0000] {processor.py:157} INFO - Started process (PID=61257) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T04:41:10.406+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T04:41:10.413+0000] {logging_mixin.py:151} INFO - [2024-09-12T04:41:10.413+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T04:41:10.449+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T04:41:10.512+0000] {logging_mixin.py:151} INFO - [2024-09-12T04:41:10.512+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T04:41:10.551+0000] {logging_mixin.py:151} INFO - [2024-09-12T04:41:10.551+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T04:41:10.595+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.195 seconds
[2024-09-12T05:04:40.974+0000] {processor.py:157} INFO - Started process (PID=61266) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T05:04:40.977+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T05:04:40.994+0000] {logging_mixin.py:151} INFO - [2024-09-12T05:04:40.992+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T05:04:41.038+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T05:04:41.106+0000] {logging_mixin.py:151} INFO - [2024-09-12T05:04:41.106+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T05:04:41.152+0000] {logging_mixin.py:151} INFO - [2024-09-12T05:04:41.152+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T05:04:41.174+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.208 seconds
[2024-09-12T05:10:56.675+0000] {processor.py:157} INFO - Started process (PID=61278) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T05:10:56.683+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T05:10:56.686+0000] {logging_mixin.py:151} INFO - [2024-09-12T05:10:56.685+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T05:10:56.723+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T05:10:56.777+0000] {logging_mixin.py:151} INFO - [2024-09-12T05:10:56.777+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T05:10:56.812+0000] {logging_mixin.py:151} INFO - [2024-09-12T05:10:56.812+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T05:10:56.830+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.165 seconds
[2024-09-12T05:11:27.156+0000] {processor.py:157} INFO - Started process (PID=61289) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T05:11:27.159+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T05:11:27.162+0000] {logging_mixin.py:151} INFO - [2024-09-12T05:11:27.161+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T05:11:27.179+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T05:11:27.207+0000] {logging_mixin.py:151} INFO - [2024-09-12T05:11:27.207+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T05:11:27.220+0000] {logging_mixin.py:151} INFO - [2024-09-12T05:11:27.220+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T05:11:27.231+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-12T05:48:51.383+0000] {processor.py:157} INFO - Started process (PID=61298) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T05:48:51.385+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T05:48:51.386+0000] {logging_mixin.py:151} INFO - [2024-09-12T05:48:51.386+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T05:48:51.393+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T05:48:51.408+0000] {logging_mixin.py:151} INFO - [2024-09-12T05:48:51.408+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T05:48:51.418+0000] {logging_mixin.py:151} INFO - [2024-09-12T05:48:51.417+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T05:48:51.429+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-09-12T05:49:21.790+0000] {processor.py:157} INFO - Started process (PID=61309) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T05:49:21.791+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T05:49:21.793+0000] {logging_mixin.py:151} INFO - [2024-09-12T05:49:21.793+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T05:49:21.808+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T05:49:21.837+0000] {logging_mixin.py:151} INFO - [2024-09-12T05:49:21.837+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T05:49:21.850+0000] {logging_mixin.py:151} INFO - [2024-09-12T05:49:21.850+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T05:49:21.860+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-12T06:05:39.064+0000] {processor.py:157} INFO - Started process (PID=61321) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T06:05:39.069+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T06:05:39.073+0000] {logging_mixin.py:151} INFO - [2024-09-12T06:05:39.073+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T06:05:39.101+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T06:05:39.146+0000] {logging_mixin.py:151} INFO - [2024-09-12T06:05:39.146+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T06:05:39.174+0000] {logging_mixin.py:151} INFO - [2024-09-12T06:05:39.174+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T06:05:39.184+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-12T06:22:52.629+0000] {processor.py:157} INFO - Started process (PID=61331) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T06:22:52.638+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T06:22:52.642+0000] {logging_mixin.py:151} INFO - [2024-09-12T06:22:52.642+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T06:22:52.674+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T06:22:52.724+0000] {logging_mixin.py:151} INFO - [2024-09-12T06:22:52.724+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T06:22:52.750+0000] {logging_mixin.py:151} INFO - [2024-09-12T06:22:52.750+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T06:22:52.783+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.159 seconds
[2024-09-12T07:17:23.633+0000] {processor.py:157} INFO - Started process (PID=61341) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T07:17:23.634+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T07:17:23.637+0000] {logging_mixin.py:151} INFO - [2024-09-12T07:17:23.636+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T07:17:23.661+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T07:17:23.684+0000] {logging_mixin.py:151} INFO - [2024-09-12T07:17:23.684+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T07:17:23.695+0000] {logging_mixin.py:151} INFO - [2024-09-12T07:17:23.695+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T07:17:23.706+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-12T07:17:53.970+0000] {processor.py:157} INFO - Started process (PID=61351) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T07:17:53.973+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T07:17:53.980+0000] {logging_mixin.py:151} INFO - [2024-09-12T07:17:53.978+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T07:17:53.995+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T07:17:54.019+0000] {logging_mixin.py:151} INFO - [2024-09-12T07:17:54.019+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T07:17:54.036+0000] {logging_mixin.py:151} INFO - [2024-09-12T07:17:54.036+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T07:17:54.046+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-12T07:24:48.483+0000] {processor.py:157} INFO - Started process (PID=61361) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T07:24:48.489+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T07:24:48.494+0000] {logging_mixin.py:151} INFO - [2024-09-12T07:24:48.493+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T07:24:48.519+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T07:24:48.572+0000] {logging_mixin.py:151} INFO - [2024-09-12T07:24:48.571+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T07:24:48.595+0000] {logging_mixin.py:151} INFO - [2024-09-12T07:24:48.594+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T07:24:48.615+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-09-12T07:41:11.206+0000] {processor.py:157} INFO - Started process (PID=61371) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T07:41:11.207+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T07:41:11.221+0000] {logging_mixin.py:151} INFO - [2024-09-12T07:41:11.218+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T07:41:11.260+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T07:41:11.358+0000] {logging_mixin.py:151} INFO - [2024-09-12T07:41:11.358+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T07:41:11.398+0000] {logging_mixin.py:151} INFO - [2024-09-12T07:41:11.398+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T07:41:11.419+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.221 seconds
[2024-09-12T08:41:22.350+0000] {processor.py:157} INFO - Started process (PID=61383) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T08:41:22.353+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T08:41:22.356+0000] {logging_mixin.py:151} INFO - [2024-09-12T08:41:22.356+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T08:41:22.373+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T08:41:22.400+0000] {logging_mixin.py:151} INFO - [2024-09-12T08:41:22.400+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T08:41:22.418+0000] {logging_mixin.py:151} INFO - [2024-09-12T08:41:22.418+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T08:41:22.437+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-12T08:41:52.792+0000] {processor.py:157} INFO - Started process (PID=61393) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T08:41:52.795+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T08:41:52.798+0000] {logging_mixin.py:151} INFO - [2024-09-12T08:41:52.798+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T08:41:52.814+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T08:41:52.840+0000] {logging_mixin.py:151} INFO - [2024-09-12T08:41:52.840+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T08:41:52.855+0000] {logging_mixin.py:151} INFO - [2024-09-12T08:41:52.855+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T08:41:52.865+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-12T09:56:31.410+0000] {processor.py:157} INFO - Started process (PID=61403) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T09:56:31.411+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T09:56:31.416+0000] {logging_mixin.py:151} INFO - [2024-09-12T09:56:31.416+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T09:56:31.435+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T09:56:31.462+0000] {logging_mixin.py:151} INFO - [2024-09-12T09:56:31.462+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T09:56:31.474+0000] {logging_mixin.py:151} INFO - [2024-09-12T09:56:31.474+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T09:56:31.484+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-12T09:57:01.827+0000] {processor.py:157} INFO - Started process (PID=61413) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T09:57:01.828+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T09:57:01.832+0000] {logging_mixin.py:151} INFO - [2024-09-12T09:57:01.831+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T09:57:01.849+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T09:57:01.876+0000] {logging_mixin.py:151} INFO - [2024-09-12T09:57:01.875+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T09:57:01.890+0000] {logging_mixin.py:151} INFO - [2024-09-12T09:57:01.890+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T09:57:01.901+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-12T11:02:07.965+0000] {processor.py:157} INFO - Started process (PID=61424) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T11:02:07.975+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T11:02:07.982+0000] {logging_mixin.py:151} INFO - [2024-09-12T11:02:07.982+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T11:02:08.000+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T11:02:08.034+0000] {logging_mixin.py:151} INFO - [2024-09-12T11:02:08.034+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T11:02:08.056+0000] {logging_mixin.py:151} INFO - [2024-09-12T11:02:08.055+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T11:02:08.065+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-09-12T11:57:37.063+0000] {processor.py:157} INFO - Started process (PID=61434) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T11:57:37.070+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T11:57:37.074+0000] {logging_mixin.py:151} INFO - [2024-09-12T11:57:37.073+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T11:57:37.093+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T11:57:37.129+0000] {logging_mixin.py:151} INFO - [2024-09-12T11:57:37.129+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T11:57:37.148+0000] {logging_mixin.py:151} INFO - [2024-09-12T11:57:37.148+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T11:57:37.168+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-12T11:58:07.519+0000] {processor.py:157} INFO - Started process (PID=61445) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T11:58:07.522+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T11:58:07.528+0000] {logging_mixin.py:151} INFO - [2024-09-12T11:58:07.527+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T11:58:07.554+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T11:58:07.588+0000] {logging_mixin.py:151} INFO - [2024-09-12T11:58:07.588+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T11:58:07.608+0000] {logging_mixin.py:151} INFO - [2024-09-12T11:58:07.608+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T11:58:07.619+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-12T12:58:33.830+0000] {processor.py:157} INFO - Started process (PID=61456) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T12:58:33.833+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T12:58:33.836+0000] {logging_mixin.py:151} INFO - [2024-09-12T12:58:33.836+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T12:58:33.862+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T12:58:33.899+0000] {logging_mixin.py:151} INFO - [2024-09-12T12:58:33.899+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T12:58:33.924+0000] {logging_mixin.py:151} INFO - [2024-09-12T12:58:33.924+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T12:58:33.943+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-09-12T12:59:04.142+0000] {processor.py:157} INFO - Started process (PID=61467) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T12:59:04.144+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T12:59:04.148+0000] {logging_mixin.py:151} INFO - [2024-09-12T12:59:04.147+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T12:59:04.176+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T12:59:04.204+0000] {logging_mixin.py:151} INFO - [2024-09-12T12:59:04.204+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T12:59:04.225+0000] {logging_mixin.py:151} INFO - [2024-09-12T12:59:04.225+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T12:59:04.238+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-12T13:59:30.442+0000] {processor.py:157} INFO - Started process (PID=61477) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T13:59:30.444+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T13:59:30.455+0000] {logging_mixin.py:151} INFO - [2024-09-12T13:59:30.452+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T13:59:30.507+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T13:59:30.560+0000] {logging_mixin.py:151} INFO - [2024-09-12T13:59:30.560+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T13:59:30.595+0000] {logging_mixin.py:151} INFO - [2024-09-12T13:59:30.595+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T13:59:30.621+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.198 seconds
[2024-09-12T14:00:00.818+0000] {processor.py:157} INFO - Started process (PID=61486) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:00:00.822+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T14:00:00.826+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:00:00.826+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:00:00.852+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:00:00.876+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:00:00.876+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T14:00:00.895+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:00:00.895+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T14:00:00.908+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-12T14:37:20.143+0000] {processor.py:157} INFO - Started process (PID=61497) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:37:20.152+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T14:37:20.161+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:37:20.160+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:37:20.204+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:37:20.269+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:37:20.269+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T14:37:20.311+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:37:20.311+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T14:37:20.339+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.203 seconds
[2024-09-12T14:37:50.494+0000] {processor.py:157} INFO - Started process (PID=61508) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:37:50.498+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T14:37:50.507+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:37:50.506+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:37:50.581+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:37:50.646+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:37:50.646+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T14:37:50.670+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:37:50.669+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T14:37:50.685+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.215 seconds
[2024-09-12T14:38:20.879+0000] {processor.py:157} INFO - Started process (PID=61518) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:38:20.880+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T14:38:20.883+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:38:20.883+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:38:20.896+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:38:20.914+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:38:20.914+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T14:38:20.925+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:38:20.925+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T14:38:20.935+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-12T14:38:51.474+0000] {processor.py:157} INFO - Started process (PID=61528) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:38:51.475+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T14:38:51.481+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:38:51.481+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:38:51.523+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:38:51.589+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:38:51.589+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T14:38:51.614+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:38:51.614+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T14:38:51.636+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.173 seconds
[2024-09-12T14:39:21.891+0000] {processor.py:157} INFO - Started process (PID=61538) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:39:21.898+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T14:39:21.903+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:39:21.903+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:39:21.940+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:39:22.000+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:39:22.000+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T14:39:22.034+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:39:22.034+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T14:39:22.051+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.188 seconds
[2024-09-12T14:39:52.390+0000] {processor.py:157} INFO - Started process (PID=61548) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:39:52.394+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T14:39:52.403+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:39:52.402+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:39:52.439+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:39:52.492+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:39:52.492+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T14:39:52.544+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:39:52.544+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T14:39:52.577+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.198 seconds
[2024-09-12T14:40:22.924+0000] {processor.py:157} INFO - Started process (PID=61558) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:40:22.927+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T14:40:22.938+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:40:22.937+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:40:22.976+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:40:23.030+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:40:23.030+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T14:40:23.054+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:40:23.054+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T14:40:23.071+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.173 seconds
[2024-09-12T14:40:53.506+0000] {processor.py:157} INFO - Started process (PID=61568) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:40:53.512+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T14:40:53.519+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:40:53.519+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:40:53.552+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:40:53.606+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:40:53.606+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T14:40:53.627+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:40:53.627+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T14:40:53.656+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.158 seconds
[2024-09-12T14:41:24.075+0000] {processor.py:157} INFO - Started process (PID=61578) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:41:24.077+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T14:41:24.084+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:41:24.084+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:41:24.112+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:41:24.166+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:41:24.165+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T14:41:24.188+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:41:24.187+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T14:41:24.203+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.137 seconds
[2024-09-12T14:41:54.436+0000] {processor.py:157} INFO - Started process (PID=61588) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:41:54.438+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T14:41:54.441+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:41:54.440+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:41:54.476+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:41:54.520+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:41:54.520+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T14:41:54.542+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:41:54.542+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T14:41:54.555+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-09-12T14:42:25.283+0000] {processor.py:157} INFO - Started process (PID=61598) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:42:25.289+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T14:42:25.293+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:42:25.293+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:42:25.321+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:42:25.382+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:42:25.382+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T14:42:25.398+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:42:25.397+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T14:42:25.416+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.149 seconds
[2024-09-12T14:42:55.790+0000] {processor.py:157} INFO - Started process (PID=61608) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:42:55.796+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T14:42:55.800+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:42:55.800+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:42:55.825+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:42:55.883+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:42:55.883+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T14:42:55.909+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:42:55.908+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T14:42:55.924+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.142 seconds
[2024-09-12T14:43:26.149+0000] {processor.py:157} INFO - Started process (PID=61618) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:43:26.159+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T14:43:26.168+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:43:26.167+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:43:26.194+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:43:26.255+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:43:26.255+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T14:43:26.276+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:43:26.276+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T14:43:26.290+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.146 seconds
[2024-09-12T14:43:56.440+0000] {processor.py:157} INFO - Started process (PID=61628) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:43:56.446+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T14:43:56.451+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:43:56.451+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:43:56.481+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:43:56.523+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:43:56.523+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T14:43:56.543+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:43:56.543+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T14:43:56.559+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-09-12T14:44:26.797+0000] {processor.py:157} INFO - Started process (PID=61638) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:44:26.802+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T14:44:26.808+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:44:26.807+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:44:26.854+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:44:26.897+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:44:26.897+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T14:44:26.918+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:44:26.918+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T14:44:26.932+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.141 seconds
[2024-09-12T14:44:57.628+0000] {processor.py:157} INFO - Started process (PID=61648) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:44:57.633+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T14:44:57.663+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:44:57.662+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:44:57.690+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:44:57.747+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:44:57.747+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T14:44:57.768+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:44:57.768+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T14:44:57.785+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.165 seconds
[2024-09-12T14:45:28.028+0000] {processor.py:157} INFO - Started process (PID=61658) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:45:28.036+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T14:45:28.046+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:45:28.045+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:45:28.078+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:45:28.153+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:45:28.153+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T14:45:28.173+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:45:28.173+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T14:45:28.189+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.181 seconds
[2024-09-12T14:45:58.374+0000] {processor.py:157} INFO - Started process (PID=61668) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:45:58.376+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T14:45:58.382+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:45:58.382+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:45:58.425+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:45:58.489+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:45:58.489+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T14:45:58.516+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:45:58.516+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T14:45:58.527+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.163 seconds
[2024-09-12T14:46:28.877+0000] {processor.py:157} INFO - Started process (PID=61678) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:46:28.881+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T14:46:28.899+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:46:28.899+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:46:28.932+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:46:28.989+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:46:28.989+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T14:46:29.016+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:46:29.016+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T14:46:29.039+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.173 seconds
[2024-09-12T14:46:59.317+0000] {processor.py:157} INFO - Started process (PID=61687) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:46:59.319+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T14:46:59.326+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:46:59.325+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:46:59.368+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:46:59.420+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:46:59.420+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T14:46:59.438+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:46:59.438+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T14:46:59.448+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-09-12T14:47:29.709+0000] {processor.py:157} INFO - Started process (PID=61698) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:47:29.711+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T14:47:29.716+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:47:29.716+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:47:29.744+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:47:29.783+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:47:29.783+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T14:47:29.810+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:47:29.810+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T14:47:29.821+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-12T14:48:00.212+0000] {processor.py:157} INFO - Started process (PID=61707) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:48:00.221+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T14:48:00.232+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:48:00.231+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:48:00.252+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:48:00.299+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:48:00.299+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T14:48:00.315+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:48:00.315+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T14:48:00.328+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-09-12T14:48:30.622+0000] {processor.py:157} INFO - Started process (PID=61718) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:48:30.625+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T14:48:30.650+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:48:30.650+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:48:30.677+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:48:30.725+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:48:30.725+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T14:48:30.746+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:48:30.746+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T14:48:30.759+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.145 seconds
[2024-09-12T14:49:01.211+0000] {processor.py:157} INFO - Started process (PID=61728) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:49:01.216+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T14:49:01.219+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:49:01.218+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:49:01.238+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:49:01.291+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:49:01.291+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T14:49:01.311+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:49:01.311+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T14:49:01.325+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-12T14:49:31.556+0000] {processor.py:157} INFO - Started process (PID=61737) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:49:31.558+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T14:49:31.581+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:49:31.578+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:49:31.604+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:49:31.651+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:49:31.651+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T14:49:31.690+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:49:31.690+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T14:49:31.702+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.156 seconds
[2024-09-12T14:50:01.869+0000] {processor.py:157} INFO - Started process (PID=61748) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:50:01.875+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T14:50:01.878+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:50:01.878+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:50:01.904+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:50:01.952+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:50:01.951+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T14:50:01.981+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:50:01.981+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T14:50:01.995+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-09-12T14:50:32.245+0000] {processor.py:157} INFO - Started process (PID=61758) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:50:32.248+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T14:50:32.266+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:50:32.263+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:50:32.313+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:50:32.350+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:50:32.350+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T14:50:32.390+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:50:32.390+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T14:50:32.404+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.166 seconds
[2024-09-12T14:51:02.550+0000] {processor.py:157} INFO - Started process (PID=61768) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:51:02.553+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T14:51:02.559+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:51:02.558+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:51:02.585+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:51:02.642+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:51:02.642+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T14:51:02.662+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:51:02.662+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T14:51:02.677+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-09-12T14:51:32.926+0000] {processor.py:157} INFO - Started process (PID=61778) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:51:32.932+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T14:51:32.939+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:51:32.939+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:51:32.963+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:51:33.024+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:51:33.024+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T14:51:33.041+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:51:33.041+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T14:51:33.056+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.137 seconds
[2024-09-12T14:52:03.518+0000] {processor.py:157} INFO - Started process (PID=61788) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:52:03.524+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T14:52:03.532+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:52:03.531+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:52:03.566+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:52:03.603+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:52:03.603+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T14:52:03.620+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:52:03.620+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T14:52:03.632+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.278 seconds
[2024-09-12T14:52:33.838+0000] {processor.py:157} INFO - Started process (PID=61798) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:52:33.842+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T14:52:33.847+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:52:33.847+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:52:33.878+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:52:33.937+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:52:33.937+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T14:52:33.958+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:52:33.958+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T14:52:33.972+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.145 seconds
[2024-09-12T14:53:04.302+0000] {processor.py:157} INFO - Started process (PID=61808) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:53:04.306+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T14:53:04.312+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:53:04.311+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:53:04.339+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:53:04.389+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:53:04.388+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T14:53:04.414+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:53:04.414+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T14:53:04.427+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.157 seconds
[2024-09-12T14:53:34.698+0000] {processor.py:157} INFO - Started process (PID=61818) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:53:34.700+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T14:53:34.711+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:53:34.710+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:53:34.738+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:53:34.790+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:53:34.790+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T14:53:34.812+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:53:34.812+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T14:53:34.834+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.141 seconds
[2024-09-12T14:54:05.044+0000] {processor.py:157} INFO - Started process (PID=61828) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:54:05.055+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T14:54:05.064+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:54:05.063+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:54:05.088+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:54:05.126+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:54:05.126+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T14:54:05.162+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:54:05.161+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T14:54:05.180+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.145 seconds
[2024-09-12T14:54:35.471+0000] {processor.py:157} INFO - Started process (PID=61838) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:54:35.474+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T14:54:35.478+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:54:35.477+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:54:35.505+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:54:35.594+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:54:35.594+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T14:54:35.624+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:54:35.624+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T14:54:35.639+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.175 seconds
[2024-09-12T14:55:06.064+0000] {processor.py:157} INFO - Started process (PID=61847) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:55:06.066+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T14:55:06.073+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:55:06.073+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:55:06.112+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:55:06.141+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:55:06.141+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T14:55:06.163+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:55:06.163+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T14:55:06.175+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-12T14:55:36.434+0000] {processor.py:157} INFO - Started process (PID=61858) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:55:36.439+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T14:55:36.444+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:55:36.443+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:55:36.472+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:55:36.514+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:55:36.514+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T14:55:36.549+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:55:36.549+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T14:55:36.566+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-09-12T14:56:06.820+0000] {processor.py:157} INFO - Started process (PID=61868) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:56:06.827+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T14:56:06.834+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:56:06.834+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:56:06.870+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:56:06.916+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:56:06.916+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T14:56:06.939+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:56:06.939+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T14:56:06.953+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.145 seconds
[2024-09-12T14:56:37.201+0000] {processor.py:157} INFO - Started process (PID=61877) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:56:37.203+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T14:56:37.209+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:56:37.208+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:56:37.240+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:56:37.305+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:56:37.305+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T14:56:37.326+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:56:37.326+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T14:56:37.338+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.147 seconds
[2024-09-12T14:57:07.791+0000] {processor.py:157} INFO - Started process (PID=61888) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:57:07.795+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T14:57:07.808+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:57:07.807+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:57:07.833+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:57:07.868+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:57:07.868+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T14:57:07.890+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:57:07.890+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T14:57:07.921+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.158 seconds
[2024-09-12T14:57:38.195+0000] {processor.py:157} INFO - Started process (PID=61898) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:57:38.200+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T14:57:38.203+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:57:38.203+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:57:38.228+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:57:38.292+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:57:38.292+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T14:57:38.315+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:57:38.315+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T14:57:38.330+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.141 seconds
[2024-09-12T14:58:08.654+0000] {processor.py:157} INFO - Started process (PID=61908) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:58:08.657+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T14:58:08.663+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:58:08.662+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:58:08.691+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:58:08.751+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:58:08.751+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T14:58:08.784+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:58:08.784+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T14:58:08.796+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.151 seconds
[2024-09-12T14:58:39.114+0000] {processor.py:157} INFO - Started process (PID=61917) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:58:39.116+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T14:58:39.123+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:58:39.123+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:58:39.157+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:58:39.199+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:58:39.199+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T14:58:39.219+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:58:39.219+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T14:58:39.248+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.141 seconds
[2024-09-12T14:59:09.451+0000] {processor.py:157} INFO - Started process (PID=61928) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:59:09.454+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T14:59:09.462+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:59:09.462+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:59:09.522+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:59:09.586+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:59:09.585+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T14:59:09.610+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:59:09.610+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T14:59:09.626+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.183 seconds
[2024-09-12T14:59:39.865+0000] {processor.py:157} INFO - Started process (PID=61937) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:59:39.868+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T14:59:39.873+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:59:39.873+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:59:39.958+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T14:59:40.025+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:59:40.024+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T14:59:40.044+0000] {logging_mixin.py:151} INFO - [2024-09-12T14:59:40.044+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T14:59:40.069+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.212 seconds
[2024-09-12T15:00:10.239+0000] {processor.py:157} INFO - Started process (PID=61947) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:00:10.249+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:00:10.266+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:00:10.266+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:00:10.303+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:00:10.374+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:00:10.374+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:00:10.400+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:00:10.399+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:00:10.415+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.194 seconds
[2024-09-12T15:00:40.786+0000] {processor.py:157} INFO - Started process (PID=61958) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:00:40.791+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:00:40.794+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:00:40.794+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:00:40.817+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:00:40.857+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:00:40.857+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:00:40.887+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:00:40.887+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:00:40.901+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-12T15:01:11.239+0000] {processor.py:157} INFO - Started process (PID=61966) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:01:11.241+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:01:11.247+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:01:11.247+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:01:11.270+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:01:11.314+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:01:11.314+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:01:11.338+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:01:11.337+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:01:11.355+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-12T15:01:41.650+0000] {processor.py:157} INFO - Started process (PID=61978) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:01:41.652+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:01:41.668+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:01:41.667+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:01:41.687+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:01:41.726+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:01:41.726+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:01:41.740+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:01:41.740+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:01:41.753+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-12T15:02:12.183+0000] {processor.py:157} INFO - Started process (PID=61988) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:02:12.185+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:02:12.191+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:02:12.191+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:02:12.213+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:02:12.250+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:02:12.250+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:02:12.271+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:02:12.271+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:02:12.294+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-12T15:02:42.630+0000] {processor.py:157} INFO - Started process (PID=61998) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:02:42.633+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:02:42.641+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:02:42.640+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:02:42.681+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:02:42.725+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:02:42.725+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:02:42.749+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:02:42.748+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:02:42.764+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-09-12T15:03:12.991+0000] {processor.py:157} INFO - Started process (PID=62008) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:03:12.997+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:03:13.010+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:03:13.009+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:03:13.050+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:03:13.099+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:03:13.098+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:03:13.122+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:03:13.122+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:03:13.133+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.151 seconds
[2024-09-12T15:03:43.537+0000] {processor.py:157} INFO - Started process (PID=62018) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:03:43.540+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:03:43.547+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:03:43.546+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:03:43.574+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:03:43.629+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:03:43.629+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:03:43.650+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:03:43.650+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:03:43.663+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-09-12T15:04:14.040+0000] {processor.py:157} INFO - Started process (PID=62028) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:04:14.051+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:04:14.070+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:04:14.068+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:04:14.107+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:04:14.150+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:04:14.150+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:04:14.186+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:04:14.186+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:04:14.203+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.171 seconds
[2024-09-12T15:04:44.363+0000] {processor.py:157} INFO - Started process (PID=62038) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:04:44.373+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:04:44.386+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:04:44.385+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:04:44.415+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:04:44.454+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:04:44.454+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:04:44.506+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:04:44.505+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:04:44.546+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.196 seconds
[2024-09-12T15:05:14.805+0000] {processor.py:157} INFO - Started process (PID=62048) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:05:14.806+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:05:14.811+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:05:14.809+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:05:14.838+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:05:14.885+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:05:14.885+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:05:14.900+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:05:14.900+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:05:14.911+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-12T15:05:45.228+0000] {processor.py:157} INFO - Started process (PID=62058) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:05:45.238+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:05:45.251+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:05:45.250+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:05:45.275+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:05:45.321+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:05:45.321+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:05:45.342+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:05:45.342+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:05:45.357+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.142 seconds
[2024-09-12T15:06:15.574+0000] {processor.py:157} INFO - Started process (PID=62067) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:06:15.582+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:06:15.589+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:06:15.588+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:06:15.619+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:06:15.683+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:06:15.683+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:06:15.704+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:06:15.704+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:06:15.720+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.165 seconds
[2024-09-12T15:06:45.970+0000] {processor.py:157} INFO - Started process (PID=62078) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:06:45.971+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:06:45.977+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:06:45.976+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:06:46.003+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:06:46.035+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:06:46.034+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:06:46.051+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:06:46.051+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:06:46.063+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-12T15:07:16.435+0000] {processor.py:157} INFO - Started process (PID=62088) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:07:16.443+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:07:16.452+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:07:16.449+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:07:16.477+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:07:16.512+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:07:16.512+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:07:16.542+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:07:16.542+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:07:16.556+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.145 seconds
[2024-09-12T15:07:46.841+0000] {processor.py:157} INFO - Started process (PID=62098) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:07:46.846+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:07:46.851+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:07:46.850+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:07:46.880+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:07:46.953+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:07:46.953+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:07:46.972+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:07:46.972+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:07:46.985+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.162 seconds
[2024-09-12T15:08:17.188+0000] {processor.py:157} INFO - Started process (PID=62108) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:08:17.191+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:08:17.199+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:08:17.198+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:08:17.231+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:08:17.276+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:08:17.276+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:08:17.296+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:08:17.296+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:08:17.316+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.137 seconds
[2024-09-12T15:08:47.533+0000] {processor.py:157} INFO - Started process (PID=62117) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:08:47.535+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:08:47.543+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:08:47.542+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:08:47.575+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:08:47.641+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:08:47.641+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:08:47.659+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:08:47.659+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:08:47.673+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.166 seconds
[2024-09-12T15:09:17.900+0000] {processor.py:157} INFO - Started process (PID=62128) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:09:17.909+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:09:17.923+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:09:17.923+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:09:17.952+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:09:17.993+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:09:17.993+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:09:18.016+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:09:18.016+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:09:18.036+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.143 seconds
[2024-09-12T15:09:48.402+0000] {processor.py:157} INFO - Started process (PID=62137) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:09:48.406+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:09:48.423+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:09:48.417+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:09:48.459+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:09:48.503+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:09:48.503+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:09:48.520+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:09:48.520+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:09:48.533+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.146 seconds
[2024-09-12T15:10:18.760+0000] {processor.py:157} INFO - Started process (PID=62147) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:10:18.763+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:10:18.769+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:10:18.767+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:10:18.797+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:10:18.856+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:10:18.856+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:10:18.878+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:10:18.877+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:10:18.893+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.142 seconds
[2024-09-12T15:10:49.140+0000] {processor.py:157} INFO - Started process (PID=62158) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:10:49.141+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:10:49.144+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:10:49.144+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:10:49.164+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:10:49.203+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:10:49.203+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:10:49.223+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:10:49.223+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:10:49.234+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-12T15:11:19.386+0000] {processor.py:157} INFO - Started process (PID=62168) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:11:19.391+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:11:19.395+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:11:19.395+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:11:19.406+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:11:19.424+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:11:19.424+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:11:19.434+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:11:19.434+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:11:19.443+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-12T15:11:49.754+0000] {processor.py:157} INFO - Started process (PID=62177) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:11:49.762+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:11:49.777+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:11:49.777+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:11:49.825+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:11:49.878+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:11:49.877+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:11:49.915+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:11:49.915+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:11:49.929+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.184 seconds
[2024-09-12T15:12:20.024+0000] {processor.py:157} INFO - Started process (PID=62188) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:12:20.027+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:12:20.030+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:12:20.030+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:12:20.046+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:12:20.067+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:12:20.067+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:12:20.096+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:12:20.096+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:12:20.109+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-12T15:12:50.382+0000] {processor.py:157} INFO - Started process (PID=62198) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:12:50.383+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:12:50.386+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:12:50.386+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:12:50.398+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:12:50.419+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:12:50.418+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:12:50.433+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:12:50.433+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:12:50.444+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-12T15:13:20.703+0000] {processor.py:157} INFO - Started process (PID=62207) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:13:20.705+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:13:20.711+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:13:20.711+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:13:20.733+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:13:20.757+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:13:20.757+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:13:20.778+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:13:20.778+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:13:20.792+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-12T15:13:51.052+0000] {processor.py:157} INFO - Started process (PID=62218) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:13:51.054+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:13:51.059+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:13:51.059+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:13:51.076+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:13:51.130+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:13:51.130+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:13:51.148+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:13:51.148+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:13:51.161+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-12T15:14:21.492+0000] {processor.py:157} INFO - Started process (PID=62228) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:14:21.497+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:14:21.500+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:14:21.500+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:14:21.520+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:14:21.560+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:14:21.560+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:14:21.575+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:14:21.575+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:14:21.586+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-12T15:14:51.934+0000] {processor.py:157} INFO - Started process (PID=62238) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:14:51.937+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:14:51.953+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:14:51.953+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:14:51.981+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:14:52.009+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:14:52.009+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:14:52.026+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:14:52.026+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:14:52.039+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-09-12T15:15:22.472+0000] {processor.py:157} INFO - Started process (PID=62248) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:15:22.475+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:15:22.482+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:15:22.481+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:15:22.534+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:15:22.577+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:15:22.577+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:15:22.606+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:15:22.606+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:15:22.621+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.169 seconds
[2024-09-12T15:15:52.818+0000] {processor.py:157} INFO - Started process (PID=62258) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:15:52.822+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:15:52.825+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:15:52.825+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:15:52.843+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:15:52.871+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:15:52.871+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:15:52.892+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:15:52.892+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:15:52.902+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-09-12T15:16:23.120+0000] {processor.py:157} INFO - Started process (PID=62268) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:16:23.122+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:16:23.124+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:16:23.124+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:16:23.135+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:16:23.157+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:16:23.157+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:16:23.168+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:16:23.168+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:16:23.177+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-12T15:16:53.463+0000] {processor.py:157} INFO - Started process (PID=62278) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:16:53.465+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:16:53.471+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:16:53.470+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:16:53.496+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:16:53.537+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:16:53.537+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:16:53.559+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:16:53.559+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:16:53.574+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-09-12T15:17:23.726+0000] {processor.py:157} INFO - Started process (PID=62288) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:17:23.728+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:17:23.731+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:17:23.731+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:17:23.745+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:17:23.777+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:17:23.777+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:17:23.791+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:17:23.791+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:17:23.802+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-12T15:17:54.113+0000] {processor.py:157} INFO - Started process (PID=62298) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:17:54.116+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:17:54.119+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:17:54.119+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:17:54.132+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:17:54.158+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:17:54.158+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:17:54.300+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:17:54.299+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:17:54.440+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.331 seconds
[2024-09-12T15:18:24.775+0000] {processor.py:157} INFO - Started process (PID=62308) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:18:24.783+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:18:24.808+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:18:24.806+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:18:24.839+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:18:24.897+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:18:24.897+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:18:24.920+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:18:24.920+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:18:24.936+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.169 seconds
[2024-09-12T15:18:55.073+0000] {processor.py:157} INFO - Started process (PID=62318) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:18:55.075+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:18:55.078+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:18:55.077+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:18:55.097+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:18:55.117+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:18:55.117+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:18:55.135+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:18:55.134+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:18:55.145+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-12T15:19:25.459+0000] {processor.py:157} INFO - Started process (PID=62328) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:19:25.461+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:19:25.465+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:19:25.464+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:19:25.490+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:19:25.546+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:19:25.546+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:19:25.565+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:19:25.565+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:19:25.578+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-12T15:19:55.794+0000] {processor.py:157} INFO - Started process (PID=62338) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:19:55.797+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:19:55.801+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:19:55.801+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:19:55.819+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:19:55.850+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:19:55.850+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:19:55.869+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:19:55.869+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:19:55.880+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-12T15:20:26.160+0000] {processor.py:157} INFO - Started process (PID=62348) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:20:26.163+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:20:26.170+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:20:26.169+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:20:26.197+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:20:26.264+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:20:26.264+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:20:26.293+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:20:26.293+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:20:26.313+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.176 seconds
[2024-09-12T15:20:56.481+0000] {processor.py:157} INFO - Started process (PID=62358) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:20:56.484+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:20:56.489+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:20:56.488+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:20:56.508+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:20:56.539+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:20:56.538+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:20:56.561+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:20:56.560+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:20:56.577+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-12T15:21:26.823+0000] {processor.py:157} INFO - Started process (PID=62368) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:21:26.826+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:21:26.828+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:21:26.828+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:21:26.843+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:21:26.867+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:21:26.867+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:21:26.889+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:21:26.889+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:21:26.907+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-12T15:21:57.102+0000] {processor.py:157} INFO - Started process (PID=62378) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:21:57.105+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:21:57.106+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:21:57.106+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:21:57.132+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:21:57.162+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:21:57.162+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:21:57.182+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:21:57.182+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:21:57.195+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-12T15:22:27.423+0000] {processor.py:157} INFO - Started process (PID=62388) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:22:27.428+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:22:27.434+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:22:27.434+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:22:27.478+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:22:27.514+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:22:27.514+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:22:27.532+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:22:27.531+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:22:27.547+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-09-12T15:22:57.853+0000] {processor.py:157} INFO - Started process (PID=62398) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:22:57.854+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:22:57.856+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:22:57.856+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:22:57.873+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:22:57.897+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:22:57.897+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:22:57.912+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:22:57.912+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:22:57.925+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-12T15:23:28.150+0000] {processor.py:157} INFO - Started process (PID=62407) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:23:28.154+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:23:28.160+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:23:28.159+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:23:28.202+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:23:28.240+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:23:28.240+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:23:28.260+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:23:28.260+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:23:28.277+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-09-12T15:23:58.477+0000] {processor.py:157} INFO - Started process (PID=62418) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:23:58.481+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:23:58.499+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:23:58.497+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:23:58.537+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:23:58.597+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:23:58.596+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:23:58.621+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:23:58.620+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:23:58.637+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.170 seconds
[2024-09-12T15:24:28.837+0000] {processor.py:157} INFO - Started process (PID=62428) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:24:28.838+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:24:28.842+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:24:28.842+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:24:28.857+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:24:28.898+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:24:28.898+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:24:28.918+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:24:28.917+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:24:28.931+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-12T15:24:59.103+0000] {processor.py:157} INFO - Started process (PID=62438) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:24:59.107+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:24:59.112+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:24:59.112+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:24:59.135+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:24:59.199+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:24:59.199+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:24:59.220+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:24:59.220+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:24:59.235+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.137 seconds
[2024-09-12T15:25:29.471+0000] {processor.py:157} INFO - Started process (PID=62448) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:25:29.481+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:25:29.496+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:25:29.495+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:25:29.518+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:25:29.551+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:25:29.551+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:25:29.576+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:25:29.576+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:25:29.590+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-09-12T15:25:59.962+0000] {processor.py:157} INFO - Started process (PID=62457) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:25:59.966+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:25:59.971+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:25:59.971+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:25:59.998+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:26:00.032+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:26:00.032+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:26:00.048+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:26:00.048+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:26:00.063+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-12T15:26:30.243+0000] {processor.py:157} INFO - Started process (PID=62468) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:26:30.244+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:26:30.247+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:26:30.247+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:26:30.266+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:26:30.284+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:26:30.284+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:26:30.301+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:26:30.301+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:26:30.313+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-12T15:27:00.667+0000] {processor.py:157} INFO - Started process (PID=62476) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:27:00.670+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:27:00.678+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:27:00.678+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:27:00.702+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:27:00.768+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:27:00.768+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:27:00.790+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:27:00.790+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:27:00.800+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.157 seconds
[2024-09-12T15:27:30.995+0000] {processor.py:157} INFO - Started process (PID=62488) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:27:30.996+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:27:31.001+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:27:31.001+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:27:31.017+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:27:31.044+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:27:31.044+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:27:31.059+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:27:31.059+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:27:31.074+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-12T15:28:01.439+0000] {processor.py:157} INFO - Started process (PID=62498) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:28:01.442+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:28:01.446+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:28:01.446+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:28:01.468+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:28:01.504+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:28:01.504+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:28:01.536+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:28:01.535+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:28:01.547+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-09-12T15:28:31.852+0000] {processor.py:157} INFO - Started process (PID=62508) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:28:31.853+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:28:31.856+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:28:31.856+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:28:31.867+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:28:31.891+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:28:31.890+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:28:31.903+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:28:31.903+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:28:31.916+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-12T15:29:02.194+0000] {processor.py:157} INFO - Started process (PID=62518) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:29:02.198+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:29:02.200+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:29:02.200+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:29:02.225+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:29:02.255+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:29:02.255+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:29:02.271+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:29:02.270+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:29:02.283+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-12T15:29:32.466+0000] {processor.py:157} INFO - Started process (PID=62528) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:29:32.467+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:29:32.471+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:29:32.471+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:29:32.498+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:29:32.522+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:29:32.522+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:29:32.537+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:29:32.537+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:29:32.549+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-12T15:30:02.902+0000] {processor.py:157} INFO - Started process (PID=62538) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:30:02.905+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:30:02.907+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:30:02.907+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:30:02.922+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:30:02.949+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:30:02.949+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:30:02.965+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:30:02.965+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:30:02.980+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-12T15:30:33.307+0000] {processor.py:157} INFO - Started process (PID=62548) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:30:33.308+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:30:33.312+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:30:33.312+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:30:33.329+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:30:33.363+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:30:33.363+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:30:33.381+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:30:33.381+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:30:33.393+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-12T15:31:03.738+0000] {processor.py:157} INFO - Started process (PID=62558) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:31:03.739+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:31:03.748+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:31:03.747+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:31:03.771+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:31:03.803+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:31:03.803+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:31:03.818+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:31:03.818+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:31:03.830+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-12T15:31:34.089+0000] {processor.py:157} INFO - Started process (PID=62568) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:31:34.092+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:31:34.099+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:31:34.099+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:31:34.154+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:31:34.199+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:31:34.199+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:31:34.222+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:31:34.221+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:31:34.237+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.156 seconds
[2024-09-12T15:32:04.600+0000] {processor.py:157} INFO - Started process (PID=62578) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:32:04.601+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:32:04.608+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:32:04.607+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:32:04.636+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:32:04.684+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:32:04.684+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:32:04.709+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:32:04.709+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:32:04.726+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-09-12T15:32:34.979+0000] {processor.py:157} INFO - Started process (PID=62588) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:32:34.985+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:32:34.992+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:32:34.992+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:32:35.014+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:32:35.074+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:32:35.073+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:32:35.099+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:32:35.099+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:32:35.115+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.145 seconds
[2024-09-12T15:33:05.370+0000] {processor.py:157} INFO - Started process (PID=62598) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:33:05.373+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:33:05.377+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:33:05.377+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:33:05.396+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:33:05.443+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:33:05.443+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:33:05.460+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:33:05.460+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:33:05.474+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-09-12T15:33:35.817+0000] {processor.py:157} INFO - Started process (PID=62607) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:33:35.820+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:33:35.827+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:33:35.827+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:33:35.850+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:33:35.919+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:33:35.918+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:33:35.938+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:33:35.938+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:33:35.953+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.143 seconds
[2024-09-12T15:34:06.123+0000] {processor.py:157} INFO - Started process (PID=62618) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:34:06.124+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:34:06.129+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:34:06.129+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:34:06.145+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:34:06.174+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:34:06.174+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:34:06.190+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:34:06.190+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:34:06.202+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-12T15:34:36.448+0000] {processor.py:157} INFO - Started process (PID=62628) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:34:36.456+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:34:36.458+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:34:36.458+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:34:36.468+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:34:36.484+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:34:36.484+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:34:36.495+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:34:36.495+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:34:36.504+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-12T15:35:06.767+0000] {processor.py:157} INFO - Started process (PID=62638) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:35:06.770+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:35:06.772+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:35:06.772+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:35:06.791+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:35:06.816+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:35:06.816+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:35:06.831+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:35:06.831+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:35:06.844+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-12T15:35:37.073+0000] {processor.py:157} INFO - Started process (PID=62648) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:35:37.075+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:35:37.081+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:35:37.080+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:35:37.101+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:35:37.130+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:35:37.130+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:35:37.146+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:35:37.146+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:35:37.158+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-12T15:36:07.380+0000] {processor.py:157} INFO - Started process (PID=62658) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:36:07.383+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:36:07.385+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:36:07.385+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:36:07.396+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:36:07.416+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:36:07.416+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:36:07.427+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:36:07.427+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:36:07.438+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-12T15:36:37.735+0000] {processor.py:157} INFO - Started process (PID=62668) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:36:37.737+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:36:37.742+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:36:37.741+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:36:37.781+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:36:37.812+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:36:37.812+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:36:37.831+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:36:37.831+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:36:37.849+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-12T15:37:08.054+0000] {processor.py:157} INFO - Started process (PID=62678) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:37:08.059+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:37:08.062+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:37:08.062+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:37:08.088+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:37:08.111+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:37:08.111+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:37:08.124+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:37:08.124+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:37:08.134+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-12T15:37:38.482+0000] {processor.py:157} INFO - Started process (PID=62688) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:37:38.488+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:37:38.492+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:37:38.492+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:37:38.533+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:37:38.564+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:37:38.563+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:37:38.578+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:37:38.577+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:37:38.589+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-12T15:38:08.830+0000] {processor.py:157} INFO - Started process (PID=62698) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:38:08.833+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:38:08.836+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:38:08.836+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:38:08.850+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:38:08.873+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:38:08.873+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:38:08.887+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:38:08.887+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:38:08.898+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-12T15:38:39.316+0000] {processor.py:157} INFO - Started process (PID=62708) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:38:39.319+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:38:39.322+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:38:39.322+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:38:39.343+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:38:39.390+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:38:39.390+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:38:39.405+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:38:39.405+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:38:39.418+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-09-12T15:39:09.661+0000] {processor.py:157} INFO - Started process (PID=62718) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:39:09.667+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:39:09.674+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:39:09.673+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:39:09.698+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:39:09.751+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:39:09.751+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:39:09.770+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:39:09.769+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:39:09.793+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.141 seconds
[2024-09-12T15:39:39.939+0000] {processor.py:157} INFO - Started process (PID=62728) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:39:39.940+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:39:39.944+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:39:39.943+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:39:39.961+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:39:39.992+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:39:39.991+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:39:40.010+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:39:40.010+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:39:40.022+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-12T15:40:10.300+0000] {processor.py:157} INFO - Started process (PID=62738) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:40:10.301+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:40:10.303+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:40:10.303+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:40:10.316+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:40:10.337+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:40:10.337+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:40:10.352+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:40:10.352+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:40:10.367+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-12T15:40:40.598+0000] {processor.py:157} INFO - Started process (PID=62748) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:40:40.605+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:40:40.611+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:40:40.610+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:40:40.629+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:40:40.673+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:40:40.673+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:40:40.690+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:40:40.690+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:40:40.701+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-12T15:41:11.067+0000] {processor.py:157} INFO - Started process (PID=62758) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:41:11.071+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:41:11.082+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:41:11.081+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:41:11.107+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:41:11.137+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:41:11.137+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:41:11.155+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:41:11.155+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:41:11.182+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-12T15:41:41.392+0000] {processor.py:157} INFO - Started process (PID=62768) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:41:41.397+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:41:41.400+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:41:41.400+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:41:41.506+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:41:41.546+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:41:41.546+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:41:41.570+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:41:41.570+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:41:41.582+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.196 seconds
[2024-09-12T15:42:11.700+0000] {processor.py:157} INFO - Started process (PID=62778) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:42:11.702+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:42:11.705+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:42:11.704+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:42:11.726+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:42:11.776+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:42:11.776+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:42:11.795+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:42:11.794+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:42:11.809+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-12T15:42:42.057+0000] {processor.py:157} INFO - Started process (PID=62788) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:42:42.061+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:42:42.065+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:42:42.064+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:42:42.092+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:42:42.140+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:42:42.140+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:42:42.164+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:42:42.163+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:42:42.178+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-09-12T15:43:12.444+0000] {processor.py:157} INFO - Started process (PID=62798) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:43:12.447+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:43:12.451+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:43:12.450+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:43:12.467+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:43:12.493+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:43:12.493+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:43:12.508+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:43:12.508+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:43:12.520+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-12T15:43:42.793+0000] {processor.py:157} INFO - Started process (PID=62808) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:43:42.796+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:43:42.798+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:43:42.798+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:43:42.809+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:43:42.832+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:43:42.832+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:43:42.843+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:43:42.843+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:43:42.855+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-12T15:44:13.166+0000] {processor.py:157} INFO - Started process (PID=62818) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:44:13.167+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:44:13.170+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:44:13.170+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:44:13.192+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:44:13.242+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:44:13.242+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:44:13.261+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:44:13.261+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:44:13.276+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-12T15:44:43.495+0000] {processor.py:157} INFO - Started process (PID=62828) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:44:43.499+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:44:43.503+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:44:43.503+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:44:43.522+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:44:43.550+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:44:43.550+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:44:43.569+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:44:43.569+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:44:43.579+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-12T15:45:13.833+0000] {processor.py:157} INFO - Started process (PID=62838) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:45:13.835+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:45:13.838+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:45:13.837+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:45:13.851+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:45:13.880+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:45:13.880+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:45:13.896+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:45:13.896+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:45:13.913+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-12T15:45:44.140+0000] {processor.py:157} INFO - Started process (PID=62848) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:45:44.144+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:45:44.152+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:45:44.152+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:45:44.169+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:45:44.199+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:45:44.199+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:45:44.215+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:45:44.215+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:45:44.226+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-12T15:46:14.442+0000] {processor.py:157} INFO - Started process (PID=62858) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:46:14.445+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:46:14.448+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:46:14.448+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:46:14.457+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:46:14.477+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:46:14.476+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:46:14.488+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:46:14.488+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:46:14.498+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-12T15:46:44.723+0000] {processor.py:157} INFO - Started process (PID=62868) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:46:44.725+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:46:44.728+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:46:44.728+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:46:44.746+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:46:44.798+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:46:44.798+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:46:44.814+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:46:44.814+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:46:44.824+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-09-12T15:47:15.023+0000] {processor.py:157} INFO - Started process (PID=62878) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:47:15.029+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:47:15.037+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:47:15.036+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:47:15.063+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:47:15.088+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:47:15.088+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:47:15.102+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:47:15.102+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:47:15.113+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-12T15:47:45.371+0000] {processor.py:157} INFO - Started process (PID=62888) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:47:45.375+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:47:45.401+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:47:45.401+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:47:45.423+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:47:45.463+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:47:45.463+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:47:45.491+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:47:45.490+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:47:45.509+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.146 seconds
[2024-09-12T15:48:15.714+0000] {processor.py:157} INFO - Started process (PID=62898) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:48:15.715+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:48:15.720+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:48:15.720+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:48:15.738+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:48:15.776+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:48:15.776+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:48:15.794+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:48:15.794+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:48:15.806+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-12T15:48:46.080+0000] {processor.py:157} INFO - Started process (PID=62908) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:48:46.082+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:48:46.086+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:48:46.086+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:48:46.105+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:48:46.164+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:48:46.164+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:48:46.182+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:48:46.182+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:48:46.195+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-09-12T15:49:16.530+0000] {processor.py:157} INFO - Started process (PID=62917) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:49:16.532+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:49:16.538+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:49:16.537+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:49:16.558+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:49:16.614+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:49:16.614+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:49:16.636+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:49:16.636+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:49:16.651+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-09-12T15:49:46.810+0000] {processor.py:157} INFO - Started process (PID=62928) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:49:46.812+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:49:46.815+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:49:46.815+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:49:46.825+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:49:46.844+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:49:46.844+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:49:46.856+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:49:46.856+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:49:46.865+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-12T15:50:17.159+0000] {processor.py:157} INFO - Started process (PID=62938) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:50:17.161+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:50:17.165+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:50:17.164+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:50:17.183+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:50:17.223+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:50:17.223+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:50:17.245+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:50:17.245+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:50:17.259+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-12T15:50:47.501+0000] {processor.py:157} INFO - Started process (PID=62948) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:50:47.506+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:50:47.516+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:50:47.513+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:50:47.534+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:50:47.563+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:50:47.563+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:50:47.579+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:50:47.579+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:50:47.591+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-09-12T15:51:17.774+0000] {processor.py:157} INFO - Started process (PID=62958) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:51:17.775+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:51:17.778+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:51:17.778+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:51:17.792+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:51:17.809+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:51:17.809+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:51:17.822+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:51:17.822+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:51:17.833+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-12T15:51:48.136+0000] {processor.py:157} INFO - Started process (PID=62968) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:51:48.137+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:51:48.142+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:51:48.141+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:51:48.159+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:51:48.186+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:51:48.186+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:51:48.211+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:51:48.211+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:51:48.227+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-09-12T15:52:18.434+0000] {processor.py:157} INFO - Started process (PID=62978) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:52:18.436+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:52:18.438+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:52:18.438+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:52:18.456+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:52:18.476+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:52:18.476+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:52:18.487+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:52:18.487+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:52:18.499+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-12T15:52:48.796+0000] {processor.py:157} INFO - Started process (PID=62988) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:52:48.797+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:52:48.799+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:52:48.799+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:52:48.818+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:52:48.868+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:52:48.868+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:52:48.885+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:52:48.885+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:52:48.896+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-12T15:53:19.106+0000] {processor.py:157} INFO - Started process (PID=62998) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:53:19.107+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:53:19.114+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:53:19.113+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:53:19.145+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:53:19.178+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:53:19.178+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:53:19.196+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:53:19.196+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:53:19.210+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-12T15:53:49.398+0000] {processor.py:157} INFO - Started process (PID=63008) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:53:49.401+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:53:49.404+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:53:49.404+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:53:49.432+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:53:49.457+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:53:49.457+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:53:49.474+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:53:49.473+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:53:49.490+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-12T15:54:19.748+0000] {processor.py:157} INFO - Started process (PID=63018) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:54:19.751+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:54:19.756+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:54:19.755+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:54:19.770+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:54:19.792+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:54:19.792+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:54:19.811+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:54:19.810+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:54:19.825+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-09-12T15:54:50.146+0000] {processor.py:157} INFO - Started process (PID=63028) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:54:50.148+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:54:50.155+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:54:50.154+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:54:50.181+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:54:50.247+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:54:50.247+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:54:50.268+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:54:50.268+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:54:50.282+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.154 seconds
[2024-09-12T15:55:20.408+0000] {processor.py:157} INFO - Started process (PID=63038) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:55:20.410+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:55:20.412+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:55:20.412+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:55:20.432+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:55:20.451+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:55:20.451+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:55:20.466+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:55:20.466+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:55:20.477+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-12T15:55:50.777+0000] {processor.py:157} INFO - Started process (PID=63048) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:55:50.779+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:55:50.782+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:55:50.782+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:55:50.801+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:55:50.839+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:55:50.839+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:55:50.865+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:55:50.865+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:55:50.892+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-12T15:56:21.098+0000] {processor.py:157} INFO - Started process (PID=63058) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:56:21.100+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:56:21.104+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:56:21.104+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:56:21.124+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:56:21.150+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:56:21.150+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:56:21.168+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:56:21.168+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:56:21.183+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-09-12T15:56:51.792+0000] {processor.py:157} INFO - Started process (PID=63068) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:56:51.797+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:56:51.801+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:56:51.801+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:56:51.822+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:56:51.866+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:56:51.866+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:56:51.888+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:56:51.888+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:56:51.906+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-12T15:57:22.202+0000] {processor.py:157} INFO - Started process (PID=63078) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:57:22.206+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:57:22.211+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:57:22.210+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:57:22.233+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:57:22.285+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:57:22.285+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:57:22.302+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:57:22.302+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:57:22.314+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-12T15:57:52.609+0000] {processor.py:157} INFO - Started process (PID=63088) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:57:52.612+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:57:52.618+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:57:52.618+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:57:52.641+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:57:52.685+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:57:52.685+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:57:52.711+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:57:52.710+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:57:52.726+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-12T15:58:22.970+0000] {processor.py:157} INFO - Started process (PID=63098) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:58:22.978+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:58:22.992+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:58:22.991+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:58:23.015+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:58:23.056+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:58:23.056+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:58:23.095+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:58:23.095+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:58:23.169+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.223 seconds
[2024-09-12T15:58:53.546+0000] {processor.py:157} INFO - Started process (PID=63108) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:58:53.551+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:58:53.564+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:58:53.563+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:58:53.588+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:58:53.652+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:58:53.652+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:58:53.675+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:58:53.674+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:58:53.689+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.151 seconds
[2024-09-12T15:59:23.902+0000] {processor.py:157} INFO - Started process (PID=63118) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:59:23.913+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:59:23.948+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:59:23.948+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:59:23.977+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:59:24.021+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:59:24.021+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:59:24.051+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:59:24.051+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:59:24.065+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.171 seconds
[2024-09-12T15:59:54.311+0000] {processor.py:157} INFO - Started process (PID=63128) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:59:54.313+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T15:59:54.320+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:59:54.319+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:59:54.373+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T15:59:54.413+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:59:54.413+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T15:59:54.433+0000] {logging_mixin.py:151} INFO - [2024-09-12T15:59:54.433+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T15:59:54.448+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.146 seconds
[2024-09-12T16:00:24.680+0000] {processor.py:157} INFO - Started process (PID=63138) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:00:24.691+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:00:24.695+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:00:24.694+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:00:24.721+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:00:24.775+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:00:24.775+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:00:24.803+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:00:24.803+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:00:24.816+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.166 seconds
[2024-09-12T16:00:55.061+0000] {processor.py:157} INFO - Started process (PID=63148) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:00:55.065+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:00:55.087+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:00:55.080+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:00:55.111+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:00:55.151+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:00:55.151+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:00:55.187+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:00:55.187+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:00:55.200+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.152 seconds
[2024-09-12T16:01:25.353+0000] {processor.py:157} INFO - Started process (PID=63158) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:01:25.357+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:01:25.358+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:01:25.358+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:01:25.371+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:01:25.396+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:01:25.396+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:01:25.411+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:01:25.411+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:01:25.423+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-12T16:01:55.760+0000] {processor.py:157} INFO - Started process (PID=63168) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:01:55.763+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:01:55.770+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:01:55.770+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:01:55.796+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:01:55.836+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:01:55.836+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:01:55.880+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:01:55.880+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:01:55.894+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.169 seconds
[2024-09-12T16:02:26.093+0000] {processor.py:157} INFO - Started process (PID=63178) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:02:26.095+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:02:26.100+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:02:26.099+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:02:26.125+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:02:26.165+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:02:26.165+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:02:26.183+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:02:26.183+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:02:26.198+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.143 seconds
[2024-09-12T16:02:56.406+0000] {processor.py:157} INFO - Started process (PID=63188) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:02:56.408+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:02:56.412+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:02:56.411+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:02:56.432+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:02:56.476+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:02:56.476+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:02:56.492+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:02:56.491+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:02:56.502+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-12T16:03:26.715+0000] {processor.py:157} INFO - Started process (PID=63198) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:03:26.718+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:03:26.723+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:03:26.722+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:03:26.759+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:03:26.807+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:03:26.807+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:03:26.846+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:03:26.846+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:03:26.860+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.153 seconds
[2024-09-12T16:03:57.098+0000] {processor.py:157} INFO - Started process (PID=63208) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:03:57.101+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:03:57.104+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:03:57.103+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:03:57.138+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:03:57.191+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:03:57.191+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:03:57.211+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:03:57.211+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:03:57.226+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.137 seconds
[2024-09-12T16:04:27.491+0000] {processor.py:157} INFO - Started process (PID=63218) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:04:27.494+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:04:27.499+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:04:27.498+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:04:27.525+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:04:27.577+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:04:27.577+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:04:27.597+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:04:27.597+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:04:27.614+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.163 seconds
[2024-09-12T16:04:57.863+0000] {processor.py:157} INFO - Started process (PID=63228) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:04:57.873+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:04:57.881+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:04:57.880+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:04:57.903+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:04:57.942+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:04:57.941+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:04:57.979+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:04:57.979+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:04:57.995+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.157 seconds
[2024-09-12T16:05:28.237+0000] {processor.py:157} INFO - Started process (PID=63237) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:05:28.241+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:05:28.244+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:05:28.244+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:05:28.262+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:05:28.309+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:05:28.309+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:05:28.325+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:05:28.325+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:05:28.338+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-12T16:05:58.600+0000] {processor.py:157} INFO - Started process (PID=63247) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:05:58.603+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:05:58.608+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:05:58.608+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:05:58.634+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:05:58.688+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:05:58.687+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:05:58.707+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:05:58.707+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:05:58.724+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.148 seconds
[2024-09-12T16:06:28.998+0000] {processor.py:157} INFO - Started process (PID=63257) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:06:29.002+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:06:29.007+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:06:29.006+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:06:29.044+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:06:29.087+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:06:29.087+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:06:29.122+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:06:29.122+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:06:29.136+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.172 seconds
[2024-09-12T16:06:59.359+0000] {processor.py:157} INFO - Started process (PID=63268) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:06:59.363+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:06:59.391+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:06:59.388+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:06:59.432+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:06:59.476+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:06:59.476+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:06:59.498+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:06:59.498+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:06:59.513+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.164 seconds
[2024-09-12T16:07:29.757+0000] {processor.py:157} INFO - Started process (PID=63278) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:07:29.758+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:07:29.763+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:07:29.763+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:07:29.799+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:07:29.837+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:07:29.836+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:07:29.853+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:07:29.853+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:07:29.865+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-12T16:08:00.178+0000] {processor.py:157} INFO - Started process (PID=63288) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:08:00.188+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:08:00.205+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:08:00.205+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:08:00.229+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:08:00.280+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:08:00.280+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:08:00.298+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:08:00.298+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:08:00.312+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.145 seconds
[2024-09-12T16:08:30.677+0000] {processor.py:157} INFO - Started process (PID=63298) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:08:30.683+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:08:30.690+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:08:30.689+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:08:30.732+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:08:30.778+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:08:30.778+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:08:30.801+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:08:30.801+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:08:30.817+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.150 seconds
[2024-09-12T16:09:01.072+0000] {processor.py:157} INFO - Started process (PID=63308) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:09:01.081+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:09:01.090+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:09:01.090+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:09:01.112+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:09:01.163+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:09:01.163+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:09:01.182+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:09:01.182+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:09:01.209+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.142 seconds
[2024-09-12T16:09:31.450+0000] {processor.py:157} INFO - Started process (PID=63318) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:09:31.453+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:09:31.457+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:09:31.457+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:09:31.536+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:09:31.589+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:09:31.589+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:09:31.617+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:09:31.617+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:09:31.637+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.194 seconds
[2024-09-12T16:10:01.798+0000] {processor.py:157} INFO - Started process (PID=63328) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:10:01.803+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:10:01.812+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:10:01.812+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:10:01.849+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:10:01.885+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:10:01.885+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:10:01.900+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:10:01.900+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:10:01.914+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-09-12T16:10:32.259+0000] {processor.py:157} INFO - Started process (PID=63338) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:10:32.267+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:10:32.274+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:10:32.273+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:10:32.303+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:10:32.394+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:10:32.393+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:10:32.419+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:10:32.419+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:10:32.436+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.194 seconds
[2024-09-12T16:11:02.601+0000] {processor.py:157} INFO - Started process (PID=63348) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:11:02.606+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:11:02.611+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:11:02.610+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:11:02.635+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:11:02.694+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:11:02.694+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:11:02.717+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:11:02.717+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:11:02.730+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.137 seconds
[2024-09-12T16:11:32.905+0000] {processor.py:157} INFO - Started process (PID=63358) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:11:32.907+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:11:32.910+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:11:32.910+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:11:32.919+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:11:32.945+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:11:32.945+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:11:32.959+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:11:32.959+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:11:32.971+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-12T16:12:03.279+0000] {processor.py:157} INFO - Started process (PID=63368) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:12:03.281+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:12:03.294+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:12:03.294+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:12:03.316+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:12:03.362+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:12:03.361+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:12:03.385+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:12:03.385+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:12:03.400+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-09-12T16:12:33.627+0000] {processor.py:157} INFO - Started process (PID=63378) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:12:33.630+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:12:33.634+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:12:33.634+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:12:33.653+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:12:33.684+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:12:33.684+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:12:33.704+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:12:33.704+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:12:33.731+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-09-12T16:13:04.048+0000] {processor.py:157} INFO - Started process (PID=63388) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:13:04.049+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:13:04.051+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:13:04.051+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:13:04.064+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:13:04.090+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:13:04.090+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:13:04.106+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:13:04.106+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:13:04.120+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-12T16:13:34.377+0000] {processor.py:157} INFO - Started process (PID=63398) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:13:34.379+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:13:34.383+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:13:34.383+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:13:34.409+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:13:34.445+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:13:34.445+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:13:34.465+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:13:34.465+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:13:34.478+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-12T16:14:04.705+0000] {processor.py:157} INFO - Started process (PID=63407) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:14:04.714+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:14:04.727+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:14:04.726+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:14:04.770+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:14:04.805+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:14:04.805+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:14:04.825+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:14:04.825+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:14:04.838+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.172 seconds
[2024-09-12T16:14:35.046+0000] {processor.py:157} INFO - Started process (PID=63418) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:14:35.048+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:14:35.054+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:14:35.053+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:14:35.073+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:14:35.103+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:14:35.103+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:14:35.122+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:14:35.122+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:14:35.142+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-12T16:15:05.544+0000] {processor.py:157} INFO - Started process (PID=63426) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:15:05.546+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:15:05.552+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:15:05.552+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:15:05.574+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:15:05.622+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:15:05.622+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:15:05.640+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:15:05.640+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:15:05.653+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-09-12T16:15:35.907+0000] {processor.py:157} INFO - Started process (PID=63438) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:15:35.914+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:15:35.920+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:15:35.920+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:15:35.944+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:15:35.996+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:15:35.996+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:15:36.015+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:15:36.015+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:15:36.028+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.154 seconds
[2024-09-12T16:16:06.373+0000] {processor.py:157} INFO - Started process (PID=63448) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:16:06.375+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:16:06.397+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:16:06.392+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:16:06.433+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:16:06.473+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:16:06.473+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:16:06.511+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:16:06.511+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:16:06.529+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.163 seconds
[2024-09-12T16:16:36.916+0000] {processor.py:157} INFO - Started process (PID=63458) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:16:36.920+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:16:36.924+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:16:36.924+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:16:37.031+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:16:37.094+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:16:37.094+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:16:37.112+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:16:37.112+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:16:37.128+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.239 seconds
[2024-09-12T16:17:07.277+0000] {processor.py:157} INFO - Started process (PID=63468) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:17:07.283+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:17:07.288+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:17:07.287+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:17:07.314+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:17:07.355+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:17:07.355+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:17:07.375+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:17:07.375+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:17:07.388+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-12T16:17:38.043+0000] {processor.py:157} INFO - Started process (PID=63478) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:17:38.049+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:17:38.055+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:17:38.055+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:17:38.094+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:17:38.163+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:17:38.162+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:17:38.184+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:17:38.184+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:17:38.202+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.174 seconds
[2024-09-12T16:18:08.636+0000] {processor.py:157} INFO - Started process (PID=63488) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:18:08.640+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:18:08.643+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:18:08.642+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:18:08.664+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:18:08.699+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:18:08.699+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:18:08.719+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:18:08.719+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:18:08.733+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-12T16:18:39.061+0000] {processor.py:157} INFO - Started process (PID=63498) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:18:39.065+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:18:39.074+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:18:39.074+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:18:39.124+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:18:39.164+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:18:39.164+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:18:39.185+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:18:39.185+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:18:39.205+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.152 seconds
[2024-09-12T16:19:09.622+0000] {processor.py:157} INFO - Started process (PID=63508) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:19:09.628+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:19:09.633+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:19:09.632+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:19:09.666+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:19:09.757+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:19:09.757+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:19:09.802+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:19:09.802+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:19:09.824+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.209 seconds
[2024-09-12T16:19:39.968+0000] {processor.py:157} INFO - Started process (PID=63518) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:19:39.972+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:19:39.977+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:19:39.977+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:19:40.003+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:19:40.036+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:19:40.036+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:19:40.057+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:19:40.057+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:19:40.083+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.146 seconds
[2024-09-12T16:20:10.402+0000] {processor.py:157} INFO - Started process (PID=63528) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:20:10.405+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:20:10.414+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:20:10.413+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:20:10.439+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:20:10.475+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:20:10.475+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:20:10.496+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:20:10.496+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:20:10.512+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-12T16:20:40.768+0000] {processor.py:157} INFO - Started process (PID=63538) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:20:40.769+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:20:40.774+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:20:40.774+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:20:40.789+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:20:40.818+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:20:40.818+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:20:40.833+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:20:40.833+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:20:40.847+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-12T16:21:11.164+0000] {processor.py:157} INFO - Started process (PID=63548) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:21:11.170+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:21:11.173+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:21:11.172+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:21:11.190+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:21:11.212+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:21:11.212+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:21:11.223+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:21:11.223+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:21:11.232+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-12T16:21:41.548+0000] {processor.py:157} INFO - Started process (PID=63558) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:21:41.549+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:21:41.557+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:21:41.556+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:21:41.573+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:21:41.605+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:21:41.605+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:21:41.627+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:21:41.627+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:21:41.643+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-12T16:22:11.887+0000] {processor.py:157} INFO - Started process (PID=63568) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:22:11.892+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:22:11.896+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:22:11.895+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:22:11.909+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:22:11.930+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:22:11.930+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:22:11.947+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:22:11.947+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:22:11.963+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-12T16:22:42.226+0000] {processor.py:157} INFO - Started process (PID=63578) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:22:42.227+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:22:42.228+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:22:42.228+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:22:42.243+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:22:42.265+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:22:42.265+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:22:42.281+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:22:42.281+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:22:42.294+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-12T16:23:12.671+0000] {processor.py:157} INFO - Started process (PID=63588) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:23:12.676+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:23:12.683+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:23:12.681+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:23:12.736+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:23:12.776+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:23:12.776+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:23:12.796+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:23:12.796+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:23:12.809+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.155 seconds
[2024-09-12T16:23:43.046+0000] {processor.py:157} INFO - Started process (PID=63597) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:23:43.049+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:23:43.055+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:23:43.055+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:23:43.084+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:23:43.135+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:23:43.135+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:23:43.156+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:23:43.155+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:23:43.168+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-09-12T16:24:13.292+0000] {processor.py:157} INFO - Started process (PID=63608) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:24:13.293+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:24:13.296+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:24:13.296+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:24:13.312+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:24:13.333+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:24:13.333+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:24:13.349+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:24:13.349+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:24:13.362+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-12T16:24:43.729+0000] {processor.py:157} INFO - Started process (PID=63618) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:24:43.732+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:24:43.737+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:24:43.736+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:24:43.757+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:24:43.803+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:24:43.802+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:24:43.826+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:24:43.826+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:24:43.841+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-09-12T16:25:14.260+0000] {processor.py:157} INFO - Started process (PID=63628) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:25:14.264+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:25:14.271+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:25:14.270+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:25:14.316+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:25:14.361+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:25:14.361+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:25:14.377+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:25:14.377+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:25:14.395+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.143 seconds
[2024-09-12T16:25:44.730+0000] {processor.py:157} INFO - Started process (PID=63638) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:25:44.733+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:25:44.742+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:25:44.741+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:25:44.769+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:25:44.801+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:25:44.801+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:25:44.817+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:25:44.817+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:25:44.831+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-12T16:26:15.134+0000] {processor.py:157} INFO - Started process (PID=63647) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:26:15.139+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:26:15.151+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:26:15.150+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:26:15.194+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:26:15.283+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:26:15.283+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:26:15.306+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:26:15.306+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:26:15.330+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.221 seconds
[2024-09-12T16:26:45.471+0000] {processor.py:157} INFO - Started process (PID=63657) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:26:45.476+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:26:45.485+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:26:45.483+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:26:45.516+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:26:45.575+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:26:45.575+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:26:45.600+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:26:45.600+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:26:45.615+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.158 seconds
[2024-09-12T16:27:15.777+0000] {processor.py:157} INFO - Started process (PID=63667) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:27:15.785+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:27:15.793+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:27:15.792+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:27:15.817+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:27:15.862+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:27:15.862+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:27:15.879+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:27:15.879+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:27:15.901+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-09-12T16:27:46.294+0000] {processor.py:157} INFO - Started process (PID=63677) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:27:46.298+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:27:46.305+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:27:46.304+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:27:46.333+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:27:46.378+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:27:46.377+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:27:46.406+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:27:46.406+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:27:46.420+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-09-12T16:28:16.645+0000] {processor.py:157} INFO - Started process (PID=63687) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:28:16.647+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:28:16.652+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:28:16.651+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:28:16.700+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:28:16.749+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:28:16.749+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:28:16.771+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:28:16.771+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:28:16.787+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.148 seconds
[2024-09-12T16:28:47.108+0000] {processor.py:157} INFO - Started process (PID=63698) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:28:47.111+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:28:47.114+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:28:47.114+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:28:47.135+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:28:47.165+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:28:47.165+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:28:47.187+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:28:47.187+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:28:47.203+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-12T16:29:17.431+0000] {processor.py:157} INFO - Started process (PID=63708) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:29:17.434+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:29:17.469+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:29:17.468+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:29:17.495+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:29:17.533+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:29:17.533+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:29:17.569+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:29:17.569+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:29:17.586+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.163 seconds
[2024-09-12T16:29:47.718+0000] {processor.py:157} INFO - Started process (PID=63718) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:29:47.720+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:29:47.723+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:29:47.723+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:29:47.746+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:29:47.790+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:29:47.790+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:29:47.809+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:29:47.809+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:29:47.826+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-12T16:30:18.060+0000] {processor.py:157} INFO - Started process (PID=63728) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:30:18.061+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:30:18.063+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:30:18.063+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:30:18.077+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:30:18.102+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:30:18.102+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:30:18.117+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:30:18.117+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:30:18.131+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-12T16:30:48.440+0000] {processor.py:157} INFO - Started process (PID=63738) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:30:48.443+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:30:48.449+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:30:48.448+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:30:48.475+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:30:48.514+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:30:48.514+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:30:48.532+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:30:48.532+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:30:48.559+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-09-12T16:31:18.698+0000] {processor.py:157} INFO - Started process (PID=63748) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:31:18.699+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:31:18.704+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:31:18.704+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:31:18.721+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:31:18.746+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:31:18.746+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:31:18.759+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:31:18.759+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:31:18.771+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-12T16:31:48.993+0000] {processor.py:157} INFO - Started process (PID=63758) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:31:48.995+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:31:48.999+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:31:48.998+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:31:49.012+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:31:49.048+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:31:49.048+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:31:49.086+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:31:49.086+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:31:49.108+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-12T16:32:19.277+0000] {processor.py:157} INFO - Started process (PID=63768) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:32:19.278+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:32:19.280+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:32:19.280+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:32:19.296+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:32:19.315+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:32:19.315+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:32:19.328+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:32:19.328+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:32:19.338+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-12T16:32:49.641+0000] {processor.py:157} INFO - Started process (PID=63778) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:32:49.645+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:32:49.652+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:32:49.651+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:32:49.676+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:32:49.709+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:32:49.709+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:32:49.733+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:32:49.733+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:32:49.749+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-12T16:33:19.942+0000] {processor.py:157} INFO - Started process (PID=63788) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:33:19.946+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:33:19.951+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:33:19.951+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:33:19.970+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:33:20.000+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:33:20.000+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:33:20.016+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:33:20.016+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:33:20.028+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-12T16:33:50.350+0000] {processor.py:157} INFO - Started process (PID=63798) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:33:50.352+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:33:50.356+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:33:50.356+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:33:50.371+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:33:50.396+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:33:50.396+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:33:50.413+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:33:50.413+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:33:50.424+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-12T16:34:20.766+0000] {processor.py:157} INFO - Started process (PID=63808) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:34:20.767+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:34:20.777+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:34:20.773+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:34:20.833+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:34:20.872+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:34:20.872+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:34:20.895+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:34:20.895+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:34:20.908+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.154 seconds
[2024-09-12T16:34:51.123+0000] {processor.py:157} INFO - Started process (PID=63818) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:34:51.125+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:34:51.130+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:34:51.129+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:34:51.151+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:34:51.212+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:34:51.212+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:34:51.229+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:34:51.229+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:34:51.244+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-09-12T16:35:21.512+0000] {processor.py:157} INFO - Started process (PID=63828) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:35:21.517+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:35:21.528+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:35:21.526+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:35:21.557+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:35:21.619+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:35:21.618+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:35:21.640+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:35:21.640+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:35:21.653+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.168 seconds
[2024-09-12T16:35:51.859+0000] {processor.py:157} INFO - Started process (PID=63838) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:35:51.861+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:35:51.865+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:35:51.865+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:35:51.890+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:35:51.942+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:35:51.942+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:35:51.983+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:35:51.982+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:35:51.997+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.147 seconds
[2024-09-12T16:36:22.242+0000] {processor.py:157} INFO - Started process (PID=63848) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:36:22.251+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:36:22.267+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:36:22.265+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:36:22.315+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:36:22.353+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:36:22.353+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:36:22.379+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:36:22.379+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:36:22.403+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.175 seconds
[2024-09-12T16:36:52.541+0000] {processor.py:157} INFO - Started process (PID=63858) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:36:52.542+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:36:52.545+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:36:52.545+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:36:52.561+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:36:52.586+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:36:52.585+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:36:52.601+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:36:52.600+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:36:52.615+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-12T16:37:22.834+0000] {processor.py:157} INFO - Started process (PID=63868) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:37:22.836+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:37:22.840+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:37:22.840+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:37:22.860+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:37:22.890+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:37:22.890+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:37:22.906+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:37:22.906+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:37:22.921+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-12T16:37:53.253+0000] {processor.py:157} INFO - Started process (PID=63878) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:37:53.255+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:37:53.262+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:37:53.262+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:37:53.288+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:37:53.340+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:37:53.340+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:37:53.359+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:37:53.359+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:37:53.375+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.160 seconds
[2024-09-12T16:38:23.590+0000] {processor.py:157} INFO - Started process (PID=63888) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:38:23.591+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:38:23.595+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:38:23.595+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:38:23.629+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:38:23.673+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:38:23.673+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:38:23.707+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:38:23.707+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:38:23.738+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.155 seconds
[2024-09-12T16:38:53.912+0000] {processor.py:157} INFO - Started process (PID=63898) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:38:53.914+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:38:53.918+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:38:53.918+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:38:53.936+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:38:53.962+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:38:53.961+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:38:53.980+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:38:53.980+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:38:53.994+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-12T16:39:24.337+0000] {processor.py:157} INFO - Started process (PID=63908) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:39:24.339+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:39:24.346+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:39:24.346+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:39:24.372+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:39:24.433+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:39:24.433+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:39:24.456+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:39:24.456+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:39:24.469+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-09-12T16:39:54.650+0000] {processor.py:157} INFO - Started process (PID=63918) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:39:54.659+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:39:54.682+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:39:54.681+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:39:54.732+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:39:54.771+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:39:54.771+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:39:54.790+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:39:54.790+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:39:54.804+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.161 seconds
[2024-09-12T16:40:25.016+0000] {processor.py:157} INFO - Started process (PID=63928) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:40:25.021+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:40:25.026+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:40:25.026+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:40:25.053+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:40:25.126+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:40:25.126+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:40:25.147+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:40:25.147+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:40:25.169+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.163 seconds
[2024-09-12T16:40:55.470+0000] {processor.py:157} INFO - Started process (PID=63938) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:40:55.474+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:40:55.478+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:40:55.478+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:40:55.495+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:40:55.525+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:40:55.525+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:40:55.541+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:40:55.541+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:40:55.555+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-12T16:41:25.875+0000] {processor.py:157} INFO - Started process (PID=63948) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:41:25.877+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:41:25.884+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:41:25.884+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:41:25.909+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:41:25.946+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:41:25.946+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:41:25.961+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:41:25.961+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:41:25.975+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-12T16:41:56.204+0000] {processor.py:157} INFO - Started process (PID=63958) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:41:56.211+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:41:56.229+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:41:56.226+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:41:56.260+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:41:56.306+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:41:56.306+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:41:56.330+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:41:56.330+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:41:56.353+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.161 seconds
[2024-09-12T16:42:26.592+0000] {processor.py:157} INFO - Started process (PID=63968) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:42:26.594+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:42:26.598+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:42:26.597+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:42:26.617+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:42:26.646+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:42:26.645+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:42:26.666+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:42:26.666+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:42:26.680+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-12T16:42:57.016+0000] {processor.py:157} INFO - Started process (PID=63978) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:42:57.019+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:42:57.027+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:42:57.026+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:42:57.068+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:42:57.103+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:42:57.102+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:42:57.128+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:42:57.127+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:42:57.143+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-09-12T16:43:27.389+0000] {processor.py:157} INFO - Started process (PID=63988) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:43:27.394+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:43:27.400+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:43:27.400+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:43:27.424+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:43:27.476+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:43:27.476+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:43:27.494+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:43:27.494+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:43:27.509+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-09-12T16:43:58.055+0000] {processor.py:157} INFO - Started process (PID=63998) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:43:58.058+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:43:58.068+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:43:58.067+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:43:58.112+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:43:58.160+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:43:58.160+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:43:58.184+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:43:58.184+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:43:58.201+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.162 seconds
[2024-09-12T16:44:28.379+0000] {processor.py:157} INFO - Started process (PID=64008) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:44:28.383+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:44:28.389+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:44:28.388+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:44:28.412+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:44:28.525+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:44:28.525+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:44:28.561+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:44:28.561+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:44:28.576+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.204 seconds
[2024-09-12T16:44:58.953+0000] {processor.py:157} INFO - Started process (PID=64018) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:44:58.959+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:44:58.965+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:44:58.965+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:44:58.991+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:44:59.041+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:44:59.041+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:44:59.060+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:44:59.060+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:44:59.073+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-12T16:45:29.333+0000] {processor.py:157} INFO - Started process (PID=64028) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:45:29.337+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:45:29.345+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:45:29.345+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:45:29.398+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:45:29.456+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:45:29.455+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:45:29.475+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:45:29.474+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:45:29.489+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.165 seconds
[2024-09-12T16:45:59.887+0000] {processor.py:157} INFO - Started process (PID=64038) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:45:59.899+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:45:59.910+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:45:59.910+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:45:59.932+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:45:59.979+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:45:59.979+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:46:00.002+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:46:00.001+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:46:00.018+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-09-12T16:46:30.200+0000] {processor.py:157} INFO - Started process (PID=64048) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:46:30.205+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:46:30.211+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:46:30.210+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:46:30.249+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:46:30.297+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:46:30.297+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:46:30.317+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:46:30.317+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:46:30.332+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.141 seconds
[2024-09-12T16:47:00.533+0000] {processor.py:157} INFO - Started process (PID=64058) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:47:00.538+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:47:00.556+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:47:00.556+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:47:00.575+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:47:00.604+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:47:00.604+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:47:00.618+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:47:00.618+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:47:00.630+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-12T16:47:30.943+0000] {processor.py:157} INFO - Started process (PID=64068) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:47:30.947+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:47:30.953+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:47:30.952+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:47:30.999+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:47:31.035+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:47:31.035+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:47:31.071+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:47:31.071+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:47:31.086+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.151 seconds
[2024-09-12T16:48:01.255+0000] {processor.py:157} INFO - Started process (PID=64077) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:48:01.260+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:48:01.264+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:48:01.263+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:48:01.286+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:48:01.336+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:48:01.336+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:48:01.352+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:48:01.352+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:48:01.363+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-12T16:48:31.540+0000] {processor.py:157} INFO - Started process (PID=64088) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:48:31.541+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:48:31.545+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:48:31.544+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:48:31.566+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:48:31.591+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:48:31.591+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:48:31.607+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:48:31.607+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:48:31.620+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-12T16:49:01.968+0000] {processor.py:157} INFO - Started process (PID=64098) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:49:01.972+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:49:01.975+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:49:01.974+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:49:02.001+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:49:02.032+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:49:02.032+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:49:02.064+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:49:02.064+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:49:02.076+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-12T16:49:32.309+0000] {processor.py:157} INFO - Started process (PID=64108) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:49:32.311+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:49:32.317+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:49:32.316+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:49:32.342+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:49:32.393+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:49:32.393+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:49:32.423+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:49:32.423+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:49:32.440+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.142 seconds
[2024-09-12T16:50:02.653+0000] {processor.py:157} INFO - Started process (PID=64118) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:50:02.656+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:50:02.663+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:50:02.662+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:50:02.688+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:50:02.742+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:50:02.741+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:50:02.760+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:50:02.760+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:50:02.775+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-09-12T16:50:33.001+0000] {processor.py:157} INFO - Started process (PID=64128) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:50:33.010+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:50:33.028+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:50:33.027+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:50:33.058+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:50:33.168+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:50:33.168+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:50:33.193+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:50:33.193+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:50:33.208+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.233 seconds
[2024-09-12T16:51:03.396+0000] {processor.py:157} INFO - Started process (PID=64138) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:51:03.401+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:51:03.405+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:51:03.404+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:51:03.437+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:51:03.495+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:51:03.494+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:51:03.514+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:51:03.514+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:51:03.528+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.141 seconds
[2024-09-12T16:51:33.755+0000] {processor.py:157} INFO - Started process (PID=64148) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:51:33.760+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:51:33.764+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:51:33.763+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:51:33.801+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:51:33.855+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:51:33.855+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:51:33.872+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:51:33.872+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:51:33.885+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.137 seconds
[2024-09-12T16:52:04.081+0000] {processor.py:157} INFO - Started process (PID=64157) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:52:04.085+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:52:04.089+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:52:04.089+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:52:04.110+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:52:04.170+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:52:04.170+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:52:04.189+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:52:04.189+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:52:04.202+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-09-12T16:52:34.592+0000] {processor.py:157} INFO - Started process (PID=64168) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:52:34.599+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:52:34.614+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:52:34.613+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:52:34.642+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:52:34.675+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:52:34.675+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:52:34.704+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:52:34.704+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:52:34.720+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.144 seconds
[2024-09-12T16:53:04.961+0000] {processor.py:157} INFO - Started process (PID=64178) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:53:04.967+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:53:04.973+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:53:04.973+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:53:04.999+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:53:05.041+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:53:05.040+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:53:05.082+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:53:05.082+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:53:05.099+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.146 seconds
[2024-09-12T16:53:35.392+0000] {processor.py:157} INFO - Started process (PID=64188) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:53:35.394+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:53:35.401+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:53:35.400+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:53:35.446+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:53:35.546+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:53:35.546+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:53:35.572+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:53:35.572+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:53:35.607+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.238 seconds
[2024-09-12T16:54:06.036+0000] {processor.py:157} INFO - Started process (PID=64198) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:54:06.043+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:54:06.049+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:54:06.049+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:54:06.074+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:54:06.138+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:54:06.138+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:54:06.159+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:54:06.159+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:54:06.173+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.159 seconds
[2024-09-12T16:54:36.551+0000] {processor.py:157} INFO - Started process (PID=64208) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:54:36.557+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:54:36.572+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:54:36.572+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:54:36.597+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:54:36.646+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:54:36.646+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:54:36.685+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:54:36.684+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:54:36.702+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.165 seconds
[2024-09-12T16:55:06.951+0000] {processor.py:157} INFO - Started process (PID=64218) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:55:06.954+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:55:06.958+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:55:06.957+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:55:06.978+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:55:07.012+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:55:07.012+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:55:07.042+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:55:07.042+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:55:07.058+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-12T16:55:37.274+0000] {processor.py:157} INFO - Started process (PID=64228) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:55:37.280+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:55:37.283+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:55:37.283+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:55:37.300+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:55:37.332+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:55:37.331+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:55:37.362+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:55:37.362+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:55:37.378+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-12T16:56:07.695+0000] {processor.py:157} INFO - Started process (PID=64238) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:56:07.697+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:56:07.702+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:56:07.701+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:56:07.719+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:56:07.753+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:56:07.753+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:56:07.772+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:56:07.772+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:56:07.787+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-12T16:56:37.990+0000] {processor.py:157} INFO - Started process (PID=64248) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:56:37.992+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:56:37.996+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:56:37.995+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:56:38.010+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:56:38.031+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:56:38.031+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:56:38.044+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:56:38.044+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:56:38.058+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-12T16:57:08.384+0000] {processor.py:157} INFO - Started process (PID=64257) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:57:08.386+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:57:08.394+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:57:08.394+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:57:08.414+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:57:08.445+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:57:08.445+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:57:08.461+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:57:08.461+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:57:08.472+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-12T16:57:38.824+0000] {processor.py:157} INFO - Started process (PID=64267) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:57:38.827+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:57:38.835+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:57:38.834+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:57:38.866+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:57:38.915+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:57:38.915+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:57:38.934+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:57:38.934+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:57:38.960+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.145 seconds
[2024-09-12T16:58:09.121+0000] {processor.py:157} INFO - Started process (PID=64277) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:58:09.128+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:58:09.138+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:58:09.137+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:58:09.163+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:58:09.230+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:58:09.230+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:58:09.251+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:58:09.251+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:58:09.268+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.181 seconds
[2024-09-12T16:58:39.482+0000] {processor.py:157} INFO - Started process (PID=64287) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:58:39.484+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:58:39.487+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:58:39.487+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:58:39.502+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:58:39.539+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:58:39.539+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:58:39.554+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:58:39.553+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:58:39.564+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-12T16:59:09.819+0000] {processor.py:157} INFO - Started process (PID=64298) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:59:09.821+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:59:09.826+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:59:09.826+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:59:09.873+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:59:09.912+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:59:09.912+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:59:09.943+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:59:09.942+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:59:09.967+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.155 seconds
[2024-09-12T16:59:40.192+0000] {processor.py:157} INFO - Started process (PID=64308) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:59:40.197+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T16:59:40.204+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:59:40.203+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:59:40.257+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T16:59:40.297+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:59:40.296+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T16:59:40.325+0000] {logging_mixin.py:151} INFO - [2024-09-12T16:59:40.325+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T16:59:40.339+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.154 seconds
[2024-09-12T17:00:10.555+0000] {processor.py:157} INFO - Started process (PID=64318) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:00:10.561+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:00:10.570+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:00:10.569+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:00:10.595+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:00:10.631+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:00:10.631+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:00:10.668+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:00:10.668+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:00:10.696+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.157 seconds
[2024-09-12T17:00:40.935+0000] {processor.py:157} INFO - Started process (PID=64328) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:00:40.938+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:00:40.945+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:00:40.944+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:00:40.971+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:00:41.009+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:00:41.009+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:00:41.029+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:00:41.029+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:00:41.060+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.163 seconds
[2024-09-12T17:01:11.283+0000] {processor.py:157} INFO - Started process (PID=64338) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:01:11.286+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:01:11.314+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:01:11.313+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:01:11.342+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:01:11.384+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:01:11.384+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:01:11.405+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:01:11.405+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:01:11.418+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.155 seconds
[2024-09-12T17:01:41.640+0000] {processor.py:157} INFO - Started process (PID=64348) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:01:41.641+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:01:41.647+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:01:41.646+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:01:41.674+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:01:41.715+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:01:41.715+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:01:41.738+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:01:41.738+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:01:41.751+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-12T17:02:11.937+0000] {processor.py:157} INFO - Started process (PID=64358) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:02:11.939+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:02:11.942+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:02:11.941+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:02:11.959+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:02:11.989+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:02:11.989+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:02:12.009+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:02:12.009+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:02:12.026+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-12T17:02:42.290+0000] {processor.py:157} INFO - Started process (PID=64368) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:02:42.291+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:02:42.294+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:02:42.294+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:02:42.314+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:02:42.336+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:02:42.336+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:02:42.352+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:02:42.351+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:02:42.368+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-12T17:03:12.596+0000] {processor.py:157} INFO - Started process (PID=64378) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:03:12.601+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:03:12.606+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:03:12.606+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:03:12.631+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:03:12.689+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:03:12.689+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:03:12.710+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:03:12.710+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:03:12.724+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.154 seconds
[2024-09-12T17:03:42.837+0000] {processor.py:157} INFO - Started process (PID=64388) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:03:42.838+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:03:42.840+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:03:42.839+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:03:42.859+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:03:42.878+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:03:42.878+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:03:42.892+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:03:42.892+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:03:42.903+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-12T17:04:13.094+0000] {processor.py:157} INFO - Started process (PID=64398) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:04:13.095+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:04:13.101+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:04:13.101+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:04:13.145+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:04:13.183+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:04:13.182+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:04:13.214+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:04:13.213+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:04:13.233+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.148 seconds
[2024-09-12T17:04:43.409+0000] {processor.py:157} INFO - Started process (PID=64408) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:04:43.418+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:04:43.429+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:04:43.428+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:04:43.462+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:04:43.505+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:04:43.505+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:04:43.526+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:04:43.526+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:04:43.543+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.141 seconds
[2024-09-12T17:05:13.765+0000] {processor.py:157} INFO - Started process (PID=64418) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:05:13.770+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:05:13.775+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:05:13.774+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:05:13.793+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:05:13.822+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:05:13.822+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:05:13.839+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:05:13.839+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:05:13.855+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-12T17:05:44.048+0000] {processor.py:157} INFO - Started process (PID=64428) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:05:44.051+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:05:44.055+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:05:44.055+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:05:44.075+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:05:44.105+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:05:44.105+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:05:44.124+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:05:44.124+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:05:44.138+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-12T17:06:14.394+0000] {processor.py:157} INFO - Started process (PID=64438) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:06:14.395+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:06:14.398+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:06:14.397+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:06:14.412+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:06:14.436+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:06:14.435+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:06:14.451+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:06:14.451+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:06:14.462+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-12T17:06:44.672+0000] {processor.py:157} INFO - Started process (PID=64448) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:06:44.677+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:06:44.681+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:06:44.681+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:06:44.705+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:06:44.748+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:06:44.748+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:06:44.770+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:06:44.770+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:06:44.786+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-12T17:07:14.930+0000] {processor.py:157} INFO - Started process (PID=64457) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:07:14.934+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:07:14.938+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:07:14.937+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:07:14.957+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:07:14.988+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:07:14.987+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:07:15.004+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:07:15.004+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:07:15.018+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-12T17:07:45.274+0000] {processor.py:157} INFO - Started process (PID=64468) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:07:45.277+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:07:45.280+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:07:45.280+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:07:45.290+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:07:45.311+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:07:45.311+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:07:45.324+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:07:45.323+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:07:45.336+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-12T17:08:15.547+0000] {processor.py:157} INFO - Started process (PID=64478) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:08:15.548+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:08:15.551+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:08:15.551+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:08:15.575+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:08:15.650+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:08:15.650+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:08:15.676+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:08:15.676+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:08:15.695+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.153 seconds
[2024-09-12T17:08:45.836+0000] {processor.py:157} INFO - Started process (PID=64488) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:08:45.840+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:08:45.843+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:08:45.843+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:08:45.871+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:08:45.907+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:08:45.907+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:08:45.921+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:08:45.921+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:08:45.932+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-12T17:09:16.242+0000] {processor.py:157} INFO - Started process (PID=64498) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:09:16.253+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:09:16.260+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:09:16.260+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:09:16.281+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:09:16.304+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:09:16.304+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:09:16.324+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:09:16.324+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:09:16.338+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-12T17:09:46.530+0000] {processor.py:157} INFO - Started process (PID=64508) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:09:46.532+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:09:46.538+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:09:46.538+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:09:46.563+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:09:46.599+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:09:46.599+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:09:46.615+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:09:46.614+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:09:46.626+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-12T17:10:16.937+0000] {processor.py:157} INFO - Started process (PID=64518) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:10:16.939+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:10:16.944+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:10:16.944+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:10:16.966+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:10:17.001+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:10:17.001+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:10:17.023+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:10:17.023+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:10:17.037+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-09-12T17:10:47.281+0000] {processor.py:157} INFO - Started process (PID=64528) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:10:47.283+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:10:47.288+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:10:47.287+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:10:47.337+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:10:47.376+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:10:47.376+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:10:47.395+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:10:47.395+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:10:47.410+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-09-12T17:11:17.662+0000] {processor.py:157} INFO - Started process (PID=64538) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:11:17.666+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:11:17.676+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:11:17.674+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:11:17.702+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:11:17.742+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:11:17.742+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:11:17.764+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:11:17.764+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:11:17.783+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-09-12T17:11:48.041+0000] {processor.py:157} INFO - Started process (PID=64548) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:11:48.043+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:11:48.049+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:11:48.048+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:11:48.088+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:11:48.128+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:11:48.128+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:11:48.168+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:11:48.168+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:11:48.183+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.151 seconds
[2024-09-12T17:12:18.368+0000] {processor.py:157} INFO - Started process (PID=64557) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:12:18.371+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:12:18.378+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:12:18.378+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:12:18.406+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:12:18.445+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:12:18.444+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:12:18.478+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:12:18.478+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:12:18.494+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.158 seconds
[2024-09-12T17:12:48.927+0000] {processor.py:157} INFO - Started process (PID=64568) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:12:48.929+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:12:48.938+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:12:48.936+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:12:48.963+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:12:49.023+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:12:49.023+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:12:49.046+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:12:49.046+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:12:49.059+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.147 seconds
[2024-09-12T17:13:19.197+0000] {processor.py:157} INFO - Started process (PID=64578) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:13:19.200+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:13:19.204+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:13:19.204+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:13:19.224+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:13:19.256+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:13:19.256+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:13:19.277+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:13:19.277+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:13:19.290+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-12T17:13:49.592+0000] {processor.py:157} INFO - Started process (PID=64588) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:13:49.596+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:13:49.602+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:13:49.602+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:13:49.631+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:13:49.688+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:13:49.688+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:13:49.708+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:13:49.708+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:13:49.724+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-09-12T17:14:19.974+0000] {processor.py:157} INFO - Started process (PID=64598) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:14:19.979+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:14:19.982+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:14:19.981+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:14:20.007+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:14:20.046+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:14:20.046+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:14:20.063+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:14:20.063+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:14:20.081+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-12T17:14:50.653+0000] {processor.py:157} INFO - Started process (PID=64607) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:14:50.660+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:14:50.667+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:14:50.666+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:14:50.699+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:14:50.739+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:14:50.739+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:14:50.783+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:14:50.783+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:14:50.797+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.171 seconds
[2024-09-12T17:15:21.210+0000] {processor.py:157} INFO - Started process (PID=64617) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:15:21.214+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:15:21.221+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:15:21.220+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:15:21.246+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:15:21.312+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:15:21.312+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:15:21.335+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:15:21.335+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:15:21.350+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.148 seconds
[2024-09-12T17:15:51.941+0000] {processor.py:157} INFO - Started process (PID=64628) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:15:51.945+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:15:51.955+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:15:51.952+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:15:52.015+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:15:52.101+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:15:52.100+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:15:52.134+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:15:52.134+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:15:52.149+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.227 seconds
[2024-09-12T17:16:22.750+0000] {processor.py:157} INFO - Started process (PID=64638) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:16:22.757+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:16:22.762+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:16:22.761+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:16:22.800+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:16:22.840+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:16:22.840+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:16:22.866+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:16:22.866+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:16:22.883+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-09-12T17:16:53.134+0000] {processor.py:157} INFO - Started process (PID=64647) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:16:53.136+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:16:53.142+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:16:53.141+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:16:53.185+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:16:53.236+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:16:53.235+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:16:53.270+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:16:53.270+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:16:53.284+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.159 seconds
[2024-09-12T17:17:23.498+0000] {processor.py:157} INFO - Started process (PID=64658) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:17:23.510+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:17:23.518+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:17:23.517+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:17:23.538+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:17:23.576+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:17:23.576+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:17:23.594+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:17:23.594+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:17:23.609+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-12T17:17:53.860+0000] {processor.py:157} INFO - Started process (PID=64668) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:17:53.864+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:17:53.867+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:17:53.867+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:17:53.898+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:17:53.959+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:17:53.958+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:17:53.984+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:17:53.984+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:17:53.995+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-09-12T17:18:24.399+0000] {processor.py:157} INFO - Started process (PID=64678) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:18:24.402+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:18:24.408+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:18:24.408+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:18:24.439+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:18:24.505+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:18:24.505+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:18:24.526+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:18:24.526+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:18:24.544+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.152 seconds
[2024-09-12T17:18:54.854+0000] {processor.py:157} INFO - Started process (PID=64688) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:18:54.856+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:18:54.862+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:18:54.861+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:18:54.891+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:18:54.932+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:18:54.932+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:18:54.948+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:18:54.948+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:18:54.963+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-12T17:19:25.409+0000] {processor.py:157} INFO - Started process (PID=64698) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:19:25.415+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:19:25.427+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:19:25.426+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:19:25.493+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:19:25.574+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:19:25.574+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:19:25.595+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:19:25.595+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:19:25.614+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.225 seconds
[2024-09-12T17:19:55.825+0000] {processor.py:157} INFO - Started process (PID=64707) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:19:55.828+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:19:55.836+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:19:55.835+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:19:55.864+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:19:55.935+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:19:55.935+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:19:55.956+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:19:55.956+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:19:55.980+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.164 seconds
[2024-09-12T17:20:26.379+0000] {processor.py:157} INFO - Started process (PID=64718) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:20:26.384+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:20:26.387+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:20:26.387+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:20:26.422+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:20:26.460+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:20:26.460+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:20:26.477+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:20:26.477+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:20:26.491+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-09-12T17:20:56.736+0000] {processor.py:157} INFO - Started process (PID=64728) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:20:56.738+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:20:56.744+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:20:56.743+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:20:56.776+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:20:56.826+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:20:56.826+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:20:56.855+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:20:56.855+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:20:56.871+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.141 seconds
[2024-09-12T17:21:27.300+0000] {processor.py:157} INFO - Started process (PID=64738) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:21:27.304+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:21:27.317+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:21:27.314+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:21:27.381+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:21:27.433+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:21:27.433+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:21:27.458+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:21:27.458+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:21:27.479+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.188 seconds
[2024-09-12T17:21:57.584+0000] {processor.py:157} INFO - Started process (PID=64748) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:21:57.588+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:21:57.593+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:21:57.592+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:21:57.609+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:21:57.641+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:21:57.640+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:21:57.661+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:21:57.661+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:21:57.674+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-12T17:22:27.914+0000] {processor.py:157} INFO - Started process (PID=64757) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:22:27.919+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:22:27.936+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:22:27.935+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:22:27.957+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:22:28.015+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:22:28.015+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:22:28.041+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:22:28.041+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:22:28.053+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.157 seconds
[2024-09-12T17:22:58.238+0000] {processor.py:157} INFO - Started process (PID=64768) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:22:58.240+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:22:58.246+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:22:58.246+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:22:58.269+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:22:58.316+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:22:58.316+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:22:58.340+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:22:58.339+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:22:58.354+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-12T17:23:28.545+0000] {processor.py:157} INFO - Started process (PID=64778) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:23:28.549+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:23:28.553+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:23:28.553+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:23:28.570+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:23:28.603+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:23:28.603+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:23:28.623+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:23:28.622+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:23:28.634+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-12T17:23:58.996+0000] {processor.py:157} INFO - Started process (PID=64788) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:23:58.997+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:23:59.004+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:23:59.004+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:23:59.028+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:23:59.071+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:23:59.071+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:23:59.089+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:23:59.089+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:23:59.103+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-12T17:24:29.335+0000] {processor.py:157} INFO - Started process (PID=64798) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:24:29.336+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:24:29.342+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:24:29.341+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:24:29.364+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:24:29.428+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:24:29.428+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:24:29.446+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:24:29.446+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:24:29.460+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-09-12T17:24:59.624+0000] {processor.py:157} INFO - Started process (PID=64808) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:24:59.628+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:24:59.634+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:24:59.633+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:24:59.669+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:24:59.721+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:24:59.721+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:24:59.737+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:24:59.737+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:24:59.748+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.154 seconds
[2024-09-12T17:25:30.103+0000] {processor.py:157} INFO - Started process (PID=64818) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:25:30.105+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:25:30.108+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:25:30.108+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:25:30.128+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:25:30.171+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:25:30.171+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:25:30.190+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:25:30.190+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:25:30.204+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-09-12T17:26:00.441+0000] {processor.py:157} INFO - Started process (PID=64828) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:26:00.444+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:26:00.450+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:26:00.449+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:26:00.483+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:26:00.513+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:26:00.513+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:26:00.538+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:26:00.537+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:26:00.549+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-12T17:26:30.754+0000] {processor.py:157} INFO - Started process (PID=64837) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:26:30.756+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:26:30.763+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:26:30.762+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:26:30.797+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:26:30.860+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:26:30.859+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:26:30.882+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:26:30.882+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:26:30.897+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.153 seconds
[2024-09-12T17:27:01.190+0000] {processor.py:157} INFO - Started process (PID=64848) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:27:01.195+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:27:01.199+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:27:01.199+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:27:01.230+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:27:01.273+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:27:01.273+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:27:01.296+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:27:01.296+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:27:01.308+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-12T17:27:31.551+0000] {processor.py:157} INFO - Started process (PID=64858) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:27:31.555+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:27:31.571+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:27:31.570+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:27:31.600+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:27:31.639+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:27:31.639+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:27:31.670+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:27:31.669+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:27:31.689+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.162 seconds
[2024-09-12T17:28:02.014+0000] {processor.py:157} INFO - Started process (PID=64868) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:28:02.020+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:28:02.026+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:28:02.025+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:28:02.050+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:28:02.095+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:28:02.095+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:28:02.119+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:28:02.119+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:28:02.135+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-09-12T17:28:32.292+0000] {processor.py:157} INFO - Started process (PID=64878) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:28:32.301+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:28:32.312+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:28:32.311+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:28:32.388+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:28:32.439+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:28:32.439+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:28:32.460+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:28:32.460+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:28:32.473+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.188 seconds
[2024-09-12T17:29:02.701+0000] {processor.py:157} INFO - Started process (PID=64888) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:29:02.712+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:29:02.716+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:29:02.715+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:29:02.738+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:29:02.785+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:29:02.785+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:29:02.800+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:29:02.800+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:29:02.814+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-09-12T17:29:33.012+0000] {processor.py:157} INFO - Started process (PID=64898) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:29:33.032+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:29:33.039+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:29:33.038+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:29:33.065+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:29:33.105+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:29:33.105+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:29:33.132+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:29:33.132+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:29:33.159+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.163 seconds
[2024-09-12T17:30:03.436+0000] {processor.py:157} INFO - Started process (PID=64908) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:30:03.440+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:30:03.445+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:30:03.445+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:30:03.465+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:30:03.512+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:30:03.512+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:30:03.527+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:30:03.527+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:30:03.540+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-12T17:30:33.905+0000] {processor.py:157} INFO - Started process (PID=64918) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:30:33.906+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:30:33.912+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:30:33.911+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:30:33.963+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:30:34.008+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:30:34.008+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:30:34.041+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:30:34.041+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:30:34.055+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.157 seconds
[2024-09-12T17:31:04.332+0000] {processor.py:157} INFO - Started process (PID=64928) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:31:04.336+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:31:04.341+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:31:04.341+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:31:04.362+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:31:04.400+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:31:04.400+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:31:04.416+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:31:04.416+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:31:04.434+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-09-12T17:31:34.651+0000] {processor.py:157} INFO - Started process (PID=64938) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:31:34.655+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:31:34.671+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:31:34.670+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:31:34.693+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:31:34.728+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:31:34.728+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:31:34.761+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:31:34.761+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:31:34.774+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-09-12T17:32:04.947+0000] {processor.py:157} INFO - Started process (PID=64948) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:32:04.950+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:32:04.955+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:32:04.954+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:32:04.981+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:32:05.012+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:32:05.012+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:32:05.031+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:32:05.031+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:32:05.047+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-09-12T17:32:35.478+0000] {processor.py:157} INFO - Started process (PID=64958) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:32:35.485+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:32:35.499+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:32:35.497+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:32:35.528+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:32:35.589+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:32:35.589+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:32:35.609+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:32:35.609+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:32:35.625+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.154 seconds
[2024-09-12T17:33:05.792+0000] {processor.py:157} INFO - Started process (PID=64968) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:33:05.796+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:33:05.802+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:33:05.801+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:33:05.829+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:33:05.871+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:33:05.871+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:33:05.921+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:33:05.921+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:33:05.935+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.173 seconds
[2024-09-12T17:33:36.252+0000] {processor.py:157} INFO - Started process (PID=64978) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:33:36.258+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:33:36.264+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:33:36.263+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:33:36.310+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:33:36.356+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:33:36.356+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:33:36.375+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:33:36.375+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:33:36.392+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.147 seconds
[2024-09-12T17:34:06.583+0000] {processor.py:157} INFO - Started process (PID=64988) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:34:06.588+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:34:06.592+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:34:06.591+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:34:06.615+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:34:06.675+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:34:06.674+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:34:06.696+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:34:06.696+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:34:06.708+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.144 seconds
[2024-09-12T17:34:36.942+0000] {processor.py:157} INFO - Started process (PID=64998) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:34:36.946+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:34:36.953+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:34:36.952+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:34:36.977+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:34:37.036+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:34:37.036+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:34:37.055+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:34:37.055+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:34:37.071+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.151 seconds
[2024-09-12T17:35:07.270+0000] {processor.py:157} INFO - Started process (PID=65008) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:35:07.272+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:35:07.277+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:35:07.276+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:35:07.292+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:35:07.315+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:35:07.315+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:35:07.329+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:35:07.329+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:35:07.342+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-12T17:35:37.619+0000] {processor.py:157} INFO - Started process (PID=65018) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:35:37.620+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:35:37.626+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:35:37.625+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:35:37.659+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:35:37.719+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:35:37.719+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:35:37.740+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:35:37.740+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:35:37.753+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-09-12T17:36:07.946+0000] {processor.py:157} INFO - Started process (PID=65028) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:36:07.952+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:36:07.961+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:36:07.960+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:36:07.988+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:36:08.050+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:36:08.050+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:36:08.069+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:36:08.069+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:36:08.082+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.145 seconds
[2024-09-12T17:36:38.257+0000] {processor.py:157} INFO - Started process (PID=65038) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:36:38.260+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:36:38.279+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:36:38.276+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:36:38.319+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:36:38.360+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:36:38.359+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:36:38.385+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:36:38.385+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:36:38.399+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.152 seconds
[2024-09-12T17:37:08.576+0000] {processor.py:157} INFO - Started process (PID=65048) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:37:08.580+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:37:08.585+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:37:08.584+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:37:08.602+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:37:08.631+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:37:08.630+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:37:08.648+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:37:08.648+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:37:08.661+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-12T17:37:38.892+0000] {processor.py:157} INFO - Started process (PID=65058) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:37:38.893+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:37:38.895+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:37:38.895+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:37:38.929+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:37:38.947+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:37:38.947+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:37:38.958+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:37:38.958+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:37:38.968+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-12T17:38:09.286+0000] {processor.py:157} INFO - Started process (PID=65068) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:38:09.289+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:38:09.307+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:38:09.306+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:38:09.342+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:38:09.378+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:38:09.378+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:38:09.398+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:38:09.398+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:38:09.411+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.155 seconds
[2024-09-12T17:38:39.560+0000] {processor.py:157} INFO - Started process (PID=65078) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:38:39.561+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:38:39.563+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:38:39.562+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:38:39.582+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:38:39.605+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:38:39.604+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:38:39.624+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:38:39.624+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:38:39.638+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-12T17:39:09.957+0000] {processor.py:157} INFO - Started process (PID=65087) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:39:09.959+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:39:09.965+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:39:09.964+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:39:09.989+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:39:10.049+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:39:10.049+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:39:10.072+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:39:10.072+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:39:10.085+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.152 seconds
[2024-09-12T17:39:40.288+0000] {processor.py:157} INFO - Started process (PID=65098) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:39:40.294+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:39:40.298+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:39:40.298+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:39:40.325+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:39:40.385+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:39:40.385+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:39:40.404+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:39:40.404+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:39:40.418+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.144 seconds
[2024-09-12T17:40:10.632+0000] {processor.py:157} INFO - Started process (PID=65108) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:40:10.638+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:40:10.645+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:40:10.644+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:40:10.690+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:40:10.731+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:40:10.730+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:40:10.751+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:40:10.751+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:40:10.780+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.155 seconds
[2024-09-12T17:40:41.044+0000] {processor.py:157} INFO - Started process (PID=65117) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:40:41.051+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:40:41.056+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:40:41.055+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:40:41.079+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:40:41.136+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:40:41.136+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:40:41.154+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:40:41.154+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:40:41.169+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-09-12T17:41:11.350+0000] {processor.py:157} INFO - Started process (PID=65128) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:41:11.357+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:41:11.367+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:41:11.366+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:41:11.402+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:41:11.436+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:41:11.436+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:41:11.467+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:41:11.467+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:41:11.481+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-09-12T17:41:41.743+0000] {processor.py:157} INFO - Started process (PID=65138) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:41:41.749+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:41:41.768+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:41:41.767+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:41:41.795+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:41:41.829+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:41:41.829+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:41:41.859+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:41:41.859+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:41:41.872+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.148 seconds
[2024-09-12T17:42:12.101+0000] {processor.py:157} INFO - Started process (PID=65148) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:42:12.103+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:42:12.109+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:42:12.108+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:42:12.135+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:42:12.200+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:42:12.200+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:42:12.221+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:42:12.221+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:42:12.233+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.141 seconds
[2024-09-12T17:42:42.545+0000] {processor.py:157} INFO - Started process (PID=65158) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:42:42.546+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:42:42.548+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:42:42.548+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:42:42.564+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:42:42.585+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:42:42.585+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:42:42.596+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:42:42.596+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:42:42.610+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-12T17:43:12.951+0000] {processor.py:157} INFO - Started process (PID=65167) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:43:12.956+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:43:12.962+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:43:12.960+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:43:12.991+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:43:13.028+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:43:13.027+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:43:13.047+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:43:13.047+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:43:13.066+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-12T17:43:43.278+0000] {processor.py:157} INFO - Started process (PID=65178) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:43:43.282+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:43:43.286+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:43:43.286+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:43:43.307+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:43:43.351+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:43:43.351+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:43:43.372+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:43:43.371+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:43:43.386+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-12T17:44:13.679+0000] {processor.py:157} INFO - Started process (PID=65187) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:44:13.688+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:44:13.698+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:44:13.697+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:44:13.723+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:44:13.759+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:44:13.759+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:44:13.778+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:44:13.778+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:44:13.793+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.147 seconds
[2024-09-12T17:44:44.057+0000] {processor.py:157} INFO - Started process (PID=65196) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:44:44.063+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:44:44.073+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:44:44.072+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:44:44.099+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:44:44.169+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:44:44.169+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:44:44.190+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:44:44.190+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:44:44.203+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.192 seconds
[2024-09-12T17:45:14.361+0000] {processor.py:157} INFO - Started process (PID=65206) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:45:14.364+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:45:14.373+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:45:14.372+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:45:14.400+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:45:14.460+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:45:14.460+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:45:14.478+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:45:14.478+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:45:14.491+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-09-12T17:45:44.834+0000] {processor.py:157} INFO - Started process (PID=65218) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:45:44.840+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:45:44.856+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:45:44.855+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:45:44.880+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:45:44.936+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:45:44.936+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:45:44.959+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:45:44.959+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:45:44.975+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.160 seconds
[2024-09-12T17:46:15.191+0000] {processor.py:157} INFO - Started process (PID=65228) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:46:15.194+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:46:15.202+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:46:15.201+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:46:15.225+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:46:15.285+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:46:15.284+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:46:15.308+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:46:15.308+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:46:15.325+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.142 seconds
[2024-09-12T17:46:45.601+0000] {processor.py:157} INFO - Started process (PID=65238) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:46:45.607+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:46:45.611+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:46:45.610+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:46:45.637+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:46:45.682+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:46:45.682+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:46:45.706+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:46:45.706+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:46:45.722+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-09-12T17:47:15.935+0000] {processor.py:157} INFO - Started process (PID=65248) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:47:15.944+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:47:15.951+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:47:15.950+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:47:15.973+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:47:16.035+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:47:16.035+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:47:16.061+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:47:16.061+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:47:16.077+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.151 seconds
[2024-09-12T17:47:46.463+0000] {processor.py:157} INFO - Started process (PID=65257) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:47:46.465+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:47:46.476+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:47:46.476+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:47:46.520+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:47:46.556+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:47:46.556+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:47:46.573+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:47:46.572+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:47:46.592+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-09-12T17:48:16.776+0000] {processor.py:157} INFO - Started process (PID=65268) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:48:16.778+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:48:16.782+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:48:16.782+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:48:16.801+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:48:16.836+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:48:16.836+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:48:16.852+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:48:16.852+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:48:16.868+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-12T17:48:47.077+0000] {processor.py:157} INFO - Started process (PID=65278) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:48:47.079+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:48:47.083+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:48:47.082+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:48:47.097+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:48:47.124+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:48:47.124+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:48:47.139+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:48:47.139+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:48:47.150+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-12T17:49:17.408+0000] {processor.py:157} INFO - Started process (PID=65288) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:49:17.411+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:49:17.416+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:49:17.415+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:49:17.436+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:49:17.489+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:49:17.489+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:49:17.506+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:49:17.506+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:49:17.521+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-12T17:49:47.799+0000] {processor.py:157} INFO - Started process (PID=65298) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:49:47.804+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:49:47.807+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:49:47.807+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:49:47.829+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:49:47.883+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:49:47.883+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:49:47.907+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:49:47.906+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:49:47.923+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-09-12T17:50:18.115+0000] {processor.py:157} INFO - Started process (PID=65308) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:50:18.118+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:50:18.120+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:50:18.120+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:50:18.141+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:50:18.185+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:50:18.184+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:50:18.204+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:50:18.204+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:50:18.217+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-12T17:50:48.595+0000] {processor.py:157} INFO - Started process (PID=65318) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:50:48.598+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:50:48.603+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:50:48.602+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:50:48.629+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:50:48.672+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:50:48.672+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:50:48.712+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:50:48.712+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:50:48.727+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.137 seconds
[2024-09-12T17:51:18.938+0000] {processor.py:157} INFO - Started process (PID=65328) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:51:18.941+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:51:18.947+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:51:18.946+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:51:19.004+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:51:19.044+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:51:19.044+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:51:19.075+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:51:19.075+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:51:19.090+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.162 seconds
[2024-09-12T17:51:49.500+0000] {processor.py:157} INFO - Started process (PID=65338) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:51:49.504+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:51:49.510+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:51:49.510+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:51:49.532+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:51:49.600+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:51:49.599+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:51:49.621+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:51:49.621+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:51:49.635+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.143 seconds
[2024-09-12T17:52:19.840+0000] {processor.py:157} INFO - Started process (PID=65348) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:52:19.846+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:52:19.854+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:52:19.852+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:52:19.880+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:52:19.919+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:52:19.919+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:52:19.949+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:52:19.949+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:52:19.964+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-09-12T17:52:50.207+0000] {processor.py:157} INFO - Started process (PID=65358) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:52:50.208+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:52:50.211+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:52:50.211+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:52:50.229+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:52:50.259+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:52:50.259+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:52:50.276+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:52:50.276+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:52:50.292+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-12T17:53:20.468+0000] {processor.py:157} INFO - Started process (PID=65368) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:53:20.469+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:53:20.471+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:53:20.471+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:53:20.492+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:53:20.522+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:53:20.522+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:53:20.538+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:53:20.538+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:53:20.547+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-12T17:53:50.927+0000] {processor.py:157} INFO - Started process (PID=65378) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:53:50.930+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:53:50.935+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:53:50.934+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:53:50.986+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:53:51.032+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:53:51.032+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:53:51.053+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:53:51.053+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:53:51.068+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.150 seconds
[2024-09-12T17:54:21.237+0000] {processor.py:157} INFO - Started process (PID=65388) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:54:21.239+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:54:21.243+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:54:21.243+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:54:21.261+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:54:21.288+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:54:21.288+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:54:21.303+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:54:21.303+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:54:21.314+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-12T17:54:51.622+0000] {processor.py:157} INFO - Started process (PID=65398) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:54:51.631+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:54:51.639+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:54:51.638+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:54:51.663+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:54:51.695+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:54:51.695+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:54:51.716+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:54:51.716+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:54:51.732+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-09-12T17:55:22.028+0000] {processor.py:157} INFO - Started process (PID=65408) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:55:22.029+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:55:22.033+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:55:22.032+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:55:22.052+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:55:22.083+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:55:22.083+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:55:22.101+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:55:22.101+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:55:22.116+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-12T17:55:52.376+0000] {processor.py:157} INFO - Started process (PID=65418) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:55:52.379+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:55:52.384+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:55:52.384+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:55:52.432+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:55:52.485+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:55:52.485+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:55:52.501+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:55:52.501+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:55:52.517+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.146 seconds
[2024-09-12T17:56:22.744+0000] {processor.py:157} INFO - Started process (PID=65428) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:56:22.748+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:56:22.754+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:56:22.754+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:56:22.777+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:56:22.852+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:56:22.852+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:56:22.872+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:56:22.872+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:56:22.887+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.150 seconds
[2024-09-12T17:56:53.048+0000] {processor.py:157} INFO - Started process (PID=65438) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:56:53.055+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:56:53.060+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:56:53.060+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:56:53.105+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:56:53.147+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:56:53.147+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:56:53.168+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:56:53.168+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:56:53.182+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.141 seconds
[2024-09-12T17:57:23.445+0000] {processor.py:157} INFO - Started process (PID=65448) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:57:23.452+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:57:23.463+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:57:23.463+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:57:23.484+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:57:23.537+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:57:23.537+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:57:23.600+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:57:23.600+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:57:23.641+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.223 seconds
[2024-09-12T17:57:53.835+0000] {processor.py:157} INFO - Started process (PID=65458) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:57:53.838+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:57:53.846+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:57:53.845+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:57:53.867+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:57:53.912+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:57:53.912+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:57:53.955+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:57:53.954+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:57:53.967+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.143 seconds
[2024-09-12T17:58:24.187+0000] {processor.py:157} INFO - Started process (PID=65468) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:58:24.190+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:58:24.196+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:58:24.195+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:58:24.213+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:58:24.244+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:58:24.244+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:58:24.262+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:58:24.261+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:58:24.275+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-12T17:58:54.558+0000] {processor.py:157} INFO - Started process (PID=65478) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:58:54.562+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:58:54.567+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:58:54.567+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:58:54.590+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:58:54.628+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:58:54.628+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:58:54.663+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:58:54.663+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:58:54.678+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.151 seconds
[2024-09-12T17:59:24.846+0000] {processor.py:157} INFO - Started process (PID=65488) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:59:24.849+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:59:24.856+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:59:24.855+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:59:24.879+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:59:24.925+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:59:24.925+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:59:24.953+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:59:24.953+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:59:24.971+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-09-12T17:59:55.233+0000] {processor.py:157} INFO - Started process (PID=65498) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:59:55.237+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T17:59:55.244+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:59:55.244+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:59:55.269+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T17:59:55.323+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:59:55.322+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T17:59:55.351+0000] {logging_mixin.py:151} INFO - [2024-09-12T17:59:55.351+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T17:59:55.365+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.171 seconds
[2024-09-12T18:00:25.555+0000] {processor.py:157} INFO - Started process (PID=65508) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:00:25.559+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:00:25.564+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:00:25.563+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:00:25.603+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:00:25.662+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:00:25.662+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:00:25.684+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:00:25.684+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:00:25.699+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.151 seconds
[2024-09-12T18:00:55.875+0000] {processor.py:157} INFO - Started process (PID=65518) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:00:55.882+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:00:55.887+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:00:55.886+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:00:55.906+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:00:55.950+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:00:55.950+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:00:55.971+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:00:55.971+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:00:55.990+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-12T18:01:26.169+0000] {processor.py:157} INFO - Started process (PID=65528) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:01:26.171+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:01:26.174+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:01:26.174+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:01:26.193+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:01:26.218+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:01:26.218+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:01:26.236+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:01:26.236+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:01:26.249+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-12T18:01:56.563+0000] {processor.py:157} INFO - Started process (PID=65538) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:01:56.565+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:01:56.568+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:01:56.568+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:01:56.592+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:01:56.631+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:01:56.630+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:01:56.652+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:01:56.652+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:01:56.671+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-12T18:02:27.009+0000] {processor.py:157} INFO - Started process (PID=65548) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:02:27.018+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:02:27.023+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:02:27.023+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:02:27.043+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:02:27.073+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:02:27.073+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:02:27.092+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:02:27.092+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:02:27.104+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-12T18:02:57.353+0000] {processor.py:157} INFO - Started process (PID=65558) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:02:57.357+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:02:57.360+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:02:57.360+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:02:57.378+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:02:57.400+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:02:57.400+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:02:57.420+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:02:57.420+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:02:57.430+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-12T18:03:27.681+0000] {processor.py:157} INFO - Started process (PID=65567) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:03:27.683+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:03:27.689+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:03:27.689+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:03:27.707+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:03:27.737+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:03:27.737+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:03:27.766+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:03:27.766+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:03:27.777+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-12T18:03:57.890+0000] {processor.py:157} INFO - Started process (PID=65578) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:03:57.892+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:03:57.898+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:03:57.897+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:03:57.930+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:03:57.990+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:03:57.990+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:03:58.014+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:03:58.014+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:03:58.029+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.146 seconds
[2024-09-12T18:04:28.203+0000] {processor.py:157} INFO - Started process (PID=65588) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:04:28.208+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:04:28.213+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:04:28.212+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:04:28.232+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:04:28.292+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:04:28.292+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:04:28.309+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:04:28.309+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:04:28.327+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-09-12T18:04:58.543+0000] {processor.py:157} INFO - Started process (PID=65598) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:04:58.545+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:04:58.548+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:04:58.548+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:04:58.564+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:04:58.600+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:04:58.600+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:04:58.615+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:04:58.615+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:04:58.629+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-12T18:05:28.805+0000] {processor.py:157} INFO - Started process (PID=65608) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:05:28.808+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:05:28.811+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:05:28.810+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:05:28.826+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:05:28.852+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:05:28.851+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:05:28.874+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:05:28.874+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:05:28.886+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-12T18:05:59.232+0000] {processor.py:157} INFO - Started process (PID=65617) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:05:59.235+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:05:59.240+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:05:59.240+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:05:59.257+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:05:59.316+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:05:59.316+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:05:59.333+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:05:59.333+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:05:59.344+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-09-12T18:06:29.634+0000] {processor.py:157} INFO - Started process (PID=65628) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:06:29.640+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:06:29.644+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:06:29.644+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:06:29.673+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:06:29.710+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:06:29.710+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:06:29.725+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:06:29.725+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:06:29.738+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-09-12T18:06:59.951+0000] {processor.py:157} INFO - Started process (PID=65638) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:06:59.953+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:06:59.957+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:06:59.957+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:06:59.979+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:07:00.008+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:07:00.008+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:07:00.024+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:07:00.024+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:07:00.043+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-12T18:07:30.449+0000] {processor.py:157} INFO - Started process (PID=65648) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:07:30.451+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:07:30.454+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:07:30.454+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:07:30.471+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:07:30.494+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:07:30.494+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:07:30.507+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:07:30.507+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:07:30.516+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-12T18:08:00.810+0000] {processor.py:157} INFO - Started process (PID=65658) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:08:00.812+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:08:00.816+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:08:00.816+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:08:00.841+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:08:00.871+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:08:00.871+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:08:00.885+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:08:00.885+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:08:00.904+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-12T18:08:31.079+0000] {processor.py:157} INFO - Started process (PID=65668) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:08:31.081+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:08:31.083+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:08:31.082+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:08:31.092+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:08:31.107+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:08:31.107+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:08:31.117+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:08:31.117+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:08:31.127+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-12T18:09:01.507+0000] {processor.py:157} INFO - Started process (PID=65678) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:09:01.509+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:09:01.514+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:09:01.514+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:09:01.532+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:09:01.562+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:09:01.562+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:09:01.576+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:09:01.576+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:09:01.589+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-12T18:09:31.888+0000] {processor.py:157} INFO - Started process (PID=65688) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:09:31.889+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:09:31.893+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:09:31.893+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:09:31.923+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:09:31.961+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:09:31.961+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:09:31.983+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:09:31.983+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:09:31.994+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-12T18:10:02.307+0000] {processor.py:157} INFO - Started process (PID=65698) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:10:02.311+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:10:02.318+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:10:02.317+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:10:02.345+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:10:02.391+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:10:02.391+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:10:02.409+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:10:02.409+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:10:02.423+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-12T18:10:32.664+0000] {processor.py:157} INFO - Started process (PID=65708) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:10:32.667+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:10:32.671+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:10:32.671+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:10:32.698+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:10:32.737+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:10:32.737+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:10:32.751+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:10:32.751+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:10:32.763+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-12T18:11:03.039+0000] {processor.py:157} INFO - Started process (PID=65718) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:11:03.041+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:11:03.044+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:11:03.044+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:11:03.062+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:11:03.100+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:11:03.100+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:11:03.117+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:11:03.117+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:11:03.128+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-12T18:11:33.370+0000] {processor.py:157} INFO - Started process (PID=65727) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:11:33.372+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:11:33.376+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:11:33.375+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:11:33.406+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:11:33.432+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:11:33.432+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:11:33.446+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:11:33.446+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:11:33.456+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-12T18:12:03.704+0000] {processor.py:157} INFO - Started process (PID=65738) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:12:03.707+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:12:03.710+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:12:03.709+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:12:03.724+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:12:03.745+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:12:03.745+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:12:03.757+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:12:03.757+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:12:03.767+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-12T18:12:34.072+0000] {processor.py:157} INFO - Started process (PID=65748) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:12:34.072+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:12:34.074+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:12:34.074+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:12:34.084+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:12:34.100+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:12:34.100+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:12:34.110+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:12:34.110+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:12:34.119+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-12T18:13:04.512+0000] {processor.py:157} INFO - Started process (PID=65758) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:13:04.515+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:13:04.518+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:13:04.518+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:13:04.532+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:13:04.556+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:13:04.556+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:13:04.572+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:13:04.572+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:13:04.581+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-12T18:13:34.811+0000] {processor.py:157} INFO - Started process (PID=65768) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:13:34.813+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:13:34.815+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:13:34.815+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:13:34.831+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:13:34.846+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:13:34.846+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:13:34.858+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:13:34.857+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:13:34.867+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-12T18:14:05.155+0000] {processor.py:157} INFO - Started process (PID=65778) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:14:05.156+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:14:05.159+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:14:05.158+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:14:05.175+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:14:05.201+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:14:05.200+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:14:05.217+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:14:05.217+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:14:05.232+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-12T18:14:35.437+0000] {processor.py:157} INFO - Started process (PID=65788) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:14:35.439+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:14:35.441+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:14:35.441+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:14:35.456+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:14:35.477+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:14:35.477+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:14:35.488+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:14:35.488+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:14:35.495+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-12T18:15:05.781+0000] {processor.py:157} INFO - Started process (PID=65798) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:15:05.785+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:15:05.787+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:15:05.787+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:15:05.801+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:15:05.835+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:15:05.835+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:15:05.848+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:15:05.848+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:15:05.859+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-12T18:15:36.054+0000] {processor.py:157} INFO - Started process (PID=65808) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:15:36.055+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:15:36.058+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:15:36.058+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:15:36.074+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:15:36.097+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:15:36.097+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:15:36.110+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:15:36.110+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:15:36.120+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-12T18:16:06.316+0000] {processor.py:157} INFO - Started process (PID=65818) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:16:06.318+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:16:06.321+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:16:06.320+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:16:06.334+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:16:06.354+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:16:06.354+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:16:06.371+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:16:06.371+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:16:06.380+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-12T18:16:36.744+0000] {processor.py:157} INFO - Started process (PID=65828) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:16:36.746+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:16:36.749+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:16:36.749+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:16:36.771+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:16:36.793+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:16:36.793+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:16:36.806+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:16:36.806+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:16:36.818+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-12T18:17:07.232+0000] {processor.py:157} INFO - Started process (PID=65838) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:17:07.245+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:17:07.257+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:17:07.257+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:17:07.274+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:17:07.300+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:17:07.300+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:17:07.323+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:17:07.322+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:17:07.342+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-12T18:17:37.549+0000] {processor.py:157} INFO - Started process (PID=65848) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:17:37.552+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:17:37.556+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:17:37.556+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:17:37.573+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:17:37.610+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:17:37.610+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:17:37.626+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:17:37.626+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:17:37.635+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-12T18:18:07.853+0000] {processor.py:157} INFO - Started process (PID=65858) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:18:07.855+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:18:07.857+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:18:07.857+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:18:07.871+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:18:07.894+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:18:07.893+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:18:07.907+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:18:07.906+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:18:07.916+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-12T18:18:38.211+0000] {processor.py:157} INFO - Started process (PID=65868) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:18:38.216+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:18:38.218+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:18:38.218+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:18:38.229+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:18:38.250+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:18:38.250+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:18:38.260+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:18:38.260+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:18:38.267+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-12T18:19:08.676+0000] {processor.py:157} INFO - Started process (PID=65878) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:19:08.682+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:19:08.691+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:19:08.689+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:19:08.710+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:19:08.756+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:19:08.756+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:19:08.774+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:19:08.774+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:19:08.785+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-12T18:19:39.036+0000] {processor.py:157} INFO - Started process (PID=65888) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:19:39.040+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:19:39.050+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:19:39.048+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:19:39.084+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:19:39.147+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:19:39.147+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:19:39.175+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:19:39.175+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:19:39.190+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.164 seconds
[2024-09-12T18:20:09.597+0000] {processor.py:157} INFO - Started process (PID=65898) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:20:09.599+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:20:09.604+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:20:09.603+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:20:09.619+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:20:09.654+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:20:09.654+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:20:09.671+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:20:09.671+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:20:09.682+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-12T18:20:39.934+0000] {processor.py:157} INFO - Started process (PID=65908) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:20:39.937+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:20:39.941+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:20:39.940+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:20:39.958+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:20:39.988+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:20:39.988+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:20:40.004+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:20:40.004+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:20:40.017+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-12T18:21:10.267+0000] {processor.py:157} INFO - Started process (PID=65918) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:21:10.271+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:21:10.276+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:21:10.275+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:21:10.316+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:21:10.356+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:21:10.355+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:21:10.375+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:21:10.375+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:21:10.388+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-09-12T18:21:40.556+0000] {processor.py:157} INFO - Started process (PID=65928) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:21:40.558+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:21:40.563+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:21:40.563+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:21:40.607+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:21:40.644+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:21:40.644+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:21:40.677+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:21:40.676+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:21:40.690+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.141 seconds
[2024-09-12T18:22:10.902+0000] {processor.py:157} INFO - Started process (PID=65938) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:22:10.905+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:22:10.909+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:22:10.909+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:22:10.924+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:22:10.955+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:22:10.955+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:22:10.971+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:22:10.971+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:22:10.981+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-12T18:22:41.307+0000] {processor.py:157} INFO - Started process (PID=65948) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:22:41.308+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:22:41.319+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:22:41.314+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:22:41.344+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:22:41.393+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:22:41.393+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:22:41.406+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:22:41.406+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:22:41.417+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-09-12T18:23:11.642+0000] {processor.py:157} INFO - Started process (PID=65956) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:23:11.643+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:23:11.648+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:23:11.647+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:23:11.693+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:23:11.718+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:23:11.718+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:23:11.736+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:23:11.736+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:23:11.746+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-09-12T18:23:42.071+0000] {processor.py:157} INFO - Started process (PID=65968) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:23:42.075+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:23:42.079+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:23:42.079+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:23:42.099+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:23:42.118+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:23:42.118+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:23:42.131+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:23:42.131+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:23:42.142+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-12T18:24:12.456+0000] {processor.py:157} INFO - Started process (PID=65978) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:24:12.457+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:24:12.458+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:24:12.458+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:24:12.468+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:24:12.484+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:24:12.484+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:24:12.494+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:24:12.494+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:24:12.504+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-12T18:24:42.878+0000] {processor.py:157} INFO - Started process (PID=65987) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:24:42.880+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:24:42.884+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:24:42.883+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:24:42.901+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:24:42.928+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:24:42.928+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:24:42.941+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:24:42.941+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:24:42.951+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-12T18:25:13.176+0000] {processor.py:157} INFO - Started process (PID=65998) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:25:13.182+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:25:13.184+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:25:13.184+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:25:13.194+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:25:13.208+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:25:13.208+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:25:13.219+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:25:13.219+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:25:13.228+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-12T18:25:43.550+0000] {processor.py:157} INFO - Started process (PID=66008) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:25:43.552+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:25:43.555+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:25:43.555+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:25:43.575+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:25:43.601+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:25:43.601+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:25:43.615+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:25:43.615+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:25:43.625+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-12T18:26:13.981+0000] {processor.py:157} INFO - Started process (PID=66018) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:26:13.982+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:26:13.984+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:26:13.984+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:26:13.998+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:26:14.021+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:26:14.021+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:26:14.033+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:26:14.033+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:26:14.043+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-12T18:26:44.285+0000] {processor.py:157} INFO - Started process (PID=66028) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:26:44.286+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:26:44.287+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:26:44.287+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:26:44.301+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:26:44.314+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:26:44.314+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:26:44.324+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:26:44.324+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:26:44.333+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-12T18:27:14.654+0000] {processor.py:157} INFO - Started process (PID=66038) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:27:14.656+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:27:14.660+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:27:14.660+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:27:14.677+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:27:14.726+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:27:14.726+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:27:14.740+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:27:14.740+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:27:14.751+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-12T18:27:45.093+0000] {processor.py:157} INFO - Started process (PID=66048) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:27:45.094+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:27:45.098+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:27:45.097+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:27:45.113+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:27:45.136+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:27:45.136+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:27:45.146+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:27:45.146+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:27:45.155+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-12T18:28:15.441+0000] {processor.py:157} INFO - Started process (PID=66058) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:28:15.447+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:28:15.458+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:28:15.456+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:28:15.476+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:28:15.500+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:28:15.499+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:28:15.512+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:28:15.512+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:28:15.525+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-12T18:28:45.772+0000] {processor.py:157} INFO - Started process (PID=66068) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:28:45.774+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:28:45.778+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:28:45.778+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:28:45.794+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:28:45.833+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:28:45.833+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:28:45.856+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:28:45.856+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:28:45.868+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-12T18:29:16.038+0000] {processor.py:157} INFO - Started process (PID=66078) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:29:16.041+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:29:16.043+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:29:16.043+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:29:16.059+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:29:16.075+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:29:16.074+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:29:16.087+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:29:16.087+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:29:16.097+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-12T18:29:46.393+0000] {processor.py:157} INFO - Started process (PID=66088) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:29:46.395+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:29:46.398+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:29:46.397+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:29:46.415+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:29:46.438+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:29:46.438+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:29:46.450+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:29:46.450+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:29:46.460+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-12T18:30:16.696+0000] {processor.py:157} INFO - Started process (PID=66098) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:30:16.697+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:30:16.710+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:30:16.708+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:30:16.727+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:30:16.751+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:30:16.751+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:30:16.764+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:30:16.764+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:30:16.773+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-12T18:30:46.991+0000] {processor.py:157} INFO - Started process (PID=66108) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:30:46.997+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:30:47.006+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:30:47.006+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:30:47.032+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:30:47.058+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:30:47.058+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:30:47.071+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:30:47.071+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:30:47.081+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-12T18:31:17.294+0000] {processor.py:157} INFO - Started process (PID=66118) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:31:17.295+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:31:17.298+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:31:17.298+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:31:17.312+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:31:17.333+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:31:17.333+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:31:17.346+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:31:17.346+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:31:17.356+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-12T18:31:47.653+0000] {processor.py:157} INFO - Started process (PID=66128) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:31:47.655+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:31:47.660+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:31:47.660+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:31:47.673+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:31:47.696+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:31:47.696+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:31:47.708+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:31:47.708+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:31:47.720+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-12T18:32:17.956+0000] {processor.py:157} INFO - Started process (PID=66138) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:32:17.957+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:32:17.960+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:32:17.960+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:32:17.975+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:32:17.990+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:32:17.990+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:32:17.999+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:32:17.999+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:32:18.007+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-12T18:32:48.431+0000] {processor.py:157} INFO - Started process (PID=66148) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:32:48.435+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:32:48.437+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:32:48.437+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:32:48.453+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:32:48.477+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:32:48.477+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:32:48.489+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:32:48.489+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:32:48.499+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-12T18:33:18.774+0000] {processor.py:157} INFO - Started process (PID=66158) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:33:18.776+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:33:18.802+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:33:18.796+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:33:18.869+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:33:18.899+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:33:18.899+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:33:18.918+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:33:18.918+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:33:18.928+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.168 seconds
[2024-09-12T18:33:49.120+0000] {processor.py:157} INFO - Started process (PID=66168) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:33:49.123+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:33:49.135+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:33:49.135+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:33:49.151+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:33:49.188+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:33:49.188+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:33:49.201+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:33:49.201+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:33:49.211+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-12T18:34:19.517+0000] {processor.py:157} INFO - Started process (PID=66178) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:34:19.520+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:34:19.523+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:34:19.523+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:34:19.548+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:34:19.574+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:34:19.574+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:34:19.589+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:34:19.589+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:34:19.600+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-12T18:34:49.823+0000] {processor.py:157} INFO - Started process (PID=66188) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:34:49.825+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:34:49.827+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:34:49.827+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:34:49.836+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:34:49.852+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:34:49.852+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:34:49.862+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:34:49.862+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:34:49.870+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-12T18:35:20.173+0000] {processor.py:157} INFO - Started process (PID=66198) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:35:20.174+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:35:20.178+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:35:20.178+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:35:20.191+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:35:20.214+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:35:20.214+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:35:20.227+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:35:20.227+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:35:20.236+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-12T18:35:50.579+0000] {processor.py:157} INFO - Started process (PID=66208) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:35:50.580+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:35:50.581+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:35:50.581+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:35:50.595+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:35:50.608+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:35:50.608+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:35:50.619+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:35:50.619+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:35:50.629+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-12T18:36:20.972+0000] {processor.py:157} INFO - Started process (PID=66218) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:36:20.976+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:36:20.978+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:36:20.978+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:36:20.994+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:36:21.019+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:36:21.019+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:36:21.032+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:36:21.032+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:36:21.041+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-12T18:36:51.352+0000] {processor.py:157} INFO - Started process (PID=66228) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:36:51.353+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:36:51.354+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:36:51.354+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:36:51.370+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:36:51.382+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:36:51.382+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:36:51.391+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:36:51.391+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:36:51.401+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-12T18:37:21.746+0000] {processor.py:157} INFO - Started process (PID=66238) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:37:21.748+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:37:21.751+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:37:21.750+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:37:21.775+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:37:21.804+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:37:21.804+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:37:21.817+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:37:21.817+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:37:21.827+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-12T18:37:52.117+0000] {processor.py:157} INFO - Started process (PID=66248) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:37:52.119+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:37:52.121+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:37:52.121+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:37:52.136+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:37:52.159+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:37:52.159+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:37:52.171+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:37:52.171+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:37:52.181+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-12T18:38:22.490+0000] {processor.py:157} INFO - Started process (PID=66258) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:38:22.493+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:38:22.494+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:38:22.494+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:38:22.505+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:38:22.524+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:38:22.524+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:38:22.535+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:38:22.535+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:38:22.543+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-12T18:38:52.882+0000] {processor.py:157} INFO - Started process (PID=66268) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:38:52.884+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:38:52.894+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:38:52.890+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:38:52.916+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:38:52.941+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:38:52.941+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:38:52.954+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:38:52.953+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:38:52.962+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-12T18:39:23.151+0000] {processor.py:157} INFO - Started process (PID=66278) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:39:23.155+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:39:23.168+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:39:23.167+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:39:23.184+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:39:23.206+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:39:23.206+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:39:23.219+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:39:23.219+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:39:23.229+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-12T18:39:53.453+0000] {processor.py:157} INFO - Started process (PID=66288) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:39:53.454+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:39:53.455+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:39:53.455+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:39:53.467+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:39:53.483+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:39:53.483+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:39:53.493+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:39:53.493+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:39:53.502+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-12T18:40:23.805+0000] {processor.py:157} INFO - Started process (PID=66297) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:40:23.807+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:40:23.810+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:40:23.810+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:40:23.825+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:40:23.846+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:40:23.846+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:40:23.858+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:40:23.858+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:40:23.872+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-12T18:40:54.076+0000] {processor.py:157} INFO - Started process (PID=66308) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:40:54.078+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:40:54.080+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:40:54.080+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:40:54.094+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:40:54.107+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:40:54.107+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:40:54.117+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:40:54.117+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:40:54.126+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-12T18:41:24.464+0000] {processor.py:157} INFO - Started process (PID=66316) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:41:24.468+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:41:24.484+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:41:24.483+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:41:24.501+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:41:24.530+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:41:24.530+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:41:24.556+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:41:24.555+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:41:24.568+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-12T18:41:54.834+0000] {processor.py:157} INFO - Started process (PID=66327) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:41:54.836+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:41:54.843+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:41:54.842+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:41:54.866+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:41:54.895+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:41:54.895+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:41:54.907+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:41:54.907+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:41:54.916+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-12T18:42:25.135+0000] {processor.py:157} INFO - Started process (PID=66338) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:42:25.136+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:42:25.138+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:42:25.138+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:42:25.150+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:42:25.163+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:42:25.162+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:42:25.171+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:42:25.171+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:42:25.179+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-09-12T18:42:55.560+0000] {processor.py:157} INFO - Started process (PID=66348) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:42:55.562+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:42:55.570+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:42:55.570+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:42:55.586+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:42:55.612+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:42:55.612+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:42:55.625+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:42:55.624+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:42:55.634+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-12T18:43:25.880+0000] {processor.py:157} INFO - Started process (PID=66358) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:43:25.881+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:43:25.883+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:43:25.883+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:43:25.893+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:43:25.909+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:43:25.909+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:43:25.921+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:43:25.921+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:43:25.932+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-12T18:43:56.250+0000] {processor.py:157} INFO - Started process (PID=66367) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:43:56.251+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:43:56.255+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:43:56.255+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:43:56.271+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:43:56.295+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:43:56.295+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:43:56.307+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:43:56.307+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:43:56.318+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-12T18:44:26.593+0000] {processor.py:157} INFO - Started process (PID=66378) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:44:26.596+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:44:26.600+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:44:26.600+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:44:26.615+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:44:26.636+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:44:26.636+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:44:26.654+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:44:26.653+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:44:26.672+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-12T18:44:56.961+0000] {processor.py:157} INFO - Started process (PID=66387) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:44:56.964+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:44:56.973+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:44:56.972+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:44:57.004+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:44:57.039+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:44:57.039+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:44:57.064+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:44:57.064+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:44:57.077+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-12T18:45:27.312+0000] {processor.py:157} INFO - Started process (PID=66398) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:45:27.315+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:45:27.319+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:45:27.318+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:45:27.350+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:45:27.416+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:45:27.415+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:45:27.446+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:45:27.446+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:45:27.468+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.162 seconds
[2024-09-12T18:45:57.907+0000] {processor.py:157} INFO - Started process (PID=66406) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:45:57.912+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:45:57.926+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:45:57.923+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:45:57.963+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:45:58.012+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:45:58.012+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:45:58.030+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:45:58.030+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:45:58.043+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.155 seconds
[2024-09-12T18:46:28.376+0000] {processor.py:157} INFO - Started process (PID=66418) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:46:28.378+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:46:28.384+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:46:28.384+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:46:28.403+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:46:28.438+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:46:28.438+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:46:28.456+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:46:28.455+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:46:28.471+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-09-12T18:46:58.798+0000] {processor.py:157} INFO - Started process (PID=66427) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:46:58.804+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:46:58.808+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:46:58.808+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:46:58.830+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:46:58.865+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:46:58.864+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:46:58.889+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:46:58.889+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:46:58.905+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-09-12T18:47:29.166+0000] {processor.py:157} INFO - Started process (PID=66438) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:47:29.174+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:47:29.190+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:47:29.186+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:47:29.222+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:47:29.285+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:47:29.285+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:47:29.304+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:47:29.304+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:47:29.325+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.181 seconds
[2024-09-12T18:47:59.478+0000] {processor.py:157} INFO - Started process (PID=66448) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:47:59.482+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:47:59.488+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:47:59.487+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:47:59.517+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:47:59.563+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:47:59.562+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:47:59.588+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:47:59.588+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:47:59.617+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.149 seconds
[2024-09-12T18:48:29.958+0000] {processor.py:157} INFO - Started process (PID=66458) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:48:29.968+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:48:29.981+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:48:29.981+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:48:30.004+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:48:30.053+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:48:30.053+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:48:30.072+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:48:30.072+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:48:30.084+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.145 seconds
[2024-09-12T18:49:00.313+0000] {processor.py:157} INFO - Started process (PID=66468) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:49:00.319+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:49:00.326+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:49:00.325+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:49:00.390+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:49:00.431+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:49:00.431+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:49:00.453+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:49:00.452+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:49:00.475+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.170 seconds
[2024-09-12T18:49:30.851+0000] {processor.py:157} INFO - Started process (PID=66477) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:49:30.854+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:49:30.859+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:49:30.859+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:49:30.898+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:49:30.933+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:49:30.933+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:49:30.947+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:49:30.947+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:49:30.957+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-12T18:50:01.217+0000] {processor.py:157} INFO - Started process (PID=66488) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:50:01.219+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:50:01.223+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:50:01.222+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:50:01.240+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:50:01.281+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:50:01.281+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:50:01.297+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:50:01.297+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:50:01.317+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-12T18:50:31.514+0000] {processor.py:157} INFO - Started process (PID=66498) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:50:31.515+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:50:31.520+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:50:31.519+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:50:31.534+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:50:31.557+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:50:31.557+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:50:31.570+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:50:31.569+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:50:31.579+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-12T18:51:01.894+0000] {processor.py:157} INFO - Started process (PID=66508) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:51:01.897+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:51:01.899+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:51:01.899+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:51:01.917+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:51:01.938+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:51:01.938+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:51:01.951+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:51:01.951+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:51:01.965+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-12T18:51:32.213+0000] {processor.py:157} INFO - Started process (PID=66518) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:51:32.216+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:51:32.219+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:51:32.219+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:51:32.235+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:51:32.258+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:51:32.258+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:51:32.272+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:51:32.272+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:51:32.284+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-12T18:52:02.567+0000] {processor.py:157} INFO - Started process (PID=66528) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:52:02.569+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:52:02.571+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:52:02.571+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:52:02.585+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:52:02.608+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:52:02.608+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:52:02.621+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:52:02.621+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:52:02.632+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-12T18:52:32.838+0000] {processor.py:157} INFO - Started process (PID=66538) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:52:32.840+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:52:32.842+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:52:32.841+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:52:32.852+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:52:32.868+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:52:32.868+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:52:32.878+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:52:32.878+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:52:32.889+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-12T18:53:03.239+0000] {processor.py:157} INFO - Started process (PID=66548) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:53:03.242+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:53:03.245+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:53:03.245+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:53:03.257+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:53:03.279+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:53:03.279+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:53:03.293+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:53:03.293+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:53:03.303+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-12T18:53:33.555+0000] {processor.py:157} INFO - Started process (PID=66558) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:53:33.556+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:53:33.559+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:53:33.559+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:53:33.570+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:53:33.592+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:53:33.592+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:53:33.607+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:53:33.607+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:53:33.618+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-12T18:54:03.943+0000] {processor.py:157} INFO - Started process (PID=66567) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:54:03.945+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:54:03.950+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:54:03.950+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:54:03.965+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:54:03.992+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:54:03.991+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:54:04.006+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:54:04.006+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:54:04.017+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-12T18:54:34.327+0000] {processor.py:157} INFO - Started process (PID=66578) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:54:34.330+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:54:34.333+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:54:34.333+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:54:34.341+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:54:34.357+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:54:34.357+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:54:34.369+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:54:34.369+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:54:34.376+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-12T18:55:04.703+0000] {processor.py:157} INFO - Started process (PID=66588) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:55:04.705+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:55:04.710+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:55:04.710+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:55:04.723+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:55:04.756+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:55:04.756+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:55:04.768+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:55:04.768+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:55:04.778+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-12T18:55:35.077+0000] {processor.py:157} INFO - Started process (PID=66598) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:55:35.078+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:55:35.081+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:55:35.081+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:55:35.089+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:55:35.104+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:55:35.104+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:55:35.114+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:55:35.114+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:55:35.125+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-12T18:56:05.479+0000] {processor.py:157} INFO - Started process (PID=66608) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:56:05.482+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:56:05.485+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:56:05.485+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:56:05.501+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:56:05.533+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:56:05.533+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:56:05.545+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:56:05.545+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:56:05.555+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-12T18:56:35.836+0000] {processor.py:157} INFO - Started process (PID=66618) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:56:35.837+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:56:35.839+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:56:35.838+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:56:35.852+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:56:35.869+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:56:35.869+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:56:35.881+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:56:35.881+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:56:35.889+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-12T18:57:06.297+0000] {processor.py:157} INFO - Started process (PID=66627) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:57:06.298+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:57:06.307+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:57:06.306+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:57:06.321+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:57:06.345+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:57:06.345+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:57:06.357+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:57:06.357+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:57:06.366+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-12T18:57:36.645+0000] {processor.py:157} INFO - Started process (PID=66638) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:57:36.647+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:57:36.648+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:57:36.648+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:57:36.657+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:57:36.673+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:57:36.673+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:57:36.683+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:57:36.683+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:57:36.694+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-12T18:58:06.979+0000] {processor.py:157} INFO - Started process (PID=66647) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:58:06.980+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:58:06.986+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:58:06.986+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:58:07.001+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:58:07.029+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:58:07.029+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:58:07.042+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:58:07.042+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:58:07.050+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-12T18:58:37.352+0000] {processor.py:157} INFO - Started process (PID=66658) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:58:37.353+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:58:37.355+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:58:37.354+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:58:37.363+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:58:37.379+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:58:37.379+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:58:37.391+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:58:37.391+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:58:37.400+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-12T18:59:07.786+0000] {processor.py:157} INFO - Started process (PID=66667) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:59:07.789+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:59:07.790+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:59:07.790+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:59:07.806+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:59:07.838+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:59:07.838+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:59:07.851+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:59:07.851+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:59:07.862+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-09-12T18:59:38.228+0000] {processor.py:157} INFO - Started process (PID=66677) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:59:38.230+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T18:59:38.234+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:59:38.234+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:59:38.267+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T18:59:38.293+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:59:38.293+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T18:59:38.305+0000] {logging_mixin.py:151} INFO - [2024-09-12T18:59:38.305+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T18:59:38.315+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-12T19:00:08.638+0000] {processor.py:157} INFO - Started process (PID=66688) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:00:08.645+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:00:08.648+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:00:08.648+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:00:08.669+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:00:08.726+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:00:08.726+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:00:08.755+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:00:08.755+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:00:08.766+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.137 seconds
[2024-09-12T19:00:38.979+0000] {processor.py:157} INFO - Started process (PID=66698) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:00:38.982+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:00:38.985+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:00:38.984+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:00:39.001+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:00:39.025+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:00:39.024+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:00:39.037+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:00:39.037+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:00:39.047+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-12T19:01:09.339+0000] {processor.py:157} INFO - Started process (PID=66708) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:01:09.340+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:01:09.342+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:01:09.342+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:01:09.358+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:01:09.382+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:01:09.382+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:01:09.395+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:01:09.395+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:01:09.406+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-12T19:01:39.768+0000] {processor.py:157} INFO - Started process (PID=66718) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:01:39.769+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:01:39.772+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:01:39.772+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:01:39.788+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:01:39.813+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:01:39.813+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:01:39.827+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:01:39.827+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:01:39.837+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-12T19:02:10.094+0000] {processor.py:157} INFO - Started process (PID=66728) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:02:10.095+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:02:10.097+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:02:10.097+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:02:10.111+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:02:10.130+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:02:10.130+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:02:10.143+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:02:10.143+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:02:10.151+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-12T19:02:40.430+0000] {processor.py:157} INFO - Started process (PID=66738) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:02:40.431+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:02:40.434+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:02:40.434+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:02:40.451+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:02:40.470+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:02:40.469+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:02:40.479+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:02:40.479+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:02:40.487+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-12T19:03:10.861+0000] {processor.py:157} INFO - Started process (PID=66748) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:03:10.862+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:03:10.864+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:03:10.864+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:03:10.873+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:03:10.899+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:03:10.899+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:03:10.909+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:03:10.909+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:03:10.919+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-12T19:03:41.236+0000] {processor.py:157} INFO - Started process (PID=66758) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:03:41.238+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:03:41.240+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:03:41.240+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:03:41.255+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:03:41.293+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:03:41.293+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:03:41.307+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:03:41.307+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:03:41.318+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-12T19:04:11.555+0000] {processor.py:157} INFO - Started process (PID=66768) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:04:11.556+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:04:11.559+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:04:11.559+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:04:11.572+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:04:11.588+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:04:11.588+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:04:11.599+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:04:11.599+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:04:11.608+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-12T19:04:42.011+0000] {processor.py:157} INFO - Started process (PID=66778) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:04:42.012+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:04:42.017+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:04:42.016+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:04:42.052+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:04:42.080+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:04:42.079+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:04:42.093+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:04:42.093+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:04:42.102+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-12T19:05:12.350+0000] {processor.py:157} INFO - Started process (PID=66788) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:05:12.351+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:05:12.354+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:05:12.353+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:05:12.367+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:05:12.390+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:05:12.390+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:05:12.404+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:05:12.404+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:05:12.414+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-12T19:05:42.761+0000] {processor.py:157} INFO - Started process (PID=66798) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:05:42.764+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:05:42.767+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:05:42.767+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:05:42.780+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:05:42.798+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:05:42.798+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:05:42.808+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:05:42.808+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:05:42.818+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-12T19:06:13.139+0000] {processor.py:157} INFO - Started process (PID=66807) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:06:13.140+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:06:13.142+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:06:13.142+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:06:13.171+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:06:13.195+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:06:13.195+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:06:13.216+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:06:13.216+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:06:13.226+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-12T19:06:43.438+0000] {processor.py:157} INFO - Started process (PID=66818) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:06:43.441+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:06:43.444+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:06:43.444+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:06:43.455+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:06:43.473+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:06:43.473+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:06:43.484+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:06:43.484+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:06:43.495+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-12T19:07:13.856+0000] {processor.py:157} INFO - Started process (PID=66827) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:07:13.859+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:07:13.861+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:07:13.860+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:07:13.891+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:07:13.916+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:07:13.916+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:07:13.928+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:07:13.928+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:07:13.939+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-12T19:07:44.240+0000] {processor.py:157} INFO - Started process (PID=66838) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:07:44.242+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:07:44.244+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:07:44.243+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:07:44.253+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:07:44.273+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:07:44.273+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:07:44.283+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:07:44.283+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:07:44.292+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-12T19:08:14.604+0000] {processor.py:157} INFO - Started process (PID=66847) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:08:14.606+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:08:14.609+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:08:14.608+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:08:14.624+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:08:14.645+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:08:14.645+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:08:14.667+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:08:14.667+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:08:14.685+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-12T19:08:45.065+0000] {processor.py:157} INFO - Started process (PID=66858) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:08:45.068+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:08:45.070+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:08:45.069+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:08:45.080+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:08:45.098+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:08:45.098+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:08:45.109+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:08:45.109+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:08:45.118+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-12T19:09:15.455+0000] {processor.py:157} INFO - Started process (PID=66868) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:09:15.458+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:09:15.461+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:09:15.461+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:09:15.476+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:09:15.499+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:09:15.499+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:09:15.511+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:09:15.511+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:09:15.521+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-12T19:09:45.857+0000] {processor.py:157} INFO - Started process (PID=66878) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:09:45.861+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:09:45.863+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:09:45.863+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:09:45.874+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:09:45.892+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:09:45.892+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:09:45.903+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:09:45.903+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:09:45.912+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-12T19:10:16.235+0000] {processor.py:157} INFO - Started process (PID=66888) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:10:16.238+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:10:16.240+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:10:16.239+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:10:16.253+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:10:16.275+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:10:16.275+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:10:16.289+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:10:16.289+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:10:16.297+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-12T19:10:46.520+0000] {processor.py:157} INFO - Started process (PID=66898) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:10:46.521+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:10:46.523+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:10:46.523+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:10:46.534+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:10:46.548+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:10:46.548+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:10:46.558+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:10:46.558+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:10:46.567+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-12T19:11:16.869+0000] {processor.py:157} INFO - Started process (PID=66908) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:11:16.870+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:11:16.871+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:11:16.871+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:11:16.883+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:11:16.899+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:11:16.899+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:11:16.910+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:11:16.910+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:11:16.929+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-12T19:11:47.329+0000] {processor.py:157} INFO - Started process (PID=66918) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:11:47.329+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:11:47.332+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:11:47.332+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:11:47.353+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:11:47.376+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:11:47.376+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:11:47.389+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:11:47.389+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:11:47.401+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-12T19:12:17.658+0000] {processor.py:157} INFO - Started process (PID=66928) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:12:17.662+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:12:17.665+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:12:17.664+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:12:17.675+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:12:17.691+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:12:17.691+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:12:17.701+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:12:17.701+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:12:17.710+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-12T19:12:47.985+0000] {processor.py:157} INFO - Started process (PID=66938) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:12:47.986+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:12:47.988+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:12:47.988+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:12:47.996+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:12:48.011+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:12:48.011+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:12:48.020+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:12:48.020+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:12:48.029+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-09-12T19:13:18.393+0000] {processor.py:157} INFO - Started process (PID=66948) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:13:18.395+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:13:18.398+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:13:18.398+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:13:18.431+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:13:18.457+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:13:18.457+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:13:18.470+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:13:18.470+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:13:18.480+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-12T19:13:48.764+0000] {processor.py:157} INFO - Started process (PID=66958) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:13:48.766+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:13:48.769+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:13:48.769+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:13:48.782+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:13:48.804+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:13:48.804+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:13:48.816+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:13:48.816+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:13:48.824+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-12T19:14:19.211+0000] {processor.py:157} INFO - Started process (PID=66968) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:14:19.212+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:14:19.214+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:14:19.214+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:14:19.224+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:14:19.242+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:14:19.242+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:14:19.255+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:14:19.255+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:14:19.262+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-12T19:14:49.629+0000] {processor.py:157} INFO - Started process (PID=66976) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:14:49.630+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:14:49.633+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:14:49.633+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:14:49.647+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:14:49.671+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:14:49.671+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:14:49.681+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:14:49.681+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:14:49.689+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-12T19:15:19.924+0000] {processor.py:157} INFO - Started process (PID=66988) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:15:19.926+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:15:19.930+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:15:19.930+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:15:19.948+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:15:19.963+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:15:19.963+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:15:19.973+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:15:19.973+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:15:19.982+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-12T19:15:50.301+0000] {processor.py:157} INFO - Started process (PID=66997) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:15:50.302+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:15:50.305+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:15:50.304+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:15:50.320+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:15:50.350+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:15:50.350+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:15:50.370+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:15:50.370+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:15:50.379+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-12T19:16:20.604+0000] {processor.py:157} INFO - Started process (PID=67008) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:16:20.607+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:16:20.611+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:16:20.611+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:16:20.630+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:16:20.651+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:16:20.651+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:16:20.679+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:16:20.679+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:16:20.689+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-12T19:16:50.938+0000] {processor.py:157} INFO - Started process (PID=67018) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:16:50.945+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:16:50.947+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:16:50.947+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:16:50.956+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:16:50.974+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:16:50.974+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:16:50.985+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:16:50.985+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:16:50.994+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-12T19:17:21.319+0000] {processor.py:157} INFO - Started process (PID=67028) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:17:21.320+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:17:21.323+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:17:21.322+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:17:21.338+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:17:21.363+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:17:21.363+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:17:21.385+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:17:21.385+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:17:21.404+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-12T19:17:51.683+0000] {processor.py:157} INFO - Started process (PID=67038) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:17:51.685+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:17:51.687+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:17:51.687+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:17:51.702+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:17:51.728+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:17:51.728+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:17:51.740+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:17:51.740+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:17:51.748+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-12T19:18:22.053+0000] {processor.py:157} INFO - Started process (PID=67048) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:18:22.055+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:18:22.057+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:18:22.057+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:18:22.068+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:18:22.093+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:18:22.093+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:18:22.107+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:18:22.107+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:18:22.120+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-12T19:18:52.463+0000] {processor.py:157} INFO - Started process (PID=67056) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:18:52.465+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:18:52.468+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:18:52.468+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:18:52.482+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:18:52.514+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:18:52.514+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:18:52.526+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:18:52.526+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:18:52.536+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-12T19:19:22.790+0000] {processor.py:157} INFO - Started process (PID=67068) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:19:22.792+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:19:22.801+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:19:22.801+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:19:22.810+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:19:22.823+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:19:22.823+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:19:22.835+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:19:22.835+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:19:22.842+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-12T19:19:53.177+0000] {processor.py:157} INFO - Started process (PID=67078) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:19:53.178+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:19:53.182+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:19:53.182+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:19:53.215+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:19:53.243+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:19:53.243+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:19:53.256+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:19:53.256+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:19:53.267+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-12T19:20:23.517+0000] {processor.py:157} INFO - Started process (PID=67088) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:20:23.519+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:20:23.521+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:20:23.521+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:20:23.531+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:20:23.548+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:20:23.548+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:20:23.558+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:20:23.558+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:20:23.566+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-12T19:20:53.862+0000] {processor.py:157} INFO - Started process (PID=67098) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:20:53.862+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:20:53.864+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:20:53.864+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:20:53.880+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:20:53.917+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:20:53.917+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:20:53.933+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:20:53.933+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:20:53.943+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-12T19:21:24.185+0000] {processor.py:157} INFO - Started process (PID=67108) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:21:24.188+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:21:24.193+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:21:24.193+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:21:24.211+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:21:24.247+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:21:24.247+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:21:24.266+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:21:24.266+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:21:24.281+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-12T19:21:54.430+0000] {processor.py:157} INFO - Started process (PID=67118) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:21:54.431+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:21:54.433+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:21:54.433+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:21:54.447+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:21:54.462+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:21:54.462+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:21:54.473+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:21:54.473+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:21:54.482+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-12T19:22:24.754+0000] {processor.py:157} INFO - Started process (PID=67128) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:22:24.756+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:22:24.757+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:22:24.757+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:22:24.772+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:22:24.797+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:22:24.797+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:22:24.809+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:22:24.809+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:22:24.818+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-12T19:22:55.211+0000] {processor.py:157} INFO - Started process (PID=67138) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:22:55.213+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:22:55.215+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:22:55.215+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:22:55.225+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:22:55.251+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:22:55.251+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:22:55.264+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:22:55.264+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:22:55.275+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-12T19:23:25.621+0000] {processor.py:157} INFO - Started process (PID=67148) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:23:25.622+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:23:25.624+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:23:25.624+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:23:25.633+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:23:25.651+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:23:25.651+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:23:25.662+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:23:25.662+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:23:25.671+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-12T19:23:56.074+0000] {processor.py:157} INFO - Started process (PID=67158) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:23:56.076+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:23:56.082+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:23:56.081+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:23:56.100+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:23:56.136+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:23:56.136+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:23:56.148+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:23:56.148+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:23:56.158+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-12T19:24:26.351+0000] {processor.py:157} INFO - Started process (PID=67168) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:24:26.353+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:24:26.355+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:24:26.355+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:24:26.366+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:24:26.383+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:24:26.382+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:24:26.392+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:24:26.391+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:24:26.400+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-12T19:24:56.736+0000] {processor.py:157} INFO - Started process (PID=67178) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:24:56.739+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:24:56.741+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:24:56.741+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:24:56.751+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:24:56.769+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:24:56.769+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:24:56.779+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:24:56.779+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:24:56.789+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-12T19:25:27.147+0000] {processor.py:157} INFO - Started process (PID=67188) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:25:27.150+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:25:27.153+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:25:27.153+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:25:27.179+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:25:27.217+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:25:27.217+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:25:27.230+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:25:27.230+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:25:27.241+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-12T19:25:57.454+0000] {processor.py:157} INFO - Started process (PID=67198) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:25:57.455+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:25:57.456+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:25:57.456+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:25:57.471+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:25:57.487+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:25:57.487+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:25:57.497+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:25:57.497+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:25:57.507+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-12T19:26:27.841+0000] {processor.py:157} INFO - Started process (PID=67208) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:26:27.843+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:26:27.846+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:26:27.845+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:26:27.862+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:26:27.883+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:26:27.883+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:26:27.896+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:26:27.895+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:26:27.906+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-12T19:26:58.226+0000] {processor.py:157} INFO - Started process (PID=67218) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:26:58.227+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:26:58.229+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:26:58.228+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:26:58.238+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:26:58.254+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:26:58.254+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:26:58.264+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:26:58.264+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:26:58.272+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-12T19:27:28.634+0000] {processor.py:157} INFO - Started process (PID=67228) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:27:28.636+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:27:28.638+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:27:28.638+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:27:28.654+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:27:28.669+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:27:28.669+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:27:28.679+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:27:28.679+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:27:28.688+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-12T19:27:58.986+0000] {processor.py:157} INFO - Started process (PID=67238) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:27:58.988+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:27:58.990+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:27:58.989+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:27:59.002+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:27:59.024+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:27:59.024+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:27:59.038+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:27:59.038+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:27:59.047+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-12T19:28:29.369+0000] {processor.py:157} INFO - Started process (PID=67248) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:28:29.370+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:28:29.372+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:28:29.371+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:28:29.381+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:28:29.403+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:28:29.403+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:28:29.416+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:28:29.416+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:28:29.429+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-12T19:28:59.712+0000] {processor.py:157} INFO - Started process (PID=67258) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:28:59.714+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:28:59.716+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:28:59.716+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:28:59.727+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:28:59.744+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:28:59.744+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:28:59.755+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:28:59.755+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:28:59.764+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-12T19:29:30.092+0000] {processor.py:157} INFO - Started process (PID=67268) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:29:30.095+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:29:30.098+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:29:30.097+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:29:30.119+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:29:30.143+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:29:30.143+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:29:30.157+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:29:30.157+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:29:30.169+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-12T19:30:00.489+0000] {processor.py:157} INFO - Started process (PID=67277) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:30:00.491+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:30:00.494+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:30:00.494+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:30:00.510+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:30:00.524+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:30:00.524+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:30:00.534+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:30:00.534+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:30:00.543+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-12T19:30:30.914+0000] {processor.py:157} INFO - Started process (PID=67288) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:30:30.917+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:30:30.920+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:30:30.919+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:30:30.935+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:30:30.950+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:30:30.950+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:30:30.960+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:30:30.960+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:30:30.968+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-12T19:31:01.315+0000] {processor.py:157} INFO - Started process (PID=67298) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:31:01.318+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:31:01.321+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:31:01.321+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:31:01.337+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:31:01.362+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:31:01.362+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:31:01.375+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:31:01.375+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:31:01.386+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-12T19:31:31.596+0000] {processor.py:157} INFO - Started process (PID=67308) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:31:31.598+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:31:31.600+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:31:31.600+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:31:31.612+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:31:31.627+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:31:31.627+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:31:31.639+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:31:31.639+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:31:31.648+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-12T19:32:01.951+0000] {processor.py:157} INFO - Started process (PID=67318) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:32:01.954+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:32:01.958+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:32:01.957+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:32:01.976+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:32:02.000+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:32:02.000+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:32:02.012+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:32:02.012+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:32:02.022+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-12T19:32:32.307+0000] {processor.py:157} INFO - Started process (PID=67328) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:32:32.310+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:32:32.312+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:32:32.312+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:32:32.321+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:32:32.338+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:32:32.338+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:32:32.347+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:32:32.347+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:32:32.357+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-12T19:33:02.711+0000] {processor.py:157} INFO - Started process (PID=67338) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:33:02.715+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:33:02.720+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:33:02.719+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:33:02.736+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:33:02.763+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:33:02.763+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:33:02.776+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:33:02.776+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:33:02.785+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-12T19:33:33.007+0000] {processor.py:157} INFO - Started process (PID=67348) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:33:33.011+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:33:33.014+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:33:33.013+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:33:33.033+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:33:33.063+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:33:33.063+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:33:33.081+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:33:33.081+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:33:33.093+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-12T19:34:03.462+0000] {processor.py:157} INFO - Started process (PID=67358) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:34:03.465+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:34:03.468+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:34:03.467+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:34:03.482+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:34:03.504+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:34:03.504+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:34:03.517+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:34:03.517+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:34:03.525+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-12T19:34:33.767+0000] {processor.py:157} INFO - Started process (PID=67367) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:34:33.776+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:34:33.780+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:34:33.779+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:34:33.797+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:34:33.827+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:34:33.827+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:34:33.851+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:34:33.851+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:34:33.863+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-12T19:35:04.218+0000] {processor.py:157} INFO - Started process (PID=67378) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:35:04.221+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:35:04.224+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:35:04.223+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:35:04.258+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:35:04.306+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:35:04.306+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:35:04.328+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:35:04.328+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:35:04.339+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-09-12T19:35:34.813+0000] {processor.py:157} INFO - Started process (PID=67388) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:35:34.816+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:35:34.827+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:35:34.827+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:35:34.878+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:35:34.939+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:35:34.939+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:35:34.960+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:35:34.960+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:35:34.973+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.176 seconds
[2024-09-12T19:36:05.185+0000] {processor.py:157} INFO - Started process (PID=67398) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:36:05.188+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:36:05.194+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:36:05.193+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:36:05.247+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:36:05.292+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:36:05.291+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:36:05.310+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:36:05.310+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:36:05.323+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.142 seconds
[2024-09-12T19:36:35.552+0000] {processor.py:157} INFO - Started process (PID=67408) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:36:35.554+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:36:35.561+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:36:35.560+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:36:35.583+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:36:35.616+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:36:35.616+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:36:35.631+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:36:35.631+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:36:35.643+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-12T19:37:05.909+0000] {processor.py:157} INFO - Started process (PID=67417) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:37:05.912+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:37:05.916+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:37:05.915+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:37:05.935+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:37:05.963+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:37:05.962+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:37:05.976+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:37:05.976+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:37:05.987+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-12T19:37:36.275+0000] {processor.py:157} INFO - Started process (PID=67427) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:37:36.276+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:37:36.280+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:37:36.280+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:37:36.296+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:37:36.320+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:37:36.320+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:37:36.333+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:37:36.333+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:37:36.343+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-12T19:38:06.665+0000] {processor.py:157} INFO - Started process (PID=67438) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:38:06.666+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:38:06.671+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:38:06.671+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:38:06.690+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:38:06.716+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:38:06.716+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:38:06.729+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:38:06.729+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:38:06.738+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-12T19:38:36.996+0000] {processor.py:157} INFO - Started process (PID=67448) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:38:36.999+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:38:37.002+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:38:37.001+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:38:37.041+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:38:37.074+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:38:37.074+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:38:37.088+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:38:37.088+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:38:37.105+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-12T19:39:07.345+0000] {processor.py:157} INFO - Started process (PID=67457) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:39:07.347+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:39:07.351+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:39:07.350+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:39:07.374+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:39:07.405+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:39:07.405+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:39:07.418+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:39:07.418+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:39:07.429+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-12T19:39:37.690+0000] {processor.py:157} INFO - Started process (PID=67468) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:39:37.694+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:39:37.696+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:39:37.696+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:39:37.720+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:39:37.759+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:39:37.759+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:39:37.779+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:39:37.779+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:39:37.794+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-12T19:40:07.998+0000] {processor.py:157} INFO - Started process (PID=67478) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:40:07.999+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:40:08.004+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:40:08.003+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:40:08.021+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:40:08.046+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:40:08.046+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:40:08.060+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:40:08.060+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:40:08.072+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-12T19:40:38.354+0000] {processor.py:157} INFO - Started process (PID=67487) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:40:38.356+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:40:38.360+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:40:38.359+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:40:38.377+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:40:38.405+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:40:38.405+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:40:38.425+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:40:38.425+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:40:38.436+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-12T19:41:08.639+0000] {processor.py:157} INFO - Started process (PID=67498) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:41:08.641+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:41:08.646+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:41:08.646+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:41:08.663+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:41:08.691+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:41:08.691+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:41:08.704+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:41:08.704+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:41:08.716+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-12T19:41:39.053+0000] {processor.py:157} INFO - Started process (PID=67508) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:41:39.057+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:41:39.063+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:41:39.062+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:41:39.085+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:41:39.110+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:41:39.110+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:41:39.122+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:41:39.122+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:41:39.134+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-12T19:42:09.462+0000] {processor.py:157} INFO - Started process (PID=67518) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:42:09.464+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:42:09.469+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:42:09.469+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:42:09.483+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:42:09.510+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:42:09.510+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:42:09.524+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:42:09.524+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:42:09.535+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-12T19:42:39.790+0000] {processor.py:157} INFO - Started process (PID=67528) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:42:39.791+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:42:39.795+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:42:39.794+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:42:39.815+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:42:39.842+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:42:39.842+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:42:39.856+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:42:39.856+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:42:39.869+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-12T19:43:10.280+0000] {processor.py:157} INFO - Started process (PID=67538) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:43:10.282+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:43:10.285+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:43:10.285+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:43:10.300+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:43:10.325+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:43:10.325+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:43:10.340+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:43:10.340+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:43:10.350+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-12T19:43:40.700+0000] {processor.py:157} INFO - Started process (PID=67548) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:43:40.705+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:43:40.708+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:43:40.707+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:43:40.727+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:43:40.757+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:43:40.757+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:43:40.780+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:43:40.780+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:43:40.791+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-12T19:44:11.060+0000] {processor.py:157} INFO - Started process (PID=67558) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:44:11.063+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:44:11.072+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:44:11.071+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:44:11.098+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:44:11.126+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:44:11.126+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:44:11.138+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:44:11.138+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:44:11.149+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-12T19:44:41.376+0000] {processor.py:157} INFO - Started process (PID=67568) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:44:41.383+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:44:41.388+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:44:41.387+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:44:41.406+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:44:41.435+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:44:41.435+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:44:41.449+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:44:41.449+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:44:41.464+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-12T19:45:11.728+0000] {processor.py:157} INFO - Started process (PID=67578) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:45:11.730+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:45:11.736+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:45:11.735+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:45:11.751+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:45:11.777+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:45:11.777+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:45:11.791+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:45:11.790+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:45:11.802+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-12T19:45:42.029+0000] {processor.py:157} INFO - Started process (PID=67588) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:45:42.032+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:45:42.037+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:45:42.036+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:45:42.057+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:45:42.104+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:45:42.104+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:45:42.122+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:45:42.122+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:45:42.134+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-12T19:46:12.365+0000] {processor.py:157} INFO - Started process (PID=67598) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:46:12.368+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:46:12.372+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:46:12.372+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:46:12.397+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:46:12.448+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:46:12.448+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:46:12.470+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:46:12.470+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:46:12.484+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-09-12T19:46:42.804+0000] {processor.py:157} INFO - Started process (PID=67608) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:46:42.806+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:46:42.808+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:46:42.808+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:46:42.826+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:46:42.861+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:46:42.861+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:46:42.884+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:46:42.884+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:46:42.899+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-12T19:47:13.100+0000] {processor.py:157} INFO - Started process (PID=67618) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:47:13.103+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:47:13.115+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:47:13.112+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:47:13.184+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:47:13.216+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:47:13.216+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:47:13.240+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:47:13.240+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:47:13.253+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.157 seconds
[2024-09-12T19:47:43.386+0000] {processor.py:157} INFO - Started process (PID=67628) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:47:43.388+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:47:43.390+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:47:43.389+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:47:43.405+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:47:43.422+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:47:43.422+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:47:43.431+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:47:43.431+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:47:43.439+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-12T19:48:13.807+0000] {processor.py:157} INFO - Started process (PID=67638) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:48:13.813+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:48:13.817+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:48:13.817+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:48:13.838+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:48:13.881+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:48:13.881+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:48:13.895+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:48:13.894+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:48:13.906+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-12T19:48:44.068+0000] {processor.py:157} INFO - Started process (PID=67648) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:48:44.069+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:48:44.071+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:48:44.071+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:48:44.087+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:48:44.101+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:48:44.101+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:48:44.111+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:48:44.111+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:48:44.119+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-12T19:49:14.505+0000] {processor.py:157} INFO - Started process (PID=67658) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:49:14.507+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:49:14.513+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:49:14.512+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:49:14.544+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:49:14.591+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:49:14.590+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:49:14.611+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:49:14.611+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:49:14.627+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-09-12T19:49:44.803+0000] {processor.py:157} INFO - Started process (PID=67668) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:49:44.804+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:49:44.807+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:49:44.807+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:49:44.824+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:49:44.854+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:49:44.854+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:49:44.869+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:49:44.869+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:49:44.881+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-12T19:50:15.171+0000] {processor.py:157} INFO - Started process (PID=67678) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:50:15.172+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:50:15.175+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:50:15.175+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:50:15.213+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:50:15.244+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:50:15.244+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:50:15.260+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:50:15.259+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:50:15.270+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-12T19:50:45.466+0000] {processor.py:157} INFO - Started process (PID=67688) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:50:45.470+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:50:45.474+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:50:45.473+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:50:45.490+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:50:45.516+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:50:45.516+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:50:45.532+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:50:45.532+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:50:45.541+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-12T19:51:15.804+0000] {processor.py:157} INFO - Started process (PID=67698) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:51:15.809+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:51:15.818+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:51:15.817+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:51:15.834+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:51:15.857+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:51:15.857+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:51:15.869+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:51:15.869+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:51:15.879+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-12T19:51:46.229+0000] {processor.py:157} INFO - Started process (PID=67708) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:51:46.231+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:51:46.234+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:51:46.234+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:51:46.252+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:51:46.286+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:51:46.286+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:51:46.299+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:51:46.299+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:51:46.311+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-12T19:52:16.532+0000] {processor.py:157} INFO - Started process (PID=67717) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:52:16.535+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:52:16.548+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:52:16.546+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:52:16.576+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:52:16.618+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:52:16.618+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:52:16.640+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:52:16.640+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:52:16.655+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-09-12T19:52:46.998+0000] {processor.py:157} INFO - Started process (PID=67728) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:52:46.998+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:52:47.001+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:52:47.001+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:52:47.028+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:52:47.059+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:52:47.059+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:52:47.072+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:52:47.072+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:52:47.082+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-12T19:53:17.421+0000] {processor.py:157} INFO - Started process (PID=67738) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:53:17.428+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:53:17.431+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:53:17.431+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:53:17.449+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:53:17.473+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:53:17.473+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:53:17.485+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:53:17.485+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:53:17.498+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-12T19:53:47.841+0000] {processor.py:157} INFO - Started process (PID=67748) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:53:47.846+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:53:47.851+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:53:47.851+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:53:47.879+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:53:47.909+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:53:47.909+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:53:47.949+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:53:47.949+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:53:47.960+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-09-12T19:54:18.140+0000] {processor.py:157} INFO - Started process (PID=67758) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:54:18.145+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:54:18.154+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:54:18.153+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:54:18.176+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:54:18.207+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:54:18.207+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:54:18.222+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:54:18.222+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:54:18.235+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-12T19:54:48.450+0000] {processor.py:157} INFO - Started process (PID=67767) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:54:48.452+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:54:48.457+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:54:48.457+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:54:48.474+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:54:48.510+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:54:48.510+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:54:48.524+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:54:48.524+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:54:48.533+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-12T19:55:18.724+0000] {processor.py:157} INFO - Started process (PID=67778) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:55:18.726+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:55:18.733+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:55:18.733+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:55:18.748+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:55:18.772+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:55:18.771+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:55:18.786+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:55:18.785+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:55:18.800+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-12T19:55:49.111+0000] {processor.py:157} INFO - Started process (PID=67788) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:55:49.113+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:55:49.118+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:55:49.117+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:55:49.141+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:55:49.177+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:55:49.177+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:55:49.191+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:55:49.190+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:55:49.201+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-12T19:56:19.427+0000] {processor.py:157} INFO - Started process (PID=67797) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:56:19.430+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:56:19.435+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:56:19.435+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:56:19.456+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:56:19.481+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:56:19.481+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:56:19.494+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:56:19.494+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:56:19.503+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-12T19:56:49.717+0000] {processor.py:157} INFO - Started process (PID=67808) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:56:49.719+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:56:49.724+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:56:49.724+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:56:49.746+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:56:49.773+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:56:49.773+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:56:49.786+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:56:49.786+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:56:49.796+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-12T19:57:20.028+0000] {processor.py:157} INFO - Started process (PID=67818) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:57:20.032+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:57:20.036+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:57:20.036+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:57:20.052+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:57:20.106+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:57:20.106+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:57:20.120+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:57:20.120+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:57:20.129+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-12T19:57:50.453+0000] {processor.py:157} INFO - Started process (PID=67828) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:57:50.459+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:57:50.462+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:57:50.461+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:57:50.485+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:57:50.513+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:57:50.513+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:57:50.539+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:57:50.539+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:57:50.550+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-12T19:58:20.786+0000] {processor.py:157} INFO - Started process (PID=67838) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:58:20.792+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:58:20.798+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:58:20.797+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:58:20.819+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:58:20.867+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:58:20.867+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:58:20.882+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:58:20.882+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:58:20.893+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-12T19:58:51.104+0000] {processor.py:157} INFO - Started process (PID=67848) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:58:51.105+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:58:51.108+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:58:51.107+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:58:51.121+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:58:51.135+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:58:51.135+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:58:51.145+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:58:51.145+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:58:51.154+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-12T19:59:21.432+0000] {processor.py:157} INFO - Started process (PID=67858) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:59:21.434+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:59:21.437+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:59:21.436+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:59:21.455+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:59:21.482+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:59:21.482+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:59:21.497+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:59:21.496+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:59:21.506+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-12T19:59:51.711+0000] {processor.py:157} INFO - Started process (PID=67868) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:59:51.714+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T19:59:51.717+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:59:51.717+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:59:51.735+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T19:59:51.767+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:59:51.767+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T19:59:51.784+0000] {logging_mixin.py:151} INFO - [2024-09-12T19:59:51.784+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T19:59:51.796+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-12T20:00:22.049+0000] {processor.py:157} INFO - Started process (PID=67878) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:00:22.052+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:00:22.056+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:00:22.056+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:00:22.087+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:00:22.127+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:00:22.126+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:00:22.154+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:00:22.154+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:00:22.178+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-09-12T20:00:52.353+0000] {processor.py:157} INFO - Started process (PID=67888) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:00:52.356+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:00:52.360+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:00:52.360+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:00:52.380+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:00:52.409+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:00:52.408+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:00:52.425+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:00:52.425+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:00:52.468+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-09-12T20:01:22.678+0000] {processor.py:157} INFO - Started process (PID=67897) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:01:22.685+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:01:22.693+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:01:22.691+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:01:22.711+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:01:22.734+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:01:22.734+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:01:22.752+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:01:22.752+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:01:22.765+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-12T20:01:53.079+0000] {processor.py:157} INFO - Started process (PID=67908) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:01:53.081+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:01:53.083+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:01:53.082+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:01:53.093+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:01:53.111+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:01:53.111+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:01:53.123+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:01:53.123+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:01:53.132+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-12T20:02:23.601+0000] {processor.py:157} INFO - Started process (PID=67918) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:02:23.603+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:02:23.608+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:02:23.607+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:02:23.630+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:02:23.659+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:02:23.659+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:02:23.673+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:02:23.673+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:02:23.683+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-12T20:02:53.975+0000] {processor.py:157} INFO - Started process (PID=67928) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:02:53.986+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:02:53.991+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:02:53.991+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:02:54.009+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:02:54.038+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:02:54.037+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:02:54.054+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:02:54.054+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:02:54.070+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-12T20:03:24.280+0000] {processor.py:157} INFO - Started process (PID=67938) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:03:24.284+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:03:24.288+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:03:24.288+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:03:24.307+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:03:24.332+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:03:24.332+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:03:24.346+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:03:24.346+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:03:24.357+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-12T20:03:54.566+0000] {processor.py:157} INFO - Started process (PID=67948) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:03:54.567+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:03:54.570+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:03:54.570+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:03:54.588+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:03:54.616+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:03:54.616+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:03:54.630+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:03:54.630+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:03:54.639+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-12T20:04:24.906+0000] {processor.py:157} INFO - Started process (PID=67958) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:04:24.910+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:04:24.914+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:04:24.914+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:04:24.947+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:04:25.004+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:04:25.004+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:04:25.029+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:04:25.029+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:04:25.046+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.144 seconds
[2024-09-12T20:04:55.206+0000] {processor.py:157} INFO - Started process (PID=67967) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:04:55.211+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:04:55.218+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:04:55.218+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:04:55.251+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:04:55.283+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:04:55.283+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:04:55.315+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:04:55.315+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:04:55.326+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-09-12T20:05:25.650+0000] {processor.py:157} INFO - Started process (PID=67977) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:05:25.652+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:05:25.656+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:05:25.656+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:05:25.673+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:05:25.697+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:05:25.697+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:05:25.712+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:05:25.712+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:05:25.726+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-12T20:05:56.066+0000] {processor.py:157} INFO - Started process (PID=67988) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:05:56.070+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:05:56.073+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:05:56.073+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:05:56.101+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:05:56.131+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:05:56.131+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:05:56.146+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:05:56.146+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:05:56.156+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-12T20:06:26.428+0000] {processor.py:157} INFO - Started process (PID=67998) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:06:26.434+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:06:26.440+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:06:26.440+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:06:26.488+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:06:26.567+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:06:26.567+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:06:26.587+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:06:26.587+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:06:26.599+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.178 seconds
[2024-09-12T20:06:56.725+0000] {processor.py:157} INFO - Started process (PID=68007) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:06:56.731+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:06:56.735+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:06:56.735+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:06:56.757+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:06:56.793+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:06:56.793+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:06:56.808+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:06:56.808+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:06:56.819+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-12T20:07:27.163+0000] {processor.py:157} INFO - Started process (PID=68018) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:07:27.167+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:07:27.172+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:07:27.172+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:07:27.190+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:07:27.214+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:07:27.214+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:07:27.240+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:07:27.240+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:07:27.249+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-12T20:07:57.623+0000] {processor.py:157} INFO - Started process (PID=68027) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:07:57.626+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:07:57.632+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:07:57.631+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:07:57.662+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:07:57.688+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:07:57.688+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:07:57.700+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:07:57.700+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:07:57.709+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-12T20:08:27.935+0000] {processor.py:157} INFO - Started process (PID=68038) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:08:27.936+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:08:27.946+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:08:27.946+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:08:27.966+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:08:28.012+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:08:28.011+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:08:28.030+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:08:28.030+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:08:28.041+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-09-12T20:08:58.451+0000] {processor.py:157} INFO - Started process (PID=68048) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:08:58.457+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:08:58.466+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:08:58.465+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:08:58.488+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:08:58.532+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:08:58.532+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:08:58.546+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:08:58.546+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:08:58.558+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-12T20:09:28.792+0000] {processor.py:157} INFO - Started process (PID=68058) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:09:28.794+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:09:28.798+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:09:28.797+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:09:28.821+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:09:28.851+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:09:28.851+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:09:28.866+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:09:28.866+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:09:28.877+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-12T20:09:59.250+0000] {processor.py:157} INFO - Started process (PID=68068) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:09:59.259+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:09:59.268+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:09:59.267+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:09:59.286+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:09:59.310+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:09:59.310+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:09:59.323+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:09:59.323+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:09:59.333+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-12T20:10:29.628+0000] {processor.py:157} INFO - Started process (PID=68078) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:10:29.635+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:10:29.655+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:10:29.653+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:10:29.700+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:10:29.751+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:10:29.751+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:10:29.768+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:10:29.768+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:10:29.784+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.178 seconds
[2024-09-12T20:10:59.972+0000] {processor.py:157} INFO - Started process (PID=68088) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:10:59.976+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:10:59.984+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:10:59.982+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:11:00.005+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:11:00.041+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:11:00.040+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:11:00.058+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:11:00.058+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:11:00.072+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-09-12T20:11:30.338+0000] {processor.py:157} INFO - Started process (PID=68098) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:11:30.340+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:11:30.344+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:11:30.344+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:11:30.363+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:11:30.396+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:11:30.396+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:11:30.410+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:11:30.410+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:11:30.420+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-12T20:12:00.708+0000] {processor.py:157} INFO - Started process (PID=68108) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:12:00.711+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:12:00.716+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:12:00.715+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:12:00.751+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:12:00.783+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:12:00.783+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:12:00.797+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:12:00.797+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:12:00.808+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-09-12T20:12:31.168+0000] {processor.py:157} INFO - Started process (PID=68118) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:12:31.170+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:12:31.174+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:12:31.173+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:12:31.195+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:12:31.222+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:12:31.222+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:12:31.235+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:12:31.235+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:12:31.245+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-12T20:13:01.542+0000] {processor.py:157} INFO - Started process (PID=68128) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:13:01.545+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:13:01.549+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:13:01.549+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:13:01.571+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:13:01.612+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:13:01.612+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:13:01.627+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:13:01.627+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:13:01.639+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-12T20:13:31.869+0000] {processor.py:157} INFO - Started process (PID=68138) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:13:31.870+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:13:31.879+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:13:31.876+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:13:31.924+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:13:31.971+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:13:31.971+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:13:31.987+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:13:31.987+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:13:31.998+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-09-12T20:14:02.168+0000] {processor.py:157} INFO - Started process (PID=68148) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:14:02.171+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:14:02.175+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:14:02.175+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:14:02.218+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:14:02.256+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:14:02.256+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:14:02.271+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:14:02.271+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:14:02.284+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-12T20:14:32.579+0000] {processor.py:157} INFO - Started process (PID=68158) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:14:32.581+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:14:32.585+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:14:32.585+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:14:32.621+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:14:32.652+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:14:32.652+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:14:32.671+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:14:32.671+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:14:32.691+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-09-12T20:15:03.128+0000] {processor.py:157} INFO - Started process (PID=68168) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:15:03.132+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:15:03.136+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:15:03.135+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:15:03.158+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:15:03.187+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:15:03.187+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:15:03.201+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:15:03.201+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:15:03.213+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-12T20:15:33.468+0000] {processor.py:157} INFO - Started process (PID=68178) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:15:33.470+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:15:33.475+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:15:33.474+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:15:33.493+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:15:33.518+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:15:33.518+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:15:33.531+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:15:33.531+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:15:33.543+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-12T20:16:03.893+0000] {processor.py:157} INFO - Started process (PID=68187) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:16:03.895+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:16:03.900+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:16:03.899+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:16:03.917+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:16:03.945+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:16:03.945+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:16:03.962+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:16:03.962+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:16:03.972+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-12T20:16:34.232+0000] {processor.py:157} INFO - Started process (PID=68198) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:16:34.234+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:16:34.240+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:16:34.239+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:16:34.283+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:16:34.322+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:16:34.322+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:16:34.348+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:16:34.348+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:16:34.361+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-09-12T20:17:04.965+0000] {processor.py:157} INFO - Started process (PID=68208) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:17:04.968+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:17:04.972+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:17:04.971+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:17:04.994+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:17:05.029+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:17:05.029+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:17:05.043+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:17:05.043+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:17:05.051+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-12T20:17:35.266+0000] {processor.py:157} INFO - Started process (PID=68218) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:17:35.269+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:17:35.273+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:17:35.272+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:17:35.291+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:17:35.333+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:17:35.332+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:17:35.354+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:17:35.353+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:17:35.366+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-12T20:18:05.626+0000] {processor.py:157} INFO - Started process (PID=68228) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:18:05.628+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:18:05.635+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:18:05.633+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:18:05.657+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:18:05.697+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:18:05.697+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:18:05.714+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:18:05.714+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:18:05.730+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-12T20:18:36.026+0000] {processor.py:157} INFO - Started process (PID=68238) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:18:36.028+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:18:36.034+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:18:36.033+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:18:36.062+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:18:36.093+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:18:36.093+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:18:36.107+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:18:36.107+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:18:36.119+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-12T20:19:06.406+0000] {processor.py:157} INFO - Started process (PID=68247) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:19:06.411+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:19:06.418+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:19:06.417+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:19:06.454+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:19:06.501+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:19:06.501+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:19:06.528+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:19:06.528+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:19:06.559+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.161 seconds
[2024-09-12T20:19:36.718+0000] {processor.py:157} INFO - Started process (PID=68256) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:19:36.722+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:19:36.728+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:19:36.727+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:19:36.752+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:19:36.793+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:19:36.793+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:19:36.807+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:19:36.807+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:19:36.818+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-09-12T20:20:07.119+0000] {processor.py:157} INFO - Started process (PID=68267) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:20:07.121+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:20:07.129+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:20:07.128+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:20:07.154+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:20:07.190+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:20:07.190+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:20:07.203+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:20:07.203+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:20:07.214+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-12T20:20:37.447+0000] {processor.py:157} INFO - Started process (PID=68277) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:20:37.449+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:20:37.458+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:20:37.456+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:20:37.485+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:20:37.521+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:20:37.520+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:20:37.541+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:20:37.541+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:20:37.552+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-12T20:21:07.790+0000] {processor.py:157} INFO - Started process (PID=68288) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:21:07.791+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:21:07.802+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:21:07.802+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:21:07.824+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:21:07.857+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:21:07.857+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:21:07.871+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:21:07.871+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:21:07.881+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-12T20:21:38.113+0000] {processor.py:157} INFO - Started process (PID=68298) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:21:38.121+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:21:38.126+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:21:38.126+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:21:38.162+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:21:38.195+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:21:38.195+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:21:38.209+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:21:38.209+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:21:38.219+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-12T20:22:08.410+0000] {processor.py:157} INFO - Started process (PID=68308) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:22:08.411+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:22:08.417+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:22:08.416+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:22:08.439+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:22:08.468+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:22:08.468+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:22:08.483+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:22:08.483+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:22:08.497+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-12T20:22:38.814+0000] {processor.py:157} INFO - Started process (PID=68318) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:22:38.819+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:22:38.822+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:22:38.821+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:22:38.849+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:22:38.875+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:22:38.875+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:22:38.888+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:22:38.888+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:22:38.907+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-12T20:23:09.200+0000] {processor.py:157} INFO - Started process (PID=68328) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:23:09.202+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:23:09.212+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:23:09.209+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:23:09.248+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:23:09.280+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:23:09.280+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:23:09.295+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:23:09.295+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:23:09.305+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-12T20:23:39.659+0000] {processor.py:157} INFO - Started process (PID=68338) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:23:39.663+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:23:39.671+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:23:39.670+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:23:39.720+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:23:39.776+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:23:39.776+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:23:39.807+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:23:39.807+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:23:39.821+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.169 seconds
[2024-09-12T20:24:09.962+0000] {processor.py:157} INFO - Started process (PID=68347) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:24:09.965+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:24:09.968+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:24:09.967+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:24:09.987+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:24:10.024+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:24:10.024+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:24:10.038+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:24:10.037+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:24:10.054+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-12T20:24:40.236+0000] {processor.py:157} INFO - Started process (PID=68358) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:24:40.239+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:24:40.243+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:24:40.243+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:24:40.260+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:24:40.285+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:24:40.285+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:24:40.300+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:24:40.300+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:24:40.313+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-12T20:25:10.617+0000] {processor.py:157} INFO - Started process (PID=68368) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:25:10.618+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:25:10.621+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:25:10.621+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:25:10.641+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:25:10.662+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:25:10.661+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:25:10.676+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:25:10.675+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:25:10.685+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-12T20:25:41.081+0000] {processor.py:157} INFO - Started process (PID=68378) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:25:41.086+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:25:41.100+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:25:41.100+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:25:41.126+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:25:41.174+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:25:41.174+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:25:41.196+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:25:41.196+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:25:41.208+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.142 seconds
[2024-09-12T20:26:11.385+0000] {processor.py:157} INFO - Started process (PID=68388) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:26:11.388+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:26:11.393+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:26:11.393+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:26:11.414+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:26:11.454+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:26:11.454+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:26:11.467+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:26:11.467+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:26:11.479+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-12T20:26:41.756+0000] {processor.py:157} INFO - Started process (PID=68397) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:26:41.757+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:26:41.762+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:26:41.761+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:26:41.810+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:26:41.867+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:26:41.867+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:26:41.909+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:26:41.909+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:26:41.933+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.184 seconds
[2024-09-12T20:27:12.257+0000] {processor.py:157} INFO - Started process (PID=68407) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:27:12.260+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:27:12.268+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:27:12.267+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:27:12.311+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:27:12.368+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:27:12.368+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:27:12.389+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:27:12.389+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:27:12.404+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.155 seconds
[2024-09-12T20:27:42.605+0000] {processor.py:157} INFO - Started process (PID=68418) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:27:42.606+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:27:42.610+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:27:42.610+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:27:42.629+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:27:42.668+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:27:42.668+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:27:42.684+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:27:42.684+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:27:42.694+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-12T20:28:12.984+0000] {processor.py:157} INFO - Started process (PID=68427) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:28:12.986+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:28:12.991+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:28:12.991+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:28:13.008+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:28:13.034+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:28:13.034+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:28:13.060+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:28:13.059+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:28:13.071+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-12T20:28:43.352+0000] {processor.py:157} INFO - Started process (PID=68438) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:28:43.354+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:28:43.356+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:28:43.356+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:28:43.380+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:28:43.418+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:28:43.418+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:28:43.431+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:28:43.431+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:28:43.442+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-12T20:29:13.701+0000] {processor.py:157} INFO - Started process (PID=68448) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:29:13.702+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:29:13.706+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:29:13.705+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:29:13.725+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:29:13.753+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:29:13.753+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:29:13.767+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:29:13.767+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:29:13.778+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-12T20:29:43.999+0000] {processor.py:157} INFO - Started process (PID=68458) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:29:44.002+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:29:44.006+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:29:44.005+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:29:44.023+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:29:44.050+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:29:44.050+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:29:44.071+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:29:44.071+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:29:44.083+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-12T20:30:14.340+0000] {processor.py:157} INFO - Started process (PID=68467) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:30:14.341+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:30:14.345+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:30:14.345+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:30:14.363+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:30:14.396+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:30:14.396+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:30:14.411+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:30:14.411+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:30:14.423+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-12T20:30:44.720+0000] {processor.py:157} INFO - Started process (PID=68478) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:30:44.722+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:30:44.724+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:30:44.724+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:30:44.736+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:30:44.755+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:30:44.755+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:30:44.766+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:30:44.766+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:30:44.776+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-12T20:31:15.069+0000] {processor.py:157} INFO - Started process (PID=68488) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:31:15.070+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:31:15.075+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:31:15.075+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:31:15.108+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:31:15.136+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:31:15.136+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:31:15.150+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:31:15.150+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:31:15.161+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-12T20:31:45.409+0000] {processor.py:157} INFO - Started process (PID=68498) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:31:45.410+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:31:45.412+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:31:45.412+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:31:45.425+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:31:45.444+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:31:45.444+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:31:45.458+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:31:45.458+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:31:45.468+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-12T20:32:15.806+0000] {processor.py:157} INFO - Started process (PID=68508) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:32:15.807+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:32:15.812+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:32:15.811+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:32:15.829+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:32:15.872+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:32:15.872+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:32:15.885+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:32:15.885+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:32:15.895+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-12T20:32:46.097+0000] {processor.py:157} INFO - Started process (PID=68518) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:32:46.100+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:32:46.104+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:32:46.104+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:32:46.115+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:32:46.133+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:32:46.133+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:32:46.144+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:32:46.143+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:32:46.153+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-12T20:33:16.478+0000] {processor.py:157} INFO - Started process (PID=68528) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:33:16.482+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:33:16.486+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:33:16.486+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:33:16.503+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:33:16.541+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:33:16.541+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:33:16.554+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:33:16.554+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:33:16.565+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-12T20:33:46.851+0000] {processor.py:157} INFO - Started process (PID=68538) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:33:46.854+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:33:46.857+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:33:46.857+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:33:46.871+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:33:46.895+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:33:46.895+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:33:46.907+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:33:46.907+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:33:46.916+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-12T20:34:17.232+0000] {processor.py:157} INFO - Started process (PID=68548) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:34:17.236+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:34:17.240+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:34:17.239+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:34:17.254+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:34:17.276+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:34:17.276+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:34:17.291+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:34:17.291+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:34:17.300+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-12T20:34:47.549+0000] {processor.py:157} INFO - Started process (PID=68558) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:34:47.550+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:34:47.552+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:34:47.552+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:34:47.565+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:34:47.580+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:34:47.580+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:34:47.592+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:34:47.592+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:34:47.602+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-12T20:35:17.983+0000] {processor.py:157} INFO - Started process (PID=68568) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:35:17.984+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:35:17.992+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:35:17.991+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:35:18.015+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:35:18.045+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:35:18.044+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:35:18.059+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:35:18.058+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:35:18.067+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-12T20:35:48.381+0000] {processor.py:157} INFO - Started process (PID=68578) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:35:48.382+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:35:48.385+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:35:48.385+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:35:48.403+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:35:48.421+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:35:48.421+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:35:48.433+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:35:48.433+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:35:48.456+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-12T20:36:18.782+0000] {processor.py:157} INFO - Started process (PID=68587) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:36:18.783+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:36:18.802+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:36:18.797+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:36:18.829+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:36:18.855+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:36:18.855+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:36:18.867+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:36:18.867+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:36:18.879+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-12T20:36:49.118+0000] {processor.py:157} INFO - Started process (PID=68598) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:36:49.122+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:36:49.124+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:36:49.124+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:36:49.141+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:36:49.165+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:36:49.165+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:36:49.178+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:36:49.178+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:36:49.187+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-12T20:37:19.491+0000] {processor.py:157} INFO - Started process (PID=68608) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:37:19.492+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:37:19.494+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:37:19.493+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:37:19.505+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:37:19.522+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:37:19.522+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:37:19.536+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:37:19.536+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:37:19.547+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-12T20:37:49.829+0000] {processor.py:157} INFO - Started process (PID=68618) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:37:49.830+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:37:49.832+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:37:49.832+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:37:49.850+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:37:49.870+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:37:49.870+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:37:49.891+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:37:49.891+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:37:49.899+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-12T20:38:20.146+0000] {processor.py:157} INFO - Started process (PID=68628) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:38:20.147+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:38:20.150+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:38:20.150+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:38:20.165+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:38:20.185+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:38:20.185+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:38:20.198+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:38:20.198+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:38:20.206+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-12T20:38:50.565+0000] {processor.py:157} INFO - Started process (PID=68638) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:38:50.568+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:38:50.572+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:38:50.572+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:38:50.601+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:38:50.626+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:38:50.626+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:38:50.638+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:38:50.638+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:38:50.647+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-12T20:39:20.982+0000] {processor.py:157} INFO - Started process (PID=68648) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:39:20.984+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:39:20.988+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:39:20.988+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:39:21.006+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:39:21.031+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:39:21.031+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:39:21.047+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:39:21.047+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:39:21.060+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-12T20:39:51.415+0000] {processor.py:157} INFO - Started process (PID=68658) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:39:51.421+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:39:51.428+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:39:51.427+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:39:51.461+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:39:51.519+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:39:51.519+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:39:51.538+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:39:51.538+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:39:51.551+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.154 seconds
[2024-09-12T20:40:21.743+0000] {processor.py:157} INFO - Started process (PID=68668) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:40:21.749+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:40:21.753+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:40:21.752+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:40:21.770+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:40:21.812+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:40:21.812+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:40:21.826+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:40:21.826+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:40:21.838+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-12T20:40:52.110+0000] {processor.py:157} INFO - Started process (PID=68678) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:40:52.114+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:40:52.119+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:40:52.119+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:40:52.135+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:40:52.157+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:40:52.157+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:40:52.175+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:40:52.175+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:40:52.185+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-12T20:41:22.402+0000] {processor.py:157} INFO - Started process (PID=68687) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:41:22.404+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:41:22.410+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:41:22.410+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:41:22.453+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:41:22.510+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:41:22.509+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:41:22.529+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:41:22.529+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:41:22.540+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.146 seconds
[2024-09-12T20:41:52.916+0000] {processor.py:157} INFO - Started process (PID=68698) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:41:52.918+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:41:52.925+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:41:52.924+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:41:52.944+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:41:52.990+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:41:52.990+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:41:53.004+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:41:53.004+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:41:53.017+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-09-12T20:42:23.215+0000] {processor.py:157} INFO - Started process (PID=68707) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:42:23.218+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:42:23.223+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:42:23.222+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:42:23.240+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:42:23.266+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:42:23.266+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:42:23.290+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:42:23.290+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:42:23.300+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-12T20:42:53.573+0000] {processor.py:157} INFO - Started process (PID=68718) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:42:53.576+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:42:53.582+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:42:53.581+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:42:53.598+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:42:53.633+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:42:53.632+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:42:53.646+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:42:53.646+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:42:53.656+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-12T20:43:23.970+0000] {processor.py:157} INFO - Started process (PID=68728) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:43:23.976+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:43:23.980+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:43:23.980+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:43:23.998+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:43:24.024+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:43:24.024+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:43:24.049+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:43:24.049+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:43:24.059+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-12T20:43:54.412+0000] {processor.py:157} INFO - Started process (PID=68738) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:43:54.415+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:43:54.419+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:43:54.419+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:43:54.443+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:43:54.460+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:43:54.460+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:43:54.471+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:43:54.471+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:43:54.481+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-12T20:44:24.763+0000] {processor.py:157} INFO - Started process (PID=68748) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:44:24.765+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:44:24.767+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:44:24.767+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:44:24.782+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:44:24.803+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:44:24.803+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:44:24.816+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:44:24.816+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:44:24.827+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-12T20:44:55.203+0000] {processor.py:157} INFO - Started process (PID=68758) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:44:55.206+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:44:55.209+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:44:55.208+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:44:55.225+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:44:55.248+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:44:55.248+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:44:55.261+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:44:55.261+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:44:55.271+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-12T20:45:25.612+0000] {processor.py:157} INFO - Started process (PID=68768) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:45:25.613+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:45:25.615+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:45:25.615+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:45:25.627+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:45:25.645+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:45:25.645+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:45:25.656+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:45:25.656+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:45:25.663+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-12T20:45:56.031+0000] {processor.py:157} INFO - Started process (PID=68777) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:45:56.033+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:45:56.038+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:45:56.038+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:45:56.083+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:45:56.108+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:45:56.108+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:45:56.121+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:45:56.121+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:45:56.136+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-12T20:46:26.333+0000] {processor.py:157} INFO - Started process (PID=68788) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:46:26.336+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:46:26.339+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:46:26.339+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:46:26.365+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:46:26.388+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:46:26.388+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:46:26.401+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:46:26.401+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:46:26.410+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-12T20:46:56.715+0000] {processor.py:157} INFO - Started process (PID=68798) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:46:56.716+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:46:56.718+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:46:56.718+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:46:56.727+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:46:56.743+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:46:56.743+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:46:56.753+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:46:56.753+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:46:56.762+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-12T20:47:27.145+0000] {processor.py:157} INFO - Started process (PID=68808) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:47:27.147+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:47:27.152+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:47:27.151+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:47:27.194+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:47:27.218+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:47:27.218+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:47:27.231+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:47:27.231+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:47:27.242+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-12T20:47:57.503+0000] {processor.py:157} INFO - Started process (PID=68818) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:47:57.505+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:47:57.507+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:47:57.507+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:47:57.523+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:47:57.547+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:47:57.547+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:47:57.562+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:47:57.562+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:47:57.573+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-12T20:48:27.885+0000] {processor.py:157} INFO - Started process (PID=68828) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:48:27.886+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:48:27.888+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:48:27.888+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:48:27.899+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:48:27.920+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:48:27.920+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:48:27.934+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:48:27.934+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:48:27.945+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-12T20:48:58.432+0000] {processor.py:157} INFO - Started process (PID=68838) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:48:58.438+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:48:58.444+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:48:58.444+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:48:58.469+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:48:58.521+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:48:58.521+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:48:58.553+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:48:58.553+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:48:58.577+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.153 seconds
[2024-09-12T20:49:28.991+0000] {processor.py:157} INFO - Started process (PID=68848) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:49:28.993+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:49:29.000+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:49:28.997+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:49:29.026+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:49:29.068+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:49:29.068+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:49:29.083+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:49:29.083+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:49:29.095+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-09-12T20:49:59.500+0000] {processor.py:157} INFO - Started process (PID=68858) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:49:59.503+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:49:59.511+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:49:59.510+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:49:59.534+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:49:59.569+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:49:59.569+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:49:59.583+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:49:59.583+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:49:59.595+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-12T20:50:29.802+0000] {processor.py:157} INFO - Started process (PID=68868) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:50:29.805+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:50:29.809+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:50:29.809+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:50:29.844+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:50:29.879+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:50:29.879+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:50:29.901+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:50:29.900+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:50:29.915+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-12T20:51:00.393+0000] {processor.py:157} INFO - Started process (PID=68878) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:51:00.401+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:51:00.419+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:51:00.418+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:51:00.475+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:51:00.548+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:51:00.548+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:51:00.565+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:51:00.565+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:51:00.580+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.210 seconds
[2024-09-12T20:51:30.769+0000] {processor.py:157} INFO - Started process (PID=68888) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:51:30.770+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:51:30.776+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:51:30.776+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:51:30.795+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:51:30.841+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:51:30.840+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:51:30.855+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:51:30.855+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:51:30.866+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-12T20:52:01.346+0000] {processor.py:157} INFO - Started process (PID=68898) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:52:01.349+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:52:01.356+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:52:01.355+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:52:01.375+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:52:01.431+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:52:01.431+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:52:01.446+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:52:01.446+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:52:01.457+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-12T20:52:31.678+0000] {processor.py:157} INFO - Started process (PID=68908) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:52:31.680+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:52:31.687+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:52:31.686+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:52:31.705+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:52:31.750+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:52:31.750+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:52:31.766+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:52:31.766+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:52:31.778+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-09-12T20:53:02.044+0000] {processor.py:157} INFO - Started process (PID=68918) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:53:02.047+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:53:02.055+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:53:02.054+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:53:02.106+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:53:02.137+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:53:02.137+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:53:02.152+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:53:02.152+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:53:02.162+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-12T20:53:32.566+0000] {processor.py:157} INFO - Started process (PID=68927) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:53:32.569+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:53:32.579+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:53:32.578+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:53:32.603+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:53:32.676+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:53:32.676+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:53:32.693+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:53:32.693+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:53:32.705+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.165 seconds
[2024-09-12T20:54:02.845+0000] {processor.py:157} INFO - Started process (PID=68937) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:54:02.847+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:54:02.853+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:54:02.853+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:54:02.873+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:54:02.914+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:54:02.914+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:54:02.928+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:54:02.928+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:54:02.939+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-12T20:54:33.332+0000] {processor.py:157} INFO - Started process (PID=68948) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:54:33.333+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:54:33.337+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:54:33.337+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:54:33.352+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:54:33.391+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:54:33.391+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:54:33.405+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:54:33.405+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:54:33.417+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-12T20:55:03.722+0000] {processor.py:157} INFO - Started process (PID=68958) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:55:03.727+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:55:03.730+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:55:03.729+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:55:03.745+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:55:03.780+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:55:03.779+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:55:03.793+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:55:03.793+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:55:03.802+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-12T20:55:34.049+0000] {processor.py:157} INFO - Started process (PID=68968) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:55:34.053+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:55:34.054+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:55:34.054+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:55:34.070+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:55:34.094+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:55:34.094+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:55:34.107+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:55:34.106+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:55:34.117+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-12T20:56:04.443+0000] {processor.py:157} INFO - Started process (PID=68978) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:56:04.445+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:56:04.452+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:56:04.449+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:56:04.483+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:56:04.509+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:56:04.509+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:56:04.533+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:56:04.533+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:56:04.544+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-09-12T20:56:34.739+0000] {processor.py:157} INFO - Started process (PID=68987) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:56:34.743+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:56:34.747+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:56:34.746+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:56:34.762+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:56:34.799+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:56:34.799+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:56:34.814+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:56:34.814+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:56:34.823+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-12T20:57:05.222+0000] {processor.py:157} INFO - Started process (PID=68998) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:57:05.225+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:57:05.227+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:57:05.227+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:57:05.244+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:57:05.281+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:57:05.281+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:57:05.294+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:57:05.294+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:57:05.306+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-12T20:57:35.558+0000] {processor.py:157} INFO - Started process (PID=69008) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:57:35.559+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:57:35.563+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:57:35.563+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:57:35.578+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:57:35.597+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:57:35.597+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:57:35.609+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:57:35.609+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:57:35.619+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-12T20:58:05.887+0000] {processor.py:157} INFO - Started process (PID=69018) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:58:05.888+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:58:05.890+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:58:05.890+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:58:05.904+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:58:05.928+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:58:05.928+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:58:05.942+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:58:05.942+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:58:05.951+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-12T20:58:36.333+0000] {processor.py:157} INFO - Started process (PID=69027) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:58:36.338+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:58:36.341+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:58:36.341+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:58:36.361+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:58:36.410+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:58:36.410+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:58:36.424+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:58:36.424+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:58:36.438+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-09-12T20:59:06.845+0000] {processor.py:157} INFO - Started process (PID=69038) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:59:06.847+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:59:06.852+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:59:06.852+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:59:06.877+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:59:06.907+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:59:06.907+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:59:06.922+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:59:06.922+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:59:06.933+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-12T20:59:37.178+0000] {processor.py:157} INFO - Started process (PID=69048) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:59:37.179+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T20:59:37.183+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:59:37.183+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:59:37.214+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T20:59:37.241+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:59:37.240+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T20:59:37.260+0000] {logging_mixin.py:151} INFO - [2024-09-12T20:59:37.260+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T20:59:37.271+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-12T21:00:07.588+0000] {processor.py:157} INFO - Started process (PID=69058) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:00:07.593+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:00:07.599+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:00:07.598+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:00:07.620+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:00:07.649+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:00:07.649+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:00:07.675+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:00:07.675+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:00:07.687+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-12T21:00:37.912+0000] {processor.py:157} INFO - Started process (PID=69067) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:00:37.914+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:00:37.917+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:00:37.917+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:00:37.943+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:00:37.967+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:00:37.967+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:00:37.982+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:00:37.982+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:00:37.993+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-12T21:01:08.254+0000] {processor.py:157} INFO - Started process (PID=69077) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:01:08.256+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:01:08.261+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:01:08.261+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:01:08.280+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:01:08.307+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:01:08.307+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:01:08.324+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:01:08.324+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:01:08.339+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-12T21:01:38.587+0000] {processor.py:157} INFO - Started process (PID=69088) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:01:38.591+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:01:38.595+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:01:38.594+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:01:38.613+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:01:38.649+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:01:38.649+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:01:38.663+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:01:38.663+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:01:38.674+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-12T21:02:08.932+0000] {processor.py:157} INFO - Started process (PID=69097) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:02:08.935+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:02:08.940+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:02:08.940+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:02:08.958+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:02:08.992+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:02:08.992+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:02:09.007+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:02:09.007+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:02:09.021+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-12T21:02:39.389+0000] {processor.py:157} INFO - Started process (PID=69108) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:02:39.392+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:02:39.398+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:02:39.398+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:02:39.415+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:02:39.445+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:02:39.445+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:02:39.459+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:02:39.459+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:02:39.470+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-12T21:03:09.776+0000] {processor.py:157} INFO - Started process (PID=69118) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:03:09.779+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:03:09.784+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:03:09.783+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:03:09.818+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:03:09.847+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:03:09.847+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:03:09.867+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:03:09.867+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:03:09.880+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-09-12T21:03:40.190+0000] {processor.py:157} INFO - Started process (PID=69128) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:03:40.197+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:03:40.232+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:03:40.229+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:03:40.281+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:03:40.316+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:03:40.316+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:03:40.353+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:03:40.353+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:03:40.366+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.195 seconds
[2024-09-12T21:04:10.581+0000] {processor.py:157} INFO - Started process (PID=69138) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:04:10.585+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:04:10.589+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:04:10.589+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:04:10.615+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:04:10.644+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:04:10.644+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:04:10.658+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:04:10.658+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:04:10.670+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-12T21:04:40.888+0000] {processor.py:157} INFO - Started process (PID=69148) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:04:40.890+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:04:40.904+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:04:40.903+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:04:40.921+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:04:40.949+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:04:40.949+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:04:40.973+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:04:40.973+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:04:40.985+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-12T21:05:11.235+0000] {processor.py:157} INFO - Started process (PID=69158) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:05:11.238+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:05:11.243+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:05:11.243+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:05:11.262+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:05:11.300+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:05:11.300+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:05:11.313+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:05:11.313+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:05:11.323+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-12T21:05:41.563+0000] {processor.py:157} INFO - Started process (PID=69168) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:05:41.566+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:05:41.571+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:05:41.570+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:05:41.587+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:05:41.622+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:05:41.622+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:05:41.634+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:05:41.634+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:05:41.645+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-12T21:06:11.909+0000] {processor.py:157} INFO - Started process (PID=69177) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:06:11.912+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:06:11.923+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:06:11.922+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:06:11.946+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:06:11.985+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:06:11.985+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:06:12.000+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:06:12.000+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:06:12.011+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-09-12T21:06:42.203+0000] {processor.py:157} INFO - Started process (PID=69188) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:06:42.207+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:06:42.209+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:06:42.209+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:06:42.224+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:06:42.250+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:06:42.250+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:06:42.267+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:06:42.267+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:06:42.277+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-12T21:07:12.557+0000] {processor.py:157} INFO - Started process (PID=69198) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:07:12.560+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:07:12.566+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:07:12.565+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:07:12.584+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:07:12.621+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:07:12.621+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:07:12.633+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:07:12.632+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:07:12.643+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-12T21:07:42.883+0000] {processor.py:157} INFO - Started process (PID=69207) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:07:42.885+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:07:42.891+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:07:42.890+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:07:42.932+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:07:42.953+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:07:42.953+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:07:42.967+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:07:42.967+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:07:42.976+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-12T21:08:13.278+0000] {processor.py:157} INFO - Started process (PID=69218) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:08:13.281+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:08:13.292+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:08:13.291+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:08:13.311+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:08:13.335+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:08:13.335+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:08:13.347+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:08:13.347+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:08:13.358+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-12T21:08:43.712+0000] {processor.py:157} INFO - Started process (PID=69228) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:08:43.720+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:08:43.726+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:08:43.725+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:08:43.765+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:08:43.792+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:08:43.792+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:08:43.812+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:08:43.811+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:08:43.825+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-09-12T21:09:14.159+0000] {processor.py:157} INFO - Started process (PID=69238) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:09:14.167+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:09:14.174+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:09:14.174+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:09:14.223+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:09:14.276+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:09:14.276+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:09:14.295+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:09:14.295+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:09:14.309+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.162 seconds
[2024-09-12T21:09:44.581+0000] {processor.py:157} INFO - Started process (PID=69248) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:09:44.591+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:09:44.594+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:09:44.593+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:09:44.616+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:09:44.649+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:09:44.649+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:09:44.665+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:09:44.664+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:09:44.683+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-12T21:10:15.020+0000] {processor.py:157} INFO - Started process (PID=69258) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:10:15.025+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:10:15.032+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:10:15.031+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:10:15.069+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:10:15.108+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:10:15.108+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:10:15.134+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:10:15.134+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:10:15.146+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-09-12T21:10:45.334+0000] {processor.py:157} INFO - Started process (PID=69267) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:10:45.337+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:10:45.341+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:10:45.341+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:10:45.357+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:10:45.394+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:10:45.394+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:10:45.407+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:10:45.407+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:10:45.418+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-12T21:11:15.690+0000] {processor.py:157} INFO - Started process (PID=69278) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:11:15.694+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:11:15.697+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:11:15.697+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:11:15.718+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:11:15.744+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:11:15.744+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:11:15.759+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:11:15.759+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:11:15.773+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-12T21:11:46.067+0000] {processor.py:157} INFO - Started process (PID=69288) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:11:46.068+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:11:46.071+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:11:46.071+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:11:46.092+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:11:46.134+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:11:46.133+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:11:46.149+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:11:46.149+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:11:46.162+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-12T21:12:16.398+0000] {processor.py:157} INFO - Started process (PID=69298) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:12:16.404+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:12:16.406+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:12:16.406+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:12:16.421+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:12:16.448+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:12:16.448+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:12:16.465+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:12:16.465+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:12:16.475+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-12T21:12:46.727+0000] {processor.py:157} INFO - Started process (PID=69308) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:12:46.730+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:12:46.757+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:12:46.757+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:12:46.776+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:12:46.802+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:12:46.802+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:12:46.816+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:12:46.815+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:12:46.827+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-09-12T21:13:17.049+0000] {processor.py:157} INFO - Started process (PID=69318) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:13:17.051+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:13:17.062+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:13:17.058+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:13:17.088+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:13:17.125+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:13:17.125+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:13:17.139+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:13:17.138+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:13:17.149+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-09-12T21:13:47.473+0000] {processor.py:157} INFO - Started process (PID=69328) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:13:47.478+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:13:47.482+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:13:47.481+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:13:47.507+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:13:47.546+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:13:47.545+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:13:47.574+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:13:47.574+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:13:47.590+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.137 seconds
[2024-09-12T21:14:17.843+0000] {processor.py:157} INFO - Started process (PID=69338) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:14:17.847+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:14:17.850+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:14:17.850+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:14:17.872+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:14:17.907+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:14:17.907+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:14:17.920+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:14:17.920+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:14:17.930+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-12T21:14:48.211+0000] {processor.py:157} INFO - Started process (PID=69348) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:14:48.213+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:14:48.216+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:14:48.216+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:14:48.236+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:14:48.264+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:14:48.264+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:14:48.279+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:14:48.279+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:14:48.304+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-12T21:15:18.597+0000] {processor.py:157} INFO - Started process (PID=69358) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:15:18.599+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:15:18.604+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:15:18.603+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:15:18.621+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:15:18.655+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:15:18.655+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:15:18.678+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:15:18.677+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:15:18.688+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-12T21:15:48.901+0000] {processor.py:157} INFO - Started process (PID=69367) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:15:48.906+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:15:48.909+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:15:48.909+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:15:48.929+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:15:48.956+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:15:48.956+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:15:48.970+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:15:48.970+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:15:48.980+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-12T21:16:19.322+0000] {processor.py:157} INFO - Started process (PID=69378) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:16:19.324+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:16:19.330+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:16:19.330+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:16:19.346+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:16:19.375+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:16:19.375+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:16:19.389+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:16:19.389+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:16:19.399+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-12T21:16:49.657+0000] {processor.py:157} INFO - Started process (PID=69388) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:16:49.665+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:16:49.670+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:16:49.670+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:16:49.689+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:16:49.713+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:16:49.713+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:16:49.739+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:16:49.738+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:16:49.750+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-12T21:17:20.008+0000] {processor.py:157} INFO - Started process (PID=69398) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:17:20.010+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:17:20.013+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:17:20.013+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:17:20.029+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:17:20.050+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:17:20.050+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:17:20.063+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:17:20.063+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:17:20.072+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-12T21:17:50.352+0000] {processor.py:157} INFO - Started process (PID=69407) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:17:50.358+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:17:50.364+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:17:50.364+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:17:50.383+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:17:50.411+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:17:50.411+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:17:50.425+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:17:50.425+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:17:50.436+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-12T21:18:20.742+0000] {processor.py:157} INFO - Started process (PID=69418) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:18:20.746+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:18:20.750+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:18:20.750+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:18:20.768+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:18:20.799+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:18:20.799+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:18:20.821+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:18:20.821+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:18:20.831+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-12T21:18:51.165+0000] {processor.py:157} INFO - Started process (PID=69428) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:18:51.169+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:18:51.174+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:18:51.173+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:18:51.193+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:18:51.221+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:18:51.221+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:18:51.234+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:18:51.234+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:18:51.244+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-12T21:19:21.486+0000] {processor.py:157} INFO - Started process (PID=69438) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:19:21.487+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:19:21.490+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:19:21.490+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:19:21.503+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:19:21.518+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:19:21.518+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:19:21.529+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:19:21.529+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:19:21.539+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-12T21:19:51.854+0000] {processor.py:157} INFO - Started process (PID=69447) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:19:51.862+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:19:51.869+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:19:51.869+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:19:51.912+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:19:51.949+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:19:51.949+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:19:51.966+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:19:51.966+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:19:51.985+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.137 seconds
[2024-09-12T21:20:22.224+0000] {processor.py:157} INFO - Started process (PID=69458) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:20:22.227+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:20:22.236+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:20:22.236+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:20:22.286+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:20:22.339+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:20:22.339+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:20:22.357+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:20:22.356+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:20:22.367+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.149 seconds
[2024-09-12T21:20:52.667+0000] {processor.py:157} INFO - Started process (PID=69468) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:20:52.670+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:20:52.689+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:20:52.689+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:20:52.708+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:20:52.734+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:20:52.734+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:20:52.749+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:20:52.749+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:20:52.761+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-12T21:21:23.108+0000] {processor.py:157} INFO - Started process (PID=69478) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:21:23.112+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:21:23.116+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:21:23.115+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:21:23.132+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:21:23.162+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:21:23.162+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:21:23.179+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:21:23.179+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:21:23.193+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-12T21:21:53.532+0000] {processor.py:157} INFO - Started process (PID=69488) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:21:53.540+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:21:53.548+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:21:53.548+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:21:53.567+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:21:53.602+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:21:53.602+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:21:53.616+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:21:53.616+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:21:53.627+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-12T21:22:23.979+0000] {processor.py:157} INFO - Started process (PID=69498) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:22:23.984+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:22:23.986+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:22:23.986+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:22:24.005+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:22:24.041+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:22:24.041+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:22:24.055+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:22:24.055+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:22:24.066+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-12T21:22:54.330+0000] {processor.py:157} INFO - Started process (PID=69508) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:22:54.333+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:22:54.337+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:22:54.336+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:22:54.352+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:22:54.388+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:22:54.388+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:22:54.402+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:22:54.402+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:22:54.413+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-12T21:23:24.652+0000] {processor.py:157} INFO - Started process (PID=69518) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:23:24.655+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:23:24.657+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:23:24.657+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:23:24.670+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:23:24.687+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:23:24.687+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:23:24.699+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:23:24.699+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:23:24.708+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-12T21:23:54.920+0000] {processor.py:157} INFO - Started process (PID=69527) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:23:54.924+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:23:54.928+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:23:54.927+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:23:54.951+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:23:54.986+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:23:54.986+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:23:55.001+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:23:55.001+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:23:55.013+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-12T21:24:25.315+0000] {processor.py:157} INFO - Started process (PID=69538) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:24:25.318+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:24:25.324+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:24:25.324+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:24:25.357+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:24:25.405+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:24:25.405+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:24:25.426+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:24:25.426+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:24:25.452+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.144 seconds
[2024-09-12T21:24:55.694+0000] {processor.py:157} INFO - Started process (PID=69548) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:24:55.695+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:24:55.699+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:24:55.698+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:24:55.717+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:24:55.749+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:24:55.749+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:24:55.762+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:24:55.762+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:24:55.772+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-09-12T21:25:26.011+0000] {processor.py:157} INFO - Started process (PID=69557) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:25:26.019+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:25:26.029+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:25:26.029+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:25:26.047+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:25:26.073+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:25:26.073+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:25:26.096+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:25:26.096+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:25:26.106+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-12T21:25:56.442+0000] {processor.py:157} INFO - Started process (PID=69568) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:25:56.445+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:25:56.448+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:25:56.448+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:25:56.465+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:25:56.489+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:25:56.489+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:25:56.518+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:25:56.518+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:25:56.529+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-09-12T21:26:26.775+0000] {processor.py:157} INFO - Started process (PID=69578) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:26:26.777+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:26:26.784+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:26:26.784+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:26:26.808+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:26:26.832+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:26:26.832+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:26:26.863+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:26:26.863+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:26:26.874+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-12T21:26:57.335+0000] {processor.py:157} INFO - Started process (PID=69588) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:26:57.339+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:26:57.342+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:26:57.341+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:26:57.360+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:26:57.395+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:26:57.395+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:26:57.409+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:26:57.409+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:26:57.422+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-12T21:27:27.645+0000] {processor.py:157} INFO - Started process (PID=69598) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:27:27.646+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:27:27.647+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:27:27.647+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:27:27.657+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:27:27.674+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:27:27.673+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:27:27.684+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:27:27.684+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:27:27.692+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-12T21:27:57.952+0000] {processor.py:157} INFO - Started process (PID=69608) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:27:57.954+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:27:57.955+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:27:57.955+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:27:57.968+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:27:57.987+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:27:57.987+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:27:58.000+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:27:58.000+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:27:58.009+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-12T21:28:28.431+0000] {processor.py:157} INFO - Started process (PID=69617) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:28:28.434+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:28:28.439+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:28:28.439+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:28:28.464+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:28:28.495+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:28:28.495+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:28:28.509+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:28:28.509+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:28:28.520+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-12T21:28:58.782+0000] {processor.py:157} INFO - Started process (PID=69627) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:28:58.784+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:28:58.789+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:28:58.789+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:28:58.804+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:28:58.837+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:28:58.837+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:28:58.850+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:28:58.850+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:28:58.860+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-12T21:29:29.093+0000] {processor.py:157} INFO - Started process (PID=69638) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:29:29.095+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:29:29.109+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:29:29.108+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:29:29.129+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:29:29.160+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:29:29.160+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:29:29.181+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:29:29.181+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:29:29.193+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-09-12T21:29:59.588+0000] {processor.py:157} INFO - Started process (PID=69648) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:29:59.590+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:29:59.596+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:29:59.595+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:29:59.614+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:29:59.659+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:29:59.659+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:29:59.674+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:29:59.673+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:29:59.685+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-12T21:30:29.947+0000] {processor.py:157} INFO - Started process (PID=69657) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:30:29.949+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:30:29.956+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:30:29.955+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:30:29.980+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:30:30.011+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:30:30.011+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:30:30.045+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:30:30.045+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:30:30.055+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-09-12T21:31:00.302+0000] {processor.py:157} INFO - Started process (PID=69668) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:31:00.304+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:31:00.314+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:31:00.313+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:31:00.375+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:31:00.402+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:31:00.402+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:31:00.427+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:31:00.427+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:31:00.439+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.147 seconds
[2024-09-12T21:31:30.661+0000] {processor.py:157} INFO - Started process (PID=69677) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:31:30.668+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:31:30.687+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:31:30.687+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:31:30.713+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:31:30.740+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:31:30.740+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:31:30.753+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:31:30.753+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:31:30.763+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-12T21:32:00.988+0000] {processor.py:157} INFO - Started process (PID=69687) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:32:00.990+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:32:00.996+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:32:00.996+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:32:01.014+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:32:01.053+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:32:01.053+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:32:01.069+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:32:01.069+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:32:01.079+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-12T21:32:31.272+0000] {processor.py:157} INFO - Started process (PID=69698) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:32:31.276+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:32:31.285+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:32:31.284+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:32:31.301+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:32:31.326+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:32:31.326+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:32:31.339+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:32:31.338+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:32:31.349+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-12T21:33:01.584+0000] {processor.py:157} INFO - Started process (PID=69708) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:33:01.586+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:33:01.591+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:33:01.590+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:33:01.607+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:33:01.636+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:33:01.636+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:33:01.650+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:33:01.650+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:33:01.663+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-12T21:33:31.985+0000] {processor.py:157} INFO - Started process (PID=69718) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:33:31.987+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:33:31.996+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:33:31.995+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:33:32.027+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:33:32.093+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:33:32.092+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:33:32.140+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:33:32.140+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:33:32.158+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.186 seconds
[2024-09-12T21:34:02.528+0000] {processor.py:157} INFO - Started process (PID=69727) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:34:02.530+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:34:02.536+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:34:02.535+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:34:02.569+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:34:02.626+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:34:02.626+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:34:02.642+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:34:02.642+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:34:02.663+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.144 seconds
[2024-09-12T21:34:32.920+0000] {processor.py:157} INFO - Started process (PID=69738) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:34:32.925+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:34:32.929+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:34:32.929+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:34:32.947+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:34:32.988+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:34:32.987+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:34:33.007+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:34:33.007+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:34:33.019+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-12T21:35:03.362+0000] {processor.py:157} INFO - Started process (PID=69748) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:35:03.368+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:35:03.372+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:35:03.372+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:35:03.393+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:35:03.438+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:35:03.438+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:35:03.455+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:35:03.455+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:35:03.467+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-12T21:35:34.060+0000] {processor.py:157} INFO - Started process (PID=69758) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:35:34.070+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:35:34.075+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:35:34.075+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:35:34.110+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:35:34.173+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:35:34.172+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:35:34.195+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:35:34.195+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:35:34.211+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.175 seconds
[2024-09-12T21:36:04.596+0000] {processor.py:157} INFO - Started process (PID=69768) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:36:04.598+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:36:04.608+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:36:04.607+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:36:04.630+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:36:04.659+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:36:04.659+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:36:04.689+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:36:04.689+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:36:04.702+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-12T21:36:34.935+0000] {processor.py:157} INFO - Started process (PID=69778) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:36:34.938+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:36:34.943+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:36:34.942+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:36:34.972+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:36:35.012+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:36:35.012+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:36:35.053+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:36:35.052+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:36:35.076+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.146 seconds
[2024-09-12T21:37:05.277+0000] {processor.py:157} INFO - Started process (PID=69788) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:37:05.279+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:37:05.282+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:37:05.282+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:37:05.313+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:37:05.343+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:37:05.343+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:37:05.356+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:37:05.356+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:37:05.368+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-12T21:37:35.730+0000] {processor.py:157} INFO - Started process (PID=69798) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:37:35.732+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:37:35.736+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:37:35.736+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:37:35.768+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:37:35.793+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:37:35.793+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:37:35.805+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:37:35.805+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:37:35.816+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-12T21:38:06.094+0000] {processor.py:157} INFO - Started process (PID=69807) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:38:06.097+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:38:06.102+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:38:06.102+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:38:06.126+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:38:06.152+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:38:06.152+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:38:06.168+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:38:06.168+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:38:06.186+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-12T21:38:36.436+0000] {processor.py:157} INFO - Started process (PID=69818) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:38:36.439+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:38:36.443+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:38:36.443+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:38:36.464+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:38:36.504+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:38:36.504+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:38:36.518+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:38:36.518+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:38:36.530+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-12T21:39:06.903+0000] {processor.py:157} INFO - Started process (PID=69828) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:39:06.905+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:39:06.910+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:39:06.910+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:39:06.937+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:39:06.966+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:39:06.966+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:39:06.981+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:39:06.980+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:39:06.991+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-12T21:39:37.466+0000] {processor.py:157} INFO - Started process (PID=69838) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:39:37.469+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:39:37.477+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:39:37.476+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:39:37.520+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:39:37.555+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:39:37.555+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:39:37.571+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:39:37.571+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:39:37.583+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-12T21:40:07.891+0000] {processor.py:157} INFO - Started process (PID=69848) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:40:07.893+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:40:07.899+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:40:07.899+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:40:07.918+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:40:07.956+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:40:07.956+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:40:07.972+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:40:07.972+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:40:07.981+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-12T21:40:38.252+0000] {processor.py:157} INFO - Started process (PID=69858) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:40:38.256+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:40:38.266+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:40:38.265+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:40:38.289+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:40:38.340+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:40:38.340+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:40:38.363+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:40:38.363+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:40:38.376+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-09-12T21:41:08.595+0000] {processor.py:157} INFO - Started process (PID=69868) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:41:08.599+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:41:08.604+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:41:08.604+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:41:08.622+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:41:08.651+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:41:08.651+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:41:08.669+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:41:08.669+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:41:08.682+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-12T21:41:38.943+0000] {processor.py:157} INFO - Started process (PID=69878) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:41:38.949+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:41:38.961+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:41:38.960+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:41:38.991+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:41:39.069+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:41:39.069+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:41:39.088+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:41:39.088+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:41:39.113+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.188 seconds
[2024-09-12T21:42:09.292+0000] {processor.py:157} INFO - Started process (PID=69888) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:42:09.297+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:42:09.314+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:42:09.312+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:42:09.331+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:42:09.356+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:42:09.356+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:42:09.369+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:42:09.369+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:42:09.378+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-12T21:42:39.690+0000] {processor.py:157} INFO - Started process (PID=69898) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:42:39.697+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:42:39.708+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:42:39.707+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:42:39.726+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:42:39.752+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:42:39.752+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:42:39.772+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:42:39.772+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:42:39.782+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-12T21:43:10.192+0000] {processor.py:157} INFO - Started process (PID=69908) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:43:10.199+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:43:10.206+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:43:10.206+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:43:10.230+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:43:10.262+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:43:10.262+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:43:10.275+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:43:10.275+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:43:10.286+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-12T21:43:40.527+0000] {processor.py:157} INFO - Started process (PID=69918) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:43:40.529+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:43:40.532+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:43:40.532+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:43:40.557+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:43:40.591+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:43:40.591+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:43:40.604+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:43:40.604+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:43:40.614+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-12T21:44:10.989+0000] {processor.py:157} INFO - Started process (PID=69928) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:44:10.991+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:44:10.995+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:44:10.994+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:44:11.013+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:44:11.039+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:44:11.039+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:44:11.065+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:44:11.065+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:44:11.077+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-12T21:44:41.375+0000] {processor.py:157} INFO - Started process (PID=69938) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:44:41.376+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:44:41.380+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:44:41.380+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:44:41.399+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:44:41.435+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:44:41.434+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:44:41.448+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:44:41.448+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:44:41.459+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-12T21:45:11.656+0000] {processor.py:157} INFO - Started process (PID=69948) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:45:11.660+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:45:11.663+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:45:11.663+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:45:11.680+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:45:11.717+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:45:11.717+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:45:11.731+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:45:11.731+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:45:11.741+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-12T21:45:41.973+0000] {processor.py:157} INFO - Started process (PID=69958) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:45:41.975+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:45:41.980+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:45:41.979+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:45:42.015+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:45:42.048+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:45:42.048+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:45:42.062+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:45:42.062+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:45:42.072+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-12T21:46:12.259+0000] {processor.py:157} INFO - Started process (PID=69968) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:46:12.261+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:46:12.267+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:46:12.266+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:46:12.290+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:46:12.316+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:46:12.316+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:46:12.337+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:46:12.337+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:46:12.348+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-12T21:46:42.615+0000] {processor.py:157} INFO - Started process (PID=69978) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:46:42.618+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:46:42.621+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:46:42.620+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:46:42.634+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:46:42.656+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:46:42.656+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:46:42.670+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:46:42.670+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:46:42.685+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-12T21:47:12.954+0000] {processor.py:157} INFO - Started process (PID=69988) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:47:12.956+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:47:12.959+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:47:12.959+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:47:12.974+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:47:12.995+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:47:12.995+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:47:13.008+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:47:13.007+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:47:13.019+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-12T21:47:43.273+0000] {processor.py:157} INFO - Started process (PID=69998) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:47:43.275+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:47:43.278+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:47:43.278+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:47:43.294+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:47:43.317+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:47:43.317+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:47:43.330+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:47:43.330+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:47:43.340+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-12T21:48:13.701+0000] {processor.py:157} INFO - Started process (PID=70008) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:48:13.704+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:48:13.706+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:48:13.706+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:48:13.721+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:48:13.749+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:48:13.749+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:48:13.764+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:48:13.764+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:48:13.782+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-12T21:48:44.100+0000] {processor.py:157} INFO - Started process (PID=70018) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:48:44.110+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:48:44.117+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:48:44.116+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:48:44.135+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:48:44.177+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:48:44.177+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:48:44.192+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:48:44.191+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:48:44.204+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-12T21:49:14.566+0000] {processor.py:157} INFO - Started process (PID=70028) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:49:14.567+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:49:14.584+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:49:14.583+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:49:14.603+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:49:14.634+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:49:14.634+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:49:14.662+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:49:14.662+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:49:14.671+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-12T21:49:44.851+0000] {processor.py:157} INFO - Started process (PID=70038) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:49:44.852+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:49:44.854+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:49:44.854+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:49:44.875+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:49:44.889+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:49:44.889+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:49:44.898+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:49:44.898+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:49:44.906+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-12T21:50:15.273+0000] {processor.py:157} INFO - Started process (PID=70048) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:50:15.276+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:50:15.286+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:50:15.285+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:50:15.304+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:50:15.333+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:50:15.333+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:50:15.346+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:50:15.345+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:50:15.356+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-12T21:50:45.644+0000] {processor.py:157} INFO - Started process (PID=70058) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:50:45.649+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:50:45.652+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:50:45.652+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:50:45.672+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:50:45.699+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:50:45.699+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:50:45.712+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:50:45.712+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:50:45.723+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-12T21:51:15.980+0000] {processor.py:157} INFO - Started process (PID=70068) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:51:15.981+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:51:15.985+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:51:15.984+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:51:16.002+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:51:16.025+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:51:16.025+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:51:16.038+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:51:16.038+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:51:16.049+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-12T21:51:46.388+0000] {processor.py:157} INFO - Started process (PID=70078) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:51:46.392+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:51:46.396+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:51:46.396+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:51:46.417+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:51:46.462+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:51:46.462+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:51:46.477+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:51:46.477+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:51:46.489+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-12T21:52:16.728+0000] {processor.py:157} INFO - Started process (PID=70087) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:52:16.730+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:52:16.740+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:52:16.737+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:52:16.759+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:52:16.797+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:52:16.797+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:52:16.809+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:52:16.809+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:52:16.820+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-12T21:52:47.068+0000] {processor.py:157} INFO - Started process (PID=70098) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:52:47.071+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:52:47.074+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:52:47.074+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:52:47.094+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:52:47.140+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:52:47.140+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:52:47.155+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:52:47.155+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:52:47.165+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-12T21:53:17.450+0000] {processor.py:157} INFO - Started process (PID=70108) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:53:17.452+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:53:17.458+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:53:17.457+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:53:17.475+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:53:17.515+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:53:17.515+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:53:17.528+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:53:17.528+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:53:17.538+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-12T21:53:47.795+0000] {processor.py:157} INFO - Started process (PID=70118) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:53:47.798+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:53:47.806+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:53:47.806+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:53:47.832+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:53:47.861+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:53:47.861+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:53:47.877+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:53:47.877+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:53:47.890+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-12T21:54:18.269+0000] {processor.py:157} INFO - Started process (PID=70128) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:54:18.271+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:54:18.281+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:54:18.280+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:54:18.302+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:54:18.326+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:54:18.326+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:54:18.341+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:54:18.340+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:54:18.351+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-12T21:54:48.678+0000] {processor.py:157} INFO - Started process (PID=70138) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:54:48.684+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:54:48.688+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:54:48.688+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:54:48.705+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:54:48.733+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:54:48.733+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:54:48.761+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:54:48.761+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:54:48.774+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-12T21:55:18.977+0000] {processor.py:157} INFO - Started process (PID=70148) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:55:18.981+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:55:18.993+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:55:18.992+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:55:19.020+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:55:19.048+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:55:19.048+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:55:19.061+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:55:19.061+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:55:19.079+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-12T21:55:49.286+0000] {processor.py:157} INFO - Started process (PID=70158) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:55:49.289+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:55:49.292+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:55:49.291+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:55:49.309+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:55:49.335+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:55:49.335+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:55:49.348+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:55:49.348+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:55:49.359+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-12T21:56:19.643+0000] {processor.py:157} INFO - Started process (PID=70167) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:56:19.645+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:56:19.651+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:56:19.651+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:56:19.680+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:56:19.707+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:56:19.707+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:56:19.719+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:56:19.719+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:56:19.730+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-12T21:56:50.033+0000] {processor.py:157} INFO - Started process (PID=70178) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:56:50.036+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:56:50.039+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:56:50.039+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:56:50.056+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:56:50.091+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:56:50.091+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:56:50.106+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:56:50.106+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:56:50.115+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-12T21:57:20.349+0000] {processor.py:157} INFO - Started process (PID=70188) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:57:20.350+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:57:20.354+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:57:20.354+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:57:20.372+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:57:20.394+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:57:20.394+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:57:20.410+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:57:20.410+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:57:20.421+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-12T21:57:50.733+0000] {processor.py:157} INFO - Started process (PID=70197) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:57:50.737+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:57:50.740+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:57:50.740+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:57:50.773+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:57:50.799+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:57:50.799+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:57:50.812+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:57:50.812+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:57:50.822+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-12T21:58:21.059+0000] {processor.py:157} INFO - Started process (PID=70208) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:58:21.060+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:58:21.063+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:58:21.063+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:58:21.078+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:58:21.108+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:58:21.108+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:58:21.123+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:58:21.122+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:58:21.134+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-12T21:58:51.338+0000] {processor.py:157} INFO - Started process (PID=70218) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:58:51.340+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:58:51.342+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:58:51.342+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:58:51.352+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:58:51.369+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:58:51.369+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:58:51.379+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:58:51.379+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:58:51.388+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-12T21:59:21.722+0000] {processor.py:157} INFO - Started process (PID=70228) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:59:21.724+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:59:21.728+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:59:21.727+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:59:21.747+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:59:21.770+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:59:21.770+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:59:21.783+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:59:21.783+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:59:21.793+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-12T21:59:52.125+0000] {processor.py:157} INFO - Started process (PID=70238) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:59:52.127+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T21:59:52.132+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:59:52.132+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:59:52.151+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T21:59:52.179+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:59:52.179+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T21:59:52.193+0000] {logging_mixin.py:151} INFO - [2024-09-12T21:59:52.193+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T21:59:52.207+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-12T22:00:22.486+0000] {processor.py:157} INFO - Started process (PID=70248) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:00:22.488+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:00:22.492+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:00:22.491+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:00:22.519+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:00:22.546+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:00:22.546+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:00:22.560+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:00:22.560+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:00:22.574+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-12T22:00:52.828+0000] {processor.py:157} INFO - Started process (PID=70258) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:00:52.830+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:00:52.833+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:00:52.833+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:00:52.850+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:00:52.888+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:00:52.888+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:00:52.902+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:00:52.902+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:00:52.914+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-12T22:01:23.196+0000] {processor.py:157} INFO - Started process (PID=70268) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:01:23.197+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:01:23.200+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:01:23.200+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:01:23.218+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:01:23.239+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:01:23.238+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:01:23.251+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:01:23.251+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:01:23.261+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-12T22:01:53.629+0000] {processor.py:157} INFO - Started process (PID=70278) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:01:53.630+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:01:53.632+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:01:53.632+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:01:53.642+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:01:53.658+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:01:53.658+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:01:53.668+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:01:53.667+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:01:53.677+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-12T22:02:24.055+0000] {processor.py:157} INFO - Started process (PID=70286) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:02:24.057+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:02:24.061+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:02:24.061+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:02:24.079+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:02:24.122+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:02:24.121+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:02:24.138+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:02:24.138+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:02:24.152+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-12T22:02:54.372+0000] {processor.py:157} INFO - Started process (PID=70298) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:02:54.379+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:02:54.395+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:02:54.394+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:02:54.418+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:02:54.455+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:02:54.455+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:02:54.471+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:02:54.471+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:02:54.482+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-12T22:03:24.718+0000] {processor.py:157} INFO - Started process (PID=70308) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:03:24.720+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:03:24.723+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:03:24.723+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:03:24.738+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:03:24.758+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:03:24.758+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:03:24.770+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:03:24.770+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:03:24.779+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-12T22:03:55.210+0000] {processor.py:157} INFO - Started process (PID=70318) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:03:55.213+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:03:55.220+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:03:55.219+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:03:55.239+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:03:55.289+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:03:55.289+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:03:55.304+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:03:55.304+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:03:55.314+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-09-12T22:04:25.590+0000] {processor.py:157} INFO - Started process (PID=70328) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:04:25.600+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:04:25.612+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:04:25.612+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:04:25.630+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:04:25.655+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:04:25.654+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:04:25.668+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:04:25.668+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:04:25.678+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-12T22:04:55.961+0000] {processor.py:157} INFO - Started process (PID=70338) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:04:55.970+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:04:55.976+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:04:55.976+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:04:55.994+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:04:56.043+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:04:56.042+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:04:56.062+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:04:56.062+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:04:56.076+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-09-12T22:05:26.316+0000] {processor.py:157} INFO - Started process (PID=70348) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:05:26.317+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:05:26.339+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:05:26.335+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:05:26.355+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:05:26.378+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:05:26.378+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:05:26.391+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:05:26.391+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:05:26.400+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-12T22:05:56.697+0000] {processor.py:157} INFO - Started process (PID=70358) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:05:56.706+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:05:56.714+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:05:56.713+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:05:56.732+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:05:56.757+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:05:56.757+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:05:56.782+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:05:56.782+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:05:56.795+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-09-12T22:06:27.060+0000] {processor.py:157} INFO - Started process (PID=70368) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:06:27.068+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:06:27.082+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:06:27.081+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:06:27.105+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:06:27.231+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:06:27.230+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:06:27.247+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:06:27.247+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:06:27.259+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.210 seconds
[2024-09-12T22:06:57.416+0000] {processor.py:157} INFO - Started process (PID=70378) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:06:57.423+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:06:57.430+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:06:57.430+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:06:57.469+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:06:57.522+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:06:57.522+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:06:57.539+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:06:57.539+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:06:57.552+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.145 seconds
[2024-09-12T22:07:27.982+0000] {processor.py:157} INFO - Started process (PID=70388) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:07:27.986+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:07:27.997+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:07:27.993+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:07:28.032+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:07:28.087+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:07:28.087+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:07:28.105+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:07:28.105+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:07:28.122+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.150 seconds
[2024-09-12T22:07:58.409+0000] {processor.py:157} INFO - Started process (PID=70398) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:07:58.413+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:07:58.415+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:07:58.415+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:07:58.433+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:07:58.459+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:07:58.459+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:07:58.472+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:07:58.472+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:07:58.481+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-12T22:08:28.786+0000] {processor.py:157} INFO - Started process (PID=70408) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:08:28.788+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:08:28.793+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:08:28.793+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:08:28.812+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:08:28.840+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:08:28.840+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:08:28.863+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:08:28.863+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:08:28.876+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-12T22:08:59.311+0000] {processor.py:157} INFO - Started process (PID=70418) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:08:59.313+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:08:59.318+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:08:59.317+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:08:59.366+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:08:59.397+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:08:59.397+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:08:59.421+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:08:59.421+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:08:59.432+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-09-12T22:09:29.617+0000] {processor.py:157} INFO - Started process (PID=70428) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:09:29.620+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:09:29.622+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:09:29.622+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:09:29.643+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:09:29.669+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:09:29.668+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:09:29.684+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:09:29.684+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:09:29.692+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-12T22:09:59.992+0000] {processor.py:157} INFO - Started process (PID=70438) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:09:59.997+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:10:00.004+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:10:00.003+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:10:00.043+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:10:00.068+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:10:00.068+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:10:00.081+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:10:00.081+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:10:00.091+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-09-12T22:10:30.309+0000] {processor.py:157} INFO - Started process (PID=70448) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:10:30.313+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:10:30.315+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:10:30.315+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:10:30.332+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:10:30.355+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:10:30.355+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:10:30.369+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:10:30.369+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:10:30.380+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-12T22:11:00.660+0000] {processor.py:157} INFO - Started process (PID=70458) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:11:00.667+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:11:00.670+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:11:00.670+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:11:00.687+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:11:00.722+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:11:00.722+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:11:00.738+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:11:00.738+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:11:00.751+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-12T22:11:31.012+0000] {processor.py:157} INFO - Started process (PID=70468) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:11:31.015+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:11:31.019+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:11:31.019+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:11:31.053+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:11:31.078+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:11:31.078+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:11:31.095+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:11:31.095+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:11:31.110+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-12T22:12:01.513+0000] {processor.py:157} INFO - Started process (PID=70478) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:12:01.519+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:12:01.526+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:12:01.525+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:12:01.566+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:12:01.617+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:12:01.617+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:12:01.637+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:12:01.637+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:12:01.652+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.147 seconds
[2024-09-12T22:12:31.838+0000] {processor.py:157} INFO - Started process (PID=70488) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:12:31.842+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:12:31.844+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:12:31.844+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:12:31.879+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:12:31.920+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:12:31.920+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:12:31.938+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:12:31.938+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:12:31.957+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-12T22:13:02.230+0000] {processor.py:157} INFO - Started process (PID=70498) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:13:02.233+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:13:02.238+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:13:02.238+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:13:02.266+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:13:02.325+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:13:02.325+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:13:02.343+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:13:02.343+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:13:02.356+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.137 seconds
[2024-09-12T22:13:32.567+0000] {processor.py:157} INFO - Started process (PID=70508) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:13:32.570+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:13:32.574+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:13:32.573+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:13:32.584+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:13:32.598+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:13:32.597+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:13:32.608+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:13:32.608+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:13:32.616+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-12T22:14:02.989+0000] {processor.py:157} INFO - Started process (PID=70518) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:14:02.992+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:14:02.997+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:14:02.997+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:14:03.032+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:14:03.061+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:14:03.061+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:14:03.077+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:14:03.077+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:14:03.089+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-09-12T22:14:33.392+0000] {processor.py:157} INFO - Started process (PID=70528) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:14:33.396+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:14:33.399+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:14:33.399+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:14:33.432+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:14:33.460+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:14:33.460+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:14:33.478+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:14:33.478+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:14:33.488+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-12T22:15:03.768+0000] {processor.py:157} INFO - Started process (PID=70538) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:15:03.771+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:15:03.781+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:15:03.780+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:15:03.811+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:15:03.872+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:15:03.871+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:15:03.891+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:15:03.891+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:15:03.903+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.146 seconds
[2024-09-12T22:15:34.146+0000] {processor.py:157} INFO - Started process (PID=70548) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:15:34.148+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:15:34.154+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:15:34.153+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:15:34.173+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:15:34.201+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:15:34.201+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:15:34.222+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:15:34.222+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:15:34.233+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-12T22:16:04.497+0000] {processor.py:157} INFO - Started process (PID=70558) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:16:04.498+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:16:04.502+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:16:04.502+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:16:04.525+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:16:04.550+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:16:04.550+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:16:04.565+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:16:04.565+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:16:04.583+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-12T22:16:34.843+0000] {processor.py:157} INFO - Started process (PID=70568) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:16:34.846+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:16:34.851+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:16:34.850+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:16:34.866+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:16:34.892+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:16:34.892+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:16:34.917+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:16:34.916+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:16:34.928+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-12T22:17:05.295+0000] {processor.py:157} INFO - Started process (PID=70578) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:17:05.299+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:17:05.303+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:17:05.303+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:17:05.325+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:17:05.358+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:17:05.358+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:17:05.376+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:17:05.376+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:17:05.388+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-12T22:17:35.605+0000] {processor.py:157} INFO - Started process (PID=70588) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:17:35.606+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:17:35.609+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:17:35.609+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:17:35.619+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:17:35.636+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:17:35.636+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:17:35.645+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:17:35.645+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:17:35.654+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-12T22:18:05.933+0000] {processor.py:157} INFO - Started process (PID=70597) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:18:05.940+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:18:05.951+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:18:05.951+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:18:05.967+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:18:05.990+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:18:05.990+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:18:06.004+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:18:06.003+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:18:06.012+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-12T22:18:36.257+0000] {processor.py:157} INFO - Started process (PID=70608) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:18:36.258+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:18:36.261+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:18:36.260+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:18:36.271+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:18:36.288+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:18:36.288+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:18:36.299+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:18:36.299+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:18:36.306+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-12T22:19:06.559+0000] {processor.py:157} INFO - Started process (PID=70618) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:19:06.561+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:19:06.564+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:19:06.563+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:19:06.579+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:19:06.601+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:19:06.600+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:19:06.613+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:19:06.613+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:19:06.624+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-12T22:19:36.893+0000] {processor.py:157} INFO - Started process (PID=70628) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:19:36.895+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:19:36.897+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:19:36.897+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:19:36.907+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:19:36.925+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:19:36.925+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:19:36.937+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:19:36.937+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:19:36.947+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-12T22:20:07.278+0000] {processor.py:157} INFO - Started process (PID=70638) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:20:07.280+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:20:07.283+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:20:07.282+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:20:07.299+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:20:07.325+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:20:07.325+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:20:07.337+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:20:07.336+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:20:07.347+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-12T22:20:37.614+0000] {processor.py:157} INFO - Started process (PID=70648) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:20:37.618+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:20:37.621+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:20:37.621+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:20:37.637+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:20:37.664+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:20:37.663+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:20:37.681+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:20:37.681+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:20:37.692+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-12T22:21:07.996+0000] {processor.py:157} INFO - Started process (PID=70658) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:21:08.000+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:21:08.003+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:21:08.003+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:21:08.015+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:21:08.031+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:21:08.031+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:21:08.041+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:21:08.041+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:21:08.050+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-12T22:21:38.296+0000] {processor.py:157} INFO - Started process (PID=70668) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:21:38.297+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:21:38.299+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:21:38.299+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:21:38.316+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:21:38.350+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:21:38.350+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:21:38.368+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:21:38.368+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:21:38.390+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-12T22:22:08.699+0000] {processor.py:157} INFO - Started process (PID=70678) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:22:08.701+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:22:08.706+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:22:08.706+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:22:08.727+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:22:08.762+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:22:08.762+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:22:08.776+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:22:08.775+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:22:08.785+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-12T22:22:38.983+0000] {processor.py:157} INFO - Started process (PID=70688) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:22:38.989+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:22:39.006+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:22:39.004+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:22:39.024+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:22:39.063+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:22:39.063+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:22:39.076+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:22:39.076+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:22:39.085+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-09-12T22:23:09.287+0000] {processor.py:157} INFO - Started process (PID=70698) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:23:09.291+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:23:09.295+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:23:09.294+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:23:09.316+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:23:09.344+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:23:09.344+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:23:09.359+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:23:09.359+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:23:09.377+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-12T22:23:39.702+0000] {processor.py:157} INFO - Started process (PID=70708) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:23:39.706+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:23:39.709+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:23:39.709+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:23:39.745+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:23:39.777+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:23:39.777+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:23:39.791+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:23:39.791+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:23:39.802+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-12T22:24:10.189+0000] {processor.py:157} INFO - Started process (PID=70718) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:24:10.196+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:24:10.201+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:24:10.200+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:24:10.234+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:24:10.259+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:24:10.259+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:24:10.272+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:24:10.271+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:24:10.282+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-12T22:24:40.547+0000] {processor.py:157} INFO - Started process (PID=70728) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:24:40.549+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:24:40.551+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:24:40.551+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:24:40.568+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:24:40.591+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:24:40.591+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:24:40.601+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:24:40.601+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:24:40.610+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-12T22:25:10.903+0000] {processor.py:157} INFO - Started process (PID=70738) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:25:10.906+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:25:10.911+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:25:10.911+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:25:10.927+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:25:10.953+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:25:10.953+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:25:10.977+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:25:10.977+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:25:10.988+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-12T22:25:41.242+0000] {processor.py:157} INFO - Started process (PID=70748) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:25:41.245+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:25:41.252+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:25:41.252+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:25:41.267+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:25:41.291+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:25:41.291+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:25:41.304+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:25:41.304+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:25:41.317+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-12T22:26:11.685+0000] {processor.py:157} INFO - Started process (PID=70758) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:26:11.689+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:26:11.693+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:26:11.693+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:26:11.707+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:26:11.746+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:26:11.746+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:26:11.760+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:26:11.760+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:26:11.771+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-12T22:26:42.025+0000] {processor.py:157} INFO - Started process (PID=70768) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:26:42.030+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:26:42.034+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:26:42.034+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:26:42.047+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:26:42.072+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:26:42.071+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:26:42.085+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:26:42.085+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:26:42.095+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-12T22:27:12.412+0000] {processor.py:157} INFO - Started process (PID=70778) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:27:12.416+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:27:12.419+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:27:12.418+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:27:12.440+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:27:12.481+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:27:12.481+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:27:12.496+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:27:12.496+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:27:12.507+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-12T22:27:42.812+0000] {processor.py:157} INFO - Started process (PID=70787) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:27:42.814+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:27:42.819+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:27:42.818+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:27:42.842+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:27:42.884+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:27:42.884+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:27:42.902+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:27:42.902+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:27:42.914+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-09-12T22:28:13.213+0000] {processor.py:157} INFO - Started process (PID=70797) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:28:13.217+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:28:13.224+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:28:13.223+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:28:13.244+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:28:13.289+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:28:13.289+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:28:13.302+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:28:13.302+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:28:13.312+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-12T22:28:43.543+0000] {processor.py:157} INFO - Started process (PID=70808) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:28:43.547+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:28:43.552+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:28:43.552+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:28:43.587+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:28:43.614+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:28:43.614+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:28:43.628+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:28:43.628+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:28:43.640+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-12T22:29:13.892+0000] {processor.py:157} INFO - Started process (PID=70818) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:29:13.894+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:29:13.905+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:29:13.902+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:29:13.929+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:29:13.960+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:29:13.959+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:29:13.976+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:29:13.976+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:29:13.996+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-12T22:29:44.311+0000] {processor.py:157} INFO - Started process (PID=70827) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:29:44.312+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:29:44.318+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:29:44.317+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:29:44.349+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:29:44.376+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:29:44.376+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:29:44.401+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:29:44.401+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:29:44.411+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-09-12T22:30:14.635+0000] {processor.py:157} INFO - Started process (PID=70838) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:30:14.637+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:30:14.643+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:30:14.642+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:30:14.683+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:30:14.710+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:30:14.710+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:30:14.724+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:30:14.724+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:30:14.736+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-09-12T22:30:45.110+0000] {processor.py:157} INFO - Started process (PID=70848) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:30:45.113+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:30:45.116+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:30:45.116+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:30:45.131+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:30:45.153+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:30:45.153+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:30:45.166+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:30:45.166+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:30:45.174+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-12T22:31:15.401+0000] {processor.py:157} INFO - Started process (PID=70857) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:31:15.405+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:31:15.410+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:31:15.409+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:31:15.441+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:31:15.487+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:31:15.487+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:31:15.504+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:31:15.504+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:31:15.516+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-12T22:31:45.752+0000] {processor.py:157} INFO - Started process (PID=70868) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:31:45.755+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:31:45.759+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:31:45.759+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:31:45.786+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:31:45.813+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:31:45.813+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:31:45.827+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:31:45.827+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:31:45.845+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-12T22:32:16.090+0000] {processor.py:157} INFO - Started process (PID=70878) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:32:16.092+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:32:16.093+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:32:16.093+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:32:16.104+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:32:16.121+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:32:16.121+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:32:16.132+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:32:16.132+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:32:16.141+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-12T22:32:46.410+0000] {processor.py:157} INFO - Started process (PID=70887) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:32:46.412+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:32:46.416+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:32:46.416+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:32:46.436+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:32:46.457+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:32:46.457+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:32:46.470+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:32:46.470+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:32:46.481+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-12T22:33:16.791+0000] {processor.py:157} INFO - Started process (PID=70898) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:33:16.795+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:33:16.796+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:33:16.796+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:33:16.815+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:33:16.841+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:33:16.841+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:33:16.862+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:33:16.862+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:33:16.874+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-12T22:33:47.119+0000] {processor.py:157} INFO - Started process (PID=70908) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:33:47.120+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:33:47.123+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:33:47.123+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:33:47.140+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:33:47.165+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:33:47.165+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:33:47.178+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:33:47.178+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:33:47.192+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-12T22:34:17.441+0000] {processor.py:157} INFO - Started process (PID=70918) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:34:17.444+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:34:17.446+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:34:17.446+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:34:17.458+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:34:17.475+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:34:17.475+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:34:17.485+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:34:17.485+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:34:17.494+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-12T22:34:47.766+0000] {processor.py:157} INFO - Started process (PID=70928) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:34:47.768+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:34:47.771+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:34:47.770+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:34:47.805+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:34:47.838+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:34:47.838+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:34:47.850+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:34:47.850+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:34:47.860+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-12T22:35:18.108+0000] {processor.py:157} INFO - Started process (PID=70938) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:35:18.109+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:35:18.113+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:35:18.112+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:35:18.130+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:35:18.154+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:35:18.154+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:35:18.169+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:35:18.169+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:35:18.180+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-12T22:35:48.486+0000] {processor.py:157} INFO - Started process (PID=70948) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:35:48.488+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:35:48.491+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:35:48.491+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:35:48.507+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:35:48.527+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:35:48.527+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:35:48.540+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:35:48.540+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:35:48.549+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-12T22:36:18.859+0000] {processor.py:157} INFO - Started process (PID=70958) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:36:18.861+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:36:18.864+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:36:18.864+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:36:18.878+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:36:18.898+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:36:18.898+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:36:18.913+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:36:18.913+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:36:18.922+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-12T22:36:49.260+0000] {processor.py:157} INFO - Started process (PID=70968) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:36:49.261+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:36:49.263+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:36:49.263+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:36:49.274+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:36:49.297+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:36:49.297+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:36:49.333+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:36:49.332+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:36:49.344+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-12T22:37:19.637+0000] {processor.py:157} INFO - Started process (PID=70978) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:37:19.638+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:37:19.644+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:37:19.644+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:37:19.659+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:37:19.686+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:37:19.686+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:37:19.708+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:37:19.708+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:37:19.718+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-12T22:37:50.018+0000] {processor.py:157} INFO - Started process (PID=70988) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:37:50.023+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:37:50.027+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:37:50.026+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:37:50.043+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:37:50.075+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:37:50.075+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:37:50.087+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:37:50.087+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:37:50.097+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-12T22:38:20.540+0000] {processor.py:157} INFO - Started process (PID=70998) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:38:20.542+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:38:20.546+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:38:20.546+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:38:20.562+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:38:20.588+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:38:20.588+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:38:20.600+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:38:20.600+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:38:20.610+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-12T22:38:50.899+0000] {processor.py:157} INFO - Started process (PID=71007) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:38:50.901+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:38:50.905+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:38:50.905+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:38:50.925+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:38:50.965+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:38:50.965+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:38:50.979+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:38:50.979+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:38:50.988+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-12T22:39:21.383+0000] {processor.py:157} INFO - Started process (PID=71018) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:39:21.385+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:39:21.392+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:39:21.392+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:39:21.419+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:39:21.445+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:39:21.445+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:39:21.462+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:39:21.462+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:39:21.482+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-12T22:39:51.722+0000] {processor.py:157} INFO - Started process (PID=71028) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:39:51.723+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:39:51.727+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:39:51.727+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:39:51.744+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:39:51.783+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:39:51.783+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:39:51.801+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:39:51.801+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:39:51.811+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-12T22:40:22.098+0000] {processor.py:157} INFO - Started process (PID=71038) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:40:22.103+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:40:22.108+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:40:22.107+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:40:22.122+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:40:22.147+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:40:22.147+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:40:22.161+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:40:22.160+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:40:22.171+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-12T22:40:52.534+0000] {processor.py:157} INFO - Started process (PID=71046) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:40:52.535+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:40:52.540+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:40:52.539+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:40:52.555+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:40:52.576+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:40:52.576+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:40:52.587+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:40:52.587+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:40:52.596+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-12T22:41:22.892+0000] {processor.py:157} INFO - Started process (PID=71058) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:41:22.894+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:41:22.896+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:41:22.896+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:41:22.908+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:41:22.924+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:41:22.924+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:41:22.938+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:41:22.938+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:41:22.947+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-12T22:41:53.337+0000] {processor.py:157} INFO - Started process (PID=71067) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:41:53.338+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:41:53.342+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:41:53.342+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:41:53.356+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:41:53.379+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:41:53.379+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:41:53.392+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:41:53.392+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:41:53.401+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-12T22:42:23.660+0000] {processor.py:157} INFO - Started process (PID=71078) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:42:23.661+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:42:23.663+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:42:23.663+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:42:23.675+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:42:23.690+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:42:23.690+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:42:23.699+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:42:23.699+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:42:23.707+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-12T22:42:54.071+0000] {processor.py:157} INFO - Started process (PID=71088) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:42:54.073+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:42:54.076+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:42:54.076+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:42:54.116+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:42:54.142+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:42:54.142+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:42:54.156+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:42:54.156+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:42:54.166+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-12T22:43:24.413+0000] {processor.py:157} INFO - Started process (PID=71098) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:43:24.414+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:43:24.417+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:43:24.417+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:43:24.434+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:43:24.455+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:43:24.454+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:43:24.468+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:43:24.468+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:43:24.477+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-12T22:43:54.713+0000] {processor.py:157} INFO - Started process (PID=71108) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:43:54.714+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:43:54.715+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:43:54.715+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:43:54.729+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:43:54.743+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:43:54.743+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:43:54.754+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:43:54.754+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:43:54.764+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-12T22:44:25.112+0000] {processor.py:157} INFO - Started process (PID=71118) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:44:25.115+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:44:25.118+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:44:25.117+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:44:25.138+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:44:25.167+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:44:25.167+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:44:25.180+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:44:25.180+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:44:25.189+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-12T22:44:55.503+0000] {processor.py:157} INFO - Started process (PID=71126) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:44:55.505+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:44:55.509+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:44:55.509+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:44:55.537+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:44:55.568+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:44:55.568+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:44:55.581+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:44:55.581+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:44:55.591+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-12T22:45:25.827+0000] {processor.py:157} INFO - Started process (PID=71138) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:45:25.830+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:45:25.847+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:45:25.843+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:45:25.867+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:45:25.892+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:45:25.892+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:45:25.905+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:45:25.905+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:45:25.914+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-12T22:45:56.137+0000] {processor.py:157} INFO - Started process (PID=71148) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:45:56.142+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:45:56.145+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:45:56.144+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:45:56.161+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:45:56.183+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:45:56.183+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:45:56.196+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:45:56.196+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:45:56.207+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-12T22:46:26.550+0000] {processor.py:157} INFO - Started process (PID=71158) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:46:26.552+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:46:26.555+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:46:26.554+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:46:26.574+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:46:26.602+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:46:26.602+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:46:26.617+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:46:26.616+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:46:26.627+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-12T22:46:57.009+0000] {processor.py:157} INFO - Started process (PID=71168) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:46:57.010+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:46:57.013+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:46:57.013+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:46:57.025+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:46:57.041+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:46:57.041+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:46:57.051+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:46:57.051+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:46:57.060+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-12T22:47:27.408+0000] {processor.py:157} INFO - Started process (PID=71178) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:47:27.409+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:47:27.412+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:47:27.412+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:47:27.428+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:47:27.453+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:47:27.453+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:47:27.466+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:47:27.466+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:47:27.480+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-12T22:47:57.712+0000] {processor.py:157} INFO - Started process (PID=71188) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:47:57.713+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:47:57.715+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:47:57.715+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:47:57.725+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:47:57.740+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:47:57.740+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:47:57.750+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:47:57.750+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:47:57.760+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-12T22:48:28.072+0000] {processor.py:157} INFO - Started process (PID=71198) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:48:28.073+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:48:28.078+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:48:28.077+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:48:28.104+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:48:28.141+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:48:28.141+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:48:28.154+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:48:28.154+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:48:28.163+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-12T22:48:58.426+0000] {processor.py:157} INFO - Started process (PID=71208) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:48:58.429+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:48:58.432+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:48:58.432+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:48:58.448+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:48:58.464+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:48:58.464+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:48:58.474+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:48:58.474+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:48:58.485+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-12T22:49:28.870+0000] {processor.py:157} INFO - Started process (PID=71218) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:49:28.875+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:49:28.879+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:49:28.879+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:49:28.902+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:49:28.920+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:49:28.920+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:49:28.942+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:49:28.942+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:49:28.953+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-12T22:49:59.245+0000] {processor.py:157} INFO - Started process (PID=71228) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:49:59.247+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:49:59.250+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:49:59.249+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:49:59.262+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:49:59.285+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:49:59.285+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:49:59.296+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:49:59.295+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:49:59.305+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-12T22:50:29.683+0000] {processor.py:157} INFO - Started process (PID=71238) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:50:29.684+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:50:29.698+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:50:29.693+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:50:29.726+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:50:29.764+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:50:29.764+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:50:29.777+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:50:29.777+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:50:29.788+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-12T22:51:00.108+0000] {processor.py:157} INFO - Started process (PID=71246) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:51:00.110+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:51:00.114+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:51:00.114+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:51:00.133+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:51:00.178+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:51:00.177+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:51:00.191+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:51:00.191+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:51:00.201+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-12T22:51:30.450+0000] {processor.py:157} INFO - Started process (PID=71258) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:51:30.451+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:51:30.462+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:51:30.461+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:51:30.482+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:51:30.525+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:51:30.525+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:51:30.539+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:51:30.539+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:51:30.551+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-12T22:52:00.914+0000] {processor.py:157} INFO - Started process (PID=71267) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:52:00.920+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:52:00.927+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:52:00.926+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:52:00.947+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:52:00.988+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:52:00.987+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:52:01.001+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:52:01.001+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:52:01.011+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-12T22:52:31.173+0000] {processor.py:157} INFO - Started process (PID=71278) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:52:31.175+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:52:31.177+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:52:31.176+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:52:31.188+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:52:31.204+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:52:31.204+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:52:31.214+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:52:31.214+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:52:31.225+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-12T22:53:01.507+0000] {processor.py:157} INFO - Started process (PID=71288) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:53:01.508+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:53:01.513+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:53:01.513+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:53:01.532+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:53:01.569+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:53:01.569+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:53:01.583+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:53:01.583+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:53:01.597+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-12T22:53:31.990+0000] {processor.py:157} INFO - Started process (PID=71298) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:53:32.003+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:53:32.023+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:53:32.022+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:53:32.051+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:53:32.089+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:53:32.089+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:53:32.105+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:53:32.105+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:53:32.123+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.149 seconds
[2024-09-12T22:54:02.462+0000] {processor.py:157} INFO - Started process (PID=71308) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:54:02.467+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:54:02.469+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:54:02.469+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:54:02.493+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:54:02.528+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:54:02.528+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:54:02.542+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:54:02.542+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:54:02.552+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-12T22:54:32.868+0000] {processor.py:157} INFO - Started process (PID=71318) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:54:32.872+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:54:32.879+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:54:32.878+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:54:32.895+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:54:32.930+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:54:32.930+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:54:32.959+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:54:32.958+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:54:32.983+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-12T22:55:03.296+0000] {processor.py:157} INFO - Started process (PID=71328) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:55:03.301+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:55:03.318+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:55:03.318+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:55:03.344+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:55:03.396+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:55:03.396+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:55:03.412+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:55:03.412+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:55:03.424+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-09-12T22:55:33.618+0000] {processor.py:157} INFO - Started process (PID=71337) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:55:33.624+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:55:33.638+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:55:33.637+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:55:33.660+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:55:33.684+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:55:33.684+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:55:33.697+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:55:33.697+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:55:33.707+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-12T22:56:04.000+0000] {processor.py:157} INFO - Started process (PID=71348) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:56:04.001+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:56:04.004+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:56:04.004+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:56:04.022+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:56:04.045+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:56:04.045+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:56:04.060+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:56:04.060+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:56:04.071+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-12T22:56:34.268+0000] {processor.py:157} INFO - Started process (PID=71358) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:56:34.270+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:56:34.271+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:56:34.271+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:56:34.282+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:56:34.298+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:56:34.298+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:56:34.308+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:56:34.308+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:56:34.321+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-12T22:57:04.634+0000] {processor.py:157} INFO - Started process (PID=71367) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:57:04.635+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:57:04.639+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:57:04.639+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:57:04.658+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:57:04.700+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:57:04.700+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:57:04.714+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:57:04.714+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:57:04.724+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-12T22:57:34.944+0000] {processor.py:157} INFO - Started process (PID=71378) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:57:34.945+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:57:34.947+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:57:34.947+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:57:34.961+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:57:34.976+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:57:34.976+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:57:34.988+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:57:34.988+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:57:34.997+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-12T22:58:05.310+0000] {processor.py:157} INFO - Started process (PID=71388) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:58:05.312+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:58:05.315+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:58:05.315+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:58:05.355+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:58:05.382+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:58:05.381+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:58:05.394+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:58:05.394+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:58:05.406+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-12T22:58:35.729+0000] {processor.py:157} INFO - Started process (PID=71397) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:58:35.732+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:58:35.739+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:58:35.739+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:58:35.761+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:58:35.790+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:58:35.789+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:58:35.823+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:58:35.823+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:58:35.833+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-12T22:59:06.131+0000] {processor.py:157} INFO - Started process (PID=71408) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:59:06.132+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:59:06.138+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:59:06.138+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:59:06.159+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:59:06.198+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:59:06.197+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:59:06.214+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:59:06.214+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:59:06.224+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-12T22:59:36.457+0000] {processor.py:157} INFO - Started process (PID=71418) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:59:36.462+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T22:59:36.469+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:59:36.468+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:59:36.494+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T22:59:36.529+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:59:36.528+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T22:59:36.545+0000] {logging_mixin.py:151} INFO - [2024-09-12T22:59:36.545+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T22:59:36.556+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-09-12T23:00:06.782+0000] {processor.py:157} INFO - Started process (PID=71428) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:00:06.784+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T23:00:06.791+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:00:06.790+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:00:06.810+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:00:06.838+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:00:06.838+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T23:00:06.872+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:00:06.872+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T23:00:06.883+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-12T23:00:37.241+0000] {processor.py:157} INFO - Started process (PID=71438) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:00:37.242+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T23:00:37.248+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:00:37.247+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:00:37.268+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:00:37.295+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:00:37.295+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T23:00:37.315+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:00:37.314+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T23:00:37.326+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-12T23:01:26.023+0000] {processor.py:157} INFO - Started process (PID=71449) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:01:26.025+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T23:01:26.030+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:01:26.030+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:01:26.042+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:01:26.062+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:01:26.062+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T23:01:26.074+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:01:26.074+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T23:01:26.085+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-12T23:18:11.768+0000] {processor.py:157} INFO - Started process (PID=71458) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:18:11.769+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T23:18:11.778+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:18:11.776+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:18:11.856+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:18:11.995+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:18:11.995+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T23:18:12.045+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:18:12.045+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T23:18:12.083+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.337 seconds
[2024-09-12T23:18:42.470+0000] {processor.py:157} INFO - Started process (PID=71470) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:18:42.471+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T23:18:42.475+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:18:42.474+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:18:42.491+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:18:42.522+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:18:42.522+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T23:18:42.542+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:18:42.542+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T23:18:42.557+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-12T23:19:12.860+0000] {processor.py:157} INFO - Started process (PID=71480) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:19:12.862+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T23:19:12.864+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:19:12.864+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:19:12.874+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:19:12.895+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:19:12.895+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T23:19:12.909+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:19:12.909+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T23:19:12.919+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-12T23:19:43.279+0000] {processor.py:157} INFO - Started process (PID=71488) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:19:43.281+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T23:19:43.284+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:19:43.284+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:19:43.315+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:19:43.353+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:19:43.353+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T23:19:43.371+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:19:43.371+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T23:19:43.381+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-09-12T23:20:13.705+0000] {processor.py:157} INFO - Started process (PID=71500) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:20:13.706+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T23:20:13.709+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:20:13.709+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:20:13.726+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:20:13.753+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:20:13.753+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T23:20:13.768+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:20:13.768+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T23:20:13.784+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-12T23:20:44.197+0000] {processor.py:157} INFO - Started process (PID=71510) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:20:44.197+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T23:20:44.200+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:20:44.200+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:20:44.214+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:20:44.236+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:20:44.236+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T23:20:44.251+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:20:44.251+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T23:20:44.260+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-12T23:21:14.603+0000] {processor.py:157} INFO - Started process (PID=71520) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:21:14.604+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T23:21:14.605+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:21:14.605+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:21:14.620+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:21:14.642+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:21:14.642+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T23:21:14.651+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:21:14.651+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T23:21:14.661+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-12T23:21:45.097+0000] {processor.py:157} INFO - Started process (PID=71530) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:21:45.099+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T23:21:45.101+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:21:45.100+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:21:45.110+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:21:45.134+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:21:45.134+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T23:21:45.145+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:21:45.145+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T23:21:45.155+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-12T23:22:15.575+0000] {processor.py:157} INFO - Started process (PID=71539) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:22:15.576+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T23:22:15.579+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:22:15.579+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:22:15.594+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:22:15.618+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:22:15.618+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T23:22:15.632+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:22:15.631+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T23:22:15.643+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-12T23:22:46.041+0000] {processor.py:157} INFO - Started process (PID=71550) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:22:46.042+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T23:22:46.045+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:22:46.045+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:22:46.060+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:22:46.088+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:22:46.088+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T23:22:46.103+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:22:46.103+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T23:22:46.113+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-12T23:23:16.508+0000] {processor.py:157} INFO - Started process (PID=71560) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:23:16.509+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T23:23:16.511+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:23:16.511+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:23:16.521+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:23:16.537+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:23:16.537+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T23:23:16.548+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:23:16.548+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T23:23:16.558+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-12T23:23:46.910+0000] {processor.py:157} INFO - Started process (PID=71570) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:23:46.910+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T23:23:46.915+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:23:46.915+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:23:46.948+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:23:46.978+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:23:46.978+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T23:23:46.996+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:23:46.996+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T23:23:47.008+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-12T23:24:17.311+0000] {processor.py:157} INFO - Started process (PID=71580) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:24:17.313+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T23:24:17.316+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:24:17.316+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:24:17.330+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:24:17.354+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:24:17.354+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T23:24:17.370+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:24:17.369+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T23:24:17.380+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-12T23:24:47.787+0000] {processor.py:157} INFO - Started process (PID=71590) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:24:47.788+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T23:24:47.791+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:24:47.790+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:24:47.800+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:24:47.818+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:24:47.818+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T23:24:47.830+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:24:47.830+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T23:24:47.841+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-12T23:25:18.267+0000] {processor.py:157} INFO - Started process (PID=71600) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:25:18.268+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T23:25:18.272+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:25:18.271+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:25:18.289+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:25:18.316+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:25:18.316+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T23:25:18.330+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:25:18.329+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T23:25:18.340+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-12T23:25:48.662+0000] {processor.py:157} INFO - Started process (PID=71610) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:25:48.663+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T23:25:48.666+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:25:48.665+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:25:48.679+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:25:48.702+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:25:48.702+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T23:25:48.713+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:25:48.713+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T23:25:48.724+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-12T23:26:19.007+0000] {processor.py:157} INFO - Started process (PID=71620) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:26:19.008+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T23:26:19.009+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:26:19.009+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:26:19.025+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:26:19.038+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:26:19.038+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T23:26:19.050+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:26:19.050+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T23:26:19.060+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-12T23:26:49.441+0000] {processor.py:157} INFO - Started process (PID=71630) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:26:49.443+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T23:26:49.446+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:26:49.445+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:26:49.477+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:26:49.504+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:26:49.504+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T23:26:49.518+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:26:49.518+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T23:26:49.528+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-12T23:27:19.845+0000] {processor.py:157} INFO - Started process (PID=71640) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:27:19.846+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T23:27:19.848+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:27:19.847+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:27:19.858+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:27:19.874+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:27:19.874+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T23:27:19.884+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:27:19.884+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T23:27:19.894+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-12T23:27:50.154+0000] {processor.py:157} INFO - Started process (PID=71650) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:27:50.155+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T23:27:50.157+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:27:50.157+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:27:50.170+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:27:50.188+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:27:50.188+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T23:27:50.200+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:27:50.200+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T23:27:50.208+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-12T23:28:20.589+0000] {processor.py:157} INFO - Started process (PID=71660) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:28:20.592+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T23:28:20.595+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:28:20.594+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:28:20.609+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:28:20.630+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:28:20.630+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T23:28:20.647+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:28:20.647+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T23:28:20.657+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-12T23:28:51.024+0000] {processor.py:157} INFO - Started process (PID=71670) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:28:51.025+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T23:28:51.027+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:28:51.027+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:28:51.037+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:28:51.054+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:28:51.054+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T23:28:51.064+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:28:51.064+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T23:28:51.074+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-12T23:29:21.463+0000] {processor.py:157} INFO - Started process (PID=71680) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:29:21.465+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T23:29:21.468+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:29:21.468+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:29:21.483+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:29:21.506+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:29:21.505+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T23:29:21.518+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:29:21.518+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T23:29:21.527+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-12T23:29:51.828+0000] {processor.py:157} INFO - Started process (PID=71690) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:29:51.829+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T23:29:51.830+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:29:51.830+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:29:51.839+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:29:51.854+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:29:51.854+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T23:29:51.863+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:29:51.863+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T23:29:51.872+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-09-12T23:30:22.067+0000] {processor.py:157} INFO - Started process (PID=71699) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:30:22.068+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T23:30:22.072+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:30:22.071+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:30:22.085+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:30:22.105+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:30:22.105+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T23:30:22.116+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:30:22.116+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T23:30:22.127+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-12T23:30:52.453+0000] {processor.py:157} INFO - Started process (PID=71710) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:30:52.454+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T23:30:52.456+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:30:52.455+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:30:52.472+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:30:52.487+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:30:52.487+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T23:30:52.498+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:30:52.497+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T23:30:52.505+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-12T23:31:22.929+0000] {processor.py:157} INFO - Started process (PID=71720) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:31:22.930+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T23:31:22.931+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:31:22.931+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:31:22.944+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:31:22.961+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:31:22.961+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T23:31:22.972+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:31:22.972+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T23:31:22.981+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-12T23:31:53.365+0000] {processor.py:157} INFO - Started process (PID=71730) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:31:53.367+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T23:31:53.369+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:31:53.369+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:31:53.379+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:31:53.395+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:31:53.395+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T23:31:53.405+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:31:53.405+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T23:31:53.413+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-12T23:32:23.816+0000] {processor.py:157} INFO - Started process (PID=71738) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:32:23.818+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T23:32:23.822+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:32:23.821+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:32:23.838+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:32:23.860+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:32:23.860+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T23:32:23.873+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:32:23.873+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T23:32:23.883+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-12T23:32:54.140+0000] {processor.py:157} INFO - Started process (PID=71750) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:32:54.140+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T23:32:54.142+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:32:54.142+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:32:54.158+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:32:54.171+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:32:54.171+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T23:32:54.181+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:32:54.181+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T23:32:54.189+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-12T23:33:24.522+0000] {processor.py:157} INFO - Started process (PID=71760) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:33:24.525+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T23:33:24.533+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:33:24.533+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:33:24.548+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:33:24.573+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:33:24.573+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T23:33:24.585+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:33:24.585+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T23:33:24.594+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-12T23:33:54.979+0000] {processor.py:157} INFO - Started process (PID=71770) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:33:54.981+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T23:33:54.986+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:33:54.986+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:33:54.999+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:33:55.017+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:33:55.017+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T23:33:55.029+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:33:55.028+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T23:33:55.038+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-12T23:34:25.306+0000] {processor.py:157} INFO - Started process (PID=71780) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:34:25.309+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T23:34:25.311+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:34:25.310+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:34:25.325+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:34:25.345+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:34:25.345+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T23:34:25.357+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:34:25.357+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T23:34:25.365+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-12T23:34:55.673+0000] {processor.py:157} INFO - Started process (PID=71790) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:34:55.674+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T23:34:55.675+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:34:55.675+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:34:55.685+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:34:55.701+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:34:55.700+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T23:34:55.711+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:34:55.711+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T23:34:55.722+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-12T23:35:26.034+0000] {processor.py:157} INFO - Started process (PID=71800) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:35:26.035+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T23:35:26.037+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:35:26.036+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:35:26.048+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:35:26.070+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:35:26.069+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T23:35:26.079+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:35:26.079+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T23:35:26.089+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-12T23:35:56.439+0000] {processor.py:157} INFO - Started process (PID=71810) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:35:56.442+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T23:35:56.444+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:35:56.444+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:35:56.461+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:35:56.483+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:35:56.483+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T23:35:56.495+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:35:56.495+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T23:35:56.504+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-12T23:36:26.878+0000] {processor.py:157} INFO - Started process (PID=71820) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:36:26.880+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T23:36:26.881+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:36:26.881+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:36:26.896+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:36:26.908+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:36:26.908+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T23:36:26.921+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:36:26.921+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T23:36:26.932+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-12T23:36:57.333+0000] {processor.py:157} INFO - Started process (PID=71830) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:36:57.334+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T23:36:57.335+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:36:57.335+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:36:57.351+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:36:57.365+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:36:57.365+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T23:36:57.381+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:36:57.380+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T23:36:57.389+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-12T23:37:27.785+0000] {processor.py:157} INFO - Started process (PID=71840) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:37:27.787+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T23:37:27.789+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:37:27.789+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:37:27.807+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:37:27.844+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:37:27.844+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T23:37:27.856+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:37:27.856+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T23:37:27.866+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-12T23:37:58.208+0000] {processor.py:157} INFO - Started process (PID=71850) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:37:58.209+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T23:37:58.211+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:37:58.211+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:37:58.221+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:37:58.238+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:37:58.238+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T23:37:58.248+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:37:58.248+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T23:37:58.257+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-12T23:38:28.557+0000] {processor.py:157} INFO - Started process (PID=71860) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:38:28.558+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T23:38:28.560+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:38:28.560+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:38:28.575+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:38:28.596+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:38:28.596+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T23:38:28.608+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:38:28.608+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T23:38:28.616+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-12T23:38:59.071+0000] {processor.py:157} INFO - Started process (PID=71870) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:38:59.072+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T23:38:59.074+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:38:59.074+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:38:59.114+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:38:59.134+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:38:59.134+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T23:38:59.146+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:38:59.145+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T23:38:59.156+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-12T23:39:29.508+0000] {processor.py:157} INFO - Started process (PID=71880) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:39:29.510+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T23:39:29.514+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:39:29.514+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:39:29.530+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:39:29.564+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:39:29.564+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T23:39:29.580+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:39:29.580+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T23:39:29.592+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-12T23:39:59.870+0000] {processor.py:157} INFO - Started process (PID=71890) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:39:59.871+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T23:39:59.873+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:39:59.873+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:39:59.882+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:39:59.899+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:39:59.899+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T23:39:59.909+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:39:59.909+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T23:39:59.920+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-12T23:40:30.407+0000] {processor.py:157} INFO - Started process (PID=71900) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:40:30.409+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T23:40:30.411+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:40:30.411+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:40:30.421+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:40:30.444+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:40:30.444+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T23:40:30.457+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:40:30.456+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T23:40:30.467+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-12T23:41:00.701+0000] {processor.py:157} INFO - Started process (PID=71910) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:41:00.705+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T23:41:00.708+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:41:00.708+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:41:00.722+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:41:00.742+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:41:00.742+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T23:41:00.752+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:41:00.752+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T23:41:00.761+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-12T23:41:31.059+0000] {processor.py:157} INFO - Started process (PID=71920) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:41:31.060+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T23:41:31.062+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:41:31.062+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:41:31.073+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:41:31.089+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:41:31.089+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T23:41:31.101+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:41:31.101+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T23:41:31.108+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-12T23:42:01.439+0000] {processor.py:157} INFO - Started process (PID=71930) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:42:01.440+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T23:42:01.442+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:42:01.442+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:42:01.453+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:42:01.472+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:42:01.472+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T23:42:01.484+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:42:01.484+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T23:42:01.494+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-12T23:42:31.837+0000] {processor.py:157} INFO - Started process (PID=71940) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:42:31.838+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T23:42:31.840+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:42:31.839+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:42:31.851+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:42:31.868+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:42:31.868+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T23:42:31.883+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:42:31.883+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T23:42:31.891+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-12T23:43:02.230+0000] {processor.py:157} INFO - Started process (PID=71950) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:43:02.233+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T23:43:02.239+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:43:02.237+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:43:02.272+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:43:02.288+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:43:02.288+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T23:43:02.299+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:43:02.299+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T23:43:02.307+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-12T23:43:32.623+0000] {processor.py:157} INFO - Started process (PID=71960) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:43:32.623+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T23:43:32.625+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:43:32.625+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:43:32.636+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:43:32.657+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:43:32.657+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T23:43:32.669+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:43:32.669+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T23:43:32.679+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-12T23:44:03.037+0000] {processor.py:157} INFO - Started process (PID=71970) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:44:03.040+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T23:44:03.043+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:44:03.043+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:44:03.059+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:44:03.076+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:44:03.076+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T23:44:03.088+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:44:03.088+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T23:44:03.096+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-12T23:44:33.572+0000] {processor.py:157} INFO - Started process (PID=71979) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:44:33.572+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T23:44:33.574+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:44:33.574+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:44:33.583+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:44:33.617+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:44:33.617+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T23:44:33.630+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:44:33.630+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T23:44:33.640+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-12T23:45:03.908+0000] {processor.py:157} INFO - Started process (PID=71990) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:45:03.909+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T23:45:03.913+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:45:03.913+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:45:03.929+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:45:03.948+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:45:03.948+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T23:45:03.958+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:45:03.958+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T23:45:03.969+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-12T23:45:34.291+0000] {processor.py:157} INFO - Started process (PID=72000) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:45:34.294+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T23:45:34.295+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:45:34.295+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:45:34.305+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:45:34.326+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:45:34.326+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T23:45:34.338+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:45:34.338+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T23:45:34.347+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-12T23:46:04.666+0000] {processor.py:157} INFO - Started process (PID=72010) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:46:04.668+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T23:46:04.678+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:46:04.677+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:46:04.695+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:46:04.712+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:46:04.712+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T23:46:04.723+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:46:04.723+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T23:46:04.732+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-12T23:46:34.981+0000] {processor.py:157} INFO - Started process (PID=72020) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:46:34.982+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T23:46:34.983+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:46:34.983+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:46:35.002+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:46:35.020+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:46:35.019+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T23:46:35.031+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:46:35.030+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T23:46:35.040+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-12T23:47:05.391+0000] {processor.py:157} INFO - Started process (PID=72030) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:47:05.394+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T23:47:05.396+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:47:05.396+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:47:05.411+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:47:05.429+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:47:05.429+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T23:47:05.440+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:47:05.440+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T23:47:05.449+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-12T23:47:35.754+0000] {processor.py:157} INFO - Started process (PID=72040) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:47:35.755+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T23:47:35.757+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:47:35.757+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:47:35.768+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:47:35.784+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:47:35.784+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T23:47:35.796+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:47:35.796+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T23:47:35.807+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-12T23:48:06.220+0000] {processor.py:157} INFO - Started process (PID=72048) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:48:06.221+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T23:48:06.225+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:48:06.224+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:48:06.238+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:48:06.263+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:48:06.262+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T23:48:06.280+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:48:06.280+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T23:48:06.292+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-12T23:48:36.785+0000] {processor.py:157} INFO - Started process (PID=72060) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:48:36.786+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T23:48:36.791+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:48:36.791+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:48:36.809+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:48:36.844+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:48:36.844+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T23:48:36.859+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:48:36.859+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T23:48:36.870+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-12T23:49:07.086+0000] {processor.py:157} INFO - Started process (PID=72069) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:49:07.088+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T23:49:07.092+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:49:07.092+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:49:07.106+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:49:07.134+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:49:07.133+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T23:49:07.147+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:49:07.147+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T23:49:07.161+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-12T23:49:37.395+0000] {processor.py:157} INFO - Started process (PID=72080) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:49:37.396+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T23:49:37.398+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:49:37.398+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:49:37.408+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:49:37.425+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:49:37.425+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T23:49:37.435+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:49:37.435+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T23:49:37.444+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-12T23:50:07.785+0000] {processor.py:157} INFO - Started process (PID=72090) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:50:07.788+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T23:50:07.790+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:50:07.789+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:50:07.799+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:50:07.816+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:50:07.816+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T23:50:07.825+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:50:07.825+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T23:50:07.836+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-12T23:50:38.094+0000] {processor.py:157} INFO - Started process (PID=72100) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:50:38.095+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T23:50:38.097+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:50:38.097+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:50:38.107+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:50:38.123+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:50:38.123+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T23:50:38.133+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:50:38.133+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T23:50:38.142+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-12T23:51:08.480+0000] {processor.py:157} INFO - Started process (PID=72110) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:51:08.487+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T23:51:08.490+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:51:08.490+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:51:08.499+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:51:08.512+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:51:08.512+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T23:51:08.522+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:51:08.522+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T23:51:08.531+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-12T23:51:38.895+0000] {processor.py:157} INFO - Started process (PID=72120) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:51:38.896+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T23:51:38.900+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:51:38.900+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:51:38.921+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:51:38.948+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:51:38.947+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T23:51:38.962+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:51:38.962+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T23:51:38.973+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-12T23:52:09.155+0000] {processor.py:157} INFO - Started process (PID=72130) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:52:09.157+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T23:52:09.159+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:52:09.159+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:52:09.172+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:52:09.186+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:52:09.186+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T23:52:09.197+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:52:09.197+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T23:52:09.207+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-12T23:52:39.528+0000] {processor.py:157} INFO - Started process (PID=72140) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:52:39.528+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T23:52:39.531+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:52:39.531+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:52:39.541+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:52:39.558+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:52:39.558+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T23:52:39.568+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:52:39.567+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T23:52:39.577+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-12T23:53:09.954+0000] {processor.py:157} INFO - Started process (PID=72150) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:53:09.957+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T23:53:09.959+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:53:09.959+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:53:09.974+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:53:09.995+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:53:09.995+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T23:53:10.008+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:53:10.008+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T23:53:10.017+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-12T23:53:40.241+0000] {processor.py:157} INFO - Started process (PID=72160) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:53:40.242+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T23:53:40.244+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:53:40.244+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:53:40.254+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:53:40.269+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:53:40.269+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T23:53:40.279+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:53:40.279+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T23:53:40.287+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-09-12T23:54:10.617+0000] {processor.py:157} INFO - Started process (PID=72170) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:54:10.617+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T23:54:10.619+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:54:10.619+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:54:10.629+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:54:10.646+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:54:10.645+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T23:54:10.658+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:54:10.658+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T23:54:10.666+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-12T23:54:41.074+0000] {processor.py:157} INFO - Started process (PID=72180) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:54:41.075+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T23:54:41.075+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:54:41.075+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:54:41.085+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:54:41.097+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:54:41.097+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T23:54:41.109+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:54:41.108+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T23:54:41.118+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-09-12T23:55:11.523+0000] {processor.py:157} INFO - Started process (PID=72190) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:55:11.524+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T23:55:11.526+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:55:11.526+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:55:11.538+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:55:11.553+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:55:11.553+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T23:55:11.563+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:55:11.563+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T23:55:11.571+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-12T23:55:41.956+0000] {processor.py:157} INFO - Started process (PID=72200) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:55:41.959+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T23:55:41.961+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:55:41.961+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:55:41.977+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:55:42.006+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:55:42.006+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T23:55:42.026+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:55:42.026+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T23:55:42.039+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-12T23:56:12.354+0000] {processor.py:157} INFO - Started process (PID=72210) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:56:12.355+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T23:56:12.356+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:56:12.356+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:56:12.371+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:56:12.388+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:56:12.388+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T23:56:12.399+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:56:12.399+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T23:56:12.410+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-12T23:56:42.821+0000] {processor.py:157} INFO - Started process (PID=72220) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:56:42.821+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T23:56:42.824+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:56:42.823+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:56:42.840+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:56:42.865+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:56:42.865+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T23:56:42.881+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:56:42.880+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T23:56:42.892+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-12T23:57:13.264+0000] {processor.py:157} INFO - Started process (PID=72230) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:57:13.271+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T23:57:13.274+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:57:13.273+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:57:13.294+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:57:13.317+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:57:13.317+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T23:57:13.330+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:57:13.330+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T23:57:13.340+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-12T23:57:43.688+0000] {processor.py:157} INFO - Started process (PID=72240) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:57:43.689+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T23:57:43.691+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:57:43.691+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:57:43.702+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:57:43.718+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:57:43.718+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T23:57:43.728+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:57:43.728+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T23:57:43.739+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-12T23:58:14.112+0000] {processor.py:157} INFO - Started process (PID=72250) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:58:14.116+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T23:58:14.119+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:58:14.118+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:58:14.133+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:58:14.155+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:58:14.155+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T23:58:14.170+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:58:14.170+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T23:58:14.182+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-12T23:58:44.409+0000] {processor.py:157} INFO - Started process (PID=72260) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:58:44.412+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T23:58:44.414+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:58:44.414+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:58:44.423+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:58:44.440+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:58:44.439+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T23:58:44.451+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:58:44.451+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T23:58:44.466+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-12T23:59:14.855+0000] {processor.py:157} INFO - Started process (PID=72270) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:59:14.857+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T23:59:14.879+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:59:14.876+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:59:14.902+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:59:14.929+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:59:14.929+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T23:59:14.943+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:59:14.943+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T23:59:14.956+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-12T23:59:45.234+0000] {processor.py:157} INFO - Started process (PID=72280) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:59:45.236+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-12T23:59:45.238+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:59:45.238+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:59:45.250+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-12T23:59:45.268+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:59:45.268+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-12T23:59:45.279+0000] {logging_mixin.py:151} INFO - [2024-09-12T23:59:45.279+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-12T23:59:45.288+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
